{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from ./mbti-model/unsloth.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama3 Inst\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  14:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 128255\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Llama3 Inst\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: PAD token        = 128255 '<|reserved_special_token_250|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4403.49 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    10.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128255', 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Llama3 Inst', 'general.type': 'model', 'general.size_label': '8.0B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "model_path='./mbti-model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = Llama(\n",
    "    model_path='./mbti-model/unsloth.Q4_K_M.gguf', #다운로드받은 모델의 위치\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=33        # Number of model layers to offload to GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'esfj',\n",
       " 'enfj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'esfp',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'esfp',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'estp',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'estp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'esfj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'esfj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'estp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'entp',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'esfp',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'esfj',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'esfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'esfj',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'esfp',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'enfj',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'esfp',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'esfj',\n",
       " 'esfj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'esfp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'esfp',\n",
       " 'entp',\n",
       " 'estp',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'esfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'esfj',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'istj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'esfp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'esfj',\n",
       " 'entp',\n",
       " 'esfj',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'isfj',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'esfj',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'esfp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'esfj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'esfp',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'estp',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'esfj',\n",
       " 'esfj',\n",
       " 'entp',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'entp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'estj',\n",
       " 'estp',\n",
       " 'esfj',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'esfp',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'estp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'esfj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'estp',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'esfj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'esfj',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'esfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'esfp',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'entp',\n",
       " 'enfj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'esfp',\n",
       " 'estp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'esfj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'estp',\n",
       " 'enfj',\n",
       " 'estj',\n",
       " 'estp',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'esfj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'esfj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'esfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'esfj',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'estp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'estp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'estp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./mbti_datasets_1.csv', encoding='UTF-8')\n",
    "\n",
    "sampled_df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "texts = list(sampled_df['text'])\n",
    "mbtis = list(sampled_df['mbti'])\n",
    "\n",
    "mbtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.22 ms /   141 tokens (    0.70 ms per token,  1421.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.86 ms /     2 runs   (   16.93 ms per token,    59.06 tokens per second)\n",
      "llama_print_timings:       total time =     135.22 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    64 tokens (    0.69 ms per token,  1450.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.18 ms /    99 tokens (    0.64 ms per token,  1567.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.43 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      97.68 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      90.76 ms /   131 tokens (    0.69 ms per token,  1443.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     124.78 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.86 ms /   123 tokens (    0.58 ms per token,  1711.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     106.01 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.27 ms /    86 tokens (    0.65 ms per token,  1528.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.38 ms /     2 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =      90.23 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.04 ms /    85 tokens (    0.66 ms per token,  1516.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.10 ms /     3 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     107.25 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.00 ms /   106 tokens (    0.60 ms per token,  1656.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.42 ms /     2 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =      98.38 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    64 tokens (    0.67 ms per token,  1482.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      76.83 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.16 ms /   143 tokens (    0.65 ms per token,  1534.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     127.63 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   106 tokens (    0.61 ms per token,  1640.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =      98.49 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.66 ms /    68 tokens (    0.72 ms per token,  1397.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      82.59 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.58 ms /    95 tokens (    0.61 ms per token,  1649.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =      91.84 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    94 tokens (    0.61 ms per token,  1638.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =      91.22 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.47 ms /    85 tokens (    0.66 ms per token,  1505.17 tokens per second)\n",
      "llama_print_timings:        eval time =      50.10 ms /     3 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     108.33 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    79 tokens (    0.63 ms per token,  1588.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.97 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.09 ms /    85 tokens (    0.66 ms per token,  1515.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =      90.77 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.80 ms /   104 tokens (    0.61 ms per token,  1629.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =      98.11 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.05 ms /   123 tokens (    0.59 ms per token,  1707.12 tokens per second)\n",
      "llama_print_timings:        eval time =      50.21 ms /     3 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =     123.76 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     121.58 ms /   202 tokens (    0.60 ms per token,  1661.48 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     173.62 ms /   205 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.98 ms /    70 tokens (    0.70 ms per token,  1429.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      82.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.73 ms /   126 tokens (    0.58 ms per token,  1732.46 tokens per second)\n",
      "llama_print_timings:        eval time =      50.24 ms /     3 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     124.61 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.37 ms /   100 tokens (    0.63 ms per token,  1578.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      97.75 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.64 ms /    70 tokens (    0.69 ms per token,  1439.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      99.86 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.02 ms /    83 tokens (    0.67 ms per token,  1481.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =      90.20 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.39 ms /   118 tokens (    0.60 ms per token,  1653.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =     105.79 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.86 ms /    90 tokens (    0.63 ms per token,  1582.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =      90.84 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    75 tokens (    0.66 ms per token,  1517.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      83.41 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.21 ms /    73 tokens (    0.67 ms per token,  1483.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      83.04 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.11 ms /   120 tokens (    0.60 ms per token,  1664.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =     106.66 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      55.95 ms /    82 tokens (    0.68 ms per token,  1465.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.38 ms /     2 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =      90.71 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.20 ms /   105 tokens (    0.61 ms per token,  1635.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.42 ms /     2 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =      98.17 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.25 ms /    55 tokens (    0.77 ms per token,  1301.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      76.24 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.53 ms /    58 tokens (    0.73 ms per token,  1363.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      76.42 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      62.90 ms /    97 tokens (    0.65 ms per token,  1542.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.43 ms /     2 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =      96.96 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.76 ms /    89 tokens (    0.64 ms per token,  1567.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =      91.43 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.16 ms /    74 tokens (    0.66 ms per token,  1505.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      83.13 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    93 tokens (    0.62 ms per token,  1616.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =      92.01 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    75 tokens (    0.66 ms per token,  1522.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      82.84 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.67 ms /   160 tokens (    0.60 ms per token,  1672.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     130.17 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    77 tokens (    0.65 ms per token,  1549.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.16 ms /    90 tokens (    0.64 ms per token,  1574.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.12 ms /    97 tokens (    0.65 ms per token,  1536.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      97.97 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.38 ms /    73 tokens (    0.68 ms per token,  1478.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      83.04 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      91.79 ms /   132 tokens (    0.70 ms per token,  1438.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     125.76 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.28 ms /   239 tokens (    0.59 ms per token,  1703.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     174.02 ms /   241 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.17 ms /   132 tokens (    0.70 ms per token,  1432.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     126.93 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.13 ms /    96 tokens (    0.61 ms per token,  1651.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      92.73 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.56 ms /    85 tokens (    0.67 ms per token,  1502.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      90.81 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.10 ms /   146 tokens (    0.64 ms per token,  1551.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     128.77 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.68 ms /   150 tokens (    0.63 ms per token,  1584.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     128.83 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.19 ms /    82 tokens (    0.69 ms per token,  1459.26 tokens per second)\n",
      "llama_print_timings:        eval time =      50.22 ms /     3 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     107.34 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.95 ms /    88 tokens (    0.65 ms per token,  1545.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =      91.39 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.75 ms /   101 tokens (    0.63 ms per token,  1584.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      97.83 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.77 ms /   107 tokens (    0.61 ms per token,  1651.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.16 ms /     3 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     115.75 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    77 tokens (    0.65 ms per token,  1538.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    80 tokens (    0.64 ms per token,  1565.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      85.49 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.58 ms /    56 tokens (    0.76 ms per token,  1315.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      75.88 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.33 ms /    71 tokens (    0.69 ms per token,  1439.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =     100.34 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.17 ms /   113 tokens (    0.63 ms per token,  1587.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     105.13 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.60 ms /   179 tokens (    0.61 ms per token,  1648.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     143.16 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.36 ms /   116 tokens (    0.62 ms per token,  1625.47 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     122.68 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.23 ms /   142 tokens (    0.66 ms per token,  1523.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     128.01 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    93 tokens (    0.62 ms per token,  1615.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =      91.92 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.59 ms /   116 tokens (    0.62 ms per token,  1620.22 tokens per second)\n",
      "llama_print_timings:        eval time =      50.27 ms /     3 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     123.63 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.01 ms /   102 tokens (    0.63 ms per token,  1593.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      97.88 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.98 ms /   168 tokens (    0.64 ms per token,  1570.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     141.10 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    60 tokens (    0.72 ms per token,  1398.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      76.43 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.39 ms /    98 tokens (    0.65 ms per token,  1545.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      97.47 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.75 ms /   118 tokens (    0.61 ms per token,  1644.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     106.39 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    92 tokens (    0.63 ms per token,  1596.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      91.94 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.07 ms /    97 tokens (    0.65 ms per token,  1538.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      97.66 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.99 ms /   103 tokens (    0.62 ms per token,  1609.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      97.97 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.86 ms /    59 tokens (    0.73 ms per token,  1376.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      76.37 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    90 tokens (    0.64 ms per token,  1572.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      91.19 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.65 ms /    66 tokens (    0.74 ms per token,  1356.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      82.55 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.72 ms /   138 tokens (    0.67 ms per token,  1488.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     126.73 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.32 ms /   104 tokens (    0.62 ms per token,  1616.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      98.30 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    77 tokens (    0.65 ms per token,  1534.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      84.35 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    73 tokens (    0.68 ms per token,  1471.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      83.23 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.53 ms /    66 tokens (    0.74 ms per token,  1359.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      82.55 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.22 ms /    43 tokens (    0.84 ms per token,  1187.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      87.17 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.82 ms /    94 tokens (    0.62 ms per token,  1625.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.18 ms /     3 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =     109.55 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    62 tokens (    0.70 ms per token,  1425.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      76.90 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.08 ms /   109 tokens (    0.60 ms per token,  1674.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =      99.67 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.35 ms /   104 tokens (    0.62 ms per token,  1616.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      98.80 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.29 ms /   104 tokens (    0.62 ms per token,  1617.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      98.69 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.47 ms /    83 tokens (    0.68 ms per token,  1469.89 tokens per second)\n",
      "llama_print_timings:        eval time =      50.20 ms /     3 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     107.70 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.40 ms /    73 tokens (    0.68 ms per token,  1477.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      83.30 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.49 ms /   111 tokens (    0.59 ms per token,  1694.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      99.56 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.63 ms /   121 tokens (    0.60 ms per token,  1665.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     107.45 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.61 ms /    73 tokens (    0.68 ms per token,  1471.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.93 ms /   123 tokens (    0.59 ms per token,  1686.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     106.84 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.28 ms /   163 tokens (    0.65 ms per token,  1533.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     140.94 ms /   165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.10 ms /    96 tokens (    0.61 ms per token,  1652.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =      92.66 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    92 tokens (    0.63 ms per token,  1598.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      91.94 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.17 ms /    88 tokens (    0.65 ms per token,  1539.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.83 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   106 tokens (    0.61 ms per token,  1640.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     115.96 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      91.80 ms /   131 tokens (    0.70 ms per token,  1427.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     126.28 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.81 ms /    67 tokens (    0.73 ms per token,  1372.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      82.81 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.85 ms /    85 tokens (    0.67 ms per token,  1495.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      91.17 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.56 ms /    99 tokens (    0.64 ms per token,  1557.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =      97.73 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.48 ms /    72 tokens (    0.69 ms per token,  1455.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.18 ms /    96 tokens (    0.61 ms per token,  1649.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      92.88 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.48 ms /    84 tokens (    0.67 ms per token,  1487.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.20 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.80 ms /    87 tokens (    0.65 ms per token,  1531.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.43 ms /     2 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =      90.89 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.34 ms /   176 tokens (    0.62 ms per token,  1624.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     143.31 ms /   178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.12 ms /   141 tokens (    0.66 ms per token,  1514.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     127.99 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    79 tokens (    0.64 ms per token,  1571.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      85.08 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    76 tokens (    0.66 ms per token,  1523.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      83.10 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    56 tokens (    0.76 ms per token,  1310.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      76.13 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.82 ms /   107 tokens (    0.61 ms per token,  1650.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      99.13 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.51 ms /   142 tokens (    0.66 ms per token,  1518.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     128.28 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.32 ms /    83 tokens (    0.68 ms per token,  1473.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =      90.80 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.25 ms /   183 tokens (    0.60 ms per token,  1675.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     143.67 ms /   185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.37 ms /   115 tokens (    0.62 ms per token,  1611.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     105.35 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    90 tokens (    0.64 ms per token,  1564.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.42 ms /     2 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =      91.38 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    78 tokens (    0.64 ms per token,  1557.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      84.26 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    71 tokens (    0.69 ms per token,  1439.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      83.10 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.69 ms /    84 tokens (    0.67 ms per token,  1481.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      90.92 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.47 ms /   156 tokens (    0.61 ms per token,  1634.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     147.38 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.60 ms /    92 tokens (    0.63 ms per token,  1597.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.43 ms /     2 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =      91.97 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.55 ms /    84 tokens (    0.67 ms per token,  1485.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.72 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      90.81 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.54 ms /    55 tokens (    0.77 ms per token,  1292.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      75.92 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.20 ms /   103 tokens (    0.62 ms per token,  1604.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      98.36 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.11 ms /   154 tokens (    0.62 ms per token,  1619.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     129.46 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.03 ms /    81 tokens (    0.69 ms per token,  1445.76 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     107.66 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    64 tokens (    0.68 ms per token,  1470.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.31 ms /   134 tokens (    0.69 ms per token,  1451.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     126.30 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.19 ms /    80 tokens (    0.64 ms per token,  1562.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =      85.23 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.92 ms /   112 tokens (    0.59 ms per token,  1698.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     100.35 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      91.95 ms /   131 tokens (    0.70 ms per token,  1424.66 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     143.58 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     139.08 ms /   227 tokens (    0.61 ms per token,  1632.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     173.47 ms /   229 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.22 ms /    72 tokens (    0.68 ms per token,  1462.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.66 ms /   114 tokens (    0.63 ms per token,  1590.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     105.82 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.95 ms /    68 tokens (    0.72 ms per token,  1389.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      82.61 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    60 tokens (    0.72 ms per token,  1389.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.88 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.80 ms /    66 tokens (    0.74 ms per token,  1352.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.78 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.65 ms /    66 tokens (    0.74 ms per token,  1356.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      98.85 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.53 ms /   127 tokens (    0.58 ms per token,  1727.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     108.20 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.48 ms /   121 tokens (    0.60 ms per token,  1669.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     107.31 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.80 ms /   107 tokens (    0.61 ms per token,  1651.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      98.97 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.58 ms /    84 tokens (    0.67 ms per token,  1484.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      90.54 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.04 ms /    82 tokens (    0.68 ms per token,  1463.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      90.46 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    75 tokens (    0.66 ms per token,  1510.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      99.93 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.73 ms /    65 tokens (    0.75 ms per token,  1333.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      82.34 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.04 ms /   175 tokens (    0.62 ms per token,  1619.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     142.56 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.39 ms /   134 tokens (    0.69 ms per token,  1450.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     126.68 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.53 ms /    63 tokens (    0.69 ms per token,  1447.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.82 ms /    57 tokens (    0.75 ms per token,  1331.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      76.34 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    92 tokens (    0.63 ms per token,  1586.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      92.62 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.89 ms /    93 tokens (    0.62 ms per token,  1606.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =      92.00 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.13 ms /    90 tokens (    0.63 ms per token,  1575.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.42 ms /     2 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =      91.64 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.70 ms /    66 tokens (    0.74 ms per token,  1355.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      82.02 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.35 ms /   121 tokens (    0.60 ms per token,  1672.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     106.32 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    62 tokens (    0.70 ms per token,  1427.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.39 ms /    61 tokens (    0.71 ms per token,  1405.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.35 ms /    80 tokens (    0.64 ms per token,  1557.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      85.67 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.86 ms /   117 tokens (    0.61 ms per token,  1628.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     106.43 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.07 ms /   109 tokens (    0.60 ms per token,  1675.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.64 ms /    90 tokens (    0.64 ms per token,  1561.33 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     109.01 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.35 ms /    89 tokens (    0.64 ms per token,  1551.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     108.80 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.95 ms /    94 tokens (    0.62 ms per token,  1622.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      92.52 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.53 ms /   138 tokens (    0.67 ms per token,  1491.46 tokens per second)\n",
      "llama_print_timings:        eval time =      50.27 ms /     3 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     143.77 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    72 tokens (    0.69 ms per token,  1453.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   105 tokens (    0.62 ms per token,  1624.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =      98.86 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    74 tokens (    0.67 ms per token,  1490.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      83.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.04 ms /   131 tokens (    0.70 ms per token,  1423.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     126.28 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.33 ms /    83 tokens (    0.68 ms per token,  1473.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      90.74 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    63 tokens (    0.69 ms per token,  1445.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      76.86 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.42 ms /   189 tokens (    0.58 ms per token,  1711.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     145.33 ms /   191 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.92 ms /    66 tokens (    0.74 ms per token,  1349.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      82.12 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     106.09 ms /   161 tokens (    0.66 ms per token,  1517.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     141.04 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.54 ms /   115 tokens (    0.62 ms per token,  1607.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     105.91 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.19 ms /    95 tokens (    0.61 ms per token,  1632.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      92.80 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.42 ms /    98 tokens (    0.65 ms per token,  1545.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.20 ms /     3 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     115.02 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.61 ms /    84 tokens (    0.67 ms per token,  1483.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      90.80 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.51 ms /   148 tokens (    0.64 ms per token,  1566.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     129.33 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    56 tokens (    0.76 ms per token,  1312.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      93.07 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    79 tokens (    0.64 ms per token,  1565.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.54 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.75 ms /    65 tokens (    0.75 ms per token,  1333.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      82.69 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.19 ms /    60 tokens (    0.72 ms per token,  1389.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      76.97 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.81 ms /   107 tokens (    0.61 ms per token,  1650.85 tokens per second)\n",
      "llama_print_timings:        eval time =      50.22 ms /     3 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     115.85 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.70 ms /   172 tokens (    0.63 ms per token,  1597.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     142.20 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.96 ms /    59 tokens (    0.73 ms per token,  1373.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      76.85 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.30 ms /   109 tokens (    0.60 ms per token,  1669.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.01 ms /    87 tokens (    0.66 ms per token,  1526.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      90.84 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.51 ms /   114 tokens (    0.63 ms per token,  1594.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     106.18 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.26 ms /    80 tokens (    0.64 ms per token,  1560.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      85.86 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.50 ms /    89 tokens (    0.65 ms per token,  1547.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      92.08 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    62 tokens (    0.70 ms per token,  1425.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      77.01 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.15 ms /   118 tokens (    0.61 ms per token,  1635.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     106.71 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    64 tokens (    0.68 ms per token,  1460.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      93.94 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.31 ms /   319 tokens (    0.59 ms per token,  1685.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     223.89 ms /   321 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.97 ms /   101 tokens (    0.63 ms per token,  1578.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      97.91 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    57 tokens (    0.76 ms per token,  1324.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      76.43 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.07 ms /   101 tokens (    0.63 ms per token,  1576.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      98.39 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    77 tokens (    0.65 ms per token,  1533.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.13 ms /   172 tokens (    0.63 ms per token,  1590.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     142.38 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.00 ms /   109 tokens (    0.60 ms per token,  1677.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.25 ms /     3 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     116.28 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.93 ms /    67 tokens (    0.73 ms per token,  1369.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      82.59 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    88 tokens (    0.65 ms per token,  1529.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =      91.65 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.08 ms /   102 tokens (    0.63 ms per token,  1591.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      98.66 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    59 tokens (    0.73 ms per token,  1372.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      93.91 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.82 ms /    72 tokens (    0.69 ms per token,  1445.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      83.08 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    72 tokens (    0.69 ms per token,  1448.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      83.19 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.68 ms /    89 tokens (    0.65 ms per token,  1543.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      91.55 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.76 ms /   148 tokens (    0.64 ms per token,  1561.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     128.87 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.59 ms /    98 tokens (    0.65 ms per token,  1541.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =      98.12 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.68 ms /   115 tokens (    0.62 ms per token,  1604.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     105.77 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      91.94 ms /   129 tokens (    0.71 ms per token,  1403.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     126.03 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    84 tokens (    0.68 ms per token,  1480.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      91.45 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.72 ms /    65 tokens (    0.75 ms per token,  1334.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      82.18 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   110 tokens (    0.60 ms per token,  1677.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      99.53 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.05 ms /    68 tokens (    0.72 ms per token,  1386.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      83.13 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.26 ms /   137 tokens (    0.68 ms per token,  1469.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     127.92 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.59 ms /    98 tokens (    0.65 ms per token,  1541.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      97.90 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    61 tokens (    0.71 ms per token,  1404.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   106 tokens (    0.61 ms per token,  1630.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      98.97 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.39 ms /    96 tokens (    0.61 ms per token,  1644.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.46 ms /     2 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =      92.24 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.06 ms /    69 tokens (    0.71 ms per token,  1406.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.29 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.11 ms /    68 tokens (    0.72 ms per token,  1384.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      99.17 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    61 tokens (    0.71 ms per token,  1401.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    61 tokens (    0.71 ms per token,  1404.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    92 tokens (    0.63 ms per token,  1590.87 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     109.75 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.97 ms /    67 tokens (    0.73 ms per token,  1368.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.14 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    71 tokens (    0.70 ms per token,  1433.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.24 ms /    69 tokens (    0.71 ms per token,  1401.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.41 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.07 ms /    69 tokens (    0.71 ms per token,  1406.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      82.88 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.20 ms /    85 tokens (    0.67 ms per token,  1486.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    75 tokens (    0.66 ms per token,  1507.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.06 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.38 ms /    60 tokens (    0.72 ms per token,  1383.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.31 ms /    69 tokens (    0.71 ms per token,  1399.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      82.81 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    77 tokens (    0.65 ms per token,  1529.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.64 ms /    65 tokens (    0.75 ms per token,  1336.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      82.20 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.46 ms /    80 tokens (    0.64 ms per token,  1554.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.72 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    77 tokens (    0.65 ms per token,  1534.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      83.72 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.44 ms /    81 tokens (    0.70 ms per token,  1435.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      90.69 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.28 ms /    87 tokens (    0.66 ms per token,  1518.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.43 ms /   145 tokens (    0.65 ms per token,  1535.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     128.57 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    90 tokens (    0.64 ms per token,  1561.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.41 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   111 tokens (    0.59 ms per token,  1689.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.14 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.83 ms /   156 tokens (    0.61 ms per token,  1627.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     129.82 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    70 tokens (    0.70 ms per token,  1420.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      83.32 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    75 tokens (    0.67 ms per token,  1495.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      84.07 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    60 tokens (    0.72 ms per token,  1380.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      94.09 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.14 ms /   177 tokens (    0.62 ms per token,  1621.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     143.61 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.43 ms /    89 tokens (    0.65 ms per token,  1549.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      91.59 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.19 ms /   108 tokens (    0.60 ms per token,  1656.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      99.55 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.63 ms /    54 tokens (    0.79 ms per token,  1266.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      75.93 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    77 tokens (    0.66 ms per token,  1525.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.33 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.66 ms /    90 tokens (    0.64 ms per token,  1560.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.26 ms /     3 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     108.98 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.32 ms /   118 tokens (    0.61 ms per token,  1631.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     106.46 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.82 ms /    74 tokens (    0.67 ms per token,  1485.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     100.58 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.39 ms /   131 tokens (    0.71 ms per token,  1417.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     126.73 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.33 ms /    81 tokens (    0.70 ms per token,  1438.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      90.81 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.05 ms /    94 tokens (    0.62 ms per token,  1619.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      92.83 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.18 ms /   101 tokens (    0.64 ms per token,  1573.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =      98.23 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.43 ms /   102 tokens (    0.63 ms per token,  1583.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      98.39 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    92 tokens (    0.63 ms per token,  1590.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.24 ms /    51 tokens (    0.83 ms per token,  1207.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      76.12 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.19 ms /   101 tokens (    0.64 ms per token,  1573.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =      98.68 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    77 tokens (    0.65 ms per token,  1529.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.51 ms /    90 tokens (    0.64 ms per token,  1565.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =      91.39 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.44 ms /   103 tokens (    0.63 ms per token,  1598.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      99.27 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    62 tokens (    0.70 ms per token,  1421.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      94.36 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.52 ms /    97 tokens (    0.65 ms per token,  1527.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      97.94 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    73 tokens (    0.68 ms per token,  1468.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      99.89 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    89 tokens (    0.65 ms per token,  1540.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    62 tokens (    0.70 ms per token,  1421.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    62 tokens (    0.70 ms per token,  1422.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      93.61 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    62 tokens (    0.70 ms per token,  1421.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    79 tokens (    0.64 ms per token,  1563.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.53 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.54 ms /   190 tokens (    0.58 ms per token,  1718.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     145.20 ms /   192 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.50 ms /    53 tokens (    0.80 ms per token,  1247.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      75.80 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    74 tokens (    0.68 ms per token,  1479.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.37 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    90 tokens (    0.64 ms per token,  1562.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =      91.47 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    80 tokens (    0.64 ms per token,  1558.42 tokens per second)\n",
      "llama_print_timings:        eval time =      50.32 ms /     3 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     103.30 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    87 tokens (    0.66 ms per token,  1520.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      92.02 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.22 ms /    69 tokens (    0.71 ms per token,  1402.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.12 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.47 ms /   119 tokens (    0.61 ms per token,  1642.15 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     124.78 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.46 ms /    71 tokens (    0.70 ms per token,  1435.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      99.74 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    60 tokens (    0.73 ms per token,  1376.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     121.73 ms /   197 tokens (    0.62 ms per token,  1618.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     156.48 ms /   199 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.28 ms /    87 tokens (    0.66 ms per token,  1518.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    73 tokens (    0.68 ms per token,  1470.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.82 ms /    65 tokens (    0.75 ms per token,  1331.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      82.48 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.83 ms /    83 tokens (    0.68 ms per token,  1460.62 tokens per second)\n",
      "llama_print_timings:        eval time =      50.29 ms /     3 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     108.43 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.71 ms /   127 tokens (    0.58 ms per token,  1722.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     107.75 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.14 ms /   108 tokens (    0.60 ms per token,  1657.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.30 ms /     3 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     116.29 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    72 tokens (    0.69 ms per token,  1449.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      83.29 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.95 ms /    74 tokens (    0.67 ms per token,  1481.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    75 tokens (    0.67 ms per token,  1493.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.30 ms /   118 tokens (    0.61 ms per token,  1632.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     107.09 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.80 ms /   106 tokens (    0.61 ms per token,  1635.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      99.17 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     126.53 ms /   209 tokens (    0.61 ms per token,  1651.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     160.46 ms /   211 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.56 ms /   150 tokens (    0.64 ms per token,  1569.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     130.39 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.00 ms /   129 tokens (    0.71 ms per token,  1402.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     126.86 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   110 tokens (    0.60 ms per token,  1674.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.08 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.90 ms /   100 tokens (    0.64 ms per token,  1565.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      98.63 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.29 ms /   124 tokens (    0.59 ms per token,  1691.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     108.07 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    62 tokens (    0.70 ms per token,  1425.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.95 ms /   101 tokens (    0.63 ms per token,  1579.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      98.55 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.57 ms /   111 tokens (    0.59 ms per token,  1692.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.76 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.49 ms /   132 tokens (    0.70 ms per token,  1427.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     127.35 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.90 ms /    66 tokens (    0.74 ms per token,  1349.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      82.45 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    71 tokens (    0.70 ms per token,  1430.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.61 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.75 ms /    62 tokens (    0.71 ms per token,  1417.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.20 ms /   100 tokens (    0.64 ms per token,  1557.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      98.77 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.18 ms /    87 tokens (    0.66 ms per token,  1521.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    74 tokens (    0.68 ms per token,  1479.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.45 ms /   113 tokens (    0.63 ms per token,  1581.41 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     122.92 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    62 tokens (    0.71 ms per token,  1418.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    58 tokens (    0.75 ms per token,  1339.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.06 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.37 ms /   112 tokens (    0.59 ms per token,  1687.51 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     117.82 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    59 tokens (    0.73 ms per token,  1363.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      76.63 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.42 ms /   139 tokens (    0.67 ms per token,  1487.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     128.16 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    63 tokens (    0.69 ms per token,  1439.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.57 ms /    80 tokens (    0.64 ms per token,  1551.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      86.40 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.51 ms /    70 tokens (    0.71 ms per token,  1413.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      83.27 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.38 ms /    81 tokens (    0.70 ms per token,  1436.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      90.56 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.77 ms /   121 tokens (    0.60 ms per token,  1662.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     107.47 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.07 ms /   107 tokens (    0.61 ms per token,  1644.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      99.08 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.38 ms /   112 tokens (    0.59 ms per token,  1687.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.62 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.77 ms /    65 tokens (    0.75 ms per token,  1332.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      82.91 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.45 ms /   166 tokens (    0.65 ms per token,  1544.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     159.01 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.17 ms /   236 tokens (    0.60 ms per token,  1671.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     175.17 ms /   238 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    77 tokens (    0.65 ms per token,  1530.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /   101 tokens (    0.64 ms per token,  1571.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      99.05 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.84 ms /   136 tokens (    0.68 ms per token,  1464.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     127.08 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.03 ms /    68 tokens (    0.72 ms per token,  1386.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      82.31 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.15 ms /   111 tokens (    0.60 ms per token,  1678.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.19 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.76 ms /   147 tokens (    0.64 ms per token,  1551.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     128.99 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    85 tokens (    0.67 ms per token,  1494.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      91.24 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    75 tokens (    0.67 ms per token,  1495.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.41 ms /   103 tokens (    0.63 ms per token,  1599.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      98.68 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.24 ms /   213 tokens (    0.60 ms per token,  1674.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     161.35 ms /   215 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.52 ms /   144 tokens (    0.66 ms per token,  1523.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     129.40 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    58 tokens (    0.74 ms per token,  1344.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      76.88 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.44 ms /   117 tokens (    0.62 ms per token,  1615.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     106.64 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.11 ms /    57 tokens (    0.76 ms per token,  1322.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      76.55 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   111 tokens (    0.59 ms per token,  1689.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     100.31 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.71 ms /    65 tokens (    0.75 ms per token,  1334.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      82.62 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    70 tokens (    0.71 ms per token,  1413.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      99.97 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    78 tokens (    0.65 ms per token,  1546.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.68 ms /    98 tokens (    0.65 ms per token,  1538.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      98.39 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    48 tokens (    0.77 ms per token,  1305.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      70.17 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    56 tokens (    0.77 ms per token,  1299.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      76.53 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     169.37 ms /   282 tokens (    0.60 ms per token,  1665.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     204.10 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.60 ms /   132 tokens (    0.70 ms per token,  1425.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     127.06 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.43 ms /    80 tokens (    0.64 ms per token,  1555.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      85.70 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.63 ms /   132 tokens (    0.70 ms per token,  1425.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     126.65 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    90 tokens (    0.64 ms per token,  1559.47 tokens per second)\n",
      "llama_print_timings:        eval time =      50.29 ms /     3 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =     109.31 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.19 ms /    77 tokens (    0.65 ms per token,  1534.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.12 ms /    99 tokens (    0.65 ms per token,  1543.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      98.57 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.11 ms /   100 tokens (    0.64 ms per token,  1559.92 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     115.84 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    79 tokens (    0.64 ms per token,  1564.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.97 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.41 ms /    95 tokens (    0.61 ms per token,  1626.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      93.00 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    76 tokens (    0.66 ms per token,  1512.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      84.01 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    55 tokens (    0.78 ms per token,  1283.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      76.89 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    67 tokens (    0.74 ms per token,  1360.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      83.15 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.90 ms /    92 tokens (    0.63 ms per token,  1589.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      92.81 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.35 ms /    88 tokens (    0.65 ms per token,  1534.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      91.31 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.32 ms /    68 tokens (    0.73 ms per token,  1378.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      83.29 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.18 ms /    68 tokens (    0.72 ms per token,  1382.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      83.03 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.80 ms /   113 tokens (    0.64 ms per token,  1573.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     106.64 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    94 tokens (    0.62 ms per token,  1616.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      92.34 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.93 ms /   205 tokens (    0.60 ms per token,  1667.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     157.40 ms /   207 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.20 ms /   108 tokens (    0.60 ms per token,  1656.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      99.66 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.44 ms /    53 tokens (    0.80 ms per token,  1248.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      75.68 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.15 ms /   107 tokens (    0.61 ms per token,  1642.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      99.29 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    58 tokens (    0.74 ms per token,  1346.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.68 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.89 ms /    92 tokens (    0.63 ms per token,  1589.11 tokens per second)\n",
      "llama_print_timings:        eval time =      50.28 ms /     3 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     109.12 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.34 ms /    94 tokens (    0.62 ms per token,  1611.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      92.62 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    96 tokens (    0.61 ms per token,  1637.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.58 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    74 tokens (    0.67 ms per token,  1482.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    70 tokens (    0.71 ms per token,  1415.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.56 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    90 tokens (    0.64 ms per token,  1562.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      92.14 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.55 ms /   120 tokens (    0.60 ms per token,  1654.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     123.99 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.60 ms /    53 tokens (    0.80 ms per token,  1244.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      76.45 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    72 tokens (    0.69 ms per token,  1443.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.72 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.35 ms /    71 tokens (    0.70 ms per token,  1438.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    76 tokens (    0.66 ms per token,  1511.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.34 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.47 ms /   173 tokens (    0.63 ms per token,  1594.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     142.79 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.14 ms /    91 tokens (    0.64 ms per token,  1565.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.47 ms /     2 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =      92.43 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.01 ms /   115 tokens (    0.63 ms per token,  1596.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     106.67 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    79 tokens (    0.64 ms per token,  1565.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.94 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.19 ms /    93 tokens (    0.63 ms per token,  1598.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.81 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.44 ms /   244 tokens (    0.58 ms per token,  1713.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     177.14 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    63 tokens (    0.69 ms per token,  1441.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      76.96 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    78 tokens (    0.65 ms per token,  1547.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =      84.34 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    59 tokens (    0.74 ms per token,  1356.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    63 tokens (    0.70 ms per token,  1434.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.24 ms /   169 tokens (    0.64 ms per token,  1561.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     142.30 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.85 ms /   115 tokens (    0.62 ms per token,  1600.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     106.29 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    74 tokens (    0.67 ms per token,  1483.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.38 ms /    86 tokens (    0.67 ms per token,  1498.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     3 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.46 ms /    60 tokens (    0.72 ms per token,  1380.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.98 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.69 ms /   135 tokens (    0.69 ms per token,  1456.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     127.52 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    77 tokens (    0.65 ms per token,  1531.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.48 ms /    81 tokens (    0.70 ms per token,  1434.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.09 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.22 ms /   101 tokens (    0.64 ms per token,  1572.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      98.22 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    91 tokens (    0.64 ms per token,  1569.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.54 ms /    80 tokens (    0.64 ms per token,  1552.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      85.68 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.82 ms /    56 tokens (    0.76 ms per token,  1307.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      76.64 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    68 tokens (    0.73 ms per token,  1376.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      82.93 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.95 ms /    66 tokens (    0.74 ms per token,  1348.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      99.25 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    72 tokens (    0.69 ms per token,  1448.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.50 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    73 tokens (    0.68 ms per token,  1462.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.54 ms /    95 tokens (    0.62 ms per token,  1622.82 tokens per second)\n",
      "llama_print_timings:        eval time =      50.30 ms /     3 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     109.72 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.65 ms /    82 tokens (    0.69 ms per token,  1447.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      91.43 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.93 ms /    66 tokens (    0.74 ms per token,  1348.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.42 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    79 tokens (    0.64 ms per token,  1556.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      85.34 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.79 ms /    98 tokens (    0.65 ms per token,  1536.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      98.04 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.21 ms /   112 tokens (    0.59 ms per token,  1691.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.61 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.89 ms /    65 tokens (    0.75 ms per token,  1329.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      99.04 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.28 ms /   171 tokens (    0.63 ms per token,  1579.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     143.22 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.28 ms /   124 tokens (    0.59 ms per token,  1692.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     108.05 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    77 tokens (    0.65 ms per token,  1530.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.07 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.68 ms /   113 tokens (    0.63 ms per token,  1576.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     106.19 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.22 ms /   117 tokens (    0.62 ms per token,  1620.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     107.20 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.61 ms /   103 tokens (    0.63 ms per token,  1594.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      98.91 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    63 tokens (    0.69 ms per token,  1441.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /   226 runs   (    0.05 ms per token, 19372.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.19 ms /   107 tokens (    0.61 ms per token,  1641.36 tokens per second)\n",
      "llama_print_timings:        eval time =    3766.38 ms /   225 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =    3930.10 ms /   332 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    71 tokens (    0.70 ms per token,  1433.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      99.78 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.06 ms /    65 tokens (    0.75 ms per token,  1324.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      82.37 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.51 ms /    81 tokens (    0.70 ms per token,  1433.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      90.64 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.87 ms /   115 tokens (    0.62 ms per token,  1600.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     106.25 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.96 ms /   136 tokens (    0.68 ms per token,  1462.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     127.14 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    72 tokens (    0.69 ms per token,  1446.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     100.85 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.22 ms /    93 tokens (    0.63 ms per token,  1597.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.93 ms /   143 tokens (    0.66 ms per token,  1522.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     128.28 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.46 ms /    88 tokens (    0.65 ms per token,  1531.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      91.44 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.33 ms /    94 tokens (    0.62 ms per token,  1611.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.29 ms /     3 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     110.20 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    60 tokens (    0.73 ms per token,  1374.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    85 tokens (    0.67 ms per token,  1489.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.08 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.22 ms /    68 tokens (    0.72 ms per token,  1381.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     100.29 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.26 ms /    86 tokens (    0.67 ms per token,  1501.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =      91.74 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.82 ms /    90 tokens (    0.64 ms per token,  1556.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.98 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    76 tokens (    0.66 ms per token,  1515.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.64 ms /    70 tokens (    0.71 ms per token,  1410.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.76 ms /   115 tokens (    0.62 ms per token,  1602.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     105.90 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.44 ms /    78 tokens (    0.65 ms per token,  1546.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      84.28 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.56 ms /   125 tokens (    0.59 ms per token,  1699.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     107.62 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.90 ms /    81 tokens (    0.70 ms per token,  1423.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.66 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    77 tokens (    0.65 ms per token,  1534.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      83.59 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.04 ms /    91 tokens (    0.64 ms per token,  1567.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.26 ms /     3 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     109.72 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.51 ms /    81 tokens (    0.70 ms per token,  1433.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      91.27 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.50 ms /    88 tokens (    0.65 ms per token,  1530.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =      91.79 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.61 ms /   109 tokens (    0.60 ms per token,  1661.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      99.71 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    78 tokens (    0.65 ms per token,  1546.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.99 ms /     3 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     101.37 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    75 tokens (    0.67 ms per token,  1487.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      85.05 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.80 ms /   153 tokens (    0.63 ms per token,  1597.11 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     147.41 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    72 tokens (    0.69 ms per token,  1445.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.78 ms /    84 tokens (    0.68 ms per token,  1479.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      91.46 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.95 ms /   116 tokens (    0.62 ms per token,  1612.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     105.93 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.80 ms /   127 tokens (    0.58 ms per token,  1720.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     108.46 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.84 ms /    83 tokens (    0.68 ms per token,  1460.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      90.99 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    71 tokens (    0.70 ms per token,  1432.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.25 ms /   123 tokens (    0.60 ms per token,  1679.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     125.11 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    90 tokens (    0.64 ms per token,  1561.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.94 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.79 ms /   104 tokens (    0.62 ms per token,  1605.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      99.64 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.70 ms /   144 tokens (    0.66 ms per token,  1520.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     129.06 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.92 ms /    84 tokens (    0.68 ms per token,  1475.86 tokens per second)\n",
      "llama_print_timings:        eval time =      50.28 ms /     3 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     108.15 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.14 ms /   176 tokens (    0.62 ms per token,  1612.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     143.26 ms /   178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.53 ms /   101 tokens (    0.64 ms per token,  1565.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.23 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.08 ms /   105 tokens (    0.62 ms per token,  1613.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.84 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.72 ms /   103 tokens (    0.63 ms per token,  1591.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      98.90 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.10 ms /    67 tokens (    0.73 ms per token,  1364.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      82.72 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    88 tokens (    0.65 ms per token,  1529.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      91.71 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.46 ms /   143 tokens (    0.66 ms per token,  1513.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     129.59 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    62 tokens (    0.70 ms per token,  1425.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    72 tokens (    0.69 ms per token,  1446.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      83.08 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.33 ms /   112 tokens (    0.59 ms per token,  1688.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     100.64 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.22 ms /   116 tokens (    0.62 ms per token,  1606.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     123.44 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.78 ms /   104 tokens (    0.62 ms per token,  1605.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.29 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.01 ms /   135 tokens (    0.69 ms per token,  1451.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     127.83 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    71 tokens (    0.70 ms per token,  1428.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.07 ms /   155 tokens (    0.62 ms per token,  1613.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     130.71 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.35 ms /   117 tokens (    0.62 ms per token,  1617.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     106.34 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.15 ms /   190 tokens (    0.58 ms per token,  1709.43 tokens per second)\n",
      "llama_print_timings:        eval time =      50.59 ms /     3 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     163.03 ms /   193 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.78 ms /   243 tokens (    0.59 ms per token,  1701.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     177.19 ms /   245 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.77 ms /   127 tokens (    0.58 ms per token,  1721.47 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     125.60 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.46 ms /    94 tokens (    0.62 ms per token,  1607.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.87 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    61 tokens (    0.71 ms per token,  1399.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.81 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    75 tokens (    0.67 ms per token,  1491.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.31 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    60 tokens (    0.72 ms per token,  1381.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    72 tokens (    0.69 ms per token,  1447.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    68 tokens (    0.72 ms per token,  1380.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.20 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    72 tokens (    0.69 ms per token,  1444.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.86 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.23 ms /   106 tokens (    0.62 ms per token,  1625.12 tokens per second)\n",
      "llama_print_timings:        eval time =      50.31 ms /     3 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     116.95 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    89 tokens (    0.65 ms per token,  1542.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.42 ms /   125 tokens (    0.59 ms per token,  1702.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     107.47 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    95 tokens (    0.62 ms per token,  1625.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      92.56 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    85 tokens (    0.67 ms per token,  1486.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.49 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    55 tokens (    0.78 ms per token,  1289.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      76.34 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    72 tokens (    0.69 ms per token,  1446.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.89 ms /    54 tokens (    0.79 ms per token,  1258.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.97 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    74 tokens (    0.68 ms per token,  1480.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    62 tokens (    0.71 ms per token,  1415.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.57 ms /   119 tokens (    0.61 ms per token,  1639.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     106.64 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.60 ms /    96 tokens (    0.61 ms per token,  1638.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      93.34 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    55 tokens (    0.78 ms per token,  1279.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.80 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.88 ms /    65 tokens (    0.75 ms per token,  1329.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      82.40 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.64 ms /   103 tokens (    0.63 ms per token,  1593.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      98.59 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    62 tokens (    0.70 ms per token,  1419.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      94.42 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.22 ms /    67 tokens (    0.73 ms per token,  1361.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.56 ms /   164 tokens (    0.66 ms per token,  1524.80 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     159.55 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    61 tokens (    0.72 ms per token,  1395.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.13 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.97 ms /    97 tokens (    0.66 ms per token,  1516.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      98.33 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    76 tokens (    0.66 ms per token,  1517.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.30 ms /   170 tokens (    0.64 ms per token,  1569.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     143.18 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.55 ms /   151 tokens (    0.63 ms per token,  1580.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     130.04 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.84 ms /   111 tokens (    0.59 ms per token,  1685.78 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     117.52 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /   102 tokens (    0.63 ms per token,  1582.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      98.67 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.88 ms /    83 tokens (    0.69 ms per token,  1459.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      91.56 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    76 tokens (    0.66 ms per token,  1513.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.36 ms /    65 tokens (    0.76 ms per token,  1316.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      82.96 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.19 ms /    75 tokens (    0.67 ms per token,  1494.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =     101.16 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.17 ms /   183 tokens (    0.60 ms per token,  1660.99 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     161.71 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.80 ms /    98 tokens (    0.65 ms per token,  1536.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      98.63 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    72 tokens (    0.69 ms per token,  1446.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      83.14 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.13 ms /    66 tokens (    0.74 ms per token,  1343.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      82.38 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /   100 tokens (    0.64 ms per token,  1550.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.40 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.88 ms /   105 tokens (    0.62 ms per token,  1618.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.30 ms /     3 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     116.90 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    63 tokens (    0.70 ms per token,  1433.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.13 ms /   115 tokens (    0.63 ms per token,  1594.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     107.14 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   110 tokens (    0.60 ms per token,  1674.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     100.06 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.58 ms /    89 tokens (    0.65 ms per token,  1545.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      91.69 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.52 ms /    81 tokens (    0.70 ms per token,  1433.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =      90.50 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.08 ms /    99 tokens (    0.65 ms per token,  1544.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      98.45 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.13 ms /   161 tokens (    0.67 ms per token,  1502.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     141.52 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.45 ms /    52 tokens (    0.82 ms per token,  1224.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      76.26 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.31 ms /   129 tokens (    0.72 ms per token,  1397.50 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     143.63 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.51 ms /    70 tokens (    0.71 ms per token,  1413.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.27 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.22 ms /    74 tokens (    0.68 ms per token,  1473.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      84.18 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.98 ms /    73 tokens (    0.68 ms per token,  1460.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.81 ms /   128 tokens (    0.58 ms per token,  1734.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     107.95 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.50 ms /    69 tokens (    0.72 ms per token,  1393.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.08 ms /    66 tokens (    0.74 ms per token,  1344.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      82.56 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    59 tokens (    0.73 ms per token,  1362.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      76.61 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    63 tokens (    0.70 ms per token,  1436.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.15 ms /   116 tokens (    0.62 ms per token,  1607.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     106.48 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    58 tokens (    0.74 ms per token,  1343.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.13 ms /    91 tokens (    0.64 ms per token,  1565.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.73 ms /    97 tokens (    0.66 ms per token,  1522.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      98.48 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    76 tokens (    0.66 ms per token,  1511.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      84.20 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.82 ms /   113 tokens (    0.64 ms per token,  1573.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =     105.77 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.46 ms /   109 tokens (    0.60 ms per token,  1665.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     117.50 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    84 tokens (    0.68 ms per token,  1477.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.22 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.84 ms /    89 tokens (    0.65 ms per token,  1538.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.49 ms /     2 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.65 ms /   132 tokens (    0.70 ms per token,  1424.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     127.20 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.91 ms /   111 tokens (    0.59 ms per token,  1684.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     100.73 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    64 tokens (    0.68 ms per token,  1460.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    82 tokens (    0.69 ms per token,  1445.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.59 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.06 ms /    99 tokens (    0.65 ms per token,  1545.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      98.94 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.20 ms /   122 tokens (    0.60 ms per token,  1666.78 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     124.93 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.57 ms /   139 tokens (    0.67 ms per token,  1485.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     144.83 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.90 ms /    65 tokens (    0.75 ms per token,  1329.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.52 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1448.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      94.88 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.22 ms /   100 tokens (    0.64 ms per token,  1557.03 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     116.03 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    75 tokens (    0.67 ms per token,  1491.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      83.79 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.63 ms /    52 tokens (    0.82 ms per token,  1219.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.27 ms /   137 tokens (    0.68 ms per token,  1468.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     128.04 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.02 ms /    99 tokens (    0.65 ms per token,  1546.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      98.96 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.11 ms /    65 tokens (    0.76 ms per token,  1323.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.61 ms /    50 tokens (    0.85 ms per token,  1173.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      93.48 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.22 ms /    73 tokens (    0.69 ms per token,  1453.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      84.14 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.40 ms /   146 tokens (    0.65 ms per token,  1530.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     129.65 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    71 tokens (    0.70 ms per token,  1428.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.29 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    72 tokens (    0.70 ms per token,  1429.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     100.54 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    71 tokens (    0.71 ms per token,  1418.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      83.32 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    86 tokens (    0.67 ms per token,  1497.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.34 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.65 ms /    80 tokens (    0.65 ms per token,  1548.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      85.78 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    76 tokens (    0.66 ms per token,  1510.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     100.65 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.42 ms /   105 tokens (    0.62 ms per token,  1605.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    56 tokens (    0.77 ms per token,  1297.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.97 ms /   151 tokens (    0.64 ms per token,  1573.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     130.19 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.52 ms /    69 tokens (    0.72 ms per token,  1393.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    68 tokens (    0.73 ms per token,  1376.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.99 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.62 ms /   117 tokens (    0.62 ms per token,  1611.06 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     124.47 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.51 ms /   155 tokens (    0.62 ms per token,  1606.12 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     148.75 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    75 tokens (    0.68 ms per token,  1480.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.39 ms /   100 tokens (    0.64 ms per token,  1553.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      98.54 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    57 tokens (    0.76 ms per token,  1316.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    60 tokens (    0.73 ms per token,  1369.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.30 ms /    73 tokens (    0.69 ms per token,  1451.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    95 tokens (    0.62 ms per token,  1620.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      93.37 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.94 ms /   113 tokens (    0.64 ms per token,  1570.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     106.20 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.28 ms /   135 tokens (    0.69 ms per token,  1447.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     128.01 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    56 tokens (    0.77 ms per token,  1297.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.05 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.49 ms /   134 tokens (    0.70 ms per token,  1433.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     127.85 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.92 ms /   165 tokens (    0.65 ms per token,  1528.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     143.01 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.50 ms /    68 tokens (    0.73 ms per token,  1373.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.21 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.95 ms /    95 tokens (    0.62 ms per token,  1611.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      92.91 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     166.20 ms /   257 tokens (    0.65 ms per token,  1546.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     200.08 ms /   259 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.78 ms /   109 tokens (    0.60 ms per token,  1656.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      99.96 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.82 ms /   108 tokens (    0.61 ms per token,  1640.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.30 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.39 ms /    68 tokens (    0.73 ms per token,  1376.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.50 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.21 ms /    91 tokens (    0.64 ms per token,  1563.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.09 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.93 ms /   220 tokens (    0.59 ms per token,  1706.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     162.84 ms /   222 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.10 ms /   139 tokens (    0.68 ms per token,  1477.17 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     145.34 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.67 ms /   108 tokens (    0.61 ms per token,  1644.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     100.21 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.27 ms /   106 tokens (    0.62 ms per token,  1624.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.32 ms /    99 tokens (    0.65 ms per token,  1539.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.13 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.10 ms /   111 tokens (    0.60 ms per token,  1679.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.91 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.65 ms /    80 tokens (    0.65 ms per token,  1548.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      86.24 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    72 tokens (    0.70 ms per token,  1436.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    60 tokens (    0.73 ms per token,  1368.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    62 tokens (    0.71 ms per token,  1414.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    84 tokens (    0.68 ms per token,  1467.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.42 ms /    93 tokens (    0.63 ms per token,  1592.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.64 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    84 tokens (    0.68 ms per token,  1467.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.36 ms /   100 tokens (    0.64 ms per token,  1553.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      98.37 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    64 tokens (    0.69 ms per token,  1451.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    62 tokens (    0.71 ms per token,  1406.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     5 runs   (    0.05 ms per token, 19305.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    73 tokens (    0.69 ms per token,  1458.75 tokens per second)\n",
      "llama_print_timings:        eval time =      65.88 ms /     4 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     117.52 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.46 ms /   147 tokens (    0.65 ms per token,  1539.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     130.45 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /   100 tokens (    0.64 ms per token,  1551.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      98.96 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    61 tokens (    0.72 ms per token,  1392.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    62 tokens (    0.71 ms per token,  1406.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    57 tokens (    0.76 ms per token,  1318.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.86 ms /    61 tokens (    0.72 ms per token,  1390.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    75 tokens (    0.67 ms per token,  1483.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.60 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.95 ms /   119 tokens (    0.61 ms per token,  1631.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.00 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    56 tokens (    0.77 ms per token,  1298.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.07 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    68 tokens (    0.73 ms per token,  1375.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      99.98 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    64 tokens (    0.69 ms per token,  1444.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    85 tokens (    0.67 ms per token,  1481.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      91.82 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    73 tokens (    0.69 ms per token,  1456.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.89 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    78 tokens (    0.65 ms per token,  1534.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.84 ms /    87 tokens (    0.66 ms per token,  1504.23 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     109.61 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.99 ms /    83 tokens (    0.69 ms per token,  1456.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      90.93 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.37 ms /    56 tokens (    0.77 ms per token,  1291.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      94.48 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    87 tokens (    0.67 ms per token,  1503.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.31 ms /   211 tokens (    0.60 ms per token,  1657.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     161.08 ms /   213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.25 ms /   134 tokens (    0.70 ms per token,  1437.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     127.29 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.45 ms /    86 tokens (    0.67 ms per token,  1496.90 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     109.45 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    95 tokens (    0.62 ms per token,  1612.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.53 ms /   106 tokens (    0.62 ms per token,  1617.65 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     116.64 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.73 ms /   125 tokens (    0.59 ms per token,  1695.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     108.23 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    88 tokens (    0.66 ms per token,  1522.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.00 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.80 ms /    93 tokens (    0.63 ms per token,  1581.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      93.38 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.28 ms /   105 tokens (    0.62 ms per token,  1608.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.09 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.11 ms /   106 tokens (    0.61 ms per token,  1628.04 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     117.18 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.04 ms /   153 tokens (    0.63 ms per token,  1593.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     130.14 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    76 tokens (    0.66 ms per token,  1509.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.20 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.94 ms /   103 tokens (    0.63 ms per token,  1586.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.73 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.60 ms /    85 tokens (    0.68 ms per token,  1475.69 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     109.09 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.39 ms /   122 tokens (    0.60 ms per token,  1662.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     107.57 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    77 tokens (    0.66 ms per token,  1518.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     101.44 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    73 tokens (    0.69 ms per token,  1450.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      84.47 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   101 tokens (    0.64 ms per token,  1562.96 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     116.30 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.12 ms /   105 tokens (    0.62 ms per token,  1612.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.31 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.11 ms /    57 tokens (    0.76 ms per token,  1322.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.66 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.87 ms /    78 tokens (    0.65 ms per token,  1533.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =      84.90 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.46 ms /   135 tokens (    0.69 ms per token,  1444.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     127.62 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.41 ms /   143 tokens (    0.66 ms per token,  1514.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     129.17 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    92 tokens (    0.64 ms per token,  1574.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      93.09 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.09 ms /    65 tokens (    0.76 ms per token,  1324.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.99 ms /   125 tokens (    0.59 ms per token,  1689.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     108.24 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.33 ms /   153 tokens (    0.63 ms per token,  1588.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     130.45 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    77 tokens (    0.66 ms per token,  1519.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.38 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.96 ms /    54 tokens (    0.80 ms per token,  1257.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      93.77 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.98 ms /    80 tokens (    0.65 ms per token,  1539.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     103.08 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.02 ms /    65 tokens (    0.75 ms per token,  1326.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.22 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    55 tokens (    0.78 ms per token,  1279.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      93.55 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    57 tokens (    0.76 ms per token,  1311.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.08 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    68 tokens (    0.73 ms per token,  1363.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.36 ms /    93 tokens (    0.63 ms per token,  1593.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.92 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    71 tokens (    0.70 ms per token,  1429.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.24 ms /    55 tokens (    0.79 ms per token,  1272.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.55 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.38 ms /   154 tokens (    0.63 ms per token,  1597.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.84 ms /     2 runs   (   16.92 ms per token,    59.10 tokens per second)\n",
      "llama_print_timings:       total time =     131.42 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     144.74 ms /   253 tokens (    0.57 ms per token,  1747.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.97 ms /     3 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     196.05 ms /   256 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    76 tokens (    0.66 ms per token,  1504.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    79 tokens (    0.64 ms per token,  1554.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.30 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    70 tokens (    0.71 ms per token,  1407.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.22 ms /   366 tokens (    0.59 ms per token,  1700.57 tokens per second)\n",
      "llama_print_timings:        eval time =      51.90 ms /     3 runs   (   17.30 ms per token,    57.80 tokens per second)\n",
      "llama_print_timings:       total time =     268.21 ms /   369 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.72 ms /   112 tokens (    0.60 ms per token,  1678.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.05 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    75 tokens (    0.67 ms per token,  1484.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      84.53 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    76 tokens (    0.67 ms per token,  1500.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.50 ms /   161 tokens (    0.67 ms per token,  1497.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     142.50 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    61 tokens (    0.72 ms per token,  1391.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.39 ms /   115 tokens (    0.63 ms per token,  1588.57 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     124.27 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.81 ms /   130 tokens (    0.71 ms per token,  1400.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     127.18 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.32 ms /   106 tokens (    0.62 ms per token,  1622.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     116.63 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    62 tokens (    0.71 ms per token,  1408.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    89 tokens (    0.65 ms per token,  1535.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.71 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.56 ms /    93 tokens (    0.63 ms per token,  1588.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      93.05 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.52 ms /    93 tokens (    0.63 ms per token,  1589.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      92.67 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    75 tokens (    0.67 ms per token,  1487.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.91 ms /   125 tokens (    0.59 ms per token,  1691.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     109.34 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    81 tokens (    0.70 ms per token,  1424.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.06 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.97 ms /    98 tokens (    0.65 ms per token,  1531.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      98.49 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.29 ms /    93 tokens (    0.63 ms per token,  1595.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.86 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.37 ms /    57 tokens (    0.76 ms per token,  1314.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      76.93 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    85 tokens (    0.67 ms per token,  1481.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.63 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    69 tokens (    0.72 ms per token,  1389.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.79 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.46 ms /   126 tokens (    0.59 ms per token,  1692.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     109.06 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    84 tokens (    0.68 ms per token,  1468.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.66 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    93 tokens (    0.63 ms per token,  1596.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      92.50 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.73 ms /    95 tokens (    0.62 ms per token,  1617.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.73 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    97 tokens (    0.66 ms per token,  1508.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.98 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.28 ms /    67 tokens (    0.74 ms per token,  1359.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      82.75 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    83 tokens (    0.69 ms per token,  1454.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.75 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.38 ms /    91 tokens (    0.64 ms per token,  1558.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =      93.92 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    63 tokens (    0.70 ms per token,  1432.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.17 ms /   113 tokens (    0.64 ms per token,  1565.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     106.87 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    70 tokens (    0.71 ms per token,  1406.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    68 tokens (    0.73 ms per token,  1374.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.91 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.08 ms /   110 tokens (    0.60 ms per token,  1664.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     100.37 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.73 ms /   108 tokens (    0.61 ms per token,  1643.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     100.50 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.89 ms /   131 tokens (    0.71 ms per token,  1410.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     128.03 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.56 ms /    85 tokens (    0.68 ms per token,  1476.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.95 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.74 ms /    89 tokens (    0.65 ms per token,  1541.50 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     109.54 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.30 ms /   105 tokens (    0.62 ms per token,  1608.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.67 ms /   135 tokens (    0.69 ms per token,  1441.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.57 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.46 ms /   100 tokens (    0.64 ms per token,  1551.37 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     115.97 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.61 ms /   107 tokens (    0.61 ms per token,  1630.85 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     117.52 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    82 tokens (    0.70 ms per token,  1436.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.29 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.37 ms /    49 tokens (    0.86 ms per token,  1156.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      75.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.11 ms /    83 tokens (    0.69 ms per token,  1453.28 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     108.52 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.97 ms /    46 tokens (    0.80 ms per token,  1244.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      70.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.04 ms /    91 tokens (    0.64 ms per token,  1567.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.75 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.24 ms /    66 tokens (    0.75 ms per token,  1340.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.03 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.31 ms /    56 tokens (    0.77 ms per token,  1292.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.81 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.75 ms /    86 tokens (    0.67 ms per token,  1489.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.52 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    79 tokens (    0.64 ms per token,  1552.34 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     102.43 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.92 ms /    79 tokens (    0.64 ms per token,  1551.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      85.52 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    73 tokens (    0.69 ms per token,  1456.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     101.19 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    77 tokens (    0.66 ms per token,  1511.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.76 ms /     3 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     102.10 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    55 tokens (    0.78 ms per token,  1281.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      93.33 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    55 tokens (    0.78 ms per token,  1276.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      76.53 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.38 ms /    85 tokens (    0.68 ms per token,  1481.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.77 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    75 tokens (    0.67 ms per token,  1492.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.46 ms /    68 tokens (    0.73 ms per token,  1374.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =     100.44 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.81 ms /   137 tokens (    0.68 ms per token,  1460.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     129.02 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    72 tokens (    0.70 ms per token,  1437.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.36 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    58 tokens (    0.75 ms per token,  1327.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.24 ms /    64 tokens (    0.69 ms per token,  1446.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.09 ms /    80 tokens (    0.65 ms per token,  1535.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      86.87 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    87 tokens (    0.66 ms per token,  1513.60 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     109.09 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.51 ms /   126 tokens (    0.59 ms per token,  1691.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     126.93 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.27 ms /    68 tokens (    0.72 ms per token,  1380.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.79 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    74 tokens (    0.68 ms per token,  1463.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =     100.79 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.40 ms /   128 tokens (    0.58 ms per token,  1720.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     109.26 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.87 ms /    89 tokens (    0.65 ms per token,  1537.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    75 tokens (    0.67 ms per token,  1489.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.64 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    63 tokens (    0.70 ms per token,  1420.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.36 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.15 ms /   114 tokens (    0.63 ms per token,  1580.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     106.37 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.24 ms /    56 tokens (    0.77 ms per token,  1295.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      76.77 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.92 ms /    93 tokens (    0.63 ms per token,  1578.52 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     110.88 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.97 ms /   103 tokens (    0.63 ms per token,  1585.25 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     116.17 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    78 tokens (    0.65 ms per token,  1538.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =      85.20 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    66 tokens (    0.75 ms per token,  1329.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.24 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    63 tokens (    0.70 ms per token,  1432.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.02 ms /   114 tokens (    0.63 ms per token,  1583.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     106.99 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.01 ms /   119 tokens (    0.61 ms per token,  1629.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     107.09 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.98 ms /    81 tokens (    0.70 ms per token,  1421.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      91.29 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    61 tokens (    0.72 ms per token,  1391.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.95 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    62 tokens (    0.71 ms per token,  1404.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.20 ms /    65 tokens (    0.76 ms per token,  1321.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      82.60 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    68 tokens (    0.73 ms per token,  1368.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.45 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.93 ms /   120 tokens (    0.61 ms per token,  1645.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     107.87 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.94 ms /    88 tokens (    0.66 ms per token,  1518.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =      93.33 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.43 ms /   115 tokens (    0.63 ms per token,  1587.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     106.88 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.05 ms /   126 tokens (    0.59 ms per token,  1701.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     108.68 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.98 ms /   132 tokens (    0.70 ms per token,  1419.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     127.93 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.70 ms /   102 tokens (    0.63 ms per token,  1576.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      98.95 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      67.08 ms /   112 tokens (    0.60 ms per token,  1669.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     119.60 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.65 ms /   149 tokens (    0.64 ms per token,  1557.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     130.31 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    67 tokens (    0.74 ms per token,  1350.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    83 tokens (    0.69 ms per token,  1453.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.16 ms /    79 tokens (    0.65 ms per token,  1544.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.07 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.95 ms /   103 tokens (    0.63 ms per token,  1585.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      99.23 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.05 ms /    65 tokens (    0.75 ms per token,  1325.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.13 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    72 tokens (    0.70 ms per token,  1437.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      84.12 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.97 ms /    70 tokens (    0.71 ms per token,  1400.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =     100.24 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.95 ms /   118 tokens (    0.62 ms per token,  1617.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     107.24 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    87 tokens (    0.66 ms per token,  1511.18 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.51 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    84 tokens (    0.68 ms per token,  1470.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      91.41 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    63 tokens (    0.70 ms per token,  1432.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.85 ms /    62 tokens (    0.71 ms per token,  1413.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.29 ms /    91 tokens (    0.64 ms per token,  1561.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.79 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    62 tokens (    0.71 ms per token,  1408.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    61 tokens (    0.72 ms per token,  1391.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      94.20 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.18 ms /   222 tokens (    0.58 ms per token,  1718.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     163.09 ms /   224 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.20 ms /    83 tokens (    0.69 ms per token,  1451.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.32 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.08 ms /   104 tokens (    0.63 ms per token,  1598.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.24 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.59 ms /   123 tokens (    0.60 ms per token,  1671.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     108.59 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    75 tokens (    0.67 ms per token,  1493.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.88 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    61 tokens (    0.72 ms per token,  1385.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    62 tokens (    0.71 ms per token,  1410.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    77 tokens (    0.66 ms per token,  1509.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      85.13 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.42 ms /    68 tokens (    0.73 ms per token,  1376.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.04 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    75 tokens (    0.67 ms per token,  1486.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     100.61 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.95 ms /   110 tokens (    0.60 ms per token,  1667.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.22 ms /    84 tokens (    0.68 ms per token,  1467.99 tokens per second)\n",
      "llama_print_timings:        eval time =      50.32 ms /     3 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     109.51 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.49 ms /    93 tokens (    0.63 ms per token,  1590.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.09 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.02 ms /    91 tokens (    0.64 ms per token,  1568.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.99 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.25 ms /   111 tokens (    0.60 ms per token,  1675.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     100.40 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    75 tokens (    0.67 ms per token,  1489.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.63 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    83 tokens (    0.69 ms per token,  1454.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      91.22 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    70 tokens (    0.71 ms per token,  1401.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.27 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.45 ms /    97 tokens (    0.66 ms per token,  1505.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      98.76 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.23 ms /    99 tokens (    0.65 ms per token,  1541.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.64 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.25 ms /   189 tokens (    0.59 ms per token,  1698.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     145.95 ms /   191 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.84 ms /   184 tokens (    0.60 ms per token,  1660.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     145.12 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.79 ms /    82 tokens (    0.69 ms per token,  1443.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =      91.67 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    74 tokens (    0.68 ms per token,  1467.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.32 ms /    66 tokens (    0.75 ms per token,  1338.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.96 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    72 tokens (    0.70 ms per token,  1436.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    67 tokens (    0.74 ms per token,  1349.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.60 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.87 ms /   102 tokens (    0.64 ms per token,  1572.40 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     117.07 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.27 ms /   115 tokens (    0.63 ms per token,  1591.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     106.80 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    66 tokens (    0.75 ms per token,  1339.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      83.08 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.36 ms /   189 tokens (    0.59 ms per token,  1697.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     146.56 ms /   191 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.67 ms /    88 tokens (    0.66 ms per token,  1526.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.69 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.22 ms /    65 tokens (    0.76 ms per token,  1320.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.62 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    77 tokens (    0.66 ms per token,  1516.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.49 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    75 tokens (    0.67 ms per token,  1490.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    61 tokens (    0.72 ms per token,  1387.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      95.46 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    89 tokens (    0.65 ms per token,  1536.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.77 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    99 tokens (    0.65 ms per token,  1540.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      99.05 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.07 ms /   126 tokens (    0.59 ms per token,  1701.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     108.07 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    70 tokens (    0.71 ms per token,  1405.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.43 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    74 tokens (    0.68 ms per token,  1470.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    63 tokens (    0.70 ms per token,  1431.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      94.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.19 ms /    63 tokens (    0.70 ms per token,  1425.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.02 ms /   108 tokens (    0.61 ms per token,  1635.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     100.43 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    64 tokens (    0.69 ms per token,  1452.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      95.03 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.02 ms /    80 tokens (    0.65 ms per token,  1537.90 tokens per second)\n",
      "llama_print_timings:        eval time =      50.31 ms /     3 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     103.07 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.05 ms /    65 tokens (    0.75 ms per token,  1325.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      82.28 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    87 tokens (    0.66 ms per token,  1512.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      92.25 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.07 ms /    91 tokens (    0.64 ms per token,  1566.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.08 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.79 ms /    81 tokens (    0.70 ms per token,  1426.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.53 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.48 ms /   202 tokens (    0.61 ms per token,  1635.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     157.75 ms /   204 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.39 ms /   115 tokens (    0.63 ms per token,  1588.51 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     124.31 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    59 tokens (    0.74 ms per token,  1345.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      95.14 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.07 ms /   159 tokens (    0.61 ms per token,  1637.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     131.94 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.78 ms /    80 tokens (    0.65 ms per token,  1545.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      86.02 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.49 ms /    93 tokens (    0.63 ms per token,  1590.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.50 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.16 ms /   130 tokens (    0.72 ms per token,  1395.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     128.32 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.39 ms /    87 tokens (    0.66 ms per token,  1515.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.98 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.93 ms /   171 tokens (    0.64 ms per token,  1569.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     143.07 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.96 ms /    95 tokens (    0.62 ms per token,  1611.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.16 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.34 ms /    92 tokens (    0.63 ms per token,  1576.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    77 tokens (    0.66 ms per token,  1520.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.70 ms /     3 runs   (   16.57 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     101.67 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    67 tokens (    0.74 ms per token,  1355.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      82.77 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.68 ms /    87 tokens (    0.66 ms per token,  1508.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     109.20 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    70 tokens (    0.71 ms per token,  1406.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   100 tokens (    0.65 ms per token,  1547.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      99.08 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    89 tokens (    0.65 ms per token,  1534.46 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     110.04 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    76 tokens (    0.66 ms per token,  1504.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.39 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1543.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      86.04 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.11 ms /    98 tokens (    0.65 ms per token,  1528.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      98.39 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.18 ms /   132 tokens (    0.71 ms per token,  1416.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     127.41 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    61 tokens (    0.72 ms per token,  1391.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.77 ms /   107 tokens (    0.61 ms per token,  1626.91 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     117.33 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.40 ms /   122 tokens (    0.60 ms per token,  1662.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.49 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.87 ms /   102 tokens (    0.64 ms per token,  1572.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      99.22 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.81 ms /    95 tokens (    0.62 ms per token,  1615.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.81 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    55 tokens (    0.78 ms per token,  1278.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    58 tokens (    0.75 ms per token,  1335.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      93.86 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.01 ms /    88 tokens (    0.66 ms per token,  1517.11 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     109.45 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    70 tokens (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      84.19 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.33 ms /    66 tokens (    0.75 ms per token,  1337.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.68 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.69 ms /    75 tokens (    0.68 ms per token,  1479.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.63 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.77 ms /   177 tokens (    0.62 ms per token,  1612.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     144.10 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    60 tokens (    0.73 ms per token,  1372.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.46 ms /    59 tokens (    0.74 ms per token,  1357.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      76.76 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.58 ms /    93 tokens (    0.63 ms per token,  1587.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.48 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.99 ms /    90 tokens (    0.64 ms per token,  1551.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.35 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.54 ms /   140 tokens (    0.68 ms per token,  1480.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     146.25 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.58 ms /   143 tokens (    0.66 ms per token,  1512.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     128.86 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    86 tokens (    0.67 ms per token,  1493.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    61 tokens (    0.72 ms per token,  1393.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.13 ms /    91 tokens (    0.64 ms per token,  1565.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.54 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.16 ms /   214 tokens (    0.60 ms per token,  1669.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.30 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     162.76 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.13 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    66 tokens (    0.75 ms per token,  1326.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.06 ms /   118 tokens (    0.62 ms per token,  1615.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.23 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.39 ms /   100 tokens (    0.64 ms per token,  1553.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      98.36 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    69 tokens (    0.72 ms per token,  1385.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      84.35 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.32 ms /    67 tokens (    0.74 ms per token,  1358.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      82.67 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.28 ms /   159 tokens (    0.61 ms per token,  1634.47 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     149.44 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    67 tokens (    0.74 ms per token,  1349.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.11 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.52 ms /   101 tokens (    0.64 ms per token,  1565.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =      99.25 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    68 tokens (    0.73 ms per token,  1372.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    68 tokens (    0.73 ms per token,  1372.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.11 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    68 tokens (    0.73 ms per token,  1367.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   107 tokens (    0.61 ms per token,  1628.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.82 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    79 tokens (    0.65 ms per token,  1546.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.76 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.95 ms /   178 tokens (    0.62 ms per token,  1618.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     145.13 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.94 ms /    80 tokens (    0.65 ms per token,  1540.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      86.31 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.46 ms /   190 tokens (    0.59 ms per token,  1704.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     145.99 ms /   192 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.13 ms /    65 tokens (    0.76 ms per token,  1322.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      99.40 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.85 ms /    60 tokens (    0.73 ms per token,  1368.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.05 ms /    83 tokens (    0.69 ms per token,  1454.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      91.74 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.82 ms /    80 tokens (    0.65 ms per token,  1543.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      85.95 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.98 ms /    89 tokens (    0.65 ms per token,  1535.14 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     109.57 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.73 ms /    94 tokens (    0.62 ms per token,  1600.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.73 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.88 ms /   110 tokens (    0.60 ms per token,  1669.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.29 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.93 ms /   113 tokens (    0.64 ms per token,  1571.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     106.63 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.51 ms /    98 tokens (    0.66 ms per token,  1519.21 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     117.03 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    74 tokens (    0.68 ms per token,  1473.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.46 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    68 tokens (    0.73 ms per token,  1376.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.30 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    70 tokens (    0.71 ms per token,  1404.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    77 tokens (    0.66 ms per token,  1512.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      84.99 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.85 ms /   108 tokens (    0.61 ms per token,  1640.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.08 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.10 ms /   104 tokens (    0.63 ms per token,  1597.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.74 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.10 ms /    84 tokens (    0.68 ms per token,  1471.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.93 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.54 ms /    85 tokens (    0.68 ms per token,  1477.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.59 ms /   153 tokens (    0.63 ms per token,  1583.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     131.60 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.11 ms /   113 tokens (    0.64 ms per token,  1566.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     107.30 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.28 ms /    63 tokens (    0.70 ms per token,  1422.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    58 tokens (    0.75 ms per token,  1334.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.04 ms /   125 tokens (    0.59 ms per token,  1688.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     108.55 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    59 tokens (    0.74 ms per token,  1355.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.01 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.56 ms /    86 tokens (    0.67 ms per token,  1493.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.36 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    77 tokens (    0.66 ms per token,  1525.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.13 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    68 tokens (    0.73 ms per token,  1367.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.75 ms /   124 tokens (    0.59 ms per token,  1681.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     107.82 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.94 ms /    71 tokens (    0.70 ms per token,  1421.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.24 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.09 ms /   125 tokens (    0.59 ms per token,  1687.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     109.41 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.99 ms /   126 tokens (    0.59 ms per token,  1703.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     125.78 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.51 ms /    85 tokens (    0.68 ms per token,  1478.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    84 tokens (    0.68 ms per token,  1471.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.77 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    70 tokens (    0.72 ms per token,  1396.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.94 ms /    70 tokens (    0.71 ms per token,  1401.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.29 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.36 ms /   178 tokens (    0.62 ms per token,  1612.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     145.37 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.10 ms /   115 tokens (    0.63 ms per token,  1594.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     106.74 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    57 tokens (    0.76 ms per token,  1315.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.57 ms /   121 tokens (    0.61 ms per token,  1644.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     107.66 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.57 ms /   100 tokens (    0.65 ms per token,  1548.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.12 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.59 ms /   109 tokens (    0.60 ms per token,  1661.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.91 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    62 tokens (    0.71 ms per token,  1412.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.22 ms /   140 tokens (    0.67 ms per token,  1485.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     129.18 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.96 ms /    80 tokens (    0.65 ms per token,  1539.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      87.18 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.80 ms /   102 tokens (    0.64 ms per token,  1574.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      99.04 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.31 ms /   111 tokens (    0.60 ms per token,  1673.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.45 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    74 tokens (    0.68 ms per token,  1470.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     101.35 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.48 ms /   134 tokens (    0.70 ms per token,  1433.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     127.87 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.17 ms /    92 tokens (    0.63 ms per token,  1581.60 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     109.68 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.72 ms /   102 tokens (    0.63 ms per token,  1576.04 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     116.54 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    69 tokens (    0.72 ms per token,  1384.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.15 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    60 tokens (    0.72 ms per token,  1379.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.18 ms /    83 tokens (    0.69 ms per token,  1451.48 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     108.84 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.88 ms /    78 tokens (    0.65 ms per token,  1532.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    53 tokens (    0.81 ms per token,  1237.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.32 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    54 tokens (    0.80 ms per token,  1253.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.41 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.02 ms /    80 tokens (    0.65 ms per token,  1537.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      86.30 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    70 tokens (    0.71 ms per token,  1408.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.53 ms /   105 tokens (    0.62 ms per token,  1602.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.94 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.98 ms /    83 tokens (    0.69 ms per token,  1456.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.58 ms /   116 tokens (    0.63 ms per token,  1598.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     107.26 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    83 tokens (    0.69 ms per token,  1454.58 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     108.77 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    74 tokens (    0.68 ms per token,  1470.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    89 tokens (    0.65 ms per token,  1535.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.34 ms /   141 tokens (    0.67 ms per token,  1494.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     128.60 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.38 ms /    73 tokens (    0.69 ms per token,  1449.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.88 ms /    80 tokens (    0.65 ms per token,  1542.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      86.32 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    79 tokens (    0.65 ms per token,  1549.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.08 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.45 ms /   101 tokens (    0.64 ms per token,  1567.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.30 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.18 ms /   126 tokens (    0.59 ms per token,  1698.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     109.11 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /   150 runs   (    0.05 ms per token, 18970.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    74 tokens (    0.68 ms per token,  1472.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2504.65 ms /   149 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =    2619.16 ms /   223 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.29 ms /    65 tokens (    0.76 ms per token,  1318.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.12 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    72 tokens (    0.69 ms per token,  1439.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     100.96 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.77 ms /    93 tokens (    0.63 ms per token,  1582.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      93.24 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.34 ms /    57 tokens (    0.76 ms per token,  1315.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.27 ms /    67 tokens (    0.74 ms per token,  1359.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     100.30 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.79 ms /    89 tokens (    0.65 ms per token,  1540.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.07 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.83 ms /    81 tokens (    0.70 ms per token,  1425.43 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     108.06 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.88 ms /    77 tokens (    0.66 ms per token,  1513.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.46 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.71 ms /    80 tokens (    0.65 ms per token,  1546.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      86.60 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    76 tokens (    0.67 ms per token,  1502.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    59 tokens (    0.74 ms per token,  1345.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.83 ms /    95 tokens (    0.62 ms per token,  1614.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.88 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /   100 tokens (    0.64 ms per token,  1551.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      98.97 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    62 tokens (    0.71 ms per token,  1409.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.54 ms /   107 tokens (    0.61 ms per token,  1632.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.17 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    61 tokens (    0.72 ms per token,  1395.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.07 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.50 ms /   143 tokens (    0.66 ms per token,  1513.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     129.22 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    89 tokens (    0.65 ms per token,  1535.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.84 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    92 tokens (    0.63 ms per token,  1577.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    70 tokens (    0.72 ms per token,  1395.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.02 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    73 tokens (    0.69 ms per token,  1448.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.47 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.23 ms /    88 tokens (    0.66 ms per token,  1511.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.03 ms /   113 tokens (    0.64 ms per token,  1568.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     106.72 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.12 ms /   104 tokens (    0.63 ms per token,  1597.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     116.76 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.54 ms /   104 tokens (    0.63 ms per token,  1586.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.66 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    71 tokens (    0.70 ms per token,  1424.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.28 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    88 tokens (    0.66 ms per token,  1520.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.31 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.88 ms /    62 tokens (    0.71 ms per token,  1412.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    56 tokens (    0.77 ms per token,  1294.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    62 tokens (    0.71 ms per token,  1408.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    68 tokens (    0.73 ms per token,  1374.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.38 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.73 ms /   112 tokens (    0.60 ms per token,  1678.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     102.00 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.70 ms /   124 tokens (    0.59 ms per token,  1682.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     108.67 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    90 tokens (    0.64 ms per token,  1552.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.09 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    57 tokens (    0.76 ms per token,  1315.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.97 ms /   101 tokens (    0.64 ms per token,  1554.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     117.05 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.87 ms /   144 tokens (    0.66 ms per token,  1517.80 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     147.09 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.12 ms /   140 tokens (    0.67 ms per token,  1487.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     128.59 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    68 tokens (    0.73 ms per token,  1367.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.91 ms /   143 tokens (    0.66 ms per token,  1506.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     129.22 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    59 tokens (    0.74 ms per token,  1346.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      94.44 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    73 tokens (    0.69 ms per token,  1449.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.68 ms /   116 tokens (    0.63 ms per token,  1595.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.56 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    61 tokens (    0.72 ms per token,  1393.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.04 ms /    96 tokens (    0.61 ms per token,  1626.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      93.00 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.54 ms /    51 tokens (    0.83 ms per token,  1198.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      93.30 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.91 ms /   151 tokens (    0.64 ms per token,  1574.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     130.77 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.14 ms /   104 tokens (    0.63 ms per token,  1596.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.73 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.19 ms /   213 tokens (    0.60 ms per token,  1661.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.99 ms /     3 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     179.27 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.67 ms /    87 tokens (    0.66 ms per token,  1508.50 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.28 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    70 tokens (    0.71 ms per token,  1404.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.18 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    76 tokens (    0.67 ms per token,  1494.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.75 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.10 ms /   110 tokens (    0.60 ms per token,  1664.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.47 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    69 tokens (    0.72 ms per token,  1391.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.72 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.09 ms /   102 tokens (    0.64 ms per token,  1567.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.50 ms /     2 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =      99.90 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.28 ms /   116 tokens (    0.62 ms per token,  1604.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     107.03 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.03 ms /   126 tokens (    0.59 ms per token,  1702.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     108.80 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.98 ms /    97 tokens (    0.66 ms per token,  1516.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =      99.06 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    88 tokens (    0.66 ms per token,  1521.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.47 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    67 tokens (    0.74 ms per token,  1349.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.99 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.20 ms /   103 tokens (    0.63 ms per token,  1579.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     116.42 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.54 ms /   111 tokens (    0.60 ms per token,  1668.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     101.17 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    60 tokens (    0.73 ms per token,  1363.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      95.29 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    73 tokens (    0.69 ms per token,  1453.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.84 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.63 ms /   101 tokens (    0.64 ms per token,  1562.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      99.43 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.20 ms /    66 tokens (    0.75 ms per token,  1341.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.35 ms /    66 tokens (    0.75 ms per token,  1337.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.95 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.94 ms /    62 tokens (    0.71 ms per token,  1411.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    94 tokens (    0.62 ms per token,  1604.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.56 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    60 tokens (    0.73 ms per token,  1374.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    61 tokens (    0.72 ms per token,  1381.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.45 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.22 ms /    96 tokens (    0.62 ms per token,  1620.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.59 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.54 ms /   128 tokens (    0.58 ms per token,  1717.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     109.28 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.67 ms /    88 tokens (    0.66 ms per token,  1526.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.10 ms /    65 tokens (    0.76 ms per token,  1323.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.36 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    86 tokens (    0.67 ms per token,  1492.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.29 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.83 ms /   125 tokens (    0.59 ms per token,  1693.15 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     125.19 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.40 ms /    49 tokens (    0.87 ms per token,  1155.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      93.16 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    83 tokens (    0.69 ms per token,  1452.98 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     108.42 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    69 tokens (    0.72 ms per token,  1383.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.52 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.81 ms /   112 tokens (    0.60 ms per token,  1676.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.43 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    64 tokens (    0.69 ms per token,  1442.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.42 ms /    76 tokens (    0.66 ms per token,  1507.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.74 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.67 ms /    85 tokens (    0.68 ms per token,  1474.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.13 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.16 ms /    85 tokens (    0.67 ms per token,  1486.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.68 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.59 ms /    75 tokens (    0.67 ms per token,  1482.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.85 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.96 ms /    96 tokens (    0.61 ms per token,  1628.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.18 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.34 ms /    93 tokens (    0.63 ms per token,  1594.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.09 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.64 ms /   108 tokens (    0.61 ms per token,  1645.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.88 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    74 tokens (    0.68 ms per token,  1469.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.74 ms /    94 tokens (    0.62 ms per token,  1600.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.45 ms /   132 tokens (    0.71 ms per token,  1412.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     127.60 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.29 ms /    63 tokens (    0.70 ms per token,  1422.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.22 ms /   103 tokens (    0.63 ms per token,  1579.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.95 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    63 tokens (    0.70 ms per token,  1429.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      95.26 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    65 tokens (    0.76 ms per token,  1321.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.41 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.63 ms /    51 tokens (    0.84 ms per token,  1196.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      76.08 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    69 tokens (    0.72 ms per token,  1388.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.38 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.66 ms /   150 tokens (    0.64 ms per token,  1568.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     130.34 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.50 ms /   136 tokens (    0.69 ms per token,  1454.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     127.63 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.94 ms /    88 tokens (    0.66 ms per token,  1518.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.34 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    75 tokens (    0.67 ms per token,  1486.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.83 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.53 ms /    85 tokens (    0.68 ms per token,  1477.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     109.39 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.64 ms /    93 tokens (    0.63 ms per token,  1585.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.83 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.47 ms /   106 tokens (    0.62 ms per token,  1618.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.36 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    74 tokens (    0.68 ms per token,  1471.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.86 ms /   108 tokens (    0.61 ms per token,  1639.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.65 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.19 ms /   115 tokens (    0.63 ms per token,  1592.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     124.90 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.63 ms /   181 tokens (    0.61 ms per token,  1636.04 tokens per second)\n",
      "llama_print_timings:        eval time =      50.71 ms /     3 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     162.36 ms /   184 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.46 ms /   100 tokens (    0.64 ms per token,  1551.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      99.17 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.30 ms /    73 tokens (    0.69 ms per token,  1451.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    91 tokens (    0.64 ms per token,  1560.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.84 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.92 ms /   169 tokens (    0.64 ms per token,  1551.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     143.92 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.19 ms /   213 tokens (    0.60 ms per token,  1661.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.95 ms /     3 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     179.12 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.11 ms /    61 tokens (    0.72 ms per token,  1383.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.46 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.00 ms /   130 tokens (    0.72 ms per token,  1397.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     127.39 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.99 ms /    97 tokens (    0.66 ms per token,  1515.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      98.61 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.82 ms /    80 tokens (    0.65 ms per token,  1543.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      86.92 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.92 ms /   109 tokens (    0.60 ms per token,  1653.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.95 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    94 tokens (    0.62 ms per token,  1603.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     110.29 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    77 tokens (    0.66 ms per token,  1514.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      84.64 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.42 ms /    83 tokens (    0.69 ms per token,  1445.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.61 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    79 tokens (    0.65 ms per token,  1548.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.40 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    59 tokens (    0.74 ms per token,  1349.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.36 ms /    65 tokens (    0.76 ms per token,  1316.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.56 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.12 ms /   115 tokens (    0.63 ms per token,  1594.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     106.99 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /    60 tokens (    0.73 ms per token,  1373.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.43 ms /    96 tokens (    0.62 ms per token,  1615.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      94.30 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.54 ms /    86 tokens (    0.67 ms per token,  1494.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    74 tokens (    0.68 ms per token,  1476.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.15 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    73 tokens (    0.69 ms per token,  1451.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.95 ms /    94 tokens (    0.63 ms per token,  1594.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.89 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.76 ms /   218 tokens (    0.59 ms per token,  1693.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     163.15 ms /   220 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.39 ms /    65 tokens (    0.76 ms per token,  1316.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      82.77 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    91 tokens (    0.64 ms per token,  1556.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.04 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.39 ms /    99 tokens (    0.65 ms per token,  1537.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      98.74 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.84 ms /   108 tokens (    0.61 ms per token,  1640.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     100.05 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.78 ms /    89 tokens (    0.65 ms per token,  1540.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.05 ms /   113 tokens (    0.64 ms per token,  1568.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     106.75 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.59 ms /   112 tokens (    0.59 ms per token,  1681.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.67 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    64 tokens (    0.69 ms per token,  1447.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      95.38 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    55 tokens (    0.78 ms per token,  1279.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.50 ms /   141 tokens (    0.67 ms per token,  1492.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     128.99 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.81 ms /    78 tokens (    0.65 ms per token,  1535.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =      85.56 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.01 ms /    86 tokens (    0.67 ms per token,  1482.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.91 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.11 ms /   163 tokens (    0.66 ms per token,  1507.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     160.30 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    79 tokens (    0.64 ms per token,  1552.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.27 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    73 tokens (    0.69 ms per token,  1457.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.71 ms /   112 tokens (    0.60 ms per token,  1678.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     101.53 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.03 ms /    97 tokens (    0.66 ms per token,  1514.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      98.04 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.70 ms /   123 tokens (    0.60 ms per token,  1669.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     108.03 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    72 tokens (    0.69 ms per token,  1442.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.55 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.66 ms /    93 tokens (    0.63 ms per token,  1585.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.80 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    69 tokens (    0.72 ms per token,  1389.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    86 tokens (    0.67 ms per token,  1490.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.97 ms /    96 tokens (    0.61 ms per token,  1627.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    67 tokens (    0.73 ms per token,  1362.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.30 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    59 tokens (    0.74 ms per token,  1353.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    92 tokens (    0.64 ms per token,  1573.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.56 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.30 ms /   147 tokens (    0.65 ms per token,  1542.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     130.19 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.28 ms /   121 tokens (    0.61 ms per token,  1651.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.45 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.69 ms /    75 tokens (    0.68 ms per token,  1479.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    86 tokens (    0.67 ms per token,  1490.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      92.61 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.01 ms /    89 tokens (    0.65 ms per token,  1534.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.48 ms /   134 tokens (    0.70 ms per token,  1433.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.39 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.93 ms /    82 tokens (    0.69 ms per token,  1440.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     108.86 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.01 ms /    97 tokens (    0.66 ms per token,  1515.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      98.15 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.49 ms /   133 tokens (    0.70 ms per token,  1422.58 tokens per second)\n",
      "llama_print_timings:        eval time =      50.59 ms /     3 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     145.56 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    79 tokens (    0.64 ms per token,  1555.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.43 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.46 ms /    60 tokens (    0.72 ms per token,  1380.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.97 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.61 ms /    51 tokens (    0.84 ms per token,  1197.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.49 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.64 ms /    86 tokens (    0.67 ms per token,  1492.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.68 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /    99 tokens (    0.65 ms per token,  1533.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      99.13 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    52 tokens (    0.83 ms per token,  1210.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.79 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.66 ms /   223 tokens (    0.58 ms per token,  1719.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.87 ms /     3 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     180.84 ms /   226 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.31 ms /    58 tokens (    0.75 ms per token,  1339.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.63 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.37 ms /   133 tokens (    0.70 ms per token,  1424.49 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     145.12 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    54 tokens (    0.80 ms per token,  1257.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.53 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.77 ms /   102 tokens (    0.63 ms per token,  1574.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      98.83 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    69 tokens (    0.72 ms per token,  1387.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     100.31 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    74 tokens (    0.68 ms per token,  1468.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.68 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.67 ms /   100 tokens (    0.65 ms per token,  1546.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.40 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    56 tokens (    0.77 ms per token,  1297.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.35 ms /    84 tokens (    0.68 ms per token,  1464.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     108.71 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    74 tokens (    0.68 ms per token,  1475.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =     100.54 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    72 tokens (    0.70 ms per token,  1435.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      84.56 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.98 ms /   113 tokens (    0.64 ms per token,  1569.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     106.43 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    88 tokens (    0.66 ms per token,  1515.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.66 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    74 tokens (    0.68 ms per token,  1472.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     100.92 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.35 ms /   132 tokens (    0.71 ms per token,  1414.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     127.74 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    69 tokens (    0.72 ms per token,  1388.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.66 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.73 ms /    93 tokens (    0.63 ms per token,  1583.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.95 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    76 tokens (    0.66 ms per token,  1509.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.12 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.53 ms /    92 tokens (    0.64 ms per token,  1571.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    76 tokens (    0.66 ms per token,  1506.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     101.32 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.24 ms /    79 tokens (    0.65 ms per token,  1541.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =      85.92 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.27 ms /    84 tokens (    0.68 ms per token,  1466.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    75 tokens (    0.67 ms per token,  1489.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =     101.07 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    78 tokens (    0.65 ms per token,  1529.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      84.73 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.63 ms /    77 tokens (    0.66 ms per token,  1520.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.57 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     101.38 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.82 ms /   201 tokens (    0.62 ms per token,  1623.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     158.11 ms /   203 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.38 ms /    91 tokens (    0.64 ms per token,  1558.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.11 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.38 ms /    67 tokens (    0.74 ms per token,  1356.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.84 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    83 tokens (    0.69 ms per token,  1453.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.22 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    72 tokens (    0.70 ms per token,  1434.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.43 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.33 ms /   120 tokens (    0.61 ms per token,  1636.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.15 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    61 tokens (    0.72 ms per token,  1397.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.34 ms /    85 tokens (    0.67 ms per token,  1482.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.25 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.86 ms /   118 tokens (    0.62 ms per token,  1619.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.28 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.97 ms /   131 tokens (    0.71 ms per token,  1409.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     127.50 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    67 tokens (    0.74 ms per token,  1350.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    58 tokens (    0.75 ms per token,  1326.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    87 tokens (    0.66 ms per token,  1504.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    78 tokens (    0.65 ms per token,  1534.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      85.06 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.93 ms /   109 tokens (    0.60 ms per token,  1653.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.81 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    69 tokens (    0.72 ms per token,  1381.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.89 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    77 tokens (    0.66 ms per token,  1514.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    56 tokens (    0.77 ms per token,  1299.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.70 ms /    81 tokens (    0.70 ms per token,  1428.52 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     108.03 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.76 ms /    80 tokens (    0.65 ms per token,  1545.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      86.61 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.67 ms /    80 tokens (    0.65 ms per token,  1548.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      86.48 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.43 ms /   125 tokens (    0.60 ms per token,  1679.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.32 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    74 tokens (    0.68 ms per token,  1479.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.31 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.70 ms /   112 tokens (    0.60 ms per token,  1679.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     101.15 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.25 ms /    65 tokens (    0.76 ms per token,  1319.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    84 tokens (    0.68 ms per token,  1467.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    51 tokens (    0.84 ms per token,  1195.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.22 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    74 tokens (    0.68 ms per token,  1462.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    71 tokens (    0.70 ms per token,  1426.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    54 tokens (    0.80 ms per token,  1252.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      76.70 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    90 tokens (    0.65 ms per token,  1547.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     109.52 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.14 ms /    79 tokens (    0.65 ms per token,  1544.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      85.32 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.76 ms /   103 tokens (    0.63 ms per token,  1590.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.37 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    69 tokens (    0.72 ms per token,  1393.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     100.34 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.99 ms /   246 tokens (    0.59 ms per token,  1708.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     178.61 ms /   248 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.18 ms /   109 tokens (    0.61 ms per token,  1647.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     101.00 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.03 ms /    97 tokens (    0.66 ms per token,  1514.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.52 ms /     2 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =      98.17 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    67 tokens (    0.74 ms per token,  1353.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.97 ms /    70 tokens (    0.71 ms per token,  1400.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.88 ms /   147 tokens (    0.65 ms per token,  1533.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     130.96 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    72 tokens (    0.70 ms per token,  1432.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    77 tokens (    0.66 ms per token,  1517.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    71 tokens (    0.70 ms per token,  1421.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.71 ms /   239 tokens (    0.60 ms per token,  1674.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     176.57 ms /   241 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.22 ms /   151 tokens (    0.64 ms per token,  1569.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     130.66 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.67 ms /   123 tokens (    0.60 ms per token,  1669.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     108.11 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.93 ms /    83 tokens (    0.69 ms per token,  1458.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.07 ms /   137 tokens (    0.69 ms per token,  1456.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     128.92 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /   100 tokens (    0.65 ms per token,  1549.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.26 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    89 tokens (    0.65 ms per token,  1535.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.86 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    73 tokens (    0.69 ms per token,  1457.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.33 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    68 tokens (    0.73 ms per token,  1367.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    66 tokens (    0.75 ms per token,  1329.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.27 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.40 ms /    68 tokens (    0.73 ms per token,  1376.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     100.33 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.64 ms /   116 tokens (    0.63 ms per token,  1596.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     107.06 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.28 ms /    92 tokens (    0.63 ms per token,  1578.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.62 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.59 ms /   121 tokens (    0.61 ms per token,  1644.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     108.74 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    75 tokens (    0.67 ms per token,  1487.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.60 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    85 tokens (    0.68 ms per token,  1480.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.75 ms /   112 tokens (    0.60 ms per token,  1677.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     101.81 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    74 tokens (    0.68 ms per token,  1471.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.61 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    63 tokens (    0.70 ms per token,  1420.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.39 ms /   165 tokens (    0.66 ms per token,  1522.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     143.14 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    73 tokens (    0.69 ms per token,  1455.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      84.96 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.88 ms /    97 tokens (    0.66 ms per token,  1518.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      98.31 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    71 tokens (    0.70 ms per token,  1420.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.14 ms /    88 tokens (    0.66 ms per token,  1513.67 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     110.09 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    79 tokens (    0.64 ms per token,  1553.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      85.14 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.42 ms /    67 tokens (    0.74 ms per token,  1355.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.59 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.53 ms /   105 tokens (    0.62 ms per token,  1602.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.13 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.23 ms /   163 tokens (    0.66 ms per token,  1506.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     142.71 ms /   165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    69 tokens (    0.72 ms per token,  1387.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.59 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    70 tokens (    0.72 ms per token,  1396.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      84.86 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.11 ms /   111 tokens (    0.60 ms per token,  1679.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.98 ms /    89 tokens (    0.65 ms per token,  1534.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.70 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.65 ms /    93 tokens (    0.63 ms per token,  1585.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      93.16 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.75 ms /   108 tokens (    0.61 ms per token,  1642.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.89 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    70 tokens (    0.71 ms per token,  1407.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.35 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.31 ms /   215 tokens (    0.60 ms per token,  1675.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     162.55 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    58 tokens (    0.75 ms per token,  1327.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.27 ms /    65 tokens (    0.76 ms per token,  1319.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      82.55 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.13 ms /   117 tokens (    0.63 ms per token,  1599.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.35 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    69 tokens (    0.72 ms per token,  1388.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.44 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.97 ms /    95 tokens (    0.62 ms per token,  1610.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      93.49 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    70 tokens (    0.71 ms per token,  1407.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.01 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.69 ms /   129 tokens (    0.72 ms per token,  1391.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     127.16 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.33 ms /    66 tokens (    0.75 ms per token,  1337.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.84 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.21 ms /    55 tokens (    0.79 ms per token,  1272.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.82 ms /   131 tokens (    0.71 ms per token,  1411.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     127.55 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.82 ms /    81 tokens (    0.70 ms per token,  1425.65 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     107.96 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    92 tokens (    0.64 ms per token,  1574.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.21 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.26 ms /   172 tokens (    0.64 ms per token,  1574.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =     143.65 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.71 ms /   102 tokens (    0.63 ms per token,  1576.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.09 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.28 ms /    66 tokens (    0.75 ms per token,  1339.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.59 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.41 ms /   154 tokens (    0.63 ms per token,  1597.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =     131.10 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    71 tokens (    0.70 ms per token,  1424.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.26 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.49 ms /   104 tokens (    0.63 ms per token,  1587.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.24 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    76 tokens (    0.66 ms per token,  1507.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.51 ms /    68 tokens (    0.73 ms per token,  1373.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.86 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.47 ms /   121 tokens (    0.61 ms per token,  1646.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.95 ms per token,    58.99 tokens per second)\n",
      "llama_print_timings:       total time =     109.34 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.18 ms /   120 tokens (    0.61 ms per token,  1639.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     107.86 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    79 tokens (    0.64 ms per token,  1550.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      84.87 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    75 tokens (    0.67 ms per token,  1489.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     101.37 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.41 ms /   103 tokens (    0.64 ms per token,  1574.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     100.02 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.03 ms /    83 tokens (    0.69 ms per token,  1455.37 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     108.64 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    53 tokens (    0.82 ms per token,  1223.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    72 tokens (    0.70 ms per token,  1431.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.55 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.03 ms /    96 tokens (    0.61 ms per token,  1626.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.99 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.82 ms /    78 tokens (    0.65 ms per token,  1534.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      85.41 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.91 ms /    78 tokens (    0.65 ms per token,  1532.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =      85.15 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.61 ms /   112 tokens (    0.59 ms per token,  1681.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     101.38 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.85 ms /   119 tokens (    0.61 ms per token,  1633.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     107.26 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    61 tokens (    0.72 ms per token,  1397.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      93.74 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    66 tokens (    0.75 ms per token,  1329.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.36 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    73 tokens (    0.69 ms per token,  1446.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.67 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    85 tokens (    0.68 ms per token,  1479.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.86 ms /    45 tokens (    0.82 ms per token,  1220.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      70.83 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.69 ms /   112 tokens (    0.60 ms per token,  1679.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.98 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    68 tokens (    0.73 ms per token,  1376.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    78 tokens (    0.65 ms per token,  1534.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.25 ms /     2 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =      85.16 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    75 tokens (    0.67 ms per token,  1489.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.29 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.09 ms /   104 tokens (    0.63 ms per token,  1597.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      99.86 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.39 ms /   154 tokens (    0.63 ms per token,  1597.76 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     148.85 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    72 tokens (    0.70 ms per token,  1434.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.00 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    88 tokens (    0.66 ms per token,  1523.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.65 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.19 ms /    71 tokens (    0.71 ms per token,  1414.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.90 ms /    88 tokens (    0.66 ms per token,  1519.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.70 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     7 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    73 tokens (    0.69 ms per token,  1457.58 tokens per second)\n",
      "llama_print_timings:        eval time =      98.93 ms /     6 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     150.95 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    74 tokens (    0.68 ms per token,  1466.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      85.27 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.89 ms /   109 tokens (    0.60 ms per token,  1654.25 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     117.78 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    75 tokens (    0.67 ms per token,  1486.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     101.89 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.74 ms /    87 tokens (    0.66 ms per token,  1506.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.86 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    69 tokens (    0.72 ms per token,  1387.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.46 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.41 ms /    85 tokens (    0.68 ms per token,  1480.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.40 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.61 ms /    99 tokens (    0.65 ms per token,  1532.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.25 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    78 tokens (    0.65 ms per token,  1536.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      84.99 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.22 ms /   166 tokens (    0.65 ms per token,  1533.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     142.72 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    86 tokens (    0.67 ms per token,  1490.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =      92.70 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.95 ms /    88 tokens (    0.66 ms per token,  1518.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.50 ms /   106 tokens (    0.62 ms per token,  1618.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.23 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.15 ms /    83 tokens (    0.69 ms per token,  1452.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.10 ms /   118 tokens (    0.62 ms per token,  1614.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     107.57 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.87 ms /    95 tokens (    0.62 ms per token,  1613.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.40 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    84 tokens (    0.68 ms per token,  1467.40 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     108.75 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.77 ms /   129 tokens (    0.72 ms per token,  1390.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     127.36 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    72 tokens (    0.70 ms per token,  1437.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.96 ms /   124 tokens (    0.60 ms per token,  1676.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     108.40 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.95 ms /   101 tokens (    0.64 ms per token,  1554.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      99.61 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.02 ms /    78 tokens (    0.65 ms per token,  1528.81 tokens per second)\n",
      "llama_print_timings:        eval time =      50.07 ms /     3 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     102.65 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.89 ms /   103 tokens (    0.63 ms per token,  1587.23 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     116.92 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.34 ms /    85 tokens (    0.67 ms per token,  1482.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1428.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    69 tokens (    0.72 ms per token,  1385.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    86 tokens (    0.67 ms per token,  1492.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.50 ms /    66 tokens (    0.75 ms per token,  1333.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.54 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.24 ms /    63 tokens (    0.70 ms per token,  1423.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    52 tokens (    0.82 ms per token,  1217.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.21 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    85 tokens (    0.68 ms per token,  1476.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.43 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.91 ms /    95 tokens (    0.62 ms per token,  1612.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =      94.31 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.04 ms /   111 tokens (    0.59 ms per token,  1680.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.79 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.66 ms /    87 tokens (    0.66 ms per token,  1508.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    64 tokens (    0.69 ms per token,  1450.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    64 tokens (    0.69 ms per token,  1453.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    70 tokens (    0.71 ms per token,  1405.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.39 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    83 tokens (    0.69 ms per token,  1445.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.44 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    87 tokens (    0.66 ms per token,  1504.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.13 ms /   111 tokens (    0.60 ms per token,  1678.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.63 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    54 tokens (    0.79 ms per token,  1258.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.73 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.56 ms /    75 tokens (    0.67 ms per token,  1483.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.74 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.95 ms /   102 tokens (    0.64 ms per token,  1570.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      98.99 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.97 ms /   109 tokens (    0.61 ms per token,  1652.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.23 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   108 tokens (    0.61 ms per token,  1644.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.37 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    60 tokens (    0.73 ms per token,  1364.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.46 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.52 ms /    94 tokens (    0.62 ms per token,  1606.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.61 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.44 ms /    67 tokens (    0.74 ms per token,  1355.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =     100.34 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    73 tokens (    0.69 ms per token,  1455.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    74 tokens (    0.68 ms per token,  1470.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.13 ms /   102 tokens (    0.64 ms per token,  1566.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.36 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.59 ms /   230 tokens (    0.62 ms per token,  1624.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     176.22 ms /   232 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    65 tokens (    0.76 ms per token,  1316.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.64 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.17 ms /   159 tokens (    0.61 ms per token,  1636.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     131.90 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.19 ms /    79 tokens (    0.65 ms per token,  1543.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.78 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    61 tokens (    0.72 ms per token,  1392.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.87 ms /   124 tokens (    0.60 ms per token,  1678.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.95 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    62 tokens (    0.71 ms per token,  1409.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.52 ms /   136 tokens (    0.69 ms per token,  1454.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     128.38 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    58 tokens (    0.75 ms per token,  1335.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.05 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    59 tokens (    0.74 ms per token,  1351.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.38 ms /    57 tokens (    0.76 ms per token,  1313.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.69 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.14 ms /    82 tokens (    0.70 ms per token,  1434.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     109.15 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.75 ms /    52 tokens (    0.82 ms per token,  1216.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.45 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.03 ms /    80 tokens (    0.65 ms per token,  1537.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      86.64 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.83 ms /    95 tokens (    0.62 ms per token,  1614.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      92.87 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    75 tokens (    0.67 ms per token,  1484.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.36 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.66 ms /   122 tokens (    0.60 ms per token,  1656.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     108.25 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.76 ms /    80 tokens (    0.65 ms per token,  1545.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      85.70 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.10 ms /    74 tokens (    0.68 ms per token,  1476.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.23 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.31 ms /    97 tokens (    0.66 ms per token,  1508.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      98.99 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.23 ms /   188 tokens (    0.59 ms per token,  1690.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     146.48 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    82 tokens (    0.70 ms per token,  1437.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.42 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     166.61 ms /   258 tokens (    0.65 ms per token,  1548.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.42 ms /     2 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     201.29 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    60 tokens (    0.73 ms per token,  1369.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     169.84 ms /   274 tokens (    0.62 ms per token,  1613.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     204.19 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.96 ms /   165 tokens (    0.65 ms per token,  1528.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     142.16 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.74 ms /    76 tokens (    0.67 ms per token,  1497.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     101.26 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.07 ms /   211 tokens (    0.61 ms per token,  1647.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     162.27 ms /   213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    93 tokens (    0.63 ms per token,  1586.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.44 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.08 ms /   159 tokens (    0.61 ms per token,  1637.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     131.91 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.33 ms /   133 tokens (    0.70 ms per token,  1425.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     128.60 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.91 ms /    82 tokens (    0.69 ms per token,  1440.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      91.59 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    62 tokens (    0.71 ms per token,  1403.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      94.94 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    71 tokens (    0.70 ms per token,  1419.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.54 ms /    92 tokens (    0.64 ms per token,  1571.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.51 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.79 ms /    85 tokens (    0.68 ms per token,  1470.92 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     110.04 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    84 tokens (    0.68 ms per token,  1471.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.60 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    66 tokens (    0.75 ms per token,  1341.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.78 ms /   130 tokens (    0.71 ms per token,  1401.24 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     145.01 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    94 tokens (    0.62 ms per token,  1603.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.82 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.79 ms /   101 tokens (    0.64 ms per token,  1558.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.12 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    55 tokens (    0.78 ms per token,  1276.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      93.70 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.39 ms /   131 tokens (    0.71 ms per token,  1402.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     127.62 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    63 tokens (    0.70 ms per token,  1432.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.74 ms /   141 tokens (    0.67 ms per token,  1488.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     129.05 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    67 tokens (    0.74 ms per token,  1348.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.21 ms /   119 tokens (    0.62 ms per token,  1625.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.63 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.12 ms /   230 tokens (    0.61 ms per token,  1629.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     175.40 ms /   232 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.45 ms /   105 tokens (    0.62 ms per token,  1604.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.73 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.37 ms /    64 tokens (    0.69 ms per token,  1442.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    65 tokens (    0.76 ms per token,  1313.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.91 ms /   125 tokens (    0.59 ms per token,  1691.34 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     125.45 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    77 tokens (    0.66 ms per token,  1517.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.51 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.98 ms /   108 tokens (    0.61 ms per token,  1636.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     100.72 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.39 ms /    65 tokens (    0.76 ms per token,  1316.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.64 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.32 ms /    56 tokens (    0.77 ms per token,  1292.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.05 ms /    81 tokens (    0.70 ms per token,  1419.88 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.05 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.04 ms /    96 tokens (    0.62 ms per token,  1625.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.94 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    72 tokens (    0.69 ms per token,  1439.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.29 ms /    89 tokens (    0.65 ms per token,  1526.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.72 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.97 ms /    71 tokens (    0.70 ms per token,  1420.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.71 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    72 tokens (    0.70 ms per token,  1429.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.65 ms /   128 tokens (    0.58 ms per token,  1714.58 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     126.39 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.56 ms /   100 tokens (    0.65 ms per token,  1548.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     116.62 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    92 tokens (    0.63 ms per token,  1578.72 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     109.77 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.05 ms /    80 tokens (    0.65 ms per token,  1537.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      86.71 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.73 ms /    89 tokens (    0.65 ms per token,  1541.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =      91.94 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    71 tokens (    0.70 ms per token,  1423.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.49 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.05 ms /   109 tokens (    0.61 ms per token,  1650.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.66 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.63 ms /   116 tokens (    0.63 ms per token,  1597.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     106.75 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.74 ms /    76 tokens (    0.67 ms per token,  1497.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      85.09 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.07 ms /   139 tokens (    0.68 ms per token,  1477.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.24 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    72 tokens (    0.69 ms per token,  1439.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.15 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    91 tokens (    0.64 ms per token,  1559.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     110.11 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.31 ms /    62 tokens (    0.71 ms per token,  1399.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.68 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.95 ms /   129 tokens (    0.72 ms per token,  1387.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     127.58 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    87 tokens (    0.66 ms per token,  1510.13 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.63 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.09 ms /    55 tokens (    0.78 ms per token,  1276.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.28 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.54 ms /   292 tokens (    0.64 ms per token,  1556.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     221.89 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    59 tokens (    0.74 ms per token,  1351.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.35 ms /    58 tokens (    0.75 ms per token,  1337.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      76.86 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.33 ms /    97 tokens (    0.66 ms per token,  1507.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      99.27 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    72 tokens (    0.70 ms per token,  1436.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.42 ms /    91 tokens (    0.64 ms per token,  1557.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.71 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.10 ms /   113 tokens (    0.64 ms per token,  1567.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     106.49 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1429.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    73 tokens (    0.69 ms per token,  1448.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.47 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.88 ms /   136 tokens (    0.69 ms per token,  1448.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.88 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.98 ms /   118 tokens (    0.62 ms per token,  1616.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     107.89 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.32 ms /   140 tokens (    0.67 ms per token,  1484.26 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     146.10 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    64 tokens (    0.69 ms per token,  1449.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.78 ms /   121 tokens (    0.61 ms per token,  1640.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     108.34 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.77 ms /    87 tokens (    0.66 ms per token,  1506.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.51 ms /   106 tokens (    0.62 ms per token,  1617.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.78 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.35 ms /   174 tokens (    0.63 ms per token,  1591.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     144.38 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    62 tokens (    0.71 ms per token,  1406.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    54 tokens (    0.80 ms per token,  1254.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.88 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.35 ms /   126 tokens (    0.59 ms per token,  1694.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     108.75 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    62 tokens (    0.71 ms per token,  1405.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.48 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    72 tokens (    0.70 ms per token,  1430.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.20 ms /    97 tokens (    0.66 ms per token,  1510.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      98.79 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.62 ms /   121 tokens (    0.61 ms per token,  1643.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.80 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.80 ms /    78 tokens (    0.65 ms per token,  1535.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      84.35 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.46 ms /   115 tokens (    0.63 ms per token,  1587.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.20 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.45 ms /    92 tokens (    0.64 ms per token,  1573.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.85 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.94 ms /   197 tokens (    0.62 ms per token,  1602.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     157.88 ms /   199 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.20 ms /   159 tokens (    0.61 ms per token,  1635.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     131.90 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    69 tokens (    0.72 ms per token,  1382.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      83.87 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    85 tokens (    0.67 ms per token,  1482.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.90 ms /    87 tokens (    0.67 ms per token,  1502.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.14 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.23 ms /   103 tokens (    0.63 ms per token,  1579.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     100.03 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.87 ms /    95 tokens (    0.62 ms per token,  1613.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      93.14 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.87 ms /   101 tokens (    0.64 ms per token,  1557.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      99.33 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.48 ms /   154 tokens (    0.63 ms per token,  1596.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     131.48 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.44 ms /    58 tokens (    0.75 ms per token,  1335.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    76 tokens (    0.67 ms per token,  1494.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.69 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    65 tokens (    0.76 ms per token,  1316.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      99.90 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    70 tokens (    0.71 ms per token,  1403.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.69 ms /    80 tokens (    0.65 ms per token,  1547.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.85 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    45 tokens (    0.82 ms per token,  1224.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      70.42 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.52 ms /   106 tokens (    0.62 ms per token,  1617.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     100.56 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.08 ms /   144 tokens (    0.66 ms per token,  1514.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     129.74 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.62 ms /   112 tokens (    0.59 ms per token,  1681.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     118.27 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.89 ms /    82 tokens (    0.69 ms per token,  1441.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.58 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.77 ms /   135 tokens (    0.69 ms per token,  1439.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     127.88 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.07 ms /   235 tokens (    0.60 ms per token,  1654.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     176.01 ms /   237 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    75 tokens (    0.67 ms per token,  1482.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.23 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.20 ms /    84 tokens (    0.68 ms per token,  1468.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.46 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.70 ms /   134 tokens (    0.70 ms per token,  1430.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     145.58 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    75 tokens (    0.67 ms per token,  1487.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.47 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.70 ms /   134 tokens (    0.70 ms per token,  1430.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     128.16 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    74 tokens (    0.68 ms per token,  1470.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    78 tokens (    0.65 ms per token,  1530.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.25 ms /     2 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =      85.30 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    67 tokens (    0.74 ms per token,  1348.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      83.06 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    65 tokens (    0.76 ms per token,  1315.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.28 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.28 ms /   104 tokens (    0.63 ms per token,  1593.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.70 ms /   121 tokens (    0.61 ms per token,  1641.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     109.01 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.07 ms /    83 tokens (    0.69 ms per token,  1454.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.51 ms /     2 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =      91.54 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.63 ms /    93 tokens (    0.63 ms per token,  1586.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.72 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.66 ms /    81 tokens (    0.70 ms per token,  1429.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.32 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.20 ms /   113 tokens (    0.64 ms per token,  1565.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     106.82 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.19 ms /   166 tokens (    0.65 ms per token,  1534.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     142.67 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.92 ms /    61 tokens (    0.72 ms per token,  1388.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    72 tokens (    0.70 ms per token,  1429.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.70 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.20 ms /    79 tokens (    0.65 ms per token,  1543.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.18 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.60 ms /    59 tokens (    0.74 ms per token,  1353.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.98 ms /    88 tokens (    0.66 ms per token,  1517.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.69 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.34 ms /   106 tokens (    0.62 ms per token,  1622.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.99 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.14 ms /   141 tokens (    0.67 ms per token,  1497.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     129.22 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.04 ms /    97 tokens (    0.66 ms per token,  1514.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      98.38 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    77 tokens (    0.66 ms per token,  1511.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      85.15 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.20 ms /    92 tokens (    0.63 ms per token,  1580.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.61 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    90 tokens (    0.65 ms per token,  1544.85 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.77 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.64 ms /   173 tokens (    0.63 ms per token,  1577.96 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     161.33 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.97 ms /    80 tokens (    0.65 ms per token,  1539.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =      87.47 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.56 ms /   135 tokens (    0.69 ms per token,  1442.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     128.32 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /   147 runs   (    0.05 ms per token, 18858.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.88 ms /   125 tokens (    0.59 ms per token,  1691.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2450.49 ms /   146 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    2586.85 ms /   271 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    78 tokens (    0.65 ms per token,  1528.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.08 ms /     3 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     102.76 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    82 tokens (    0.70 ms per token,  1436.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.08 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    70 tokens (    0.71 ms per token,  1407.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.52 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    66 tokens (    0.75 ms per token,  1331.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.45 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.49 ms /    84 tokens (    0.68 ms per token,  1461.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.68 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.06 ms /    65 tokens (    0.75 ms per token,  1324.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      82.72 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /    99 tokens (    0.65 ms per token,  1533.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      99.57 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.74 ms /    80 tokens (    0.65 ms per token,  1546.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      85.92 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.05 ms /   172 tokens (    0.63 ms per token,  1577.32 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     161.05 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    89 tokens (    0.66 ms per token,  1526.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.11 ms /   113 tokens (    0.64 ms per token,  1567.14 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     123.75 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.95 ms /    89 tokens (    0.65 ms per token,  1535.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.62 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.47 ms /   152 tokens (    0.63 ms per token,  1575.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     130.80 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.70 ms /    91 tokens (    0.65 ms per token,  1550.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      94.04 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.25 ms /    57 tokens (    0.76 ms per token,  1317.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.01 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.93 ms /   108 tokens (    0.61 ms per token,  1638.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     100.05 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    69 tokens (    0.72 ms per token,  1394.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    60 tokens (    0.73 ms per token,  1373.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.41 ms /    84 tokens (    0.68 ms per token,  1463.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      91.90 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    86 tokens (    0.67 ms per token,  1496.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.55 ms /   117 tokens (    0.62 ms per token,  1612.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     107.38 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.29 ms /    92 tokens (    0.63 ms per token,  1578.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.08 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.05 ms /   103 tokens (    0.63 ms per token,  1583.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      99.03 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    71 tokens (    0.70 ms per token,  1421.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.36 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.66 ms /   122 tokens (    0.60 ms per token,  1656.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     108.46 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.98 ms /   162 tokens (    0.67 ms per token,  1500.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     142.73 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.70 ms /    92 tokens (    0.64 ms per token,  1567.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      93.67 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.96 ms /    95 tokens (    0.62 ms per token,  1611.21 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     110.81 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    78 tokens (    0.65 ms per token,  1535.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.41 ms /   107 tokens (    0.61 ms per token,  1635.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.56 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    72 tokens (    0.70 ms per token,  1437.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    84 tokens (    0.68 ms per token,  1461.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.16 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    56 tokens (    0.77 ms per token,  1295.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.96 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    74 tokens (    0.68 ms per token,  1462.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =      86.19 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    68 tokens (    0.73 ms per token,  1372.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.51 ms /    66 tokens (    0.75 ms per token,  1333.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     100.13 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.29 ms /   110 tokens (    0.60 ms per token,  1659.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.64 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    58 tokens (    0.75 ms per token,  1335.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.69 ms /   128 tokens (    0.58 ms per token,  1713.73 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     126.11 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    59 tokens (    0.74 ms per token,  1354.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    72 tokens (    0.70 ms per token,  1434.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.52 ms /   115 tokens (    0.63 ms per token,  1585.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     107.00 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    81 tokens (    0.70 ms per token,  1419.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.54 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.61 ms /   115 tokens (    0.63 ms per token,  1583.85 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     124.47 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    91 tokens (    0.64 ms per token,  1561.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      93.66 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.15 ms /    98 tokens (    0.65 ms per token,  1527.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      98.34 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    68 tokens (    0.73 ms per token,  1376.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    67 tokens (    0.74 ms per token,  1347.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      99.98 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.92 ms /   170 tokens (    0.64 ms per token,  1560.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     143.60 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    72 tokens (    0.70 ms per token,  1436.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.55 ms /   215 tokens (    0.60 ms per token,  1672.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.65 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     163.17 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.01 ms /    93 tokens (    0.63 ms per token,  1576.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      94.23 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.74 ms /   136 tokens (    0.69 ms per token,  1450.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     128.79 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.90 ms /   117 tokens (    0.62 ms per token,  1605.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     108.05 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.77 ms /    92 tokens (    0.64 ms per token,  1565.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.15 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    74 tokens (    0.68 ms per token,  1473.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.82 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.24 ms /    97 tokens (    0.66 ms per token,  1510.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      98.27 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.14 ms /   111 tokens (    0.60 ms per token,  1678.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.25 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.50 ms /   165 tokens (    0.66 ms per token,  1520.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     142.85 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.14 ms /   114 tokens (    0.63 ms per token,  1580.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     107.08 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.65 ms /   133 tokens (    0.70 ms per token,  1420.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     127.93 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    64 tokens (    0.69 ms per token,  1448.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.13 ms /    82 tokens (    0.70 ms per token,  1435.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      91.64 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    74 tokens (    0.68 ms per token,  1466.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     101.42 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    89 tokens (    0.65 ms per token,  1527.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.91 ms /   119 tokens (    0.61 ms per token,  1632.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.15 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    69 tokens (    0.72 ms per token,  1384.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      83.43 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.16 ms /   109 tokens (    0.61 ms per token,  1647.45 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     117.59 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.02 ms /   186 tokens (    0.60 ms per token,  1675.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     146.13 ms /   188 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.39 ms /   128 tokens (    0.58 ms per token,  1720.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.02 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.50 ms /    98 tokens (    0.66 ms per token,  1519.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      98.60 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    66 tokens (    0.75 ms per token,  1332.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.24 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.11 ms /    88 tokens (    0.66 ms per token,  1514.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.88 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.18 ms /   151 tokens (    0.64 ms per token,  1569.96 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     147.75 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.02 ms /    81 tokens (    0.70 ms per token,  1420.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      91.42 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    68 tokens (    0.73 ms per token,  1377.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.69 ms /     3 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     100.65 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.66 ms /   161 tokens (    0.67 ms per token,  1495.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     142.28 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.24 ms /    98 tokens (    0.66 ms per token,  1525.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      98.57 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.12 ms /   109 tokens (    0.61 ms per token,  1648.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     100.39 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    70 tokens (    0.71 ms per token,  1399.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.63 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    71 tokens (    0.71 ms per token,  1416.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    73 tokens (    0.69 ms per token,  1441.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.28 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.02 ms /    80 tokens (    0.65 ms per token,  1537.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      86.29 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.35 ms /   133 tokens (    0.70 ms per token,  1424.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     128.08 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    73 tokens (    0.69 ms per token,  1455.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    69 tokens (    0.72 ms per token,  1382.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     100.81 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    92 tokens (    0.63 ms per token,  1576.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.74 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    74 tokens (    0.68 ms per token,  1471.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.23 ms /   124 tokens (    0.60 ms per token,  1670.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     109.31 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    63 tokens (    0.70 ms per token,  1431.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    71 tokens (    0.71 ms per token,  1416.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    57 tokens (    0.76 ms per token,  1313.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.91 ms /    78 tokens (    0.65 ms per token,  1532.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.25 ms /     2 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =      84.67 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.41 ms /    92 tokens (    0.63 ms per token,  1574.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.25 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    57 tokens (    0.76 ms per token,  1314.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.94 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    59 tokens (    0.74 ms per token,  1348.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.12 ms /    95 tokens (    0.62 ms per token,  1606.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.93 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    60 tokens (    0.73 ms per token,  1377.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.79 ms /   162 tokens (    0.67 ms per token,  1502.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     142.75 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      85.16 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.29 ms /   139 tokens (    0.68 ms per token,  1474.21 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     145.93 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.14 ms /    90 tokens (    0.65 ms per token,  1548.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.51 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.64 ms /    93 tokens (    0.63 ms per token,  1586.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.51 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.03 ms /   108 tokens (    0.61 ms per token,  1635.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.30 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.00 ms /   103 tokens (    0.63 ms per token,  1584.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      99.08 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.51 ms /   128 tokens (    0.58 ms per token,  1717.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     109.18 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.58 ms /    51 tokens (    0.83 ms per token,  1197.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      75.84 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.45 ms /    97 tokens (    0.66 ms per token,  1505.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      99.05 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.12 ms /   104 tokens (    0.63 ms per token,  1597.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     100.39 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    76 tokens (    0.66 ms per token,  1506.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.75 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.96 ms /   136 tokens (    0.69 ms per token,  1447.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     128.50 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.86 ms /   112 tokens (    0.60 ms per token,  1675.22 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     118.59 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.38 ms /   110 tokens (    0.60 ms per token,  1657.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     118.63 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    69 tokens (    0.72 ms per token,  1385.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      84.14 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    74 tokens (    0.68 ms per token,  1477.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.66 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.14 ms /   143 tokens (    0.67 ms per token,  1503.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     130.42 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.95 ms /   109 tokens (    0.61 ms per token,  1652.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     100.97 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.03 ms /    83 tokens (    0.69 ms per token,  1455.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      91.28 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.95 ms /    80 tokens (    0.65 ms per token,  1540.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      86.55 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.84 ms /    95 tokens (    0.62 ms per token,  1614.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =      93.84 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.75 ms /   129 tokens (    0.72 ms per token,  1390.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     127.31 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    70 tokens (    0.71 ms per token,  1401.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.32 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.29 ms /    63 tokens (    0.70 ms per token,  1422.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.55 ms /   106 tokens (    0.62 ms per token,  1617.21 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     116.87 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    63 tokens (    0.70 ms per token,  1424.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      95.27 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /    10 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    61 tokens (    0.72 ms per token,  1387.15 tokens per second)\n",
      "llama_print_timings:        eval time =     148.29 ms /     9 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     196.10 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    75 tokens (    0.68 ms per token,  1481.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    81 tokens (    0.70 ms per token,  1424.43 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     108.26 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.52 ms /    66 tokens (    0.75 ms per token,  1332.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     100.55 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    83 tokens (    0.69 ms per token,  1446.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.10 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    62 tokens (    0.72 ms per token,  1398.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.70 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    95 tokens (    0.62 ms per token,  1612.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      93.39 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.75 ms /    59 tokens (    0.74 ms per token,  1348.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      94.56 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.48 ms /   105 tokens (    0.62 ms per token,  1603.57 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     117.78 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    69 tokens (    0.72 ms per token,  1390.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     100.80 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    76 tokens (    0.67 ms per token,  1490.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     101.99 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    85 tokens (    0.68 ms per token,  1475.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.08 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.65 ms /    87 tokens (    0.66 ms per token,  1509.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.73 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.59 ms /    67 tokens (    0.74 ms per token,  1351.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.95 ms /   142 tokens (    0.67 ms per token,  1495.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     129.30 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    86 tokens (    0.67 ms per token,  1497.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.28 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.75 ms /   107 tokens (    0.61 ms per token,  1627.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.23 ms /   114 tokens (    0.63 ms per token,  1578.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.27 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    63 tokens (    0.70 ms per token,  1426.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.20 ms /   152 tokens (    0.63 ms per token,  1580.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     131.25 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    72 tokens (    0.70 ms per token,  1430.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    87 tokens (    0.67 ms per token,  1503.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     109.06 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.05 ms /   119 tokens (    0.61 ms per token,  1629.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     108.16 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.74 ms /    87 tokens (    0.66 ms per token,  1506.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.12 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    64 tokens (    0.69 ms per token,  1453.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    64 tokens (    0.69 ms per token,  1442.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      79.02 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    71 tokens (    0.70 ms per token,  1425.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.64 ms /   111 tokens (    0.60 ms per token,  1665.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     101.16 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    69 tokens (    0.72 ms per token,  1385.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.00 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.36 ms /   127 tokens (    0.59 ms per token,  1707.95 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     125.71 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.93 ms /   108 tokens (    0.61 ms per token,  1638.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.25 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    63 tokens (    0.70 ms per token,  1429.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    69 tokens (    0.72 ms per token,  1387.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    77 tokens (    0.66 ms per token,  1517.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      85.09 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.02 ms /    90 tokens (    0.64 ms per token,  1551.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    84 tokens (    0.68 ms per token,  1461.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.65 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.26 ms /   130 tokens (    0.72 ms per token,  1393.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     128.38 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    69 tokens (    0.72 ms per token,  1388.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.20 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.21 ms /    82 tokens (    0.70 ms per token,  1433.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.69 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.00 ms /   130 tokens (    0.72 ms per token,  1397.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     127.61 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    84 tokens (    0.68 ms per token,  1463.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      91.60 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    85 tokens (    0.68 ms per token,  1475.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     109.19 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.36 ms /    67 tokens (    0.74 ms per token,  1357.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    63 tokens (    0.70 ms per token,  1430.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.13 ms /    65 tokens (    0.76 ms per token,  1322.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.37 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.18 ms /   110 tokens (    0.60 ms per token,  1662.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     100.31 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.91 ms /    81 tokens (    0.70 ms per token,  1423.37 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     108.41 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.82 ms /    87 tokens (    0.66 ms per token,  1504.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      93.30 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.95 ms /    88 tokens (    0.66 ms per token,  1518.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.08 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.14 ms /   103 tokens (    0.63 ms per token,  1581.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     100.73 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.81 ms /    78 tokens (    0.65 ms per token,  1535.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =      84.95 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.39 ms /   110 tokens (    0.60 ms per token,  1657.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.39 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    62 tokens (    0.71 ms per token,  1408.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.32 ms /   151 tokens (    0.64 ms per token,  1567.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     131.01 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    72 tokens (    0.70 ms per token,  1430.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     169.46 ms /   274 tokens (    0.62 ms per token,  1616.90 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     220.71 ms /   277 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    70 tokens (    0.71 ms per token,  1402.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     100.24 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    91 tokens (    0.64 ms per token,  1560.70 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     110.25 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.79 ms /   369 tokens (    0.59 ms per token,  1702.14 tokens per second)\n",
      "llama_print_timings:        eval time =      34.70 ms /     2 runs   (   17.35 ms per token,    57.64 tokens per second)\n",
      "llama_print_timings:       total time =     252.91 ms /   371 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    68 tokens (    0.73 ms per token,  1367.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     100.14 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.34 ms /    47 tokens (    0.79 ms per token,  1258.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      71.43 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.50 ms /   121 tokens (    0.61 ms per token,  1646.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     107.97 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.09 ms /   151 tokens (    0.64 ms per token,  1571.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     131.20 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    84 tokens (    0.68 ms per token,  1467.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.06 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    58 tokens (    0.75 ms per token,  1334.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      76.84 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    57 tokens (    0.76 ms per token,  1312.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.46 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    76 tokens (    0.67 ms per token,  1499.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.21 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.90 ms /   109 tokens (    0.60 ms per token,  1654.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.23 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.91 ms /    87 tokens (    0.67 ms per token,  1502.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.59 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    84 tokens (    0.68 ms per token,  1467.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      91.58 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.95 ms /    70 tokens (    0.71 ms per token,  1401.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.15 ms /    62 tokens (    0.71 ms per token,  1404.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.92 ms /    54 tokens (    0.79 ms per token,  1258.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.87 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    85 tokens (    0.68 ms per token,  1478.65 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     108.80 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.85 ms /    60 tokens (    0.73 ms per token,  1368.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.33 ms /    63 tokens (    0.70 ms per token,  1421.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      95.37 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.38 ms /    67 tokens (    0.74 ms per token,  1356.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.36 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    70 tokens (    0.71 ms per token,  1402.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.42 ms /    91 tokens (    0.64 ms per token,  1557.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.58 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.05 ms /   139 tokens (    0.68 ms per token,  1477.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     128.29 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.56 ms /   147 tokens (    0.65 ms per token,  1538.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     129.88 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.21 ms /   110 tokens (    0.60 ms per token,  1661.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     102.19 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.02 ms /   113 tokens (    0.64 ms per token,  1568.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     107.11 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.30 ms /   111 tokens (    0.60 ms per token,  1674.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.21 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.52 ms /    67 tokens (    0.74 ms per token,  1352.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.15 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    56 tokens (    0.78 ms per token,  1289.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.74 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    71 tokens (    0.70 ms per token,  1422.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.37 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.72 ms /    93 tokens (    0.63 ms per token,  1583.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     110.46 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.58 ms /   147 tokens (    0.65 ms per token,  1537.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     130.36 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    79 tokens (    0.64 ms per token,  1554.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      85.63 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    77 tokens (    0.66 ms per token,  1511.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      85.10 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    53 tokens (    0.81 ms per token,  1230.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      76.74 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.98 ms /    70 tokens (    0.71 ms per token,  1400.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    67 tokens (    0.74 ms per token,  1347.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      83.50 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.68 ms /    94 tokens (    0.62 ms per token,  1601.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.35 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.05 ms /   164 tokens (    0.66 ms per token,  1517.76 tokens per second)\n",
      "llama_print_timings:        eval time =      50.59 ms /     3 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     159.66 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    66 tokens (    0.75 ms per token,  1336.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      84.23 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    92 tokens (    0.64 ms per token,  1570.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.87 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.00 ms /   125 tokens (    0.59 ms per token,  1689.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     108.44 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.80 ms /   135 tokens (    0.69 ms per token,  1439.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     128.23 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.11 ms /    63 tokens (    0.70 ms per token,  1428.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.37 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    92 tokens (    0.64 ms per token,  1574.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.34 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.78 ms /    53 tokens (    0.81 ms per token,  1238.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.29 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.41 ms /   168 tokens (    0.65 ms per token,  1549.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     143.21 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.11 ms /    96 tokens (    0.62 ms per token,  1624.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.80 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    75 tokens (    0.67 ms per token,  1482.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     101.32 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.01 ms /    53 tokens (    0.81 ms per token,  1232.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      76.51 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17094.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    75 tokens (    0.67 ms per token,  1483.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     101.32 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    72 tokens (    0.70 ms per token,  1424.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.94 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.99 ms /   204 tokens (    0.61 ms per token,  1645.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     159.07 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    72 tokens (    0.70 ms per token,  1436.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.45 ms /    64 tokens (    0.69 ms per token,  1439.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.68 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.07 ms /   200 tokens (    0.62 ms per token,  1612.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     158.55 ms /   202 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.27 ms /    66 tokens (    0.75 ms per token,  1339.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      82.68 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    54 tokens (    0.80 ms per token,  1253.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      76.47 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    76 tokens (    0.67 ms per token,  1495.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.26 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.63 ms /   135 tokens (    0.69 ms per token,  1441.80 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     145.71 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.79 ms /   141 tokens (    0.67 ms per token,  1487.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     129.75 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.23 ms /    57 tokens (    0.76 ms per token,  1318.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.60 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.68 ms /   148 tokens (    0.65 ms per token,  1546.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.71 ms /     3 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     148.04 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.62 ms /   237 tokens (    0.60 ms per token,  1661.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     176.61 ms /   239 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    61 tokens (    0.72 ms per token,  1383.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    62 tokens (    0.71 ms per token,  1408.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.07 ms /   171 tokens (    0.64 ms per token,  1567.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     143.31 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.02 ms /    84 tokens (    0.68 ms per token,  1473.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.35 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    72 tokens (    0.70 ms per token,  1428.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.39 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.46 ms /   154 tokens (    0.63 ms per token,  1596.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     130.74 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    58 tokens (    0.75 ms per token,  1337.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.90 ms /    99 tokens (    0.66 ms per token,  1525.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.67 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    68 tokens (    0.73 ms per token,  1372.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.68 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.39 ms /    65 tokens (    0.76 ms per token,  1316.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.23 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.39 ms /    98 tokens (    0.66 ms per token,  1521.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.68 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    81 tokens (    0.71 ms per token,  1416.46 tokens per second)\n",
      "llama_print_timings:        eval time =      50.33 ms /     3 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     108.60 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    58 tokens (    0.75 ms per token,  1340.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      76.48 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    73 tokens (    0.69 ms per token,  1454.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.38 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.40 ms /   119 tokens (    0.62 ms per token,  1621.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     107.72 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.03 ms /   132 tokens (    0.70 ms per token,  1418.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     127.54 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.18 ms /    65 tokens (    0.76 ms per token,  1321.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.59 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    78 tokens (    0.65 ms per token,  1530.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =      85.56 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    77 tokens (    0.66 ms per token,  1514.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.06 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.71 ms /    98 tokens (    0.66 ms per token,  1514.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      98.97 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    56 tokens (    0.78 ms per token,  1288.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      77.46 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.11 ms /    78 tokens (    0.66 ms per token,  1526.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =      85.41 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.10 ms /    83 tokens (    0.69 ms per token,  1453.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.16 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1449.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    66 tokens (    0.75 ms per token,  1328.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.22 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.41 ms /   180 tokens (    0.61 ms per token,  1630.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     145.36 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.83 ms /   157 tokens (    0.62 ms per token,  1621.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     131.66 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    55 tokens (    0.78 ms per token,  1279.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      93.83 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    76 tokens (    0.67 ms per token,  1492.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     101.99 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.23 ms /   219 tokens (    0.59 ms per token,  1694.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.03 ms /     3 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     180.65 ms /   222 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.00 ms /    80 tokens (    0.65 ms per token,  1538.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      86.46 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    58 tokens (    0.75 ms per token,  1332.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.97 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    86 tokens (    0.67 ms per token,  1488.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      92.35 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    65 tokens (    0.76 ms per token,  1314.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.53 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.17 ms /   111 tokens (    0.60 ms per token,  1677.62 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     118.00 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.86 ms /   172 tokens (    0.63 ms per token,  1580.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     144.06 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.31 ms /   144 tokens (    0.66 ms per token,  1510.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     130.62 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.18 ms /   114 tokens (    0.63 ms per token,  1579.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     107.05 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.03 ms /    89 tokens (    0.65 ms per token,  1533.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.54 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.68 ms /   112 tokens (    0.60 ms per token,  1679.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     101.64 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.08 ms /   151 tokens (    0.64 ms per token,  1571.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     130.98 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.55 ms /   152 tokens (    0.64 ms per token,  1574.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.97 ms /     2 runs   (   16.99 ms per token,    58.87 tokens per second)\n",
      "llama_print_timings:       total time =     131.87 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    91 tokens (    0.64 ms per token,  1561.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.16 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.43 ms /   133 tokens (    0.70 ms per token,  1423.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     128.04 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    93 tokens (    0.63 ms per token,  1590.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     110.47 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.84 ms /   107 tokens (    0.62 ms per token,  1625.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      99.93 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.55 ms /   118 tokens (    0.62 ms per token,  1604.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     125.64 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    64 tokens (    0.69 ms per token,  1450.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.03 ms /    55 tokens (    0.78 ms per token,  1278.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      93.56 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.50 ms /    91 tokens (    0.64 ms per token,  1555.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.87 ms /     2 runs   (   16.94 ms per token,    59.04 tokens per second)\n",
      "llama_print_timings:       total time =      94.48 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    79 tokens (    0.64 ms per token,  1550.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.88 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    64 tokens (    0.69 ms per token,  1453.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    59 tokens (    0.74 ms per token,  1346.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.55 ms /   107 tokens (    0.61 ms per token,  1632.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      99.88 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    82 tokens (    0.70 ms per token,  1436.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.22 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    71 tokens (    0.71 ms per token,  1416.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      85.34 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.17 ms /    90 tokens (    0.65 ms per token,  1547.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.83 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.78 ms /    80 tokens (    0.65 ms per token,  1545.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      85.78 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    71 tokens (    0.70 ms per token,  1419.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    78 tokens (    0.65 ms per token,  1529.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      85.37 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.43 ms /   106 tokens (    0.62 ms per token,  1620.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     116.99 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    73 tokens (    0.69 ms per token,  1457.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.33 ms /   173 tokens (    0.63 ms per token,  1582.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     144.04 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.38 ms /    84 tokens (    0.68 ms per token,  1463.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =      92.82 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    63 tokens (    0.70 ms per token,  1427.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.59 ms /   111 tokens (    0.60 ms per token,  1666.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.65 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.11 ms /   150 tokens (    0.64 ms per token,  1560.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     131.11 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    68 tokens (    0.73 ms per token,  1371.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.89 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   105 tokens (    0.62 ms per token,  1601.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.98 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.63 ms /   135 tokens (    0.69 ms per token,  1441.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.45 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.12 ms /    78 tokens (    0.66 ms per token,  1525.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      85.70 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.28 ms /   208 tokens (    0.61 ms per token,  1634.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     161.60 ms /   210 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.93 ms /    81 tokens (    0.70 ms per token,  1422.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    60 tokens (    0.73 ms per token,  1366.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      94.82 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    92 tokens (    0.64 ms per token,  1569.56 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     110.93 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    75 tokens (    0.67 ms per token,  1484.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.50 ms /    98 tokens (    0.66 ms per token,  1519.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.79 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.96 ms /   108 tokens (    0.61 ms per token,  1637.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     117.42 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    93 tokens (    0.63 ms per token,  1591.43 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     110.17 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.76 ms /   107 tokens (    0.61 ms per token,  1627.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.64 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.11 ms /    96 tokens (    0.62 ms per token,  1624.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.39 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    75 tokens (    0.67 ms per token,  1487.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.77 ms /    94 tokens (    0.63 ms per token,  1599.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.06 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.44 ms /    72 tokens (    0.70 ms per token,  1427.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.20 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.27 ms /   110 tokens (    0.60 ms per token,  1659.80 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     117.75 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.47 ms /    93 tokens (    0.63 ms per token,  1590.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.29 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    51 tokens (    0.84 ms per token,  1194.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.07 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.56 ms /   119 tokens (    0.62 ms per token,  1617.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     108.23 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.25 ms /    73 tokens (    0.69 ms per token,  1452.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.66 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.56 ms /   182 tokens (    0.61 ms per token,  1646.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     145.54 ms /   184 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.05 ms /    83 tokens (    0.69 ms per token,  1454.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      91.60 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    60 tokens (    0.73 ms per token,  1364.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.11 ms /    88 tokens (    0.66 ms per token,  1514.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      92.74 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    66 tokens (    0.75 ms per token,  1331.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.33 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.29 ms /   110 tokens (    0.60 ms per token,  1659.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.57 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.33 ms /   121 tokens (    0.61 ms per token,  1650.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.21 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.13 ms /   297 tokens (    0.63 ms per token,  1578.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.53 ms /     2 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     222.43 ms /   299 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    92 tokens (    0.64 ms per token,  1570.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      93.11 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    78 tokens (    0.65 ms per token,  1534.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      84.88 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    73 tokens (    0.69 ms per token,  1441.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.18 ms /    82 tokens (    0.70 ms per token,  1434.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.59 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    64 tokens (    0.69 ms per token,  1452.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.09 ms /    78 tokens (    0.66 ms per token,  1526.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      85.26 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.81 ms /    63 tokens (    0.71 ms per token,  1405.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      96.12 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.27 ms /   237 tokens (    0.60 ms per token,  1665.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =     176.64 ms /   239 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.17 ms /    89 tokens (    0.65 ms per token,  1530.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.72 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.74 ms /    87 tokens (    0.66 ms per token,  1506.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.72 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1428.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.42 ms /    84 tokens (    0.68 ms per token,  1462.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.37 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.51 ms /    91 tokens (    0.64 ms per token,  1555.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.31 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.99 ms /    82 tokens (    0.69 ms per token,  1438.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.08 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.95 ms /   119 tokens (    0.61 ms per token,  1631.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.33 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.91 ms /   147 tokens (    0.65 ms per token,  1532.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     130.38 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.35 ms /    66 tokens (    0.75 ms per token,  1337.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.17 ms /   130 tokens (    0.72 ms per token,  1395.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     128.27 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    67 tokens (    0.74 ms per token,  1360.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.56 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.36 ms /    97 tokens (    0.66 ms per token,  1507.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.10 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.22 ms /   126 tokens (    0.59 ms per token,  1697.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     108.99 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    72 tokens (    0.70 ms per token,  1429.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.60 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    67 tokens (    0.74 ms per token,  1346.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.28 ms /   144 tokens (    0.66 ms per token,  1511.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     130.06 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    58 tokens (    0.75 ms per token,  1334.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    67 tokens (    0.74 ms per token,  1349.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.22 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.56 ms /   140 tokens (    0.68 ms per token,  1480.51 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     146.10 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    64 tokens (    0.69 ms per token,  1449.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    73 tokens (    0.69 ms per token,  1448.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.15 ms /    95 tokens (    0.62 ms per token,  1605.98 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     110.50 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    74 tokens (    0.68 ms per token,  1469.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.93 ms /   100 tokens (    0.65 ms per token,  1540.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      99.35 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.01 ms /    79 tokens (    0.65 ms per token,  1548.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.51 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.54 ms /   161 tokens (    0.67 ms per token,  1497.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     142.66 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    61 tokens (    0.72 ms per token,  1392.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    76 tokens (    0.67 ms per token,  1500.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      85.07 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.52 ms /   111 tokens (    0.60 ms per token,  1668.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     101.23 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.23 ms /    48 tokens (    0.78 ms per token,  1289.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      70.76 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.58 ms /   202 tokens (    0.61 ms per token,  1634.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     158.27 ms /   204 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    77 tokens (    0.66 ms per token,  1508.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.49 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.06 ms /    78 tokens (    0.65 ms per token,  1527.49 tokens per second)\n",
      "llama_print_timings:        eval time =      50.23 ms /     3 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     103.04 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.16 ms /   126 tokens (    0.59 ms per token,  1699.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.46 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.68 ms /   184 tokens (    0.60 ms per token,  1662.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =     145.07 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.72 ms /    76 tokens (    0.67 ms per token,  1498.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.35 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    66 tokens (    0.75 ms per token,  1327.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     100.59 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.70 ms /   145 tokens (    0.66 ms per token,  1515.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.57 ms /     3 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     147.91 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    71 tokens (    0.70 ms per token,  1425.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     100.01 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1448.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.81 ms /   118 tokens (    0.62 ms per token,  1620.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.41 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.73 ms /   107 tokens (    0.61 ms per token,  1627.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     100.62 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    58 tokens (    0.75 ms per token,  1326.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    63 tokens (    0.70 ms per token,  1429.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.72 ms /    86 tokens (    0.67 ms per token,  1490.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.63 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    61 tokens (    0.72 ms per token,  1388.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.49 ms /    79 tokens (    0.65 ms per token,  1534.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      86.27 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    89 tokens (    0.65 ms per token,  1532.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      92.99 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    78 tokens (    0.65 ms per token,  1530.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =      85.26 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    76 tokens (    0.67 ms per token,  1496.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     101.89 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.44 ms /    56 tokens (    0.78 ms per token,  1289.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      77.12 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    69 tokens (    0.72 ms per token,  1379.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      85.23 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.05 ms /    65 tokens (    0.75 ms per token,  1325.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      82.90 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    70 tokens (    0.71 ms per token,  1405.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    61 tokens (    0.72 ms per token,  1385.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.89 ms /   182 tokens (    0.61 ms per token,  1641.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.92 ms /     2 runs   (   16.96 ms per token,    58.97 tokens per second)\n",
      "llama_print_timings:       total time =     146.46 ms /   184 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.54 ms /   100 tokens (    0.65 ms per token,  1549.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      98.74 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.56 ms /    58 tokens (    0.75 ms per token,  1331.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    69 tokens (    0.72 ms per token,  1383.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.08 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.01 ms /   176 tokens (    0.63 ms per token,  1599.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     144.78 ms /   178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.32 ms /    79 tokens (    0.65 ms per token,  1539.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.78 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.55 ms /   121 tokens (    0.61 ms per token,  1645.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.74 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.91 ms /    95 tokens (    0.62 ms per token,  1612.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.07 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.56 ms /   141 tokens (    0.67 ms per token,  1491.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     129.05 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.24 ms /    65 tokens (    0.76 ms per token,  1320.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.71 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    74 tokens (    0.68 ms per token,  1464.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    77 tokens (    0.66 ms per token,  1514.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      85.02 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.22 ms /    72 tokens (    0.70 ms per token,  1433.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.44 ms /    73 tokens (    0.69 ms per token,  1447.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.69 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.31 ms /    66 tokens (    0.75 ms per token,  1338.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    86 tokens (    0.67 ms per token,  1486.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.59 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.58 ms /    76 tokens (    0.67 ms per token,  1502.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    64 tokens (    0.69 ms per token,  1449.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.56 ms /    76 tokens (    0.67 ms per token,  1503.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.80 ms /    99 tokens (    0.65 ms per token,  1527.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.72 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.35 ms /   206 tokens (    0.60 ms per token,  1656.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     158.98 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.27 ms /   102 tokens (    0.64 ms per token,  1562.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      99.56 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.32 ms /    90 tokens (    0.65 ms per token,  1543.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     110.15 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    64 tokens (    0.69 ms per token,  1441.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    61 tokens (    0.72 ms per token,  1383.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.36 ms /   152 tokens (    0.63 ms per token,  1577.40 tokens per second)\n",
      "llama_print_timings:        eval time =      50.64 ms /     3 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     149.13 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    70 tokens (    0.71 ms per token,  1410.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.83 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.30 ms /    84 tokens (    0.68 ms per token,  1466.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     109.12 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    69 tokens (    0.73 ms per token,  1378.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      83.83 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    62 tokens (    0.71 ms per token,  1415.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.40 ms /    65 tokens (    0.76 ms per token,  1315.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    75 tokens (    0.68 ms per token,  1479.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.78 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    59 tokens (    0.74 ms per token,  1346.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    68 tokens (    0.73 ms per token,  1368.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.18 ms /    62 tokens (    0.71 ms per token,  1403.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.81 ms /    76 tokens (    0.67 ms per token,  1495.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      84.82 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    60 tokens (    0.73 ms per token,  1366.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.23 ms /   105 tokens (    0.62 ms per token,  1609.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      99.33 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.59 ms /    76 tokens (    0.67 ms per token,  1502.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.64 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     9 runs   (    0.05 ms per token, 19693.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.19 ms /   111 tokens (    0.60 ms per token,  1676.91 tokens per second)\n",
      "llama_print_timings:        eval time =     134.69 ms /     8 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     203.94 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    61 tokens (    0.72 ms per token,  1385.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.94 ms /    61 tokens (    0.72 ms per token,  1388.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      79.12 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.75 ms /   137 tokens (    0.68 ms per token,  1461.33 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     146.04 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.88 ms /   156 tokens (    0.62 ms per token,  1610.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     131.38 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.43 ms /    98 tokens (    0.66 ms per token,  1521.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      99.27 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.00 ms /   138 tokens (    0.68 ms per token,  1468.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     128.90 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.10 ms /   151 tokens (    0.64 ms per token,  1571.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.03 tokens per second)\n",
      "llama_print_timings:       total time =     131.73 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.39 ms /   174 tokens (    0.63 ms per token,  1590.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     143.69 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.25 ms /    79 tokens (    0.65 ms per token,  1541.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.32 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.30 ms /    82 tokens (    0.70 ms per token,  1431.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.45 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    71 tokens (    0.70 ms per token,  1421.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.26 ms /    95 tokens (    0.62 ms per token,  1603.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.86 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.40 ms /   111 tokens (    0.60 ms per token,  1671.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     100.92 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.39 ms /    56 tokens (    0.77 ms per token,  1290.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.73 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    75 tokens (    0.67 ms per token,  1483.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.64 ms /    93 tokens (    0.63 ms per token,  1586.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =      93.85 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    72 tokens (    0.70 ms per token,  1435.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.59 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    57 tokens (    0.76 ms per token,  1309.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.30 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.51 ms /   105 tokens (    0.62 ms per token,  1602.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.59 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.28 ms /    65 tokens (    0.76 ms per token,  1318.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.40 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    63 tokens (    0.70 ms per token,  1424.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.85 ms /   226 tokens (    0.62 ms per token,  1604.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =     175.38 ms /   228 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.02 ms /    78 tokens (    0.65 ms per token,  1528.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.25 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      85.27 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.57 ms /    52 tokens (    0.82 ms per token,  1221.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      94.71 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.14 ms /    91 tokens (    0.64 ms per token,  1565.21 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     110.41 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.82 ms /   101 tokens (    0.64 ms per token,  1558.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.44 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.06 ms /    55 tokens (    0.78 ms per token,  1277.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.68 ms /   154 tokens (    0.63 ms per token,  1592.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     131.42 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.22 ms /    91 tokens (    0.64 ms per token,  1563.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      93.17 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.75 ms /   100 tokens (    0.65 ms per token,  1544.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.06 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.21 ms /    82 tokens (    0.70 ms per token,  1433.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      91.50 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.59 ms /   123 tokens (    0.60 ms per token,  1671.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.03 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.93 ms /   112 tokens (    0.60 ms per token,  1673.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     101.50 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    86 tokens (    0.67 ms per token,  1490.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.51 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.55 ms /   146 tokens (    0.65 ms per token,  1528.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     130.07 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.26 ms /    65 tokens (    0.76 ms per token,  1319.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      82.82 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    71 tokens (    0.70 ms per token,  1419.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.86 ms /    68 tokens (    0.73 ms per token,  1363.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.18 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.50 ms /   115 tokens (    0.63 ms per token,  1586.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.21 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.06 ms /    79 tokens (    0.65 ms per token,  1547.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.81 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    76 tokens (    0.66 ms per token,  1505.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.43 ms /   104 tokens (    0.63 ms per token,  1589.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     100.25 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.10 ms /    88 tokens (    0.66 ms per token,  1514.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.22 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.53 ms /   111 tokens (    0.60 ms per token,  1668.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.19 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    75 tokens (    0.67 ms per token,  1487.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.79 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    78 tokens (    0.65 ms per token,  1530.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.11 ms /     3 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     102.23 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    51 tokens (    0.84 ms per token,  1195.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      76.60 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.32 ms /   253 tokens (    0.57 ms per token,  1741.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     179.62 ms /   255 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    91 tokens (    0.64 ms per token,  1559.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.68 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.46 ms /   107 tokens (    0.61 ms per token,  1634.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.05 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.23 ms /   157 tokens (    0.62 ms per token,  1614.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.80 ms /     2 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =     132.35 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.61 ms /    69 tokens (    0.72 ms per token,  1390.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.95 ms /   154 tokens (    0.63 ms per token,  1588.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     131.59 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    68 tokens (    0.73 ms per token,  1372.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.68 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    51 tokens (    0.84 ms per token,  1187.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20100.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   103 tokens (    0.63 ms per token,  1583.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     116.22 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.22 ms /    89 tokens (    0.65 ms per token,  1528.58 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     110.16 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.27 ms /   114 tokens (    0.63 ms per token,  1577.42 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     123.79 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    76 tokens (    0.67 ms per token,  1500.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     102.37 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    81 tokens (    0.70 ms per token,  1427.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      90.99 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.34 ms /    85 tokens (    0.67 ms per token,  1482.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.21 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.85 ms /    52 tokens (    0.82 ms per token,  1213.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     101.34 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     5 runs   (    0.05 ms per token, 19531.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    75 tokens (    0.67 ms per token,  1483.97 tokens per second)\n",
      "llama_print_timings:        eval time =      66.18 ms /     4 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     118.81 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.13 ms /    96 tokens (    0.62 ms per token,  1623.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    89 tokens (    0.65 ms per token,  1535.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.41 ms /   105 tokens (    0.62 ms per token,  1605.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     117.25 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    85 tokens (    0.68 ms per token,  1474.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.46 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.19 ms /   133 tokens (    0.70 ms per token,  1427.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     127.81 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.26 ms /   127 tokens (    0.58 ms per token,  1710.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     108.38 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.65 ms /   167 tokens (    0.65 ms per token,  1537.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     143.04 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.14 ms /    82 tokens (    0.70 ms per token,  1435.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.42 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.21 ms /   101 tokens (    0.65 ms per token,  1548.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.27 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.81 ms /   150 tokens (    0.64 ms per token,  1565.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     129.94 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.13 ms /   177 tokens (    0.62 ms per token,  1607.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     145.34 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.05 ms /    79 tokens (    0.65 ms per token,  1547.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      85.27 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.30 ms /   141 tokens (    0.67 ms per token,  1495.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.84 ms /     2 runs   (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:       total time =     129.16 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.86 ms /    95 tokens (    0.62 ms per token,  1614.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.83 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    72 tokens (    0.70 ms per token,  1438.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.19 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.68 ms /   146 tokens (    0.66 ms per token,  1525.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     130.39 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.46 ms /    64 tokens (    0.69 ms per token,  1439.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.51 ms /    98 tokens (    0.66 ms per token,  1519.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     100.11 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.07 ms /    88 tokens (    0.66 ms per token,  1515.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    67 tokens (    0.74 ms per token,  1355.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      82.89 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    53 tokens (    0.81 ms per token,  1232.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.65 ms /   128 tokens (    0.58 ms per token,  1714.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     109.36 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.03 ms /    52 tokens (    0.83 ms per token,  1208.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    75 tokens (    0.67 ms per token,  1484.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =     101.54 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    68 tokens (    0.73 ms per token,  1366.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.09 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.56 ms /   105 tokens (    0.62 ms per token,  1601.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     101.27 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.51 ms /    99 tokens (    0.65 ms per token,  1534.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      98.94 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    92 tokens (    0.63 ms per token,  1579.24 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.49 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.93 ms /    94 tokens (    0.63 ms per token,  1595.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.30 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.27 ms /   103 tokens (    0.63 ms per token,  1578.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.51 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.39 ms /    62 tokens (    0.72 ms per token,  1396.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      95.31 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    68 tokens (    0.73 ms per token,  1370.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    81 tokens (    0.70 ms per token,  1419.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      91.41 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.66 ms /   136 tokens (    0.69 ms per token,  1452.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     128.01 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.23 ms /    92 tokens (    0.63 ms per token,  1579.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.17 ms /   125 tokens (    0.59 ms per token,  1685.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     109.13 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    56 tokens (    0.78 ms per token,  1288.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.62 ms /   136 tokens (    0.69 ms per token,  1452.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.67 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.39 ms /     2 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =      86.07 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.40 ms /    92 tokens (    0.63 ms per token,  1575.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.81 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.84 ms /   194 tokens (    0.63 ms per token,  1579.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.84 ms /     2 runs   (   16.92 ms per token,    59.11 tokens per second)\n",
      "llama_print_timings:       total time =     157.74 ms /   196 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.08 ms /    79 tokens (    0.65 ms per token,  1546.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.70 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.16 ms /   184 tokens (    0.60 ms per token,  1655.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     145.63 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.02 ms /    82 tokens (    0.70 ms per token,  1438.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.34 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.91 ms /   170 tokens (    0.64 ms per token,  1560.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     143.65 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.78 ms /   107 tokens (    0.61 ms per token,  1626.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.71 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.03 ms /    90 tokens (    0.64 ms per token,  1550.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.50 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    71 tokens (    0.70 ms per token,  1422.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.53 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    88 tokens (    0.66 ms per token,  1515.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.46 ms /    98 tokens (    0.66 ms per token,  1520.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      99.15 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.35 ms /   138 tokens (    0.68 ms per token,  1462.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     128.88 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    58 tokens (    0.75 ms per token,  1326.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    69 tokens (    0.72 ms per token,  1382.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =      85.26 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.22 ms /   114 tokens (    0.63 ms per token,  1578.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     106.87 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.44 ms /    73 tokens (    0.69 ms per token,  1447.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.15 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.44 ms /    98 tokens (    0.66 ms per token,  1520.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =      99.52 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.17 ms /    55 tokens (    0.78 ms per token,  1274.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.45 ms /    91 tokens (    0.64 ms per token,  1556.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     109.78 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    60 tokens (    0.73 ms per token,  1367.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.70 ms /   115 tokens (    0.63 ms per token,  1581.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.15 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    71 tokens (    0.70 ms per token,  1422.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      84.48 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.73 ms /   116 tokens (    0.63 ms per token,  1594.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     107.58 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    18 runs   (    0.05 ms per token, 19565.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.95 ms /    93 tokens (    0.63 ms per token,  1577.74 tokens per second)\n",
      "llama_print_timings:        eval time =     285.77 ms /    17 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     351.51 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.55 ms /   116 tokens (    0.63 ms per token,  1598.99 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     124.19 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.16 ms /   138 tokens (    0.68 ms per token,  1465.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     129.23 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.64 ms /   115 tokens (    0.63 ms per token,  1583.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.08 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.92 ms /    80 tokens (    0.65 ms per token,  1540.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      86.57 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.78 ms /   149 tokens (    0.64 ms per token,  1555.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     130.18 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.11 ms /    98 tokens (    0.65 ms per token,  1528.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.15 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    74 tokens (    0.68 ms per token,  1473.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.19 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.04 ms /    94 tokens (    0.63 ms per token,  1592.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.96 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    61 tokens (    0.72 ms per token,  1395.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.83 ms /   123 tokens (    0.60 ms per token,  1665.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     108.11 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.56 ms /    56 tokens (    0.78 ms per token,  1285.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.92 ms /    52 tokens (    0.83 ms per token,  1211.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.31 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    70 tokens (    0.72 ms per token,  1397.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.66 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    70 tokens (    0.71 ms per token,  1406.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.21 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.85 ms /    87 tokens (    0.66 ms per token,  1503.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.48 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.35 ms /   116 tokens (    0.62 ms per token,  1603.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.25 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.59 ms /   100 tokens (    0.65 ms per token,  1548.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      98.97 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.66 ms /   143 tokens (    0.66 ms per token,  1510.67 tokens per second)\n",
      "llama_print_timings:        eval time =      50.71 ms /     3 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     147.61 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    61 tokens (    0.72 ms per token,  1398.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.28 ms /    90 tokens (    0.65 ms per token,  1544.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     110.40 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    72 tokens (    0.70 ms per token,  1432.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.41 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.43 ms /   167 tokens (    0.65 ms per token,  1540.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     143.15 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.44 ms /    65 tokens (    0.76 ms per token,  1314.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.16 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    69 tokens (    0.72 ms per token,  1385.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.11 ms /   124 tokens (    0.60 ms per token,  1673.08 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     125.68 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    73 tokens (    0.69 ms per token,  1448.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.32 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.81 ms /   117 tokens (    0.62 ms per token,  1606.83 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     124.78 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.14 ms /   104 tokens (    0.63 ms per token,  1596.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    65 tokens (    0.77 ms per token,  1305.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.73 ms /    87 tokens (    0.66 ms per token,  1507.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.52 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    76 tokens (    0.67 ms per token,  1500.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.68 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.60 ms /    92 tokens (    0.64 ms per token,  1569.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     110.74 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.89 ms /    87 tokens (    0.67 ms per token,  1502.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.41 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.86 ms /   149 tokens (    0.64 ms per token,  1554.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     130.48 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.14 ms /    79 tokens (    0.65 ms per token,  1544.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      85.88 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.67 ms /   123 tokens (    0.60 ms per token,  1669.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     107.87 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.98 ms /    83 tokens (    0.69 ms per token,  1456.73 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     108.68 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.17 ms /    82 tokens (    0.70 ms per token,  1434.37 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     108.94 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.65 ms /   116 tokens (    0.63 ms per token,  1596.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     107.62 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.75 ms /    87 tokens (    0.66 ms per token,  1506.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.23 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.54 ms /   121 tokens (    0.61 ms per token,  1645.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     108.63 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    85 tokens (    0.68 ms per token,  1476.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.25 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.46 ms /    79 tokens (    0.65 ms per token,  1535.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      86.37 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    76 tokens (    0.66 ms per token,  1507.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.10 ms /    88 tokens (    0.66 ms per token,  1514.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.19 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    63 tokens (    0.70 ms per token,  1434.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      79.25 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.33 ms /   208 tokens (    0.61 ms per token,  1633.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.30 ms /     2 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     161.81 ms /   210 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.42 ms /   178 tokens (    0.62 ms per token,  1612.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     162.63 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.54 ms /   140 tokens (    0.68 ms per token,  1480.81 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     146.80 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.81 ms /    80 tokens (    0.65 ms per token,  1544.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      86.02 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     5 runs   (    0.05 ms per token, 19157.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.55 ms /   111 tokens (    0.60 ms per token,  1668.04 tokens per second)\n",
      "llama_print_timings:        eval time =      67.39 ms /     4 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     135.46 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.36 ms /    48 tokens (    0.78 ms per token,  1284.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      71.53 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    72 tokens (    0.70 ms per token,  1438.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.30 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.17 ms /    78 tokens (    0.66 ms per token,  1524.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      85.21 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    60 tokens (    0.73 ms per token,  1372.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.29 ms /    92 tokens (    0.63 ms per token,  1578.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      92.63 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.49 ms /   133 tokens (    0.70 ms per token,  1422.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.20 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    89 tokens (    0.65 ms per token,  1539.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.71 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    71 tokens (    0.71 ms per token,  1416.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      84.18 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    85 tokens (    0.68 ms per token,  1478.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.20 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.23 ms /    97 tokens (    0.66 ms per token,  1510.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      98.80 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.40 ms /   172 tokens (    0.64 ms per token,  1572.18 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     161.40 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.56 ms /   199 tokens (    0.62 ms per token,  1610.61 tokens per second)\n",
      "llama_print_timings:        eval time =      50.68 ms /     3 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     175.43 ms /   202 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    75 tokens (    0.67 ms per token,  1483.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      84.72 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    83 tokens (    0.69 ms per token,  1448.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      91.23 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    66 tokens (    0.75 ms per token,  1337.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     100.33 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.91 ms /   161 tokens (    0.67 ms per token,  1492.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     142.76 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.01 ms /   103 tokens (    0.63 ms per token,  1584.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      99.79 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    67 tokens (    0.74 ms per token,  1347.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.97 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.55 ms /   114 tokens (    0.64 ms per token,  1571.44 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     124.60 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    76 tokens (    0.67 ms per token,  1497.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      84.69 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    73 tokens (    0.69 ms per token,  1447.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.03 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.35 ms /    66 tokens (    0.75 ms per token,  1337.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.64 ms /    92 tokens (    0.64 ms per token,  1568.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      93.51 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    78 tokens (    0.65 ms per token,  1532.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =      84.97 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    77 tokens (    0.66 ms per token,  1512.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.33 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    57 tokens (    0.76 ms per token,  1317.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.65 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    74 tokens (    0.68 ms per token,  1475.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    63 tokens (    0.70 ms per token,  1431.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.66 ms /   107 tokens (    0.61 ms per token,  1629.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.87 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    72 tokens (    0.70 ms per token,  1431.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.67 ms /    93 tokens (    0.63 ms per token,  1585.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      94.22 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.57 ms /   135 tokens (    0.69 ms per token,  1442.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     127.99 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    74 tokens (    0.68 ms per token,  1469.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.02 ms /   108 tokens (    0.61 ms per token,  1635.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.74 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    62 tokens (    0.71 ms per token,  1407.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    73 tokens (    0.69 ms per token,  1455.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.14 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    69 tokens (    0.72 ms per token,  1388.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.45 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.91 ms /   134 tokens (    0.70 ms per token,  1426.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     128.97 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    67 tokens (    0.74 ms per token,  1352.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      83.96 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.61 ms /    68 tokens (    0.73 ms per token,  1370.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    76 tokens (    0.67 ms per token,  1497.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.73 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.67 ms /   174 tokens (    0.63 ms per token,  1586.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     144.31 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.53 ms /   113 tokens (    0.64 ms per token,  1557.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     107.28 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    72 tokens (    0.70 ms per token,  1432.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.16 ms /    97 tokens (    0.66 ms per token,  1511.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.40 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   104 tokens (    0.63 ms per token,  1599.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      99.56 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.95 ms /   210 tokens (    0.61 ms per token,  1641.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     162.09 ms /   212 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.83 ms /   112 tokens (    0.60 ms per token,  1675.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     101.82 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.65 ms /   116 tokens (    0.63 ms per token,  1596.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     107.09 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.21 ms /    83 tokens (    0.69 ms per token,  1450.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      91.71 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    84 tokens (    0.68 ms per token,  1467.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.31 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    76 tokens (    0.67 ms per token,  1496.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.05 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    72 tokens (    0.70 ms per token,  1424.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     6 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.89 ms /   226 tokens (    0.62 ms per token,  1604.12 tokens per second)\n",
      "llama_print_timings:        eval time =      83.36 ms /     5 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     226.63 ms /   231 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.18 ms /    89 tokens (    0.65 ms per token,  1529.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     110.30 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.62 ms /    75 tokens (    0.67 ms per token,  1481.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.99 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    87 tokens (    0.67 ms per token,  1493.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.15 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    69 tokens (    0.72 ms per token,  1383.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.38 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    73 tokens (    0.69 ms per token,  1452.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.48 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.16 ms /    96 tokens (    0.62 ms per token,  1622.61 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     111.05 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    85 tokens (    0.68 ms per token,  1479.08 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     109.85 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    87 tokens (    0.67 ms per token,  1501.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.01 ms /    96 tokens (    0.61 ms per token,  1626.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.99 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    71 tokens (    0.70 ms per token,  1420.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    66 tokens (    0.75 ms per token,  1329.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    71 tokens (    0.71 ms per token,  1417.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.82 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    67 tokens (    0.74 ms per token,  1354.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    62 tokens (    0.71 ms per token,  1402.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.66 ms /   116 tokens (    0.63 ms per token,  1596.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     106.83 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.17 ms /   164 tokens (    0.66 ms per token,  1516.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     142.65 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.25 ms /    97 tokens (    0.66 ms per token,  1509.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      98.57 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.91 ms /    80 tokens (    0.65 ms per token,  1541.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      86.60 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.85 ms /   102 tokens (    0.64 ms per token,  1572.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      99.77 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.79 ms /    86 tokens (    0.67 ms per token,  1488.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.43 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    93 tokens (    0.63 ms per token,  1593.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.50 ms /   152 tokens (    0.63 ms per token,  1575.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     131.58 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    59 tokens (    0.74 ms per token,  1352.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    78 tokens (    0.65 ms per token,  1527.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.30 ms /     3 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     103.54 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1448.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.13 ms /    88 tokens (    0.66 ms per token,  1513.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.11 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.47 ms /    90 tokens (    0.65 ms per token,  1539.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      93.14 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.27 ms /   104 tokens (    0.63 ms per token,  1593.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      99.95 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    61 tokens (    0.72 ms per token,  1386.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     6 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    70 tokens (    0.71 ms per token,  1403.62 tokens per second)\n",
      "llama_print_timings:        eval time =      82.42 ms /     5 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     133.95 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.86 ms /   108 tokens (    0.61 ms per token,  1639.72 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     117.65 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    66 tokens (    0.75 ms per token,  1328.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.44 ms /   126 tokens (    0.59 ms per token,  1692.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     108.62 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    70 tokens (    0.71 ms per token,  1405.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.43 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    73 tokens (    0.69 ms per token,  1446.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.53 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.37 ms /   121 tokens (    0.61 ms per token,  1649.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     107.60 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.16 ms /   139 tokens (    0.68 ms per token,  1476.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     128.25 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.17 ms /   129 tokens (    0.72 ms per token,  1384.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.90 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     128.07 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.80 ms /   225 tokens (    0.63 ms per token,  1598.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.35 ms /     2 runs   (   16.67 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     174.84 ms /   227 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    68 tokens (    0.73 ms per token,  1364.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.33 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.42 ms /    64 tokens (    0.69 ms per token,  1440.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.51 ms /   141 tokens (    0.67 ms per token,  1491.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.97 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    69 tokens (    0.72 ms per token,  1383.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.77 ms /    81 tokens (    0.70 ms per token,  1426.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.25 ms /    64 tokens (    0.69 ms per token,  1446.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.07 ms /   119 tokens (    0.61 ms per token,  1628.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     107.99 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.72 ms /    87 tokens (    0.66 ms per token,  1507.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    54 tokens (    0.80 ms per token,  1252.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      94.28 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    52 tokens (    0.83 ms per token,  1203.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.76 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.41 ms /    83 tokens (    0.69 ms per token,  1445.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      92.00 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.24 ms /    63 tokens (    0.70 ms per token,  1423.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    68 tokens (    0.73 ms per token,  1366.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    74 tokens (    0.68 ms per token,  1466.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      85.22 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    68 tokens (    0.73 ms per token,  1369.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.04 ms /   151 tokens (    0.64 ms per token,  1572.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     131.06 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    62 tokens (    0.71 ms per token,  1413.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    87 tokens (    0.67 ms per token,  1501.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     109.99 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.49 ms /    85 tokens (    0.68 ms per token,  1478.60 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     110.01 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.08 ms /   110 tokens (    0.60 ms per token,  1664.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.99 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    68 tokens (    0.73 ms per token,  1362.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.33 ms /   109 tokens (    0.61 ms per token,  1643.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     100.59 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.46 ms /   160 tokens (    0.61 ms per token,  1641.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     132.12 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.22 ms /    96 tokens (    0.62 ms per token,  1621.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.99 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.42 ms /    98 tokens (    0.66 ms per token,  1521.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      98.70 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.30 ms /   111 tokens (    0.60 ms per token,  1674.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     100.58 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.67 ms /    94 tokens (    0.62 ms per token,  1602.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.29 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.85 ms /    81 tokens (    0.70 ms per token,  1424.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      91.86 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.61 ms /    77 tokens (    0.66 ms per token,  1521.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.85 ms /     3 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     101.44 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    65 tokens (    0.76 ms per token,  1310.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.40 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    54 tokens (    0.80 ms per token,  1251.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      76.57 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.60 ms /    63 tokens (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.14 ms /    65 tokens (    0.76 ms per token,  1322.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      82.50 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    62 tokens (    0.71 ms per token,  1407.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.98 ms /    80 tokens (    0.65 ms per token,  1539.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      86.85 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.12 ms /    97 tokens (    0.66 ms per token,  1512.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =      98.88 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.30 ms /   133 tokens (    0.70 ms per token,  1425.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     128.13 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    76 tokens (    0.66 ms per token,  1504.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.81 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.09 ms /   125 tokens (    0.59 ms per token,  1687.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     109.12 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    78 tokens (    0.66 ms per token,  1526.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      84.98 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    73 tokens (    0.69 ms per token,  1450.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.42 ms /   144 tokens (    0.66 ms per token,  1509.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     129.75 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /   100 tokens (    0.65 ms per token,  1549.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.31 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    71 tokens (    0.71 ms per token,  1417.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      83.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.03 ms /    88 tokens (    0.66 ms per token,  1516.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.64 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.92 ms /   119 tokens (    0.61 ms per token,  1632.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     107.61 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    73 tokens (    0.69 ms per token,  1456.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.87 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.13 ms /    83 tokens (    0.69 ms per token,  1452.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      91.83 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    69 tokens (    0.73 ms per token,  1378.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.08 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.91 ms /   162 tokens (    0.67 ms per token,  1501.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     143.02 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.87 ms /    77 tokens (    0.66 ms per token,  1513.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.83 ms /     3 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     101.51 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.30 ms /   113 tokens (    0.64 ms per token,  1563.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.17 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    62 tokens (    0.71 ms per token,  1406.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.82 ms /   107 tokens (    0.62 ms per token,  1625.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.94 ms /    82 tokens (    0.69 ms per token,  1440.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.37 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1543.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      86.78 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.74 ms /   101 tokens (    0.64 ms per token,  1560.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      98.85 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    70 tokens (    0.71 ms per token,  1404.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.68 ms /     3 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    91 tokens (    0.64 ms per token,  1561.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.59 ms /   100 tokens (    0.65 ms per token,  1548.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.19 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.78 ms /   175 tokens (    0.63 ms per token,  1594.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.67 ms /     3 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     161.55 ms /   178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.03 ms /    82 tokens (    0.70 ms per token,  1437.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.41 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.02 ms /   117 tokens (    0.62 ms per token,  1602.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     107.46 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    67 tokens (    0.74 ms per token,  1356.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.70 ms /   133 tokens (    0.70 ms per token,  1419.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     127.79 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   106 tokens (    0.62 ms per token,  1613.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.16 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    63 tokens (    0.70 ms per token,  1429.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    63 tokens (    0.70 ms per token,  1427.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    91 tokens (    0.64 ms per token,  1561.64 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     110.07 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    71 tokens (    0.71 ms per token,  1418.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.00 ms /   124 tokens (    0.60 ms per token,  1675.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     108.50 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.56 ms /   168 tokens (    0.65 ms per token,  1547.57 tokens per second)\n",
      "llama_print_timings:        eval time =      50.56 ms /     3 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     160.23 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.86 ms /   148 tokens (    0.65 ms per token,  1543.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     130.92 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.74 ms /   121 tokens (    0.61 ms per token,  1640.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.92 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.45 ms /    91 tokens (    0.64 ms per token,  1556.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.27 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    77 tokens (    0.66 ms per token,  1514.35 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     102.18 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.93 ms /   148 tokens (    0.65 ms per token,  1542.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     131.11 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    86 tokens (    0.67 ms per token,  1493.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.62 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.54 ms /   133 tokens (    0.70 ms per token,  1421.88 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     145.80 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17167.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    51 tokens (    0.84 ms per token,  1193.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.74 ms /     3 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      94.19 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    86 tokens (    0.67 ms per token,  1490.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.29 ms /   104 tokens (    0.63 ms per token,  1592.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      99.69 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /   278 runs   (    0.05 ms per token, 19306.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.86 ms /   112 tokens (    0.60 ms per token,  1675.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4671.92 ms /   277 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    4868.61 ms /   389 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.82 ms /   183 tokens (    0.61 ms per token,  1651.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.69 ms /     3 runs   (   16.90 ms per token,    59.18 tokens per second)\n",
      "llama_print_timings:       total time =     162.64 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.82 ms /   117 tokens (    0.62 ms per token,  1606.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.58 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.79 ms /    80 tokens (    0.65 ms per token,  1544.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      86.60 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.14 ms /   144 tokens (    0.66 ms per token,  1513.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     129.77 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.34 ms /    92 tokens (    0.63 ms per token,  1576.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.17 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.60 ms /    59 tokens (    0.74 ms per token,  1353.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.89 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.44 ms /   104 tokens (    0.63 ms per token,  1589.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.04 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.51 ms /   106 tokens (    0.62 ms per token,  1618.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     117.38 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.05 ms /    76 tokens (    0.67 ms per token,  1488.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     102.22 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    57 tokens (    0.76 ms per token,  1310.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.99 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.27 ms /   151 tokens (    0.64 ms per token,  1568.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.57 ms /     3 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     148.23 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    72 tokens (    0.70 ms per token,  1432.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    75 tokens (    0.68 ms per token,  1471.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.58 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.57 ms /    60 tokens (    0.73 ms per token,  1377.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.84 ms /    81 tokens (    0.70 ms per token,  1424.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      90.86 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    58 tokens (    0.75 ms per token,  1328.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.28 ms /    66 tokens (    0.75 ms per token,  1339.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      82.80 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    66 tokens (    0.75 ms per token,  1337.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.26 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    91 tokens (    0.64 ms per token,  1556.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.68 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    82 tokens (    0.70 ms per token,  1427.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /   111 runs   (    0.05 ms per token, 18871.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.74 ms /   102 tokens (    0.63 ms per token,  1575.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1854.08 ms /   110 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =    1965.99 ms /   212 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    82 tokens (    0.70 ms per token,  1437.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    78 tokens (    0.65 ms per token,  1534.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =      84.57 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    62 tokens (    0.71 ms per token,  1407.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.54 ms /   115 tokens (    0.63 ms per token,  1585.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     106.83 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    86 tokens (    0.67 ms per token,  1492.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.82 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.26 ms /    83 tokens (    0.69 ms per token,  1449.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.22 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.25 ms /   160 tokens (    0.61 ms per token,  1645.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     132.03 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    69 tokens (    0.72 ms per token,  1381.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.69 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.77 ms /    86 tokens (    0.67 ms per token,  1488.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.53 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    72 tokens (    0.70 ms per token,  1424.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      84.86 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    75 tokens (    0.67 ms per token,  1487.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.42 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.94 ms /    69 tokens (    0.72 ms per token,  1381.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.23 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.38 ms /    72 tokens (    0.70 ms per token,  1429.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.15 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.93 ms /   100 tokens (    0.65 ms per token,  1540.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     117.25 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    73 tokens (    0.69 ms per token,  1455.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     101.01 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.97 ms /   118 tokens (    0.62 ms per token,  1617.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     108.13 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    74 tokens (    0.68 ms per token,  1469.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.43 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.48 ms /    65 tokens (    0.76 ms per token,  1313.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.23 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    88 tokens (    0.66 ms per token,  1518.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    66 tokens (    0.75 ms per token,  1337.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.06 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.53 ms /    83 tokens (    0.69 ms per token,  1442.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.73 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.85 ms /   101 tokens (    0.64 ms per token,  1557.37 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     117.13 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.17 ms /   101 tokens (    0.65 ms per token,  1549.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     100.52 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    74 tokens (    0.68 ms per token,  1470.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     100.59 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    58 tokens (    0.75 ms per token,  1325.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    77 tokens (    0.66 ms per token,  1510.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.78 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.38 ms /    98 tokens (    0.66 ms per token,  1522.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      98.57 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    64 tokens (    0.69 ms per token,  1447.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    70 tokens (    0.71 ms per token,  1403.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      83.28 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    56 tokens (    0.77 ms per token,  1292.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      94.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.32 ms /    92 tokens (    0.63 ms per token,  1577.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.86 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.13 ms /   138 tokens (    0.68 ms per token,  1466.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     128.52 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.87 ms /   128 tokens (    0.58 ms per token,  1709.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     110.22 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.40 ms /    67 tokens (    0.74 ms per token,  1356.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      99.63 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    87 tokens (    0.66 ms per token,  1504.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =      93.20 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.58 ms /    87 tokens (    0.66 ms per token,  1510.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.14 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    79 tokens (    0.65 ms per token,  1549.11 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     102.55 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.50 ms /    76 tokens (    0.66 ms per token,  1505.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    81 tokens (    0.71 ms per token,  1413.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    72 tokens (    0.70 ms per token,  1438.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.60 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.31 ms /    63 tokens (    0.70 ms per token,  1421.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.47 ms /   105 tokens (    0.62 ms per token,  1603.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     100.32 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.07 ms /   227 tokens (    0.62 ms per token,  1609.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.00 ms /     3 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     192.79 ms /   230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.88 ms /    76 tokens (    0.67 ms per token,  1493.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     101.66 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    68 tokens (    0.73 ms per token,  1365.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     100.71 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     100.96 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.52 ms /    99 tokens (    0.65 ms per token,  1534.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.61 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.78 ms /    93 tokens (    0.63 ms per token,  1582.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.76 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.92 ms /    89 tokens (    0.65 ms per token,  1536.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.61 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.91 ms /   195 tokens (    0.63 ms per token,  1586.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     157.55 ms /   197 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1542.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      86.56 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    56 tokens (    0.77 ms per token,  1292.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      77.90 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    83 tokens (    0.69 ms per token,  1450.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.92 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.62 ms /    75 tokens (    0.67 ms per token,  1481.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     101.86 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    78 tokens (    0.65 ms per token,  1529.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.43 ms /     2 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =      85.96 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    66 tokens (    0.75 ms per token,  1341.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.79 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    83 tokens (    0.69 ms per token,  1442.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.37 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.32 ms /   105 tokens (    0.62 ms per token,  1607.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.81 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.19 ms /    78 tokens (    0.66 ms per token,  1523.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =      85.77 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.72 ms /    80 tokens (    0.65 ms per token,  1546.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      86.27 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.16 ms /    91 tokens (    0.64 ms per token,  1564.51 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.48 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    82 tokens (    0.70 ms per token,  1436.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      91.19 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.74 ms /   148 tokens (    0.65 ms per token,  1545.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     130.36 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.97 ms /   125 tokens (    0.59 ms per token,  1689.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     108.41 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.31 ms /    79 tokens (    0.65 ms per token,  1539.66 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     103.31 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.19 ms /    97 tokens (    0.66 ms per token,  1511.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.10 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.67 ms /   112 tokens (    0.60 ms per token,  1679.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     101.58 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    72 tokens (    0.70 ms per token,  1427.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.01 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    75 tokens (    0.67 ms per token,  1482.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.10 ms /   120 tokens (    0.61 ms per token,  1641.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.53 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    86 tokens (    0.67 ms per token,  1493.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.33 ms /    91 tokens (    0.64 ms per token,  1560.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.54 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     8 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.27 ms /   126 tokens (    0.59 ms per token,  1696.51 tokens per second)\n",
      "llama_print_timings:        eval time =     117.89 ms /     7 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     194.93 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.51 ms /    93 tokens (    0.63 ms per token,  1589.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      93.26 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.26 ms /   114 tokens (    0.63 ms per token,  1577.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     106.71 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.27 ms /    94 tokens (    0.63 ms per token,  1585.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      93.84 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.43 ms /   116 tokens (    0.62 ms per token,  1601.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.65 ms /     3 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     124.90 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    98 tokens (    0.66 ms per token,  1524.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      98.39 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.16 ms /   126 tokens (    0.59 ms per token,  1699.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     109.27 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.12 ms /   138 tokens (    0.68 ms per token,  1466.23 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     146.19 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.51 ms /   122 tokens (    0.60 ms per token,  1659.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     125.59 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    59 tokens (    0.74 ms per token,  1351.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.92 ms /    95 tokens (    0.62 ms per token,  1612.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =      94.30 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.99 ms /    81 tokens (    0.70 ms per token,  1421.25 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.60 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    70 tokens (    0.72 ms per token,  1398.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.74 ms /    59 tokens (    0.74 ms per token,  1348.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.34 ms /   125 tokens (    0.59 ms per token,  1681.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     108.97 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    72 tokens (    0.70 ms per token,  1432.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.94 ms /    69 tokens (    0.72 ms per token,  1381.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.00 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.00 ms /    80 tokens (    0.65 ms per token,  1538.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      86.82 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    69 tokens (    0.72 ms per token,  1390.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.32 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    84 tokens (    0.69 ms per token,  1459.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.51 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    66 tokens (    0.75 ms per token,  1331.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.18 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.66 ms /   141 tokens (    0.67 ms per token,  1489.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     130.16 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    76 tokens (    0.67 ms per token,  1499.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.90 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    66 tokens (    0.75 ms per token,  1332.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.07 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.05 ms /    77 tokens (    0.66 ms per token,  1508.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.84 ms /     3 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     102.26 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    58 tokens (    0.75 ms per token,  1325.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.95 ms /   137 tokens (    0.69 ms per token,  1458.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     128.69 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.06 ms /   169 tokens (    0.65 ms per token,  1549.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     143.55 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.74 ms /    94 tokens (    0.62 ms per token,  1600.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.97 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    69 tokens (    0.72 ms per token,  1387.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.20 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.01 ms /    86 tokens (    0.67 ms per token,  1482.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.00 ms /    97 tokens (    0.66 ms per token,  1515.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      98.91 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.16 ms /    95 tokens (    0.62 ms per token,  1605.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      93.92 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    82 tokens (    0.69 ms per token,  1441.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      90.99 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    75 tokens (    0.68 ms per token,  1479.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.36 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    76 tokens (    0.67 ms per token,  1500.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.92 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.51 ms /   215 tokens (    0.60 ms per token,  1673.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.39 ms /     2 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     163.75 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    77 tokens (    0.66 ms per token,  1515.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      85.06 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    77 tokens (    0.66 ms per token,  1520.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.77 ms /     3 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     101.29 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    67 tokens (    0.74 ms per token,  1346.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.46 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.00 ms /    95 tokens (    0.62 ms per token,  1610.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.98 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    57 tokens (    0.76 ms per token,  1316.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.28 ms /   170 tokens (    0.64 ms per token,  1555.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     144.47 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.05 ms /   109 tokens (    0.61 ms per token,  1650.26 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     118.56 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    72 tokens (    0.70 ms per token,  1433.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.60 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    54 tokens (    0.80 ms per token,  1252.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.30 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.95 ms /   123 tokens (    0.60 ms per token,  1663.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     108.86 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.60 ms /    50 tokens (    0.85 ms per token,  1173.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      93.88 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.08 ms /    96 tokens (    0.62 ms per token,  1625.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      93.80 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.43 ms /   116 tokens (    0.62 ms per token,  1601.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     107.43 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    72 tokens (    0.70 ms per token,  1437.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.84 ms /   108 tokens (    0.61 ms per token,  1640.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     117.48 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    54 tokens (    0.80 ms per token,  1257.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.49 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.30 ms /    63 tokens (    0.70 ms per token,  1422.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    67 tokens (    0.74 ms per token,  1348.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      83.75 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.00 ms /    96 tokens (    0.61 ms per token,  1627.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      93.39 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.55 ms /   188 tokens (    0.59 ms per token,  1685.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.04 tokens per second)\n",
      "llama_print_timings:       total time =     146.92 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    69 tokens (    0.72 ms per token,  1386.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    81 tokens (    0.70 ms per token,  1419.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      90.98 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.48 ms /   105 tokens (    0.62 ms per token,  1603.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     100.26 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    84 tokens (    0.69 ms per token,  1449.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.95 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.57 ms /   210 tokens (    0.61 ms per token,  1646.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     161.63 ms /   212 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /    98 tokens (    0.66 ms per token,  1518.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      98.71 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    66 tokens (    0.75 ms per token,  1336.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.25 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.85 ms /    86 tokens (    0.67 ms per token,  1486.50 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.92 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.80 ms /    76 tokens (    0.67 ms per token,  1495.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.36 ms /    65 tokens (    0.76 ms per token,  1316.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.92 ms /    78 tokens (    0.65 ms per token,  1531.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.48 ms /     2 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =      85.89 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.10 ms /    80 tokens (    0.65 ms per token,  1535.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      87.16 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.26 ms /   113 tokens (    0.64 ms per token,  1563.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     107.34 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.78 ms /   101 tokens (    0.64 ms per token,  1559.15 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     116.88 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.52 ms /    93 tokens (    0.63 ms per token,  1589.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.06 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.14 ms /    98 tokens (    0.65 ms per token,  1528.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      98.91 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    62 tokens (    0.71 ms per token,  1404.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    62 tokens (    0.71 ms per token,  1411.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      94.30 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.21 ms /    83 tokens (    0.69 ms per token,  1450.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =      92.94 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   106 tokens (    0.62 ms per token,  1616.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.03 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.76 ms /   142 tokens (    0.67 ms per token,  1498.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     129.48 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.57 ms /   140 tokens (    0.68 ms per token,  1480.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     129.54 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.31 ms /   104 tokens (    0.63 ms per token,  1592.28 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     116.99 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    72 tokens (    0.70 ms per token,  1427.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      84.84 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.81 ms /   108 tokens (    0.61 ms per token,  1641.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     117.20 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.36 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    99 tokens (    0.65 ms per token,  1540.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      99.53 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    70 tokens (    0.71 ms per token,  1399.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.86 ms /   122 tokens (    0.61 ms per token,  1651.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     108.68 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     141.32 ms /   228 tokens (    0.62 ms per token,  1613.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     175.49 ms /   230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.63 ms /    91 tokens (    0.64 ms per token,  1552.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.58 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.09 ms /   109 tokens (    0.61 ms per token,  1649.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     100.87 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.23 ms /    97 tokens (    0.66 ms per token,  1510.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.17 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    97 tokens (    0.66 ms per token,  1508.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      98.93 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    55 tokens (    0.79 ms per token,  1270.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      77.78 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.78 ms /    87 tokens (    0.66 ms per token,  1505.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     109.56 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    70 tokens (    0.72 ms per token,  1397.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.00 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.74 ms /   116 tokens (    0.63 ms per token,  1594.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     107.63 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.13 ms /    89 tokens (    0.65 ms per token,  1531.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =      93.44 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.72 ms /   102 tokens (    0.63 ms per token,  1575.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      99.65 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.62 ms /   167 tokens (    0.65 ms per token,  1537.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     143.01 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.97 ms /   148 tokens (    0.65 ms per token,  1542.08 tokens per second)\n",
      "llama_print_timings:        eval time =      50.61 ms /     3 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     147.41 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    61 tokens (    0.72 ms per token,  1389.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      95.19 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    60 tokens (    0.73 ms per token,  1367.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.41 ms /   100 tokens (    0.64 ms per token,  1552.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      98.35 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.26 ms /   110 tokens (    0.60 ms per token,  1660.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.10 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.41 ms /    89 tokens (    0.66 ms per token,  1523.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.79 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    78 tokens (    0.65 ms per token,  1538.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      85.30 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.87 ms /    86 tokens (    0.67 ms per token,  1486.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.86 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.01 ms /   109 tokens (    0.61 ms per token,  1651.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     101.05 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.52 ms /   105 tokens (    0.62 ms per token,  1602.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    91 tokens (    0.64 ms per token,  1556.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.92 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    60 tokens (    0.73 ms per token,  1369.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    57 tokens (    0.76 ms per token,  1309.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    75 tokens (    0.67 ms per token,  1483.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     101.90 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.63 ms /   106 tokens (    0.62 ms per token,  1615.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     100.43 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.25 ms /   138 tokens (    0.68 ms per token,  1464.14 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     145.83 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.75 ms /   184 tokens (    0.60 ms per token,  1661.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =     145.75 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.42 ms /    49 tokens (    0.87 ms per token,  1155.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      75.85 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    68 tokens (    0.74 ms per token,  1355.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.80 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    54 tokens (    0.80 ms per token,  1252.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.02 ms /   109 tokens (    0.61 ms per token,  1651.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     100.08 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    76 tokens (    0.67 ms per token,  1498.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      85.15 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.97 ms /   109 tokens (    0.61 ms per token,  1652.22 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     117.42 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.19 ms /    97 tokens (    0.66 ms per token,  1511.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     115.42 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.35 ms /   120 tokens (    0.61 ms per token,  1636.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.18 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    93 tokens (    0.63 ms per token,  1591.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     109.60 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.38 ms /    72 tokens (    0.70 ms per token,  1429.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.12 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.40 ms /   131 tokens (    0.71 ms per token,  1402.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     128.14 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    66 tokens (    0.75 ms per token,  1326.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.82 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.32 ms /    90 tokens (    0.65 ms per token,  1543.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.92 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.46 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.11 ms /    81 tokens (    0.71 ms per token,  1418.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      92.05 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.95 ms /    93 tokens (    0.63 ms per token,  1577.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      94.08 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.16 ms /    96 tokens (    0.62 ms per token,  1622.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      93.77 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    74 tokens (    0.68 ms per token,  1474.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     101.62 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.16 ms /    82 tokens (    0.70 ms per token,  1434.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.79 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.57 ms /   107 tokens (    0.61 ms per token,  1631.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.66 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.38 ms /   159 tokens (    0.61 ms per token,  1632.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     131.83 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.80 ms /    87 tokens (    0.66 ms per token,  1505.22 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     110.42 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.77 ms /   107 tokens (    0.61 ms per token,  1626.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.82 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.65 ms /    84 tokens (    0.69 ms per token,  1456.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    76 tokens (    0.67 ms per token,  1495.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    94 tokens (    0.63 ms per token,  1595.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =      94.46 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.03 ms /    83 tokens (    0.69 ms per token,  1455.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.50 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.19 ms /   160 tokens (    0.61 ms per token,  1646.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     131.91 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.99 ms /    79 tokens (    0.65 ms per token,  1549.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      85.76 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    67 tokens (    0.74 ms per token,  1353.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.60 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    52 tokens (    0.83 ms per token,  1210.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   106 tokens (    0.62 ms per token,  1616.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      99.55 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.78 ms /   101 tokens (    0.64 ms per token,  1559.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     100.35 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.77 ms /   166 tokens (    0.66 ms per token,  1526.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =     143.70 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.77 ms /   134 tokens (    0.70 ms per token,  1429.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     128.58 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.12 ms /   119 tokens (    0.61 ms per token,  1627.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     107.66 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    72 tokens (    0.70 ms per token,  1435.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.78 ms /   128 tokens (    0.58 ms per token,  1711.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     109.42 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    74 tokens (    0.68 ms per token,  1469.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.23 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    77 tokens (    0.66 ms per token,  1507.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.74 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.68 ms /    53 tokens (    0.81 ms per token,  1241.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.42 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.95 ms /    94 tokens (    0.63 ms per token,  1594.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =      93.78 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    63 tokens (    0.70 ms per token,  1429.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    77 tokens (    0.66 ms per token,  1506.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      85.10 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.12 ms /   162 tokens (    0.67 ms per token,  1498.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     142.49 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.18 ms /    90 tokens (    0.65 ms per token,  1546.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      93.27 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.34 ms /    58 tokens (    0.75 ms per token,  1338.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.83 ms /   161 tokens (    0.67 ms per token,  1493.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     142.96 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.33 ms /    95 tokens (    0.62 ms per token,  1601.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      93.76 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.82 ms /   112 tokens (    0.60 ms per token,  1676.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     101.24 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    70 tokens (    0.72 ms per token,  1397.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.46 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    53 tokens (    0.81 ms per token,  1231.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    59 tokens (    0.74 ms per token,  1346.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.62 ms /   154 tokens (    0.63 ms per token,  1593.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     131.39 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    63 tokens (    0.70 ms per token,  1430.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.16 ms /   113 tokens (    0.64 ms per token,  1566.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     106.75 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    55 tokens (    0.79 ms per token,  1268.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.41 ms /   111 tokens (    0.60 ms per token,  1671.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =     101.83 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    72 tokens (    0.69 ms per token,  1439.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    67 tokens (    0.74 ms per token,  1348.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    74 tokens (    0.68 ms per token,  1464.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.76 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.86 ms /   180 tokens (    0.62 ms per token,  1623.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.75 ms /     3 runs   (   16.92 ms per token,    59.11 tokens per second)\n",
      "llama_print_timings:       total time =     162.83 ms /   183 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    62 tokens (    0.71 ms per token,  1407.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.43 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.41 ms /   115 tokens (    0.63 ms per token,  1588.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     125.01 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    61 tokens (    0.72 ms per token,  1389.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.55 ms /   146 tokens (    0.65 ms per token,  1527.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     130.62 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    75 tokens (    0.68 ms per token,  1479.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.82 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.20 ms /   160 tokens (    0.61 ms per token,  1646.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.56 ms /     3 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     148.78 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.77 ms /   108 tokens (    0.61 ms per token,  1642.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.57 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    87 tokens (    0.67 ms per token,  1496.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.27 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.90 ms /   143 tokens (    0.66 ms per token,  1506.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     129.65 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    88 tokens (    0.66 ms per token,  1520.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.56 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.75 ms /   180 tokens (    0.62 ms per token,  1625.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     145.78 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.57 ms /    57 tokens (    0.76 ms per token,  1308.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.66 ms /   115 tokens (    0.63 ms per token,  1582.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     107.07 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    57 tokens (    0.76 ms per token,  1315.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.58 ms /   147 tokens (    0.65 ms per token,  1538.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     130.79 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   107 tokens (    0.61 ms per token,  1631.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     100.74 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.61 ms /   153 tokens (    0.63 ms per token,  1583.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.93 ms /     2 runs   (   16.97 ms per token,    58.94 tokens per second)\n",
      "llama_print_timings:       total time =     132.00 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.98 ms /   117 tokens (    0.62 ms per token,  1603.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     107.50 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.56 ms /   238 tokens (    0.60 ms per token,  1669.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.36 ms /     2 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     176.48 ms /   240 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.32 ms /   137 tokens (    0.69 ms per token,  1452.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     128.93 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    77 tokens (    0.66 ms per token,  1511.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.64 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.29 ms /    96 tokens (    0.62 ms per token,  1619.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.55 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    60 tokens (    0.73 ms per token,  1371.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.06 ms /    80 tokens (    0.65 ms per token,  1536.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     104.20 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.30 ms /   140 tokens (    0.67 ms per token,  1484.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     128.94 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.75 ms /   143 tokens (    0.66 ms per token,  1509.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     129.50 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.82 ms /    80 tokens (    0.65 ms per token,  1543.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      86.83 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.53 ms /   121 tokens (    0.61 ms per token,  1645.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.14 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    72 tokens (    0.70 ms per token,  1429.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.89 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    76 tokens (    0.67 ms per token,  1496.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    65 tokens (    0.76 ms per token,  1315.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      83.83 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    93 tokens (    0.63 ms per token,  1586.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.89 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.36 ms /   205 tokens (    0.61 ms per token,  1648.49 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     175.84 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    75 tokens (    0.67 ms per token,  1483.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.62 ms /   114 tokens (    0.64 ms per token,  1569.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     107.94 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    78 tokens (    0.65 ms per token,  1538.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.30 ms /     2 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =      84.75 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    71 tokens (    0.71 ms per token,  1418.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.18 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    68 tokens (    0.73 ms per token,  1365.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.88 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.26 ms /   151 tokens (    0.64 ms per token,  1568.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.89 ms /     2 runs   (   16.94 ms per token,    59.02 tokens per second)\n",
      "llama_print_timings:       total time =     131.82 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.43 ms /   115 tokens (    0.63 ms per token,  1587.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     106.98 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.11 ms /   103 tokens (    0.63 ms per token,  1581.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.56 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.38 ms /    75 tokens (    0.67 ms per token,  1488.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    59 tokens (    0.74 ms per token,  1349.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.59 ms /   165 tokens (    0.66 ms per token,  1519.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     143.00 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    75 tokens (    0.67 ms per token,  1486.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.20 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.38 ms /    65 tokens (    0.76 ms per token,  1316.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.29 ms /   178 tokens (    0.62 ms per token,  1613.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     145.16 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.01 ms /    55 tokens (    0.78 ms per token,  1278.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      76.41 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.46 ms /   131 tokens (    0.71 ms per token,  1401.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.08 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    61 tokens (    0.72 ms per token,  1384.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.67 ms /    99 tokens (    0.65 ms per token,  1530.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      99.44 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    83 tokens (    0.69 ms per token,  1451.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.65 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.33 ms /   160 tokens (    0.61 ms per token,  1643.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     131.69 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    67 tokens (    0.74 ms per token,  1352.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    63 tokens (    0.70 ms per token,  1426.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.94 ms /    60 tokens (    0.73 ms per token,  1365.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      94.92 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    68 tokens (    0.73 ms per token,  1370.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.91 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.04 ms /    80 tokens (    0.65 ms per token,  1537.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     103.42 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    77 tokens (    0.66 ms per token,  1510.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.05 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.24 ms /   113 tokens (    0.64 ms per token,  1564.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     106.92 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    70 tokens (    0.71 ms per token,  1399.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    82 tokens (    0.70 ms per token,  1433.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    85 tokens (    0.68 ms per token,  1480.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.95 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.66 ms /   134 tokens (    0.70 ms per token,  1430.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     128.49 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.11 ms /   109 tokens (    0.61 ms per token,  1648.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     100.50 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.17 ms /   118 tokens (    0.62 ms per token,  1612.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     107.91 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.96 ms /    77 tokens (    0.66 ms per token,  1511.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      85.08 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.66 ms /   107 tokens (    0.61 ms per token,  1629.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     117.76 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.60 ms /   160 tokens (    0.61 ms per token,  1639.38 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     149.65 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.48 ms /    64 tokens (    0.69 ms per token,  1438.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    70 tokens (    0.71 ms per token,  1399.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    69 tokens (    0.72 ms per token,  1383.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    73 tokens (    0.69 ms per token,  1450.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =      84.92 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.14 ms /    97 tokens (    0.66 ms per token,  1512.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      98.16 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    90 tokens (    0.65 ms per token,  1540.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.25 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    71 tokens (    0.71 ms per token,  1415.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    65 tokens (    0.76 ms per token,  1312.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      84.32 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    70 tokens (    0.71 ms per token,  1409.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     100.49 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    86 tokens (    0.67 ms per token,  1487.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.60 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    84 tokens (    0.68 ms per token,  1462.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.71 ms /   141 tokens (    0.67 ms per token,  1488.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     129.64 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    84 tokens (    0.69 ms per token,  1458.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.86 ms /   119 tokens (    0.61 ms per token,  1633.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     107.85 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    67 tokens (    0.74 ms per token,  1348.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.11 ms /    61 tokens (    0.72 ms per token,  1382.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.59 ms /   105 tokens (    0.62 ms per token,  1600.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.75 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.52 ms /    49 tokens (    0.87 ms per token,  1152.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.23 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.69 ms /   112 tokens (    0.60 ms per token,  1679.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     101.73 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.95 ms /    82 tokens (    0.69 ms per token,  1439.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.05 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    59 tokens (    0.74 ms per token,  1346.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.78 ms /    86 tokens (    0.67 ms per token,  1488.38 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     109.94 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    67 tokens (    0.74 ms per token,  1349.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =      85.11 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    75 tokens (    0.67 ms per token,  1489.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     100.88 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.28 ms /    90 tokens (    0.65 ms per token,  1544.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.25 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.46 ms /    67 tokens (    0.74 ms per token,  1354.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /   131 runs   (    0.05 ms per token, 18974.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.73 ms /   107 tokens (    0.61 ms per token,  1627.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2187.02 ms /   130 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =    2309.05 ms /   237 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.18 ms /    79 tokens (    0.65 ms per token,  1543.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      86.05 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.77 ms /    86 tokens (    0.67 ms per token,  1488.56 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     109.25 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.15 ms /    95 tokens (    0.62 ms per token,  1605.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.97 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    71 tokens (    0.71 ms per token,  1414.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    69 tokens (    0.73 ms per token,  1377.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.66 ms /   161 tokens (    0.67 ms per token,  1495.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     142.30 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.91 ms /   109 tokens (    0.60 ms per token,  1653.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     100.87 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.30 ms /    98 tokens (    0.66 ms per token,  1524.15 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     116.24 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    84 tokens (    0.69 ms per token,  1459.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.11 ms /   138 tokens (    0.68 ms per token,  1466.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     128.56 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.77 ms /   170 tokens (    0.64 ms per token,  1562.92 tokens per second)\n",
      "llama_print_timings:        eval time =      50.61 ms /     3 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     161.04 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    73 tokens (    0.69 ms per token,  1454.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.28 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    61 tokens (    0.72 ms per token,  1387.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      94.82 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.85 ms /    87 tokens (    0.66 ms per token,  1503.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.18 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.64 ms /    80 tokens (    0.65 ms per token,  1549.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      86.62 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    83 tokens (    0.69 ms per token,  1450.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      91.81 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.65 ms /   126 tokens (    0.59 ms per token,  1687.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     109.36 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.89 ms /    83 tokens (    0.69 ms per token,  1458.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.89 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    64 tokens (    0.69 ms per token,  1442.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.31 ms /    65 tokens (    0.76 ms per token,  1318.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      85.03 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.97 ms /   164 tokens (    0.66 ms per token,  1518.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     142.35 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    70 tokens (    0.71 ms per token,  1403.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    84 tokens (    0.69 ms per token,  1458.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.43 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.12 ms /    78 tokens (    0.66 ms per token,  1525.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.36 ms /     2 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =      86.30 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.10 ms /    73 tokens (    0.69 ms per token,  1457.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     101.08 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.09 ms /    77 tokens (    0.66 ms per token,  1507.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.82 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    75 tokens (    0.68 ms per token,  1479.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.51 ms /    99 tokens (    0.65 ms per token,  1534.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      98.80 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.20 ms /    84 tokens (    0.68 ms per token,  1468.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =      91.16 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    78 tokens (    0.65 ms per token,  1538.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.18 ms /     3 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =     102.46 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.23 ms /   157 tokens (    0.62 ms per token,  1614.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     131.84 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.65 ms /    94 tokens (    0.62 ms per token,  1602.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    58 tokens (    0.75 ms per token,  1329.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.18 ms /    77 tokens (    0.66 ms per token,  1504.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      85.26 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    85 tokens (    0.68 ms per token,  1471.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =      92.89 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     6 runs   (    0.05 ms per token, 19543.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.40 ms /   215 tokens (    0.60 ms per token,  1674.43 tokens per second)\n",
      "llama_print_timings:        eval time =      83.34 ms /     5 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     214.33 ms /   220 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.87 ms /   101 tokens (    0.64 ms per token,  1556.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.28 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.75 ms /   116 tokens (    0.63 ms per token,  1594.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     107.23 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.98 ms /    81 tokens (    0.70 ms per token,  1421.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.88 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.42 ms /    66 tokens (    0.75 ms per token,  1335.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.25 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.72 ms /   105 tokens (    0.63 ms per token,  1597.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.23 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    74 tokens (    0.68 ms per token,  1464.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.12 ms /   130 tokens (    0.72 ms per token,  1395.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.86 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     128.63 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    61 tokens (    0.72 ms per token,  1393.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.14 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    88 tokens (    0.66 ms per token,  1517.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.63 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.57 ms /   142 tokens (    0.67 ms per token,  1501.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     129.80 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.12 ms /   111 tokens (    0.60 ms per token,  1678.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     117.94 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.36 ms /   105 tokens (    0.62 ms per token,  1606.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.36 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    78 tokens (    0.65 ms per token,  1531.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =      85.01 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    73 tokens (    0.69 ms per token,  1446.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      84.51 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.45 ms /    83 tokens (    0.69 ms per token,  1444.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    70 tokens (    0.71 ms per token,  1399.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.49 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.50 ms /    66 tokens (    0.75 ms per token,  1333.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    61 tokens (    0.72 ms per token,  1387.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      94.47 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    73 tokens (    0.69 ms per token,  1449.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.00 ms /    82 tokens (    0.70 ms per token,  1438.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.29 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    74 tokens (    0.68 ms per token,  1475.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.27 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.67 ms /   168 tokens (    0.65 ms per token,  1545.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     143.43 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    68 tokens (    0.73 ms per token,  1369.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.63 ms /    75 tokens (    0.68 ms per token,  1481.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    82 tokens (    0.70 ms per token,  1430.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    58 tokens (    0.75 ms per token,  1330.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.86 ms /   123 tokens (    0.60 ms per token,  1665.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     108.84 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    72 tokens (    0.70 ms per token,  1429.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.32 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    70 tokens (    0.72 ms per token,  1398.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.91 ms /    75 tokens (    0.68 ms per token,  1473.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    79 tokens (    0.65 ms per token,  1549.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      86.34 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.83 ms /    80 tokens (    0.65 ms per token,  1543.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      86.65 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    77 tokens (    0.66 ms per token,  1519.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    63 tokens (    0.70 ms per token,  1427.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      94.85 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.01 ms /    80 tokens (    0.65 ms per token,  1538.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      86.26 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    85 tokens (    0.68 ms per token,  1473.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      92.62 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.77 ms /    95 tokens (    0.62 ms per token,  1616.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.78 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    51 tokens (    0.84 ms per token,  1187.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.80 ms /   101 tokens (    0.64 ms per token,  1558.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.63 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.76 ms /   112 tokens (    0.60 ms per token,  1677.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.33 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1448.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.63 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    94 tokens (    0.63 ms per token,  1595.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      94.09 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.62 ms /    87 tokens (    0.66 ms per token,  1509.89 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     109.36 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.28 ms /   111 tokens (    0.60 ms per token,  1674.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.47 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    63 tokens (    0.70 ms per token,  1419.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      79.00 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.81 ms /   101 tokens (    0.64 ms per token,  1558.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.26 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    68 tokens (    0.73 ms per token,  1371.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    70 tokens (    0.72 ms per token,  1392.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.29 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.86 ms /   180 tokens (    0.62 ms per token,  1623.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.84 ms /     2 runs   (   16.92 ms per token,    59.11 tokens per second)\n",
      "llama_print_timings:       total time =     145.57 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    82 tokens (    0.70 ms per token,  1437.06 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.26 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.45 ms /    64 tokens (    0.69 ms per token,  1439.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.68 ms /   134 tokens (    0.70 ms per token,  1430.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     128.42 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.87 ms /    81 tokens (    0.70 ms per token,  1424.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.63 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    76 tokens (    0.67 ms per token,  1491.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.49 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.45 ms /    84 tokens (    0.68 ms per token,  1462.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.66 ms /    80 tokens (    0.65 ms per token,  1548.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      85.91 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.01 ms /    81 tokens (    0.70 ms per token,  1420.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    67 tokens (    0.74 ms per token,  1348.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.02 ms /    86 tokens (    0.67 ms per token,  1482.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.32 ms /    67 tokens (    0.74 ms per token,  1358.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.15 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.25 ms /   110 tokens (    0.60 ms per token,  1660.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =     101.12 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1429.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.12 ms /    90 tokens (    0.65 ms per token,  1548.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.95 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    84 tokens (    0.68 ms per token,  1460.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      91.93 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.89 ms /   102 tokens (    0.64 ms per token,  1571.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      99.34 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.21 ms /    54 tokens (    0.80 ms per token,  1249.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      93.55 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    76 tokens (    0.67 ms per token,  1494.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.45 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.80 ms /    84 tokens (    0.69 ms per token,  1453.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.40 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.29 ms /    66 tokens (    0.75 ms per token,  1339.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.85 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    86 tokens (    0.67 ms per token,  1490.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.25 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.07 ms /    95 tokens (    0.62 ms per token,  1608.32 tokens per second)\n",
      "llama_print_timings:        eval time =      50.34 ms /     3 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     110.49 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    57 tokens (    0.77 ms per token,  1304.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.94 ms /    88 tokens (    0.66 ms per token,  1518.89 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     109.48 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.86 ms /    81 tokens (    0.70 ms per token,  1424.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.43 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    59 tokens (    0.75 ms per token,  1341.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    86 tokens (    0.67 ms per token,  1487.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.89 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    69 tokens (    0.72 ms per token,  1387.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      83.99 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.80 ms /   133 tokens (    0.71 ms per token,  1417.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     128.80 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.23 ms /   111 tokens (    0.60 ms per token,  1675.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     100.92 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.63 ms /   105 tokens (    0.63 ms per token,  1599.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      99.80 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    56 tokens (    0.78 ms per token,  1287.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    59 tokens (    0.74 ms per token,  1343.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      95.07 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.47 ms /    79 tokens (    0.65 ms per token,  1534.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      85.95 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.92 ms /    82 tokens (    0.69 ms per token,  1440.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      91.72 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.48 ms /   142 tokens (    0.67 ms per token,  1503.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     129.52 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.39 ms /   186 tokens (    0.60 ms per token,  1669.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     146.87 ms /   188 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    69 tokens (    0.72 ms per token,  1387.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     100.39 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.63 ms /   106 tokens (    0.62 ms per token,  1615.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.63 ms /     3 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     117.84 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    73 tokens (    0.69 ms per token,  1444.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.90 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /   106 runs   (    0.05 ms per token, 18771.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.96 ms /   122 tokens (    0.61 ms per token,  1649.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1767.47 ms /   105 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1886.33 ms /   227 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    77 tokens (    0.66 ms per token,  1513.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.54 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.73 ms /   136 tokens (    0.69 ms per token,  1451.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     128.26 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.97 ms /   103 tokens (    0.63 ms per token,  1585.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.45 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    76 tokens (    0.67 ms per token,  1494.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      85.32 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    59 tokens (    0.74 ms per token,  1359.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    76 tokens (    0.67 ms per token,  1496.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.98 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.29 ms /    96 tokens (    0.62 ms per token,  1619.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      93.81 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16304.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    62 tokens (    0.71 ms per token,  1407.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    65 tokens (    0.76 ms per token,  1317.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.28 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.59 ms /    65 tokens (    0.76 ms per token,  1310.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.45 ms /   116 tokens (    0.62 ms per token,  1600.99 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     124.01 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     101.42 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    68 tokens (    0.73 ms per token,  1369.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.05 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.70 ms /    85 tokens (    0.68 ms per token,  1473.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.49 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.19 ms /    64 tokens (    0.69 ms per token,  1448.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      95.57 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.14 ms /    96 tokens (    0.62 ms per token,  1623.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.66 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.09 ms /   124 tokens (    0.60 ms per token,  1673.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     108.51 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.35 ms /    56 tokens (    0.77 ms per token,  1291.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      94.31 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    63 tokens (    0.70 ms per token,  1420.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.87 ms /    94 tokens (    0.63 ms per token,  1596.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.85 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.28 ms /    65 tokens (    0.76 ms per token,  1319.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    86 tokens (    0.67 ms per token,  1487.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.63 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.19 ms /    89 tokens (    0.65 ms per token,  1529.45 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     109.55 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    71 tokens (    0.71 ms per token,  1413.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    59 tokens (    0.74 ms per token,  1353.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    74 tokens (    0.68 ms per token,  1469.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.86 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    83 tokens (    0.69 ms per token,  1447.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      91.45 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.80 ms /   122 tokens (    0.60 ms per token,  1653.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.03 tokens per second)\n",
      "llama_print_timings:       total time =     109.10 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.57 ms /   207 tokens (    0.60 ms per token,  1661.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.40 ms /     2 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     158.79 ms /   209 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.01 ms /    80 tokens (    0.65 ms per token,  1538.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      87.06 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.55 ms /   100 tokens (    0.65 ms per token,  1549.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.05 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.23 ms /    89 tokens (    0.65 ms per token,  1528.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.16 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.49 ms /    98 tokens (    0.66 ms per token,  1519.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      99.07 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    59 tokens (    0.74 ms per token,  1350.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    91 tokens (    0.64 ms per token,  1556.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.26 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.52 ms /   128 tokens (    0.58 ms per token,  1717.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     109.71 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    77 tokens (    0.66 ms per token,  1518.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.18 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.63 ms /    92 tokens (    0.64 ms per token,  1569.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.55 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.21 ms /    90 tokens (    0.65 ms per token,  1546.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.81 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15544.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    76 tokens (    0.66 ms per token,  1504.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      85.04 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    75 tokens (    0.67 ms per token,  1488.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      84.19 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    69 tokens (    0.72 ms per token,  1383.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.59 ms /   134 tokens (    0.70 ms per token,  1431.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     145.39 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    71 tokens (    0.70 ms per token,  1419.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.33 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.64 ms /   100 tokens (    0.65 ms per token,  1546.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.27 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.63 ms /   107 tokens (    0.61 ms per token,  1630.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     101.19 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.52 ms /   105 tokens (    0.62 ms per token,  1602.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     100.40 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    86 tokens (    0.67 ms per token,  1487.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.08 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    74 tokens (    0.68 ms per token,  1466.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.48 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.07 ms /    81 tokens (    0.70 ms per token,  1419.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.82 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.06 ms /   143 tokens (    0.66 ms per token,  1504.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     129.85 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.94 ms /   150 tokens (    0.64 ms per token,  1563.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     130.51 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.41 ms /   115 tokens (    0.63 ms per token,  1588.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     106.56 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.54 ms /   111 tokens (    0.60 ms per token,  1668.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.27 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    73 tokens (    0.69 ms per token,  1452.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.43 ms /    97 tokens (    0.66 ms per token,  1505.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.14 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.18 ms /    90 tokens (    0.65 ms per token,  1546.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      92.70 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.22 ms /    83 tokens (    0.69 ms per token,  1450.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      91.82 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.56 ms /   128 tokens (    0.58 ms per token,  1716.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     109.00 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.54 ms /   127 tokens (    0.59 ms per token,  1703.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     109.31 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.30 ms /    74 tokens (    0.68 ms per token,  1471.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     101.06 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    87 tokens (    0.67 ms per token,  1493.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.40 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.71 ms /   123 tokens (    0.60 ms per token,  1668.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     108.63 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    84 tokens (    0.68 ms per token,  1467.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.63 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.60 ms /   173 tokens (    0.63 ms per token,  1578.42 tokens per second)\n",
      "llama_print_timings:        eval time =      50.61 ms /     3 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     161.75 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    92 tokens (    0.64 ms per token,  1570.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      93.80 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    62 tokens (    0.71 ms per token,  1412.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    74 tokens (    0.68 ms per token,  1464.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    61 tokens (    0.72 ms per token,  1392.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.49 ms /   187 tokens (    0.60 ms per token,  1677.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.70 ms /     3 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =     164.06 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    52 tokens (    0.83 ms per token,  1205.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      76.97 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.28 ms /    97 tokens (    0.66 ms per token,  1509.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      98.71 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.42 ms /    99 tokens (    0.65 ms per token,  1536.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.35 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.98 ms /   162 tokens (    0.67 ms per token,  1500.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.95 ms per token,    58.98 tokens per second)\n",
      "llama_print_timings:       total time =     143.85 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.49 ms /   187 tokens (    0.60 ms per token,  1677.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.80 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     146.19 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.06 ms /   138 tokens (    0.68 ms per token,  1467.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.32 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.70 ms /   115 tokens (    0.63 ms per token,  1581.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     107.10 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.77 ms /    93 tokens (    0.63 ms per token,  1582.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      93.47 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.42 ms /    91 tokens (    0.64 ms per token,  1557.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      93.37 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    73 tokens (    0.69 ms per token,  1448.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.01 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    52 tokens (    0.82 ms per token,  1213.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.71 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1428.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.40 ms /   111 tokens (    0.60 ms per token,  1671.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     118.72 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.76 ms /    77 tokens (    0.66 ms per token,  1516.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.11 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    69 tokens (    0.72 ms per token,  1382.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.06 ms /   118 tokens (    0.62 ms per token,  1615.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     108.12 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.34 ms /    79 tokens (    0.65 ms per token,  1538.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      86.22 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.14 ms /    84 tokens (    0.68 ms per token,  1470.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      91.57 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.03 ms /    81 tokens (    0.70 ms per token,  1420.28 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     108.48 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.47 ms /   125 tokens (    0.60 ms per token,  1678.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     126.26 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    50 tokens (    0.85 ms per token,  1170.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      76.65 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    78 tokens (    0.65 ms per token,  1528.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      84.80 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.25 ms /    56 tokens (    0.77 ms per token,  1294.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.38 ms /    67 tokens (    0.74 ms per token,  1356.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.37 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.99 ms /    77 tokens (    0.66 ms per token,  1510.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.43 ms /    85 tokens (    0.68 ms per token,  1480.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =      92.42 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.79 ms /   156 tokens (    0.62 ms per token,  1611.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     131.74 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.75 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.37 ms /    79 tokens (    0.65 ms per token,  1537.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      86.33 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.02 ms /    96 tokens (    0.61 ms per token,  1626.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =      94.03 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    90 tokens (    0.65 ms per token,  1547.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.33 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.57 ms /    59 tokens (    0.74 ms per token,  1354.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.44 ms /    98 tokens (    0.66 ms per token,  1520.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.15 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.12 ms /    97 tokens (    0.66 ms per token,  1512.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      98.68 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    69 tokens (    0.72 ms per token,  1386.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     100.97 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.33 ms /    96 tokens (    0.62 ms per token,  1617.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.90 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.56 ms /   142 tokens (    0.67 ms per token,  1501.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     129.37 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.95 ms /   108 tokens (    0.61 ms per token,  1637.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     101.18 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    75 tokens (    0.68 ms per token,  1477.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.88 ms /    77 tokens (    0.66 ms per token,  1513.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.47 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.05 ms /   137 tokens (    0.69 ms per token,  1456.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     128.98 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1542.79 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     104.66 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.00 ms /    55 tokens (    0.78 ms per token,  1279.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      76.30 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.21 ms /    97 tokens (    0.66 ms per token,  1510.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      99.31 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    69 tokens (    0.72 ms per token,  1387.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.05 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.95 ms /   149 tokens (    0.64 ms per token,  1552.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     131.18 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.40 ms /   115 tokens (    0.63 ms per token,  1588.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     107.02 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.51 ms /    64 tokens (    0.70 ms per token,  1437.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.75 ms /    59 tokens (    0.74 ms per token,  1348.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    73 tokens (    0.69 ms per token,  1448.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.29 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    75 tokens (    0.67 ms per token,  1483.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.41 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.25 ms /   103 tokens (    0.63 ms per token,  1578.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      99.53 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    89 tokens (    0.65 ms per token,  1534.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.12 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.97 ms /   195 tokens (    0.63 ms per token,  1585.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.80 ms /     2 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =     157.97 ms /   197 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    73 tokens (    0.69 ms per token,  1449.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      84.80 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.19 ms /   114 tokens (    0.63 ms per token,  1579.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     106.49 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    52 tokens (    0.83 ms per token,  1210.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.52 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.86 ms /    58 tokens (    0.76 ms per token,  1322.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    64 tokens (    0.69 ms per token,  1442.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    60 tokens (    0.73 ms per token,  1364.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.18 ms /    82 tokens (    0.70 ms per token,  1434.14 tokens per second)\n",
      "llama_print_timings:        eval time =      50.56 ms /     3 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     109.47 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.21 ms /    57 tokens (    0.76 ms per token,  1319.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    61 tokens (    0.72 ms per token,  1387.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.89 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    75 tokens (    0.67 ms per token,  1490.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.90 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.31 ms /    61 tokens (    0.73 ms per token,  1376.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    78 tokens (    0.66 ms per token,  1526.54 tokens per second)\n",
      "llama_print_timings:        eval time =      50.35 ms /     3 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     103.10 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.13 ms /   132 tokens (    0.71 ms per token,  1417.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     127.65 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    69 tokens (    0.72 ms per token,  1384.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      83.70 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.38 ms /   104 tokens (    0.63 ms per token,  1590.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.39 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.26 ms /    96 tokens (    0.62 ms per token,  1620.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      94.08 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    64 tokens (    0.69 ms per token,  1443.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.63 ms /   143 tokens (    0.66 ms per token,  1511.13 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     147.12 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.79 ms /    54 tokens (    0.79 ms per token,  1261.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.26 ms /   125 tokens (    0.59 ms per token,  1683.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     110.06 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    60 tokens (    0.73 ms per token,  1374.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    72 tokens (    0.70 ms per token,  1430.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      84.53 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.38 ms /    91 tokens (    0.64 ms per token,  1558.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.01 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.78 ms /    93 tokens (    0.63 ms per token,  1582.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.88 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    83 tokens (    0.69 ms per token,  1446.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.06 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.21 ms /    66 tokens (    0.75 ms per token,  1341.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.59 ms /    72 tokens (    0.70 ms per token,  1423.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.21 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    77 tokens (    0.66 ms per token,  1518.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      85.31 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.73 ms /    86 tokens (    0.67 ms per token,  1489.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.09 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    66 tokens (    0.75 ms per token,  1336.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      99.99 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    60 tokens (    0.73 ms per token,  1372.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    68 tokens (    0.73 ms per token,  1367.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      84.26 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    54 tokens (    0.80 ms per token,  1251.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      93.45 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    75 tokens (    0.68 ms per token,  1481.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.42 ms /   104 tokens (    0.63 ms per token,  1589.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     100.27 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.72 ms /   136 tokens (    0.69 ms per token,  1451.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     128.05 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.57 ms /    92 tokens (    0.64 ms per token,  1570.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      93.31 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.06 ms /   309 tokens (    0.62 ms per token,  1625.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     224.66 ms /   311 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    68 tokens (    0.73 ms per token,  1363.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      84.72 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.34 ms /     2 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =      84.96 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.91 ms /   108 tokens (    0.61 ms per token,  1638.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.44 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.81 ms /   159 tokens (    0.62 ms per token,  1625.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     132.73 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.76 ms /   129 tokens (    0.72 ms per token,  1390.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     127.36 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.99 ms /   125 tokens (    0.59 ms per token,  1689.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     108.51 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    74 tokens (    0.68 ms per token,  1468.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.47 ms /    64 tokens (    0.69 ms per token,  1439.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.31 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.95 ms /    78 tokens (    0.65 ms per token,  1530.82 tokens per second)\n",
      "llama_print_timings:        eval time =      50.05 ms /     3 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     102.44 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.61 ms /    74 tokens (    0.68 ms per token,  1462.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      84.68 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.25 ms /   111 tokens (    0.60 ms per token,  1675.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     100.66 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.26 ms /    63 tokens (    0.70 ms per token,  1423.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.17 ms /    97 tokens (    0.66 ms per token,  1511.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      98.48 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.11 ms /    46 tokens (    0.81 ms per token,  1239.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      71.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.32 ms /    93 tokens (    0.63 ms per token,  1594.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.65 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    71 tokens (    0.70 ms per token,  1419.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.64 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.47 ms /   119 tokens (    0.62 ms per token,  1619.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     108.34 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.91 ms /    89 tokens (    0.65 ms per token,  1536.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      92.46 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    62 tokens (    0.71 ms per token,  1411.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.69 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    92 tokens (    0.64 ms per token,  1570.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.52 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.37 ms /   120 tokens (    0.61 ms per token,  1635.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     108.29 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    62 tokens (    0.71 ms per token,  1410.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    54 tokens (    0.80 ms per token,  1251.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      94.34 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    66 tokens (    0.75 ms per token,  1327.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.95 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    56 tokens (    0.77 ms per token,  1298.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.18 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.11 ms /    83 tokens (    0.69 ms per token,  1453.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.01 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.92 ms /    81 tokens (    0.70 ms per token,  1423.12 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.85 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    67 tokens (    0.74 ms per token,  1352.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.25 ms /   114 tokens (    0.63 ms per token,  1577.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     106.92 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    79 tokens (    0.64 ms per token,  1551.27 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     102.27 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   102 tokens (    0.64 ms per token,  1568.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      99.17 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.13 ms /   110 tokens (    0.60 ms per token,  1663.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     101.23 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.40 ms /   164 tokens (    0.66 ms per token,  1512.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     143.02 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    75 tokens (    0.67 ms per token,  1485.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.84 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    63 tokens (    0.70 ms per token,  1421.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      79.19 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    74 tokens (    0.68 ms per token,  1465.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.93 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.53 ms /   115 tokens (    0.63 ms per token,  1585.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     107.14 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.16 ms /    82 tokens (    0.70 ms per token,  1434.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =      92.54 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.70 ms /   108 tokens (    0.61 ms per token,  1643.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     117.00 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.42 ms /    98 tokens (    0.66 ms per token,  1521.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      98.66 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    75 tokens (    0.68 ms per token,  1479.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.38 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.32 ms /   113 tokens (    0.64 ms per token,  1562.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     106.84 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.64 ms /   116 tokens (    0.63 ms per token,  1596.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     107.60 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    69 tokens (    0.72 ms per token,  1389.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.93 ms /    94 tokens (    0.63 ms per token,  1595.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      93.73 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.24 ms /   101 tokens (    0.65 ms per token,  1548.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.36 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.65 ms /    80 tokens (    0.65 ms per token,  1549.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      86.57 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    60 tokens (    0.73 ms per token,  1363.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.72 ms /    94 tokens (    0.62 ms per token,  1600.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.49 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    64 tokens (    0.69 ms per token,  1447.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.46 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    88 tokens (    0.66 ms per token,  1517.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      93.02 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    70 tokens (    0.71 ms per token,  1404.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.39 ms /    95 tokens (    0.63 ms per token,  1599.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      94.06 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    77 tokens (    0.66 ms per token,  1517.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.80 ms /     3 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     101.88 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.52 ms /    91 tokens (    0.64 ms per token,  1554.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     110.56 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    58 tokens (    0.75 ms per token,  1325.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.50 ms /    99 tokens (    0.65 ms per token,  1534.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.20 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.97 ms /   125 tokens (    0.59 ms per token,  1689.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.74 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    70 tokens (    0.71 ms per token,  1404.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      84.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.51 ms /   144 tokens (    0.66 ms per token,  1507.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     129.96 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.75 ms /    87 tokens (    0.66 ms per token,  1506.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.19 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.09 ms /   186 tokens (    0.60 ms per token,  1674.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     146.25 ms /   188 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.57 ms /    93 tokens (    0.63 ms per token,  1587.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.89 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.86 ms /   155 tokens (    0.62 ms per token,  1600.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     131.12 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    71 tokens (    0.71 ms per token,  1415.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.24 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.17 ms /    81 tokens (    0.71 ms per token,  1416.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.76 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    58 tokens (    0.75 ms per token,  1329.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    75 tokens (    0.68 ms per token,  1481.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.68 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.62 ms /    76 tokens (    0.67 ms per token,  1501.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.73 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.45 ms /    96 tokens (    0.62 ms per token,  1614.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.77 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.44 ms /    72 tokens (    0.70 ms per token,  1427.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.31 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.36 ms /   104 tokens (    0.63 ms per token,  1591.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     100.30 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.18 ms /    98 tokens (    0.65 ms per token,  1527.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      98.87 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    64 tokens (    0.69 ms per token,  1442.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.77 ms /   375 tokens (    0.58 ms per token,  1722.04 tokens per second)\n",
      "llama_print_timings:        eval time =      34.66 ms /     2 runs   (   17.33 ms per token,    57.70 tokens per second)\n",
      "llama_print_timings:       total time =     253.61 ms /   377 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.74 ms /    94 tokens (    0.62 ms per token,  1600.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.73 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    70 tokens (    0.72 ms per token,  1398.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.08 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.68 ms /    92 tokens (    0.64 ms per token,  1567.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     110.84 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    66 tokens (    0.75 ms per token,  1331.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.39 ms /   126 tokens (    0.59 ms per token,  1693.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     109.38 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.95 ms /   138 tokens (    0.68 ms per token,  1468.85 tokens per second)\n",
      "llama_print_timings:        eval time =      50.52 ms /     3 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     145.78 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.45 ms /   104 tokens (    0.63 ms per token,  1589.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.47 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.16 ms /   114 tokens (    0.63 ms per token,  1579.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     106.35 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    71 tokens (    0.71 ms per token,  1416.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     101.32 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    84 tokens (    0.69 ms per token,  1457.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.93 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.21 ms /    65 tokens (    0.76 ms per token,  1320.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.29 ms /     2 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =      84.42 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.07 ms /    82 tokens (    0.70 ms per token,  1436.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      91.58 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.51 ms /    66 tokens (    0.75 ms per token,  1333.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      83.59 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.66 ms /    85 tokens (    0.68 ms per token,  1474.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.19 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.22 ms /    82 tokens (    0.70 ms per token,  1433.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.57 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    89 tokens (    0.65 ms per token,  1535.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      92.75 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.00 ms /    71 tokens (    0.70 ms per token,  1419.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.05 ms /   150 tokens (    0.64 ms per token,  1561.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     130.72 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.25 ms /    74 tokens (    0.68 ms per token,  1472.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.19 ms /   125 tokens (    0.59 ms per token,  1684.89 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     126.09 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.40 ms /    90 tokens (    0.65 ms per token,  1541.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.04 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    78 tokens (    0.65 ms per token,  1532.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.30 ms /     2 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =      85.08 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.23 ms /    79 tokens (    0.65 ms per token,  1542.13 tokens per second)\n",
      "llama_print_timings:        eval time =      50.50 ms /     3 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     103.14 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.89 ms /   101 tokens (    0.64 ms per token,  1556.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =      99.70 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    60 tokens (    0.73 ms per token,  1370.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.22 ms /    62 tokens (    0.71 ms per token,  1402.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.50 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.36 ms /   126 tokens (    0.59 ms per token,  1694.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.92 ms per token,    59.11 tokens per second)\n",
      "llama_print_timings:       total time =     110.01 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    72 tokens (    0.70 ms per token,  1437.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.77 ms /    87 tokens (    0.66 ms per token,  1506.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.38 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.55 ms /   127 tokens (    0.59 ms per token,  1703.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     109.07 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    72 tokens (    0.70 ms per token,  1427.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      85.21 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    76 tokens (    0.67 ms per token,  1496.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.85 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.89 ms /   155 tokens (    0.63 ms per token,  1599.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     131.23 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    72 tokens (    0.70 ms per token,  1430.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.21 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.56 ms /    57 tokens (    0.76 ms per token,  1308.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    52 tokens (    0.83 ms per token,  1207.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    72 tokens (    0.70 ms per token,  1429.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.12 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.08 ms /    80 tokens (    0.65 ms per token,  1536.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      86.43 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.10 ms /   137 tokens (    0.69 ms per token,  1455.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     129.21 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    86 tokens (    0.67 ms per token,  1493.83 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     109.96 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.10 ms /   171 tokens (    0.64 ms per token,  1567.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     143.91 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.56 ms /    91 tokens (    0.64 ms per token,  1553.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      92.86 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.01 ms /    80 tokens (    0.65 ms per token,  1538.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      86.36 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.42 ms /    73 tokens (    0.69 ms per token,  1447.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.78 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.31 ms /   110 tokens (    0.60 ms per token,  1658.90 tokens per second)\n",
      "llama_print_timings:        eval time =      50.57 ms /     3 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     118.92 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.41 ms /    92 tokens (    0.63 ms per token,  1575.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.65 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    66 tokens (    0.75 ms per token,  1331.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.17 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.17 ms /   130 tokens (    0.72 ms per token,  1395.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     128.18 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /    60 tokens (    0.73 ms per token,  1373.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.01 ms /    80 tokens (    0.65 ms per token,  1538.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      87.48 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.85 ms /    95 tokens (    0.62 ms per token,  1614.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.13 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.46 ms /   120 tokens (    0.61 ms per token,  1633.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     107.90 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    58 tokens (    0.75 ms per token,  1326.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      94.42 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.00 ms /   154 tokens (    0.63 ms per token,  1587.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.86 ms /     2 runs   (   16.93 ms per token,    59.07 tokens per second)\n",
      "llama_print_timings:       total time =     132.19 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    84 tokens (    0.68 ms per token,  1467.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.97 ms /    80 tokens (    0.65 ms per token,  1539.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      86.53 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    62 tokens (    0.71 ms per token,  1408.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.19 ms /   102 tokens (    0.64 ms per token,  1564.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     117.49 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.59 ms /    76 tokens (    0.67 ms per token,  1502.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.56 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    67 tokens (    0.74 ms per token,  1350.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    71 tokens (    0.71 ms per token,  1416.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.79 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.68 ms /   133 tokens (    0.70 ms per token,  1419.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     128.58 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.38 ms /   104 tokens (    0.63 ms per token,  1590.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.11 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    83 tokens (    0.69 ms per token,  1450.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.76 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.97 ms /    74 tokens (    0.69 ms per token,  1451.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.20 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.29 ms /   111 tokens (    0.60 ms per token,  1674.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.39 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.99 ms /   157 tokens (    0.62 ms per token,  1618.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     131.71 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.98 ms /   107 tokens (    0.62 ms per token,  1621.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     100.37 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.42 ms /   160 tokens (    0.61 ms per token,  1642.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.97 ms /     2 runs   (   16.98 ms per token,    58.88 tokens per second)\n",
      "llama_print_timings:       total time =     133.11 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    88 tokens (    0.66 ms per token,  1518.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.50 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.97 ms /    94 tokens (    0.63 ms per token,  1594.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.62 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    77 tokens (    0.66 ms per token,  1510.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.94 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.08 ms /    76 tokens (    0.67 ms per token,  1487.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      85.29 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    78 tokens (    0.65 ms per token,  1535.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.34 ms /     2 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =      85.11 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    63 tokens (    0.70 ms per token,  1428.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      95.38 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    61 tokens (    0.72 ms per token,  1387.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      95.15 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.46 ms /    65 tokens (    0.76 ms per token,  1314.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      82.98 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.62 ms /    49 tokens (    0.87 ms per token,  1149.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.93 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.86 ms /   101 tokens (    0.64 ms per token,  1557.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:       total time =      99.98 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.59 ms /    75 tokens (    0.67 ms per token,  1482.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.51 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.02 ms /    88 tokens (    0.66 ms per token,  1516.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.33 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    60 tokens (    0.73 ms per token,  1364.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    62 tokens (    0.71 ms per token,  1404.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    82 tokens (    0.70 ms per token,  1436.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      91.35 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.06 ms /    81 tokens (    0.70 ms per token,  1419.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =      92.65 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    85 tokens (    0.68 ms per token,  1479.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.79 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.81 ms /    81 tokens (    0.70 ms per token,  1425.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.36 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    66 tokens (    0.75 ms per token,  1331.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.65 ms /   155 tokens (    0.62 ms per token,  1603.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     131.22 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.77 ms /   181 tokens (    0.61 ms per token,  1634.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.97 ms /     2 runs   (   16.99 ms per token,    58.87 tokens per second)\n",
      "llama_print_timings:       total time =     146.17 ms /   183 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.64 ms /    86 tokens (    0.67 ms per token,  1492.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      92.56 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.15 ms /    79 tokens (    0.65 ms per token,  1544.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      85.93 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.52 ms /   114 tokens (    0.64 ms per token,  1571.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     107.11 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.93 ms /   112 tokens (    0.60 ms per token,  1673.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.33 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    72 tokens (    0.70 ms per token,  1435.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.56 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.22 ms /    96 tokens (    0.62 ms per token,  1621.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.97 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.40 ms /    57 tokens (    0.76 ms per token,  1313.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.53 ms /   142 tokens (    0.67 ms per token,  1502.09 tokens per second)\n",
      "llama_print_timings:        eval time =      50.67 ms /     3 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     147.41 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    71 tokens (    0.71 ms per token,  1416.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.26 ms /   125 tokens (    0.59 ms per token,  1683.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     108.61 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.83 ms /    80 tokens (    0.65 ms per token,  1543.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      86.39 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.08 ms /   147 tokens (    0.65 ms per token,  1530.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     131.70 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.91 ms /    80 tokens (    0.65 ms per token,  1541.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      85.98 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    85 tokens (    0.68 ms per token,  1480.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.26 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   105 tokens (    0.63 ms per token,  1598.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     100.91 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.36 ms /   127 tokens (    0.59 ms per token,  1707.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     109.41 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.65 ms /   127 tokens (    0.59 ms per token,  1701.23 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     126.95 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    59 tokens (    0.74 ms per token,  1350.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      94.14 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      67.03 ms /   112 tokens (    0.60 ms per token,  1670.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     102.19 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    70 tokens (    0.71 ms per token,  1407.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.06 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.44 ms /   130 tokens (    0.72 ms per token,  1391.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     127.99 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.23 ms /   144 tokens (    0.66 ms per token,  1512.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     130.49 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.88 ms /    86 tokens (    0.67 ms per token,  1485.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      92.59 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    70 tokens (    0.72 ms per token,  1395.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    71 tokens (    0.71 ms per token,  1416.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.41 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    77 tokens (    0.66 ms per token,  1516.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.86 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    73 tokens (    0.69 ms per token,  1448.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     100.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    92 tokens (    0.64 ms per token,  1569.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.11 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    76 tokens (    0.67 ms per token,  1492.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     101.77 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    56 tokens (    0.78 ms per token,  1289.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.30 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.75 ms /    99 tokens (    0.65 ms per token,  1528.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     116.97 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    87 tokens (    0.67 ms per token,  1501.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      92.82 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.68 ms /    83 tokens (    0.69 ms per token,  1439.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      93.00 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    93 tokens (    0.63 ms per token,  1596.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.43 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    67 tokens (    0.74 ms per token,  1350.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    76 tokens (    0.67 ms per token,  1496.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      85.28 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.47 ms /   126 tokens (    0.59 ms per token,  1691.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     109.17 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    71 tokens (    0.71 ms per token,  1417.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.22 ms /    95 tokens (    0.62 ms per token,  1604.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      94.13 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    57 tokens (    0.77 ms per token,  1301.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.20 ms /   151 tokens (    0.64 ms per token,  1569.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     130.55 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    73 tokens (    0.69 ms per token,  1453.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     167.14 ms /   258 tokens (    0.65 ms per token,  1543.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.44 ms /     2 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     202.02 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.70 ms /   128 tokens (    0.58 ms per token,  1713.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.95 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    71 tokens (    0.70 ms per token,  1422.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    61 tokens (    0.72 ms per token,  1383.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.96 ms /    77 tokens (    0.66 ms per token,  1511.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.32 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    55 tokens (    0.79 ms per token,  1271.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.09 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.84 ms /   116 tokens (    0.63 ms per token,  1592.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     107.22 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.54 ms /    93 tokens (    0.63 ms per token,  1588.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.36 ms /     3 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     110.32 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    69 tokens (    0.72 ms per token,  1386.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.10 ms /   102 tokens (    0.64 ms per token,  1566.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.38 ms /     3 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     116.82 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.02 ms /   107 tokens (    0.62 ms per token,  1620.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.96 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.42 ms /    75 tokens (    0.67 ms per token,  1487.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.91 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /    97 tokens (    0.66 ms per token,  1504.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      98.76 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    82 tokens (    0.70 ms per token,  1433.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.48 ms /   104 tokens (    0.63 ms per token,  1588.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.48 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    68 tokens (    0.73 ms per token,  1362.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    87 tokens (    0.66 ms per token,  1507.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.18 ms /   150 tokens (    0.64 ms per token,  1559.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     131.16 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    92 tokens (    0.63 ms per token,  1577.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.47 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.63 ms /    56 tokens (    0.78 ms per token,  1283.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    82 tokens (    0.70 ms per token,  1436.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.37 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.10 ms /   104 tokens (    0.63 ms per token,  1597.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.87 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    73 tokens (    0.69 ms per token,  1450.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.87 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    82 tokens (    0.70 ms per token,  1432.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.04 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    57 tokens (    0.76 ms per token,  1312.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.34 ms /   130 tokens (    0.72 ms per token,  1392.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.45 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    85 tokens (    0.68 ms per token,  1476.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    90 tokens (    0.65 ms per token,  1547.64 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     109.62 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.30 ms /    90 tokens (    0.65 ms per token,  1543.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.37 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.29 ms /   211 tokens (    0.61 ms per token,  1644.70 tokens per second)\n",
      "llama_print_timings:        eval time =      50.00 ms /     3 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     179.90 ms /   214 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    86 tokens (    0.67 ms per token,  1490.11 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     110.12 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     127.80 ms /   208 tokens (    0.61 ms per token,  1627.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.31 ms /     2 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     161.87 ms /   210 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.09 ms /   113 tokens (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     123.55 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.17 ms /    79 tokens (    0.65 ms per token,  1543.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      86.10 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    82 tokens (    0.70 ms per token,  1435.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.02 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    75 tokens (    0.68 ms per token,  1477.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      85.09 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    56 tokens (    0.77 ms per token,  1293.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.15 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.20 ms /   118 tokens (    0.62 ms per token,  1612.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.15 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.78 ms /    88 tokens (    0.66 ms per token,  1523.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.09 ms /    81 tokens (    0.70 ms per token,  1418.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      91.53 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    60 tokens (    0.73 ms per token,  1365.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.66 ms /    93 tokens (    0.63 ms per token,  1585.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.93 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.30 ms /   104 tokens (    0.63 ms per token,  1592.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.24 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    66 tokens (    0.75 ms per token,  1336.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.86 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    81 tokens (    0.71 ms per token,  1415.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      91.94 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.88 ms /    80 tokens (    0.65 ms per token,  1542.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      86.81 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    94 tokens (    0.62 ms per token,  1603.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.95 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.27 ms /    65 tokens (    0.76 ms per token,  1319.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      83.32 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.70 ms /   124 tokens (    0.59 ms per token,  1682.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.90 ms per token,    59.18 tokens per second)\n",
      "llama_print_timings:       total time =     109.04 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    63 tokens (    0.70 ms per token,  1428.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.67 ms /   133 tokens (    0.70 ms per token,  1419.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.19 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.38 ms /   144 tokens (    0.66 ms per token,  1509.80 tokens per second)\n",
      "llama_print_timings:        eval time =      50.66 ms /     3 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =     147.29 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    60 tokens (    0.73 ms per token,  1372.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    77 tokens (    0.66 ms per token,  1514.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.33 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    59 tokens (    0.75 ms per token,  1338.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.24 ms /   109 tokens (    0.61 ms per token,  1645.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.51 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.30 ms /    66 tokens (    0.75 ms per token,  1338.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      83.39 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.53 ms /   133 tokens (    0.70 ms per token,  1422.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     127.58 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.40 ms /   133 tokens (    0.70 ms per token,  1424.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     128.17 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.21 ms /    56 tokens (    0.77 ms per token,  1296.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      76.74 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.04 ms /    94 tokens (    0.63 ms per token,  1592.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.32 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.73 ms /   179 tokens (    0.62 ms per token,  1616.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.95 ms per token,    58.99 tokens per second)\n",
      "llama_print_timings:       total time =     146.06 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    69 tokens (    0.72 ms per token,  1391.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      83.71 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    73 tokens (    0.69 ms per token,  1444.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     101.86 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.89 ms /   123 tokens (    0.60 ms per token,  1664.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.51 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.98 ms /   142 tokens (    0.67 ms per token,  1494.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     129.93 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    58 tokens (    0.75 ms per token,  1329.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.24 ms /    79 tokens (    0.65 ms per token,  1541.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.56 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.79 ms /    86 tokens (    0.67 ms per token,  1488.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.78 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.25 ms /    74 tokens (    0.68 ms per token,  1472.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      84.31 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.37 ms /    84 tokens (    0.68 ms per token,  1464.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.57 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.82 ms /    93 tokens (    0.63 ms per token,  1581.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      94.40 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.11 ms /    65 tokens (    0.76 ms per token,  1323.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.99 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.82 ms /    85 tokens (    0.68 ms per token,  1470.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.49 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.65 ms /   179 tokens (    0.62 ms per token,  1617.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.95 ms /     2 runs   (   16.98 ms per token,    58.91 tokens per second)\n",
      "llama_print_timings:       total time =     146.04 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.05 ms /   119 tokens (    0.61 ms per token,  1628.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     108.20 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.61 ms /   101 tokens (    0.64 ms per token,  1563.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      99.32 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    71 tokens (    0.70 ms per token,  1420.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.14 ms /    54 tokens (    0.80 ms per token,  1251.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.65 ms /   105 tokens (    0.63 ms per token,  1599.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.25 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.10 ms /     3 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     102.66 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    75 tokens (    0.67 ms per token,  1485.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.99 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    73 tokens (    0.69 ms per token,  1452.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.64 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.17 ms /    87 tokens (    0.67 ms per token,  1495.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.79 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.69 ms /   161 tokens (    0.67 ms per token,  1495.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     142.43 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.67 ms /   112 tokens (    0.60 ms per token,  1679.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.96 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.10 ms /   161 tokens (    0.67 ms per token,  1489.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     142.82 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    63 tokens (    0.70 ms per token,  1431.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.94 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.74 ms /    60 tokens (    0.73 ms per token,  1371.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.69 ms /   153 tokens (    0.63 ms per token,  1582.43 tokens per second)\n",
      "llama_print_timings:        eval time =      50.60 ms /     3 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     149.07 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    78 tokens (    0.65 ms per token,  1532.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =      84.98 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.45 ms /    68 tokens (    0.73 ms per token,  1374.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    61 tokens (    0.72 ms per token,  1381.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.31 ms /   126 tokens (    0.59 ms per token,  1695.69 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     126.22 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.91 ms /    81 tokens (    0.70 ms per token,  1423.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.60 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    66 tokens (    0.75 ms per token,  1325.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     101.26 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    73 tokens (    0.69 ms per token,  1449.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.38 ms /   179 tokens (    0.62 ms per token,  1621.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     144.82 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.58 ms /   200 tokens (    0.62 ms per token,  1618.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =     157.92 ms /   202 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.06 ms /   103 tokens (    0.63 ms per token,  1583.08 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     117.05 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    73 tokens (    0.69 ms per token,  1440.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     101.36 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.70 ms /    86 tokens (    0.67 ms per token,  1490.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.97 ms /   101 tokens (    0.64 ms per token,  1554.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.87 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.98 ms /   109 tokens (    0.61 ms per token,  1651.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.39 ms /    65 tokens (    0.76 ms per token,  1316.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    54 tokens (    0.80 ms per token,  1256.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.07 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    83 tokens (    0.69 ms per token,  1447.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.79 ms /   146 tokens (    0.66 ms per token,  1524.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     130.43 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.32 ms /    98 tokens (    0.66 ms per token,  1523.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      99.24 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.23 ms /    82 tokens (    0.70 ms per token,  1432.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.39 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    75 tokens (    0.67 ms per token,  1483.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.92 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.16 ms /   102 tokens (    0.64 ms per token,  1565.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     100.15 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.37 ms /    64 tokens (    0.69 ms per token,  1442.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    68 tokens (    0.73 ms per token,  1367.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.58 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.30 ms /   110 tokens (    0.60 ms per token,  1659.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.00 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.35 ms /    63 tokens (    0.70 ms per token,  1420.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.78 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    75 tokens (    0.68 ms per token,  1477.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      85.11 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.11 ms /   110 tokens (    0.60 ms per token,  1663.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     101.16 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    74 tokens (    0.68 ms per token,  1472.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     5 runs   (    0.05 ms per token, 18726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    88 tokens (    0.66 ms per token,  1506.15 tokens per second)\n",
      "llama_print_timings:        eval time =      67.38 ms /     4 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     127.91 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.96 ms /    81 tokens (    0.70 ms per token,  1422.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      91.41 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.46 ms /    66 tokens (    0.75 ms per token,  1334.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.02 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.59 ms /    99 tokens (    0.65 ms per token,  1532.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      99.15 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    68 tokens (    0.73 ms per token,  1366.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.45 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    71 tokens (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.30 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.14 ms /    78 tokens (    0.66 ms per token,  1525.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.33 ms /     2 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =      85.83 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.46 ms /    64 tokens (    0.69 ms per token,  1439.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    66 tokens (    0.75 ms per token,  1334.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.47 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    65 tokens (    0.76 ms per token,  1321.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      82.81 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    68 tokens (    0.73 ms per token,  1363.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    71 tokens (    0.71 ms per token,  1418.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    84 tokens (    0.68 ms per token,  1464.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      92.78 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    55 tokens (    0.78 ms per token,  1276.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      76.64 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.99 ms /    77 tokens (    0.66 ms per token,  1510.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.49 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1542.88 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     104.03 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.27 ms /   249 tokens (    0.58 ms per token,  1714.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.35 ms /     2 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     180.20 ms /   251 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    74 tokens (    0.68 ms per token,  1464.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.32 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.47 ms /    99 tokens (    0.65 ms per token,  1535.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      99.28 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    87 tokens (    0.67 ms per token,  1503.58 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     109.97 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    64 tokens (    0.69 ms per token,  1443.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.20 ms /    96 tokens (    0.62 ms per token,  1621.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      94.32 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.77 ms /   127 tokens (    0.59 ms per token,  1698.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     109.97 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.56 ms /   158 tokens (    0.62 ms per token,  1619.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     132.68 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    60 tokens (    0.73 ms per token,  1375.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.35 ms /    84 tokens (    0.68 ms per token,  1464.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.16 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    71 tokens (    0.71 ms per token,  1416.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.71 ms /    87 tokens (    0.66 ms per token,  1507.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.61 ms /   134 tokens (    0.70 ms per token,  1431.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     128.53 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.84 ms /   147 tokens (    0.65 ms per token,  1533.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     130.73 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.14 ms /   125 tokens (    0.59 ms per token,  1685.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.82 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.12 ms /    80 tokens (    0.65 ms per token,  1534.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      86.73 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    63 tokens (    0.70 ms per token,  1425.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    77 tokens (    0.66 ms per token,  1513.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.90 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.87 ms /   112 tokens (    0.60 ms per token,  1674.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.57 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.17 ms /    65 tokens (    0.76 ms per token,  1321.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      82.49 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    84 tokens (    0.68 ms per token,  1461.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.33 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.46 ms /    90 tokens (    0.65 ms per token,  1539.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.85 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.57 ms /   105 tokens (    0.62 ms per token,  1601.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     100.60 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.73 ms /   107 tokens (    0.61 ms per token,  1627.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     100.46 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.99 ms /    81 tokens (    0.70 ms per token,  1421.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.06 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.53 ms /   104 tokens (    0.63 ms per token,  1587.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      99.90 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.94 ms /   123 tokens (    0.60 ms per token,  1663.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     108.49 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.55 ms /    64 tokens (    0.70 ms per token,  1436.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.45 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    59 tokens (    0.74 ms per token,  1344.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.42 ms /   146 tokens (    0.65 ms per token,  1530.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.86 ms /     2 runs   (   16.93 ms per token,    59.07 tokens per second)\n",
      "llama_print_timings:       total time =     131.08 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.27 ms /   104 tokens (    0.63 ms per token,  1593.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     100.26 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    74 tokens (    0.68 ms per token,  1466.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.31 ms /    83 tokens (    0.69 ms per token,  1448.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.67 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.18 ms /    65 tokens (    0.76 ms per token,  1321.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      82.46 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    81 tokens (    0.71 ms per token,  1414.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      92.41 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    92 tokens (    0.64 ms per token,  1573.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      93.72 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.42 ms /    49 tokens (    0.87 ms per token,  1155.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      76.07 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    68 tokens (    0.73 ms per token,  1367.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     101.54 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    75 tokens (    0.68 ms per token,  1479.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.33 ms /    96 tokens (    0.62 ms per token,  1618.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.59 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.36 ms /    85 tokens (    0.67 ms per token,  1481.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.20 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.34 ms /   104 tokens (    0.63 ms per token,  1591.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     100.20 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.84 ms /    81 tokens (    0.70 ms per token,  1425.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.47 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.43 ms /    85 tokens (    0.68 ms per token,  1480.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      91.68 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.37 ms /    64 tokens (    0.69 ms per token,  1442.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      94.86 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    63 tokens (    0.70 ms per token,  1420.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      95.49 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.08 ms /   108 tokens (    0.61 ms per token,  1634.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     100.59 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.75 ms /   107 tokens (    0.61 ms per token,  1627.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     100.44 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.27 ms /   143 tokens (    0.67 ms per token,  1500.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     130.99 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    90 tokens (    0.65 ms per token,  1543.53 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     110.51 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    70 tokens (    0.71 ms per token,  1406.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      83.97 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.58 ms /   147 tokens (    0.65 ms per token,  1537.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.04 tokens per second)\n",
      "llama_print_timings:       total time =     131.05 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.17 ms /    99 tokens (    0.65 ms per token,  1542.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      99.29 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.98 ms /   129 tokens (    0.72 ms per token,  1387.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     127.96 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    71 tokens (    0.71 ms per token,  1417.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.69 ms /    92 tokens (    0.64 ms per token,  1567.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      93.54 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.29 ms /    79 tokens (    0.65 ms per token,  1540.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      85.85 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.62 ms /   173 tokens (    0.63 ms per token,  1578.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     144.30 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    69 tokens (    0.72 ms per token,  1383.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.40 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.90 ms /   101 tokens (    0.64 ms per token,  1556.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      99.72 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    74 tokens (    0.68 ms per token,  1473.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.20 ms /   162 tokens (    0.67 ms per token,  1497.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     143.29 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.49 ms /   100 tokens (    0.64 ms per token,  1550.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     115.93 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    78 tokens (    0.65 ms per token,  1528.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.39 ms /     2 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =      85.24 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.81 ms /   123 tokens (    0.60 ms per token,  1666.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     108.39 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    69 tokens (    0.72 ms per token,  1379.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.23 ms /    91 tokens (    0.64 ms per token,  1562.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.40 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.23 ms /    89 tokens (    0.65 ms per token,  1528.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.93 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    66 tokens (    0.75 ms per token,  1331.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.38 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.47 ms /    92 tokens (    0.64 ms per token,  1573.56 tokens per second)\n",
      "llama_print_timings:        eval time =      50.60 ms /     3 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     110.76 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.45 ms /   128 tokens (    0.58 ms per token,  1719.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     109.26 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.18 ms /    64 tokens (    0.69 ms per token,  1448.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.88 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    90 tokens (    0.65 ms per token,  1544.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =      93.94 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    47 tokens (    0.79 ms per token,  1273.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      71.69 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.06 ms /   102 tokens (    0.64 ms per token,  1567.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      99.95 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    70 tokens (    0.71 ms per token,  1405.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      83.83 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    67 tokens (    0.74 ms per token,  1349.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.23 ms /    65 tokens (    0.76 ms per token,  1320.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.27 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.15 ms /    95 tokens (    0.62 ms per token,  1606.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     110.77 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.82 ms /   136 tokens (    0.69 ms per token,  1449.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     128.20 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.87 ms /    88 tokens (    0.66 ms per token,  1520.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.16 ms /   136 tokens (    0.69 ms per token,  1444.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     129.31 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    51 tokens (    0.84 ms per token,  1194.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      76.71 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    76 tokens (    0.67 ms per token,  1488.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.95 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    95 tokens (    0.62 ms per token,  1613.04 tokens per second)\n",
      "llama_print_timings:        eval time =      50.64 ms /     3 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     111.79 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.88 ms /    61 tokens (    0.72 ms per token,  1390.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    69 tokens (    0.72 ms per token,  1383.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.21 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.61 ms /   179 tokens (    0.62 ms per token,  1618.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =     145.70 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.15 ms /   126 tokens (    0.59 ms per token,  1699.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.54 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.19 ms /    61 tokens (    0.72 ms per token,  1380.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.00 ms /   155 tokens (    0.63 ms per token,  1597.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     131.57 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.87 ms /    77 tokens (    0.66 ms per token,  1513.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      85.19 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.47 ms /   173 tokens (    0.63 ms per token,  1580.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.03 tokens per second)\n",
      "llama_print_timings:       total time =     145.05 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    71 tokens (    0.71 ms per token,  1417.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.85 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    78 tokens (    0.65 ms per token,  1528.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =      85.86 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    94 tokens (    0.62 ms per token,  1603.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.46 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    66 tokens (    0.75 ms per token,  1337.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    75 tokens (    0.68 ms per token,  1480.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      85.06 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.92 ms /    96 tokens (    0.61 ms per token,  1629.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =      94.19 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.59 ms /    65 tokens (    0.76 ms per token,  1310.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.31 ms /    63 tokens (    0.70 ms per token,  1421.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.54 ms /   188 tokens (    0.59 ms per token,  1685.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     146.24 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.25 ms /    65 tokens (    0.76 ms per token,  1319.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      99.61 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    68 tokens (    0.74 ms per token,  1357.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.53 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    58 tokens (    0.75 ms per token,  1325.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.61 ms /    76 tokens (    0.67 ms per token,  1501.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.14 ms /    83 tokens (    0.69 ms per token,  1452.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.05 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.00 ms /    54 tokens (    0.80 ms per token,  1255.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      76.70 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.20 ms /   108 tokens (    0.61 ms per token,  1631.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     100.69 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.00 ms /   102 tokens (    0.64 ms per token,  1569.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      99.64 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.89 ms /    87 tokens (    0.67 ms per token,  1502.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.12 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    62 tokens (    0.71 ms per token,  1408.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.53 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    73 tokens (    0.69 ms per token,  1458.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.73 ms /   149 tokens (    0.65 ms per token,  1540.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     131.41 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    71 tokens (    0.70 ms per token,  1428.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.60 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.51 ms /   139 tokens (    0.68 ms per token,  1470.77 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     146.62 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    75 tokens (    0.67 ms per token,  1488.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.48 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    67 tokens (    0.74 ms per token,  1347.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.03 ms /   143 tokens (    0.66 ms per token,  1504.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.99 ms /     2 runs   (   16.99 ms per token,    58.84 tokens per second)\n",
      "llama_print_timings:       total time =     130.52 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.72 ms /    95 tokens (    0.62 ms per token,  1617.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.39 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.86 ms /   155 tokens (    0.62 ms per token,  1600.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     132.26 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    58 tokens (    0.75 ms per token,  1325.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.59 ms /   115 tokens (    0.63 ms per token,  1584.26 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     124.39 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.12 ms /    97 tokens (    0.66 ms per token,  1512.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      98.94 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.80 ms /    75 tokens (    0.68 ms per token,  1476.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      85.81 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    70 tokens (    0.71 ms per token,  1405.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     100.16 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      92.99 ms /   130 tokens (    0.72 ms per token,  1397.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     127.81 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    81 tokens (    0.71 ms per token,  1415.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      92.87 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.08 ms /    91 tokens (    0.64 ms per token,  1566.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      93.13 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    69 tokens (    0.72 ms per token,  1384.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.94 ms /    91 tokens (    0.65 ms per token,  1543.86 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     111.38 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.78 ms /    81 tokens (    0.70 ms per token,  1426.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      91.75 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    60 tokens (    0.73 ms per token,  1366.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    59 tokens (    0.74 ms per token,  1346.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.28 ms /    48 tokens (    0.78 ms per token,  1287.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      71.19 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.10 ms /   102 tokens (    0.64 ms per token,  1566.92 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     117.54 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    67 tokens (    0.74 ms per token,  1353.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.43 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.01 ms /    81 tokens (    0.70 ms per token,  1420.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      91.62 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    73 tokens (    0.69 ms per token,  1455.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      85.04 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.36 ms /    65 tokens (    0.76 ms per token,  1316.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.86 ms /    59 tokens (    0.74 ms per token,  1345.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.72 ms /   107 tokens (    0.61 ms per token,  1628.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      99.80 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    68 tokens (    0.73 ms per token,  1362.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.56 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.07 ms /    81 tokens (    0.70 ms per token,  1419.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.10 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    67 tokens (    0.74 ms per token,  1348.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.27 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    75 tokens (    0.68 ms per token,  1480.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.56 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.78 ms /   244 tokens (    0.59 ms per token,  1697.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     178.12 ms /   246 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     112.31 ms /   192 tokens (    0.58 ms per token,  1709.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     147.54 ms /   194 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    63 tokens (    0.70 ms per token,  1425.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.70 ms /   127 tokens (    0.59 ms per token,  1700.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.96 ms per token,    58.97 tokens per second)\n",
      "llama_print_timings:       total time =     110.75 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    68 tokens (    0.73 ms per token,  1370.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.99 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.61 ms /   206 tokens (    0.60 ms per token,  1653.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     159.42 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    72 tokens (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.24 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.71 ms /   149 tokens (    0.65 ms per token,  1540.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     131.51 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    72 tokens (    0.70 ms per token,  1436.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.91 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.07 ms /    95 tokens (    0.62 ms per token,  1608.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     111.15 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    96 tokens (    0.61 ms per token,  1629.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      93.54 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    60 tokens (    0.73 ms per token,  1366.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.76 ms /   167 tokens (    0.65 ms per token,  1535.55 tokens per second)\n",
      "llama_print_timings:        eval time =      50.77 ms /     3 runs   (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:       total time =     161.32 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.68 ms /    94 tokens (    0.62 ms per token,  1601.94 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     110.70 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.70 ms /   160 tokens (    0.61 ms per token,  1637.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     132.64 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.59 ms /    97 tokens (    0.67 ms per token,  1501.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =      99.82 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.31 ms /   158 tokens (    0.62 ms per token,  1623.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     132.56 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    82 tokens (    0.70 ms per token,  1435.50 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     108.81 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    56 tokens (    0.78 ms per token,  1290.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    66 tokens (    0.75 ms per token,  1337.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.54 ms /    91 tokens (    0.64 ms per token,  1554.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      93.89 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.92 ms /    86 tokens (    0.67 ms per token,  1484.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      93.12 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.90 ms /    55 tokens (    0.78 ms per token,  1282.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      76.55 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    85 tokens (    0.68 ms per token,  1477.67 tokens per second)\n",
      "llama_print_timings:        eval time =      50.69 ms /     3 runs   (   16.90 ms per token,    59.18 tokens per second)\n",
      "llama_print_timings:       total time =     109.96 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    69 tokens (    0.73 ms per token,  1377.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.75 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.21 ms /    69 tokens (    0.73 ms per token,  1374.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.03 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.20 ms /    96 tokens (    0.62 ms per token,  1621.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      93.64 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.33 ms /    84 tokens (    0.68 ms per token,  1465.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.55 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    52 tokens (    0.82 ms per token,  1213.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.45 ms /    85 tokens (    0.68 ms per token,  1479.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.82 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.59 ms /   134 tokens (    0.70 ms per token,  1431.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     128.42 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.68 ms /   108 tokens (    0.61 ms per token,  1644.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     117.44 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    68 tokens (    0.73 ms per token,  1362.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.56 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.13 ms /   231 tokens (    0.62 ms per token,  1625.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.33 ms /     2 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     176.64 ms /   233 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    78 tokens (    0.66 ms per token,  1519.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.45 ms /     2 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =      85.79 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    67 tokens (    0.74 ms per token,  1346.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.42 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.31 ms /    82 tokens (    0.70 ms per token,  1430.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.40 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   103 tokens (    0.63 ms per token,  1583.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      99.41 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.54 ms /    99 tokens (    0.65 ms per token,  1533.88 tokens per second)\n",
      "llama_print_timings:        eval time =      50.59 ms /     3 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     117.53 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.52 ms /   100 tokens (    0.65 ms per token,  1549.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      98.86 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.66 ms /    85 tokens (    0.68 ms per token,  1474.24 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     109.51 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   106 tokens (    0.62 ms per token,  1613.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     100.45 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.35 ms /   131 tokens (    0.71 ms per token,  1403.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     128.05 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    70 tokens (    0.72 ms per token,  1398.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.48 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.40 ms /    64 tokens (    0.69 ms per token,  1441.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.69 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     5 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.16 ms /    87 tokens (    0.67 ms per token,  1495.77 tokens per second)\n",
      "llama_print_timings:        eval time =      67.28 ms /     4 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     127.00 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    86 tokens (    0.67 ms per token,  1490.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.63 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.10 ms /    72 tokens (    0.70 ms per token,  1437.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.76 ms /   132 tokens (    0.71 ms per token,  1407.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.76 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.29 ms /    66 tokens (    0.75 ms per token,  1339.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      82.87 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    65 tokens (    0.76 ms per token,  1311.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.70 ms /     3 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     101.59 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.61 ms /    85 tokens (    0.68 ms per token,  1475.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.54 ms /     2 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =      91.98 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.21 ms /    65 tokens (    0.76 ms per token,  1320.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      83.04 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.23 ms /    77 tokens (    0.67 ms per token,  1502.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      85.55 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.97 ms /   122 tokens (    0.61 ms per token,  1649.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     109.01 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.30 ms /    81 tokens (    0.71 ms per token,  1413.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.73 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.44 ms /    68 tokens (    0.73 ms per token,  1375.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      84.24 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.97 ms /    69 tokens (    0.72 ms per token,  1380.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.53 ms /   111 tokens (    0.60 ms per token,  1668.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     101.24 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.05 ms /   143 tokens (    0.66 ms per token,  1504.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     129.31 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.39 ms /   114 tokens (    0.63 ms per token,  1574.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     106.82 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.41 ms /   169 tokens (    0.65 ms per token,  1544.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     144.74 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.70 ms /   151 tokens (    0.64 ms per token,  1561.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.84 ms /     2 runs   (   16.92 ms per token,    59.10 tokens per second)\n",
      "llama_print_timings:       total time =     131.70 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.40 ms /    92 tokens (    0.63 ms per token,  1575.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.23 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.51 ms /   111 tokens (    0.60 ms per token,  1669.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     118.88 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.18 ms /   129 tokens (    0.72 ms per token,  1384.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     127.98 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.77 ms /   107 tokens (    0.61 ms per token,  1626.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.62 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.46 ms /   131 tokens (    0.71 ms per token,  1401.62 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     145.66 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    73 tokens (    0.69 ms per token,  1446.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    71 tokens (    0.71 ms per token,  1409.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    76 tokens (    0.67 ms per token,  1496.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      85.67 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.71 ms /    80 tokens (    0.65 ms per token,  1547.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.88 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    70 tokens (    0.71 ms per token,  1404.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      84.34 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.34 ms /   127 tokens (    0.59 ms per token,  1708.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     109.51 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.60 ms /   164 tokens (    0.66 ms per token,  1510.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     143.42 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    88 tokens (    0.66 ms per token,  1520.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.85 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    56 tokens (    0.77 ms per token,  1294.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    75 tokens (    0.68 ms per token,  1473.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =      86.25 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.57 ms /    93 tokens (    0.63 ms per token,  1587.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.03 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.40 ms /   150 tokens (    0.64 ms per token,  1556.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     131.12 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.14 ms /   109 tokens (    0.61 ms per token,  1647.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.51 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.43 ms /   105 tokens (    0.62 ms per token,  1604.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.67 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.11 ms /    63 tokens (    0.70 ms per token,  1428.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.23 ms /   102 tokens (    0.64 ms per token,  1563.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.08 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.01 ms /    81 tokens (    0.70 ms per token,  1420.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.70 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.81 ms /   101 tokens (    0.64 ms per token,  1558.28 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     116.98 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.02 ms /    88 tokens (    0.66 ms per token,  1516.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.30 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    88 tokens (    0.66 ms per token,  1520.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.15 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    64 tokens (    0.69 ms per token,  1448.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.34 ms /   104 tokens (    0.63 ms per token,  1591.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     101.05 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    54 tokens (    0.80 ms per token,  1257.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.00 ms /   124 tokens (    0.60 ms per token,  1675.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.57 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.52 ms /    66 tokens (    0.75 ms per token,  1332.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     101.59 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.45 ms /    67 tokens (    0.74 ms per token,  1354.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      83.77 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.94 ms /    87 tokens (    0.67 ms per token,  1501.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    72 tokens (    0.70 ms per token,  1436.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.04 ms /   156 tokens (    0.62 ms per token,  1607.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     131.65 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    75 tokens (    0.67 ms per token,  1489.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    83 tokens (    0.69 ms per token,  1449.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.96 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.22 ms /   113 tokens (    0.64 ms per token,  1564.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     106.63 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.52 ms /    91 tokens (    0.64 ms per token,  1555.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      93.40 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.99 ms /    87 tokens (    0.67 ms per token,  1500.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.88 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    58 runs   (    0.05 ms per token, 19198.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.02 ms /    80 tokens (    0.65 ms per token,  1537.75 tokens per second)\n",
      "llama_print_timings:        eval time =     959.10 ms /    57 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =    1033.69 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.04 ms /   103 tokens (    0.63 ms per token,  1583.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     117.08 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    71 tokens (    0.70 ms per token,  1422.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      84.80 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.04 ms /   108 tokens (    0.61 ms per token,  1635.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.83 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.50 ms /    84 tokens (    0.68 ms per token,  1461.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     109.07 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    83 tokens (    0.69 ms per token,  1453.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    77 tokens (    0.66 ms per token,  1512.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.74 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    59 tokens (    0.74 ms per token,  1347.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    71 tokens (    0.70 ms per token,  1418.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      84.16 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.88 ms /    75 tokens (    0.68 ms per token,  1473.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      85.00 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    61 tokens (    0.72 ms per token,  1384.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.70 ms /   137 tokens (    0.68 ms per token,  1462.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     128.19 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    72 tokens (    0.70 ms per token,  1435.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.45 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.88 ms /   197 tokens (    0.63 ms per token,  1590.24 tokens per second)\n",
      "llama_print_timings:        eval time =      50.95 ms /     3 runs   (   16.98 ms per token,    58.88 tokens per second)\n",
      "llama_print_timings:       total time =     177.16 ms /   200 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.03 ms /   113 tokens (    0.64 ms per token,  1568.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     106.66 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.58 ms /    76 tokens (    0.67 ms per token,  1502.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     101.57 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    84 tokens (    0.68 ms per token,  1461.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      91.87 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.35 ms /   124 tokens (    0.60 ms per token,  1667.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     109.37 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.31 ms /    91 tokens (    0.64 ms per token,  1560.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.53 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.14 ms /    84 tokens (    0.68 ms per token,  1469.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.93 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.22 ms /    89 tokens (    0.65 ms per token,  1528.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.50 ms /   153 tokens (    0.63 ms per token,  1585.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     131.12 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.05 ms /    82 tokens (    0.70 ms per token,  1437.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.52 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.52 ms /   123 tokens (    0.60 ms per token,  1673.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.80 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.78 ms /    99 tokens (    0.65 ms per token,  1528.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      99.61 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    65 tokens (    0.76 ms per token,  1314.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.06 ms /   125 tokens (    0.59 ms per token,  1687.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     108.26 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.86 ms /    78 tokens (    0.65 ms per token,  1533.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      85.15 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.20 ms /   104 tokens (    0.63 ms per token,  1595.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     100.62 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    69 tokens (    0.72 ms per token,  1389.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.71 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.34 ms /   102 tokens (    0.64 ms per token,  1561.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      99.79 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.66 ms /    94 tokens (    0.62 ms per token,  1602.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.23 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.47 ms /   114 tokens (    0.64 ms per token,  1573.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =     107.93 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.69 ms /    86 tokens (    0.67 ms per token,  1490.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      91.73 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.69 ms /    76 tokens (    0.67 ms per token,  1499.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.19 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.37 ms /   185 tokens (    0.60 ms per token,  1661.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     146.01 ms /   187 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    74 tokens (    0.68 ms per token,  1467.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.30 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.57 ms /   141 tokens (    0.67 ms per token,  1490.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     129.58 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    76 tokens (    0.67 ms per token,  1502.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.49 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.51 ms /    98 tokens (    0.66 ms per token,  1519.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.27 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    73 tokens (    0.69 ms per token,  1449.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =      84.86 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    62 tokens (    0.71 ms per token,  1401.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.62 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.59 ms /   117 tokens (    0.63 ms per token,  1589.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.12 tokens per second)\n",
      "llama_print_timings:       total time =     109.31 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.34 ms /    99 tokens (    0.65 ms per token,  1538.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     116.71 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.67 ms /   101 tokens (    0.64 ms per token,  1561.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     116.72 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.06 ms /    95 tokens (    0.62 ms per token,  1608.59 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     110.70 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.80 ms /   155 tokens (    0.62 ms per token,  1601.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     132.08 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.69 ms /    76 tokens (    0.67 ms per token,  1499.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      84.67 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    70 tokens (    0.71 ms per token,  1406.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.41 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    63 tokens (    0.70 ms per token,  1429.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    62 tokens (    0.71 ms per token,  1408.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      94.99 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.66 ms /   133 tokens (    0.70 ms per token,  1420.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     128.95 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.64 ms /    87 tokens (    0.66 ms per token,  1509.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.81 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    55 tokens (    0.78 ms per token,  1274.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    69 tokens (    0.72 ms per token,  1385.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.55 ms /   104 tokens (    0.63 ms per token,  1586.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.82 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.25 ms /   131 tokens (    0.71 ms per token,  1404.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     128.15 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.12 ms /   109 tokens (    0.61 ms per token,  1648.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     101.14 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.01 ms /    82 tokens (    0.70 ms per token,  1438.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      91.85 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.82 ms /   112 tokens (    0.60 ms per token,  1676.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     101.17 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    82 tokens (    0.70 ms per token,  1427.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.10 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.56 ms /    92 tokens (    0.64 ms per token,  1571.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      94.14 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.10 ms /    73 tokens (    0.69 ms per token,  1457.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    84 tokens (    0.69 ms per token,  1457.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =      93.45 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.33 ms /   104 tokens (    0.63 ms per token,  1591.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.96 ms /   149 tokens (    0.64 ms per token,  1552.70 tokens per second)\n",
      "llama_print_timings:        eval time =      50.75 ms /     3 runs   (   16.92 ms per token,    59.12 tokens per second)\n",
      "llama_print_timings:       total time =     148.79 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    71 tokens (    0.70 ms per token,  1423.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.70 ms /   142 tokens (    0.67 ms per token,  1499.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     129.73 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    55 tokens (    0.78 ms per token,  1281.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    67 tokens (    0.74 ms per token,  1352.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.35 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.34 ms /    76 tokens (    0.68 ms per token,  1480.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.30 ms /     2 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =      86.71 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.38 ms /    99 tokens (    0.65 ms per token,  1537.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      98.74 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.13 ms /   125 tokens (    0.59 ms per token,  1686.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.96 ms per token,    58.98 tokens per second)\n",
      "llama_print_timings:       total time =     109.89 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.57 ms /   187 tokens (    0.60 ms per token,  1676.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.80 ms /     2 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =     146.06 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.79 ms /    81 tokens (    0.70 ms per token,  1426.31 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     108.74 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.70 ms /    85 tokens (    0.68 ms per token,  1473.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.42 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.49 ms /    58 tokens (    0.75 ms per token,  1333.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      94.70 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.42 ms /    73 tokens (    0.69 ms per token,  1447.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     101.12 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.44 ms /   151 tokens (    0.64 ms per token,  1565.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.03 tokens per second)\n",
      "llama_print_timings:       total time =     132.22 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.16 ms /   111 tokens (    0.60 ms per token,  1677.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     100.80 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.05 ms /   137 tokens (    0.69 ms per token,  1456.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     128.44 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    78 tokens (    0.65 ms per token,  1530.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.38 ms /     2 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =      85.50 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.33 ms /    61 tokens (    0.73 ms per token,  1376.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.80 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    73 tokens (    0.69 ms per token,  1441.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.96 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.47 ms /    93 tokens (    0.63 ms per token,  1590.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      93.46 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.75 ms /    61 tokens (    0.72 ms per token,  1394.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      94.10 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    59 tokens (    0.74 ms per token,  1346.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.07 ms /    88 tokens (    0.66 ms per token,  1515.39 tokens per second)\n",
      "llama_print_timings:        eval time =      50.56 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     110.85 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    56 tokens (    0.77 ms per token,  1291.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.92 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    59 tokens (    0.74 ms per token,  1345.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.13 ms /   119 tokens (    0.61 ms per token,  1627.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     108.10 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    76 tokens (    0.67 ms per token,  1499.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      85.25 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.67 ms /    72 tokens (    0.70 ms per token,  1421.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.00 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    72 tokens (    0.70 ms per token,  1426.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      85.35 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.44 ms /   174 tokens (    0.63 ms per token,  1589.97 tokens per second)\n",
      "llama_print_timings:        eval time =      50.65 ms /     3 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     161.33 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.22 ms /   119 tokens (    0.62 ms per token,  1625.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     107.53 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    71 tokens (    0.71 ms per token,  1416.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.40 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.26 ms /    88 tokens (    0.66 ms per token,  1510.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.24 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.47 ms /    48 tokens (    0.78 ms per token,  1281.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      71.21 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.63 ms /    92 tokens (    0.64 ms per token,  1569.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.04 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.68 ms /   121 tokens (    0.61 ms per token,  1642.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     109.06 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.99 ms /    86 tokens (    0.67 ms per token,  1482.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =      93.07 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.14 ms /    65 tokens (    0.76 ms per token,  1322.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    64 tokens (    0.69 ms per token,  1447.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      78.79 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    55 tokens (    0.78 ms per token,  1280.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      93.72 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    68 tokens (    0.73 ms per token,  1368.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      83.73 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.51 ms /   106 tokens (    0.62 ms per token,  1618.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     100.44 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.82 ms /    94 tokens (    0.63 ms per token,  1598.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      93.37 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.10 ms /    81 tokens (    0.70 ms per token,  1418.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.39 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.25 ms /    63 tokens (    0.70 ms per token,  1423.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      94.61 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.35 ms /   109 tokens (    0.61 ms per token,  1642.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     101.14 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.83 ms /   142 tokens (    0.67 ms per token,  1497.48 tokens per second)\n",
      "llama_print_timings:        eval time =      50.64 ms /     3 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     147.62 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.27 ms /   113 tokens (    0.64 ms per token,  1563.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     107.03 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.08 ms /   119 tokens (    0.61 ms per token,  1628.26 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     124.70 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    84 tokens (    0.68 ms per token,  1461.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      91.34 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    87 tokens (    0.66 ms per token,  1504.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      93.27 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    70 tokens (    0.71 ms per token,  1399.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.58 ms /    85 tokens (    0.68 ms per token,  1476.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.45 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.90 ms /   116 tokens (    0.63 ms per token,  1591.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     107.71 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.11 ms /    88 tokens (    0.66 ms per token,  1514.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =      92.37 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.13 ms /    61 tokens (    0.72 ms per token,  1382.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.06 ms /    78 tokens (    0.65 ms per token,  1527.67 tokens per second)\n",
      "llama_print_timings:        eval time =      50.20 ms /     3 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     102.79 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.67 ms /   101 tokens (    0.64 ms per token,  1561.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      98.81 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.12 ms /   110 tokens (    0.60 ms per token,  1663.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.05 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.20 ms /    78 tokens (    0.66 ms per token,  1523.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.36 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =      85.51 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.22 ms /    79 tokens (    0.65 ms per token,  1542.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      85.35 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.81 ms /    81 tokens (    0.70 ms per token,  1425.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      91.50 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.29 ms /   123 tokens (    0.60 ms per token,  1655.74 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     126.14 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    91 tokens (    0.64 ms per token,  1557.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.75 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    71 tokens (    0.71 ms per token,  1406.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.85 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.25 ms /   119 tokens (    0.62 ms per token,  1624.46 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     125.30 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.72 ms /   100 tokens (    0.65 ms per token,  1545.00 tokens per second)\n",
      "llama_print_timings:        eval time =      50.64 ms /     3 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     117.89 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.89 ms /    55 tokens (    0.78 ms per token,  1282.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      76.64 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.44 ms /    65 tokens (    0.76 ms per token,  1314.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.06 ms /   118 tokens (    0.62 ms per token,  1615.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     107.95 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    68 tokens (    0.73 ms per token,  1371.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      82.90 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.28 ms /    96 tokens (    0.62 ms per token,  1619.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      94.41 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.83 ms /   122 tokens (    0.61 ms per token,  1652.49 tokens per second)\n",
      "llama_print_timings:        eval time =      50.77 ms /     3 runs   (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:       total time =     126.95 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.24 ms /   119 tokens (    0.62 ms per token,  1624.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     108.64 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    53 tokens (    0.81 ms per token,  1234.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      76.88 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    72 tokens (    0.70 ms per token,  1423.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.31 ms /   110 tokens (    0.60 ms per token,  1658.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     101.73 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.89 ms /    78 tokens (    0.65 ms per token,  1532.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =      85.61 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    69 tokens (    0.72 ms per token,  1381.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.24 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    54 tokens (    0.80 ms per token,  1254.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.06 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    73 tokens (    0.69 ms per token,  1447.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      85.13 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /    60 tokens (    0.73 ms per token,  1373.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      95.22 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.60 ms /   140 tokens (    0.68 ms per token,  1479.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.56 ms /     3 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     147.11 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    66 tokens (    0.75 ms per token,  1333.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.83 ms /   114 tokens (    0.64 ms per token,  1565.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.12 tokens per second)\n",
      "llama_print_timings:       total time =     108.53 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.89 ms /   101 tokens (    0.64 ms per token,  1556.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     100.10 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    69 tokens (    0.72 ms per token,  1382.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.76 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.24 ms /   171 tokens (    0.64 ms per token,  1565.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.92 ms per token,    59.12 tokens per second)\n",
      "llama_print_timings:       total time =     144.72 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.91 ms /    81 tokens (    0.70 ms per token,  1423.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      91.28 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.97 ms /    84 tokens (    0.69 ms per token,  1448.93 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     109.97 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    71 tokens (    0.71 ms per token,  1415.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.34 ms /    65 tokens (    0.76 ms per token,  1317.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.26 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.47 ms /    66 tokens (    0.75 ms per token,  1334.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      83.03 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.06 ms /   103 tokens (    0.63 ms per token,  1583.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     100.02 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    56 tokens (    0.78 ms per token,  1278.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.91 ms /   108 tokens (    0.61 ms per token,  1638.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     100.09 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.06 ms /    80 tokens (    0.65 ms per token,  1536.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.90 ms /     2 runs   (   16.95 ms per token,    58.99 tokens per second)\n",
      "llama_print_timings:       total time =      88.33 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.45 ms /   100 tokens (    0.64 ms per token,  1551.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      99.09 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    74 tokens (    0.68 ms per token,  1469.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.47 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.19 ms /    52 tokens (    0.83 ms per token,  1203.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    70 tokens (    0.71 ms per token,  1402.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     101.94 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    84 tokens (    0.68 ms per token,  1461.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      91.98 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    67 tokens (    0.74 ms per token,  1349.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     100.49 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.78 ms /   105 tokens (    0.63 ms per token,  1596.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     100.59 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.06 ms /   102 tokens (    0.64 ms per token,  1567.78 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     117.29 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.14 ms /   109 tokens (    0.61 ms per token,  1647.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     101.09 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.69 ms /    93 tokens (    0.63 ms per token,  1584.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.93 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.75 ms /    93 tokens (    0.63 ms per token,  1583.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.22 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    76 tokens (    0.67 ms per token,  1497.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      85.40 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    75 tokens (    0.67 ms per token,  1485.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.26 ms /   118 tokens (    0.62 ms per token,  1610.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     108.19 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.08 ms /   113 tokens (    0.64 ms per token,  1567.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     107.54 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    57 tokens (    0.76 ms per token,  1307.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      76.99 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.67 ms /    91 tokens (    0.64 ms per token,  1551.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      93.08 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    77 tokens (    0.66 ms per token,  1514.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      84.78 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.16 ms /   102 tokens (    0.64 ms per token,  1565.45 tokens per second)\n",
      "llama_print_timings:        eval time =      50.43 ms /     3 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     116.94 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.58 ms /    74 tokens (    0.68 ms per token,  1462.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      84.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    89 tokens (    0.66 ms per token,  1524.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.21 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.13 ms /    78 tokens (    0.66 ms per token,  1525.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =      85.50 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.84 ms /   101 tokens (    0.64 ms per token,  1557.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      99.72 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    63 tokens (    0.70 ms per token,  1430.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    61 tokens (    0.72 ms per token,  1392.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    92 tokens (    0.64 ms per token,  1569.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =      93.44 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    77 tokens (    0.66 ms per token,  1518.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      85.19 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.42 ms /    72 tokens (    0.70 ms per token,  1427.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     102.55 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.54 ms /   120 tokens (    0.61 ms per token,  1631.81 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     125.74 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    64 tokens (    0.69 ms per token,  1443.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      79.38 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    73 tokens (    0.69 ms per token,  1452.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     101.68 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.34 ms /   164 tokens (    0.66 ms per token,  1513.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     142.81 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.49 ms /    91 tokens (    0.64 ms per token,  1555.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      93.29 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.53 ms /   127 tokens (    0.59 ms per token,  1703.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     109.04 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.81 ms /   155 tokens (    0.62 ms per token,  1601.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     131.12 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   105 tokens (    0.63 ms per token,  1598.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.95 ms per token,    58.98 tokens per second)\n",
      "llama_print_timings:       total time =     101.08 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    63 tokens (    0.70 ms per token,  1428.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.43 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    87 tokens (    0.67 ms per token,  1498.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =      93.03 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    73 tokens (    0.69 ms per token,  1446.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.79 ms /   116 tokens (    0.63 ms per token,  1593.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     107.92 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.12 ms /    80 tokens (    0.65 ms per token,  1534.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.90 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =      87.22 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.43 ms /    49 tokens (    0.87 ms per token,  1154.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    67 tokens (    0.74 ms per token,  1349.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      83.75 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.17 ms /    81 tokens (    0.71 ms per token,  1416.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      92.55 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.37 ms /    59 tokens (    0.74 ms per token,  1360.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    71 tokens (    0.70 ms per token,  1420.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     101.31 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.32 ms /   104 tokens (    0.63 ms per token,  1592.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     100.25 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.16 ms /   102 tokens (    0.64 ms per token,  1565.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     100.81 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.08 ms /   103 tokens (    0.63 ms per token,  1582.57 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     116.92 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.95 ms /    52 tokens (    0.83 ms per token,  1210.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    77 tokens (    0.66 ms per token,  1511.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.41 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.07 ms /    88 tokens (    0.66 ms per token,  1515.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.22 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    69 tokens (    0.72 ms per token,  1384.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      83.82 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.45 ms /   140 tokens (    0.67 ms per token,  1482.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     129.02 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    62 tokens (    0.71 ms per token,  1411.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.70 ms /    77 tokens (    0.66 ms per token,  1518.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.26 ms /   163 tokens (    0.66 ms per token,  1505.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     142.83 ms /   165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.13 ms /    82 tokens (    0.70 ms per token,  1435.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      92.16 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    87 tokens (    0.67 ms per token,  1503.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.93 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    85 tokens (    0.68 ms per token,  1479.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      92.02 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.27 ms /    79 tokens (    0.65 ms per token,  1540.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      86.65 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.30 ms /   198 tokens (    0.62 ms per token,  1605.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =     158.45 ms /   200 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    74 tokens (    0.68 ms per token,  1471.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      84.10 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    57 tokens (    0.77 ms per token,  1306.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.03 ms /   122 tokens (    0.61 ms per token,  1648.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     108.22 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    69 tokens (    0.72 ms per token,  1381.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     101.58 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.44 ms /    84 tokens (    0.68 ms per token,  1462.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      93.47 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    76 tokens (    0.66 ms per token,  1507.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     101.95 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     109.22 ms /   171 tokens (    0.64 ms per token,  1565.68 tokens per second)\n",
      "llama_print_timings:        eval time =      50.61 ms /     3 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     161.17 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.99 ms /   136 tokens (    0.69 ms per token,  1446.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.76 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    66 tokens (    0.75 ms per token,  1332.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     100.50 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.22 ms /    79 tokens (    0.65 ms per token,  1542.25 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     103.04 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      67.06 ms /   112 tokens (    0.60 ms per token,  1670.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     102.33 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.02 ms /   109 tokens (    0.61 ms per token,  1650.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     100.30 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.87 ms /   155 tokens (    0.62 ms per token,  1600.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.80 ms /     2 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =     132.08 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    70 tokens (    0.71 ms per token,  1406.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.17 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.44 ms /   109 tokens (    0.61 ms per token,  1640.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     101.20 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.52 ms /   120 tokens (    0.61 ms per token,  1632.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     107.60 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    76 tokens (    0.67 ms per token,  1501.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =     102.35 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.68 ms /    93 tokens (    0.63 ms per token,  1585.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.95 ms per token,    58.99 tokens per second)\n",
      "llama_print_timings:       total time =      94.86 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.96 ms /    87 tokens (    0.67 ms per token,  1501.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      92.76 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   107 tokens (    0.61 ms per token,  1628.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.61 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.91 ms /    80 tokens (    0.65 ms per token,  1541.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      86.43 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    67 tokens (    0.74 ms per token,  1346.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.92 ms /   101 tokens (    0.64 ms per token,  1555.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:       total time =     100.49 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    61 tokens (    0.72 ms per token,  1394.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.87 ms /    77 tokens (    0.66 ms per token,  1513.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      84.39 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.31 ms /   102 tokens (    0.64 ms per token,  1561.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     100.07 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.23 ms /    65 tokens (    0.76 ms per token,  1320.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     100.04 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.62 ms /    51 tokens (    0.84 ms per token,  1196.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      76.69 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.51 ms /   111 tokens (    0.60 ms per token,  1669.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     102.08 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.56 ms /   114 tokens (    0.64 ms per token,  1571.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     107.77 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.04 ms /   102 tokens (    0.64 ms per token,  1568.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =      99.84 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    52 tokens (    0.83 ms per token,  1209.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      94.17 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    71 tokens (    0.71 ms per token,  1415.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      83.92 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.40 ms /    65 tokens (    0.76 ms per token,  1315.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.62 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.74 ms /   128 tokens (    0.58 ms per token,  1712.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     109.53 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    67 tokens (    0.74 ms per token,  1349.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.65 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.17 ms /    79 tokens (    0.65 ms per token,  1543.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      85.94 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.51 ms /   120 tokens (    0.61 ms per token,  1632.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     108.37 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.59 ms /   122 tokens (    0.60 ms per token,  1657.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     108.54 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.19 ms /   163 tokens (    0.66 ms per token,  1506.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     143.21 ms /   165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.19 ms /   157 tokens (    0.62 ms per token,  1615.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     131.90 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.81 ms /    77 tokens (    0.66 ms per token,  1515.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.59 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    76 tokens (    0.67 ms per token,  1489.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     102.83 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    85 tokens (    0.68 ms per token,  1476.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      92.03 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.42 ms /    98 tokens (    0.66 ms per token,  1521.17 tokens per second)\n",
      "llama_print_timings:        eval time =      50.41 ms /     3 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     115.99 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.07 ms /    80 tokens (    0.65 ms per token,  1536.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =      87.10 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.62 ms /   114 tokens (    0.64 ms per token,  1569.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     107.53 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.34 ms /    63 tokens (    0.70 ms per token,  1421.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.73 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.91 ms /   136 tokens (    0.69 ms per token,  1448.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     128.81 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.34 ms /    83 tokens (    0.69 ms per token,  1447.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      91.86 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.21 ms /    90 tokens (    0.65 ms per token,  1546.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.94 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    66 tokens (    0.75 ms per token,  1331.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    59 tokens (    0.74 ms per token,  1351.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      94.43 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    64 tokens (    0.69 ms per token,  1443.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    65 tokens (    0.76 ms per token,  1315.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.01 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.53 ms /    57 tokens (    0.76 ms per token,  1309.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.74 ms /    76 tokens (    0.67 ms per token,  1497.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      85.21 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     2 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.19 ms /   110 tokens (    0.60 ms per token,  1661.86 tokens per second)\n",
      "llama_print_timings:        eval time =      16.84 ms /     1 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      83.48 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.23 ms /    66 tokens (    0.75 ms per token,  1340.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      83.31 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    57 tokens (    0.77 ms per token,  1293.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.57 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      96.16 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    68 tokens (    0.73 ms per token,  1370.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      84.43 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.14 ms /    56 tokens (    0.77 ms per token,  1298.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    63 tokens (    0.70 ms per token,  1421.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      78.79 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.10 ms /    84 tokens (    0.68 ms per token,  1471.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      92.51 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    71 tokens (    0.70 ms per token,  1423.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.19 ms /    82 tokens (    0.70 ms per token,  1433.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      91.64 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.67 ms /   115 tokens (    0.63 ms per token,  1582.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     107.14 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.96 ms /    95 tokens (    0.62 ms per token,  1611.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.56 ms /     2 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =      93.34 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.98 ms /    82 tokens (    0.69 ms per token,  1439.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =      92.07 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.48 ms /    84 tokens (    0.68 ms per token,  1461.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.54 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.42 ms /   110 tokens (    0.60 ms per token,  1656.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     100.87 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.77 ms /   154 tokens (    0.63 ms per token,  1591.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     131.15 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    73 tokens (    0.69 ms per token,  1453.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.15 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.62 ms /   255 tokens (    0.57 ms per token,  1751.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.35 ms /     2 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     180.29 ms /   257 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.97 ms /   124 tokens (    0.60 ms per token,  1676.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     108.90 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    69 tokens (    0.72 ms per token,  1382.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      83.82 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.13 ms /    94 tokens (    0.63 ms per token,  1589.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.81 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.22 ms /    62 tokens (    0.71 ms per token,  1401.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.87 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.24 ms /    96 tokens (    0.62 ms per token,  1620.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      93.84 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.12 ms /   130 tokens (    0.72 ms per token,  1396.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     128.39 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.26 ms /   131 tokens (    0.71 ms per token,  1404.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     128.02 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.35 ms /    97 tokens (    0.66 ms per token,  1507.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      98.59 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    72 tokens (    0.70 ms per token,  1422.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      85.12 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.91 ms /   113 tokens (    0.64 ms per token,  1571.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     105.98 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    59 tokens (    0.74 ms per token,  1354.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.88 ms /    52 tokens (    0.82 ms per token,  1212.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      94.87 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.38 ms /    84 tokens (    0.68 ms per token,  1464.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      92.48 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    72 tokens (    0.70 ms per token,  1434.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      84.88 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    67 tokens (    0.74 ms per token,  1348.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.48 ms /   144 tokens (    0.66 ms per token,  1508.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     129.71 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.29 ms /   131 tokens (    0.71 ms per token,  1404.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     127.96 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    58 tokens (    0.75 ms per token,  1330.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.00 ms /   136 tokens (    0.69 ms per token,  1446.73 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     145.94 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.60 ms /   104 tokens (    0.63 ms per token,  1585.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.58 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.52 ms /    84 tokens (    0.68 ms per token,  1460.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      92.17 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    63 tokens (    0.70 ms per token,  1427.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.69 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.64 ms /   114 tokens (    0.64 ms per token,  1569.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     107.85 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.06 ms /   131 tokens (    0.71 ms per token,  1407.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     127.99 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.23 ms /    70 tokens (    0.72 ms per token,  1393.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      83.94 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.43 ms /    84 tokens (    0.68 ms per token,  1462.65 tokens per second)\n",
      "llama_print_timings:        eval time =      50.65 ms /     3 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     110.62 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.01 ms /   130 tokens (    0.72 ms per token,  1397.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     128.26 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    64 tokens (    0.69 ms per token,  1453.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    59 tokens (    0.74 ms per token,  1351.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.92 ms /    95 tokens (    0.62 ms per token,  1612.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.95 ms /     2 runs   (   16.98 ms per token,    58.90 tokens per second)\n",
      "llama_print_timings:       total time =      94.45 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.19 ms /   129 tokens (    0.72 ms per token,  1384.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     127.82 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.65 ms /   107 tokens (    0.61 ms per token,  1629.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     100.23 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.05 ms /   181 tokens (    0.61 ms per token,  1629.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.86 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     146.36 ms /   183 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.53 ms /    92 tokens (    0.64 ms per token,  1571.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =      93.47 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    61 tokens (    0.72 ms per token,  1389.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    79 tokens (    0.65 ms per token,  1545.96 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     102.47 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    58 tokens (    0.76 ms per token,  1323.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =      78.91 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    92 tokens (    0.64 ms per token,  1569.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.89 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.90 ms /    93 tokens (    0.63 ms per token,  1579.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      93.78 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    72 tokens (    0.69 ms per token,  1439.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.22 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.11 ms /   101 tokens (    0.64 ms per token,  1551.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     100.08 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    71 tokens (    0.71 ms per token,  1415.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    92 tokens (    0.64 ms per token,  1569.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =      93.38 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.01 ms /    96 tokens (    0.61 ms per token,  1626.82 tokens per second)\n",
      "llama_print_timings:        eval time =      50.37 ms /     3 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     110.66 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.65 ms /    84 tokens (    0.69 ms per token,  1457.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =      92.80 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.28 ms /   146 tokens (    0.65 ms per token,  1532.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     130.30 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.73 ms /   107 tokens (    0.61 ms per token,  1627.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     100.24 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    69 tokens (    0.72 ms per token,  1388.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.49 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    81 tokens (    0.70 ms per token,  1418.96 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     108.77 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    72 tokens (    0.70 ms per token,  1436.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.77 ms /     3 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     101.64 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.55 ms /   166 tokens (    0.65 ms per token,  1529.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =     143.90 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.28 ms /   114 tokens (    0.63 ms per token,  1577.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     106.40 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    69 tokens (    0.72 ms per token,  1386.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.25 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.50 ms /   129 tokens (    0.72 ms per token,  1379.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     128.77 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.33 ms /    67 tokens (    0.74 ms per token,  1358.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.51 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.27 ms /   108 tokens (    0.61 ms per token,  1629.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     101.11 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    75 tokens (    0.68 ms per token,  1479.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      85.06 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.94 ms /   167 tokens (    0.65 ms per token,  1532.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     144.64 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.88 ms /   107 tokens (    0.62 ms per token,  1624.19 tokens per second)\n",
      "llama_print_timings:        eval time =      50.48 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     117.66 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.03 ms /    80 tokens (    0.65 ms per token,  1537.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      87.38 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.41 ms /    85 tokens (    0.68 ms per token,  1480.45 tokens per second)\n",
      "llama_print_timings:        eval time =      50.45 ms /     3 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     109.27 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.72 ms /    99 tokens (    0.65 ms per token,  1529.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      98.70 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    83 tokens (    0.69 ms per token,  1446.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      92.47 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    76 tokens (    0.66 ms per token,  1505.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.64 ms /    99 tokens (    0.65 ms per token,  1531.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      99.25 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.33 ms /    97 tokens (    0.66 ms per token,  1507.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      98.66 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.53 ms /   100 tokens (    0.65 ms per token,  1549.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      99.61 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.08 ms /   113 tokens (    0.64 ms per token,  1567.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     106.83 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.09 ms /    93 tokens (    0.64 ms per token,  1574.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.77 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.49 ms /    90 tokens (    0.65 ms per token,  1538.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =      93.73 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    59 tokens (    0.74 ms per token,  1357.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    71 tokens (    0.70 ms per token,  1418.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.13 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.92 ms /   148 tokens (    0.65 ms per token,  1542.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     130.40 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.14 ms /    56 tokens (    0.77 ms per token,  1298.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      76.49 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.24 ms /   110 tokens (    0.60 ms per token,  1660.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.09 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.80 ms /   111 tokens (    0.60 ms per token,  1661.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =     101.84 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    89 tokens (    0.65 ms per token,  1534.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.55 ms /     2 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =      92.37 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.55 ms /   140 tokens (    0.68 ms per token,  1480.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     129.74 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    73 tokens (    0.69 ms per token,  1450.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      84.86 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    63 tokens (    0.70 ms per token,  1424.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.83 ms /    79 tokens (    0.66 ms per token,  1524.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =      86.20 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.56 ms /    57 tokens (    0.76 ms per token,  1308.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      78.57 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.50 ms /    51 tokens (    0.83 ms per token,  1200.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      76.65 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.70 ms /    92 tokens (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.98 ms /     2 runs   (   16.99 ms per token,    58.87 tokens per second)\n",
      "llama_print_timings:       total time =      94.30 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    84 tokens (    0.68 ms per token,  1470.69 tokens per second)\n",
      "llama_print_timings:        eval time =      50.53 ms /     3 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     109.35 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.55 ms /    63 tokens (    0.71 ms per token,  1414.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      78.86 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.32 ms /   110 tokens (    0.60 ms per token,  1658.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     101.02 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.02 ms /    77 tokens (    0.66 ms per token,  1509.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.80 ms /     3 runs   (   16.60 ms per token,    60.23 tokens per second)\n",
      "llama_print_timings:       total time =     102.03 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.59 ms /    99 tokens (    0.65 ms per token,  1532.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      99.20 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.61 ms /    67 tokens (    0.74 ms per token,  1350.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      83.67 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.49 ms /    85 tokens (    0.68 ms per token,  1478.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20202.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.29 ms /   156 tokens (    0.62 ms per token,  1603.47 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     149.17 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.78 ms /    94 tokens (    0.63 ms per token,  1599.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      94.18 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.96 ms /    71 tokens (    0.70 ms per token,  1421.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.45 ms /   115 tokens (    0.63 ms per token,  1587.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     106.57 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.03 ms /   117 tokens (    0.62 ms per token,  1602.04 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     107.65 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.63 ms /    59 tokens (    0.74 ms per token,  1352.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    53 tokens (    0.82 ms per token,  1226.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.17 ms /    79 tokens (    0.65 ms per token,  1543.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.90 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.22 ms /    88 tokens (    0.66 ms per token,  1511.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      92.80 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    94 tokens (    0.62 ms per token,  1604.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      93.79 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.32 ms /    98 tokens (    0.66 ms per token,  1523.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =      99.23 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.23 ms /   111 tokens (    0.60 ms per token,  1675.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.98 ms /     2 runs   (   16.99 ms per token,    58.85 tokens per second)\n",
      "llama_print_timings:       total time =     102.27 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    63 tokens (    0.70 ms per token,  1426.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.72 ms /   122 tokens (    0.60 ms per token,  1654.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =     108.49 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    71 tokens (    0.71 ms per token,  1408.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      85.04 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.11 ms /    88 tokens (    0.66 ms per token,  1514.29 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.42 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.58 ms /    74 tokens (    0.68 ms per token,  1463.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.66 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    74 tokens (    0.68 ms per token,  1465.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    75 tokens (    0.68 ms per token,  1471.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.19 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    74 tokens (    0.68 ms per token,  1471.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.31 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.09 ms /    95 tokens (    0.62 ms per token,  1607.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      94.47 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    77 tokens (    0.66 ms per token,  1516.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.04 ms /    81 tokens (    0.70 ms per token,  1420.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =      93.39 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.10 ms /   113 tokens (    0.64 ms per token,  1567.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     106.84 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.98 ms /   137 tokens (    0.69 ms per token,  1457.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     128.86 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20270.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.81 ms /    60 tokens (    0.73 ms per token,  1369.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    73 tokens (    0.69 ms per token,  1444.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     101.40 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.97 ms /    60 tokens (    0.73 ms per token,  1364.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =      78.87 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.82 ms /   112 tokens (    0.60 ms per token,  1676.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.12 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.68 ms /   135 tokens (    0.69 ms per token,  1441.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     128.00 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    76 tokens (    0.67 ms per token,  1493.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      85.32 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.29 ms /   114 tokens (    0.63 ms per token,  1577.05 tokens per second)\n",
      "llama_print_timings:        eval time =      50.54 ms /     3 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     124.43 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.14 ms /    80 tokens (    0.65 ms per token,  1534.42 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     103.70 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.04 ms /    80 tokens (    0.65 ms per token,  1537.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      86.28 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.53 ms /    59 tokens (    0.74 ms per token,  1355.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    60 tokens (    0.73 ms per token,  1369.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.18 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    76 tokens (    0.67 ms per token,  1498.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      85.35 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.95 ms /   182 tokens (    0.61 ms per token,  1640.30 tokens per second)\n",
      "llama_print_timings:        eval time =      50.68 ms /     3 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =     163.36 ms /   185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.86 ms /    80 tokens (    0.65 ms per token,  1542.76 tokens per second)\n",
      "llama_print_timings:        eval time =      50.46 ms /     3 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     103.90 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.16 ms /   103 tokens (    0.63 ms per token,  1580.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     100.60 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.60 ms /    59 tokens (    0.74 ms per token,  1353.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.35 ms /    79 tokens (    0.65 ms per token,  1538.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =      86.96 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.61 ms /    94 tokens (    0.62 ms per token,  1603.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      93.89 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.81 ms /    99 tokens (    0.65 ms per token,  1527.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      99.49 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.94 ms /   108 tokens (    0.61 ms per token,  1637.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.47 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.05 ms /    89 tokens (    0.65 ms per token,  1533.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      93.19 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    86 tokens (    0.67 ms per token,  1484.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.58 ms /     2 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =      92.75 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    74 tokens (    0.68 ms per token,  1464.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.63 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.59 ms /    68 tokens (    0.73 ms per token,  1371.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      83.78 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    76 tokens (    0.67 ms per token,  1494.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     101.22 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.10 ms /    78 tokens (    0.66 ms per token,  1526.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =      85.25 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    70 tokens (    0.71 ms per token,  1402.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.76 ms /    93 tokens (    0.63 ms per token,  1582.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      93.40 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    69 tokens (    0.72 ms per token,  1384.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      83.91 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.33 ms /    63 tokens (    0.70 ms per token,  1421.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      95.88 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.19 ms /   118 tokens (    0.62 ms per token,  1612.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     108.07 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.05 ms /   162 tokens (    0.67 ms per token,  1499.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     142.77 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.28 ms /   105 tokens (    0.62 ms per token,  1608.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      99.42 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.81 ms /    86 tokens (    0.67 ms per token,  1487.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      92.38 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.53 ms /    57 tokens (    0.76 ms per token,  1309.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.69 ms /   104 tokens (    0.63 ms per token,  1583.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     100.92 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.56 ms /   140 tokens (    0.68 ms per token,  1480.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.89 ms /     2 runs   (   16.94 ms per token,    59.02 tokens per second)\n",
      "llama_print_timings:       total time =     130.01 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.62 ms /   100 tokens (    0.65 ms per token,  1547.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      99.19 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.72 ms /   128 tokens (    0.58 ms per token,  1712.99 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     126.32 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    59 tokens (    0.74 ms per token,  1343.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    74 tokens (    0.68 ms per token,  1467.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      84.90 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    91 tokens (    0.64 ms per token,  1556.06 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     110.13 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    74 tokens (    0.68 ms per token,  1466.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.89 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.20 ms /   109 tokens (    0.61 ms per token,  1646.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     101.36 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    63 tokens (    0.70 ms per token,  1435.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    59 tokens (    0.75 ms per token,  1341.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.62 ms /    73 tokens (    0.69 ms per token,  1442.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      85.41 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.24 ms /    84 tokens (    0.68 ms per token,  1467.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.32 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    70 tokens (    0.71 ms per token,  1405.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.21 ms /   137 tokens (    0.69 ms per token,  1454.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.81 ms /     2 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     129.27 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.30 ms /    65 tokens (    0.76 ms per token,  1318.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      83.44 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    58 tokens (    0.75 ms per token,  1336.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.83 ms /   107 tokens (    0.62 ms per token,  1625.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     101.43 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.38 ms /    85 tokens (    0.68 ms per token,  1481.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      91.95 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    60 tokens (    0.73 ms per token,  1370.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.35 ms /   183 tokens (    0.61 ms per token,  1643.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     146.56 ms /   185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    90 tokens (    0.65 ms per token,  1547.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =      92.60 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    57 tokens (    0.76 ms per token,  1308.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    60 tokens (    0.73 ms per token,  1363.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.80 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    55 tokens (    0.79 ms per token,  1273.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.96 ms /   149 tokens (    0.64 ms per token,  1552.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     131.21 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    57 tokens (    0.76 ms per token,  1314.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    58 tokens (    0.76 ms per token,  1321.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =      78.96 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.67 ms /   193 tokens (    0.64 ms per token,  1573.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.82 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     157.28 ms /   195 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.16 ms /   125 tokens (    0.59 ms per token,  1685.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     108.27 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.37 ms /    97 tokens (    0.66 ms per token,  1507.01 tokens per second)\n",
      "llama_print_timings:        eval time =      50.71 ms /     3 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =     117.49 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    75 tokens (    0.67 ms per token,  1486.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.81 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.02 ms /    78 tokens (    0.65 ms per token,  1528.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.32 ms /     2 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =      85.33 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.76 ms /    68 tokens (    0.73 ms per token,  1366.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      83.07 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.13 ms /   162 tokens (    0.67 ms per token,  1498.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     142.58 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.08 ms /    97 tokens (    0.66 ms per token,  1513.69 tokens per second)\n",
      "llama_print_timings:        eval time =      50.42 ms /     3 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     116.11 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    67 tokens (    0.74 ms per token,  1349.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      83.98 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    87 tokens (    0.67 ms per token,  1499.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      93.04 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.67 ms /    80 tokens (    0.65 ms per token,  1548.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      85.96 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.08 ms /    88 tokens (    0.66 ms per token,  1515.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      92.66 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    76 tokens (    0.66 ms per token,  1506.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      84.84 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    68 tokens (    0.73 ms per token,  1366.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      83.80 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    60 tokens (    0.73 ms per token,  1375.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.84 ms /    80 tokens (    0.65 ms per token,  1543.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =      86.37 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.47 ms /    84 tokens (    0.68 ms per token,  1461.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =      92.48 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.61 ms /   106 tokens (    0.62 ms per token,  1615.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     100.65 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    59 tokens (    0.74 ms per token,  1350.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    67 tokens (    0.74 ms per token,  1346.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      84.92 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.40 ms /   133 tokens (    0.70 ms per token,  1423.95 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     128.11 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.26 ms /    79 tokens (    0.65 ms per token,  1541.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      86.22 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    71 tokens (    0.70 ms per token,  1420.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      84.57 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.99 ms /    69 tokens (    0.72 ms per token,  1380.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     101.83 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     5 runs   (    0.05 ms per token, 20161.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.36 ms /   138 tokens (    0.68 ms per token,  1462.45 tokens per second)\n",
      "llama_print_timings:        eval time =      67.46 ms /     4 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     163.72 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.10 ms /    95 tokens (    0.62 ms per token,  1607.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =      94.11 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    59 tokens (    0.74 ms per token,  1352.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.89 ms /   214 tokens (    0.60 ms per token,  1660.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.35 ms /     2 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     163.11 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.58 ms /   105 tokens (    0.62 ms per token,  1601.15 tokens per second)\n",
      "llama_print_timings:        eval time =      50.62 ms /     3 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     118.31 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    78 tokens (    0.66 ms per token,  1519.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =      85.87 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.18 ms /    84 tokens (    0.68 ms per token,  1469.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.27 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    89 tokens (    0.65 ms per token,  1532.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      92.98 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    73 tokens (    0.69 ms per token,  1455.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.28 ms /    63 tokens (    0.70 ms per token,  1422.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      94.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    61 tokens (    0.72 ms per token,  1382.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.29 ms /   109 tokens (    0.61 ms per token,  1644.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.93 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.26 ms /    96 tokens (    0.62 ms per token,  1620.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      94.11 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.17 ms /   113 tokens (    0.64 ms per token,  1565.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     107.34 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.92 ms /    81 tokens (    0.70 ms per token,  1423.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.04 tokens per second)\n",
      "llama_print_timings:       total time =      92.01 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    72 tokens (    0.70 ms per token,  1431.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      84.13 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.66 ms /    85 tokens (    0.68 ms per token,  1474.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.30 ms /    64 tokens (    0.69 ms per token,  1444.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.37 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.30 ms /    97 tokens (    0.66 ms per token,  1508.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      99.08 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.91 ms /    77 tokens (    0.66 ms per token,  1512.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      85.71 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    72 tokens (    0.70 ms per token,  1425.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.96 ms /    80 tokens (    0.65 ms per token,  1539.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.63 ms /     2 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =      86.90 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.86 ms /    87 tokens (    0.67 ms per token,  1503.63 tokens per second)\n",
      "llama_print_timings:        eval time =      50.44 ms /     3 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     110.20 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.22 ms /    83 tokens (    0.69 ms per token,  1450.49 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     108.80 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.77 ms /    81 tokens (    0.70 ms per token,  1426.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      91.42 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      95.99 ms /   149 tokens (    0.64 ms per token,  1552.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     130.48 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.80 ms /    78 tokens (    0.65 ms per token,  1535.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =      84.65 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    57 tokens (    0.76 ms per token,  1307.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      94.69 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.64 ms /   104 tokens (    0.63 ms per token,  1584.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     100.36 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.30 ms /   120 tokens (    0.61 ms per token,  1637.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     107.74 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    60 tokens (    0.73 ms per token,  1369.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.86 ms /   100 tokens (    0.65 ms per token,  1541.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =      99.74 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    84 tokens (    0.68 ms per token,  1465.38 tokens per second)\n",
      "llama_print_timings:        eval time =      50.39 ms /     3 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     109.28 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.12 ms /    83 tokens (    0.69 ms per token,  1453.08 tokens per second)\n",
      "llama_print_timings:        eval time =      50.55 ms /     3 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     110.06 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    61 tokens (    0.72 ms per token,  1383.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    84 tokens (    0.69 ms per token,  1459.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =      92.10 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.75 ms /    86 tokens (    0.67 ms per token,  1489.10 tokens per second)\n",
      "llama_print_timings:        eval time =      50.47 ms /     3 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     109.31 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    68 tokens (    0.73 ms per token,  1368.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.26 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.50 ms /    73 tokens (    0.69 ms per token,  1445.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      85.22 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.41 ms /   104 tokens (    0.63 ms per token,  1590.09 tokens per second)\n",
      "llama_print_timings:        eval time =      50.58 ms /     3 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     118.06 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.37 ms /   151 tokens (    0.64 ms per token,  1566.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     130.84 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    61 tokens (    0.72 ms per token,  1385.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    73 tokens (    0.69 ms per token,  1449.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =      85.31 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.16 ms /   110 tokens (    0.60 ms per token,  1662.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.18 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    63 tokens (    0.70 ms per token,  1426.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.03 ms /    67 tokens (    0.75 ms per token,  1339.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    70 tokens (    0.72 ms per token,  1391.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.51 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    60 tokens (    0.73 ms per token,  1361.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.44 ms /    90 tokens (    0.65 ms per token,  1539.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =      93.15 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.37 ms /    84 tokens (    0.68 ms per token,  1464.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =      91.91 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.04 ms /   108 tokens (    0.61 ms per token,  1635.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      97.51 ms /   159 tokens (    0.61 ms per token,  1630.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     132.04 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.85 ms /    80 tokens (    0.65 ms per token,  1543.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      86.61 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    55 tokens (    0.78 ms per token,  1276.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.16 ms /   102 tokens (    0.64 ms per token,  1565.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.86 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     100.63 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.74 ms /    60 tokens (    0.73 ms per token,  1371.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.76 ms /   106 tokens (    0.62 ms per token,  1611.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.91 ms /     2 runs   (   16.96 ms per token,    58.97 tokens per second)\n",
      "llama_print_timings:       total time =     101.90 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.18 ms /    66 tokens (    0.75 ms per token,  1342.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.54 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.88 ms /    85 tokens (    0.68 ms per token,  1468.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.61 ms /     2 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =      92.96 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.13 ms /    73 tokens (    0.69 ms per token,  1456.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     100.63 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    68 tokens (    0.74 ms per token,  1354.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     101.57 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.36 ms /   103 tokens (    0.63 ms per token,  1575.84 tokens per second)\n",
      "llama_print_timings:        eval time =      50.40 ms /     3 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     117.38 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    76 tokens (    0.67 ms per token,  1496.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      85.07 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.86 ms /   100 tokens (    0.65 ms per token,  1541.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.88 ms /     2 runs   (   16.94 ms per token,    59.04 tokens per second)\n",
      "llama_print_timings:       total time =     100.36 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    88 tokens (    0.66 ms per token,  1521.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.24 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    67 tokens (    0.74 ms per token,  1347.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =      84.96 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    92 tokens (    0.64 ms per token,  1574.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =      93.73 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    69 tokens (    0.72 ms per token,  1384.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      83.66 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.51 ms /    89 tokens (    0.66 ms per token,  1521.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      93.35 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.36 ms /   127 tokens (    0.59 ms per token,  1708.02 tokens per second)\n",
      "llama_print_timings:        eval time =      50.51 ms /     3 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     126.57 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.59 ms /    88 tokens (    0.67 ms per token,  1501.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      94.22 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.38 ms /    95 tokens (    0.63 ms per token,  1599.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =      94.78 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    62 tokens (    0.72 ms per token,  1396.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.93 ms /   123 tokens (    0.60 ms per token,  1663.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     108.90 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.86 ms /    80 tokens (    0.65 ms per token,  1542.73 tokens per second)\n",
      "llama_print_timings:        eval time =      50.49 ms /     3 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     104.49 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.77 ms /    81 tokens (    0.70 ms per token,  1426.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =      91.48 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.30 ms /   139 tokens (    0.68 ms per token,  1474.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.71 ms /     2 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =     128.62 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.47 ms /   139 tokens (    0.68 ms per token,  1471.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.89 ms /     2 runs   (   16.94 ms per token,    59.02 tokens per second)\n",
      "llama_print_timings:       total time =     130.10 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.03 ms /   102 tokens (    0.64 ms per token,  1568.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.85 ms /     2 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =     100.37 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    60 tokens (    0.73 ms per token,  1368.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.95 ms /    85 tokens (    0.68 ms per token,  1466.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =      92.29 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     145.42 ms /   253 tokens (    0.57 ms per token,  1739.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     180.26 ms /   255 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    71 tokens (    0.71 ms per token,  1415.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.04 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.14 ms /   137 tokens (    0.69 ms per token,  1455.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.76 ms /     2 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =     129.44 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20134.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.49 ms /    85 tokens (    0.68 ms per token,  1478.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =      92.14 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    93 tokens (    0.63 ms per token,  1590.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.74 ms /     2 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =      93.61 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.86 ms /    53 tokens (    0.81 ms per token,  1236.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.92 ms /   136 tokens (    0.69 ms per token,  1448.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.70 ms /     2 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     128.44 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.48 ms /    90 tokens (    0.65 ms per token,  1538.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =      93.28 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.25 ms /    60 tokens (    0.74 ms per token,  1355.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    60 tokens (    0.73 ms per token,  1362.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.09 ms /   106 tokens (    0.62 ms per token,  1603.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.64 ms /     2 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     101.27 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.65 ms /    94 tokens (    0.62 ms per token,  1602.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =      93.35 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.15 ms /    65 tokens (    0.76 ms per token,  1322.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     100.13 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    73 tokens (    0.69 ms per token,  1445.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     101.44 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.04 ms /    78 tokens (    0.65 ms per token,  1528.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      85.46 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    75 tokens (    0.67 ms per token,  1484.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      84.93 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    71 tokens (    0.70 ms per token,  1419.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      83.90 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.12 ms /   109 tokens (    0.61 ms per token,  1648.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     100.76 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    71 tokens (    0.71 ms per token,  1417.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     101.42 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.85 ms /    81 tokens (    0.71 ms per token,  1400.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.65 ms /     2 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =      93.00 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.75 ms /   127 tokens (    0.59 ms per token,  1699.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.67 ms /     2 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     110.10 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    76 tokens (    0.67 ms per token,  1497.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =      86.07 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.59 ms /    85 tokens (    0.68 ms per token,  1476.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =      92.28 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    87 tokens (    0.67 ms per token,  1500.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =      93.72 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     110.86 ms /   184 tokens (    0.60 ms per token,  1659.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.83 ms /     2 runs   (   16.91 ms per token,    59.13 tokens per second)\n",
      "llama_print_timings:       total time =     145.74 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.38 ms /   105 tokens (    0.62 ms per token,  1606.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     100.01 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.81 ms /   142 tokens (    0.67 ms per token,  1497.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.78 ms /     2 runs   (   16.89 ms per token,    59.21 tokens per second)\n",
      "llama_print_timings:       total time =     129.99 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     142.96 ms /   234 tokens (    0.61 ms per token,  1636.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     177.50 ms /   236 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.38 ms /    63 tokens (    0.70 ms per token,  1419.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.78 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.16 ms /    79 tokens (    0.65 ms per token,  1544.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.66 ms /     2 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =      85.48 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    67 tokens (    0.74 ms per token,  1345.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      84.44 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.79 ms /   155 tokens (    0.62 ms per token,  1601.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.75 ms /     2 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     131.93 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.61 ms /   115 tokens (    0.63 ms per token,  1583.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =     106.99 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      94.50 ms /   141 tokens (    0.67 ms per token,  1492.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.77 ms /     2 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =     130.13 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      93.47 ms /   134 tokens (    0.70 ms per token,  1433.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     127.88 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19736.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.65 ms /    92 tokens (    0.64 ms per token,  1568.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.69 ms /     2 runs   (   16.84 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =      93.15 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    68 tokens (    0.73 ms per token,  1366.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     101.37 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.24 ms /    95 tokens (    0.62 ms per token,  1603.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.62 ms /     2 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =      93.67 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.04 ms /   109 tokens (    0.61 ms per token,  1650.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.68 ms /     2 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     101.26 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      96.49 ms /   150 tokens (    0.64 ms per token,  1554.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.72 ms /     2 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     131.70 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.96 ms /    78 tokens (    0.65 ms per token,  1530.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.57 ms /     2 runs   (   16.79 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =      86.30 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    55 tokens (    0.78 ms per token,  1279.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.39 ms /    63 tokens (    0.70 ms per token,  1419.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    52 tokens (    0.83 ms per token,  1208.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      76.48 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.56 ms /    92 tokens (    0.64 ms per token,  1570.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.73 ms /     2 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =      93.43 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.20 ms /   207 tokens (    0.60 ms per token,  1666.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.37 ms /     2 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     158.89 ms /   209 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.56 ms /    72 tokens (    0.70 ms per token,  1424.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.85 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.61 ms /    99 tokens (    0.65 ms per token,  1532.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.79 ms /     2 runs   (   16.89 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =      99.83 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19867.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.62 ms /   105 tokens (    0.62 ms per token,  1600.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.59 ms /     2 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     100.38 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1965.28 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    74 tokens (    0.68 ms per token,  1464.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      85.10 ms /    76 tokens\n"
     ]
    }
   ],
   "source": [
    "mbti_list = []\n",
    "\n",
    "for text in texts:\n",
    "\n",
    "    PROMPT = \"정확한 챗봇으로서 상대방의 입력에 대해 MBTI를 맞추자. 모든 대답은 MBTI 16개중 하나로 대답해줘.\"\n",
    "    instruction = text\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    generation_kwargs = {\n",
    "        \"max_tokens\": 2048,\n",
    "        \"stop\": [\"<|eot_id|>\"],\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"echo\": True,  # 프롬프트를 출력에 포함합니다.\n",
    "    }\n",
    "\n",
    "    response_msg = model(prompt, **generation_kwargs)\n",
    "    mbti         = response_msg['choices'][0]['text'][len(prompt):]\n",
    "\n",
    "    mbti_list.append(mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'esfp',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'esfj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'estp',\n",
       " 'intj',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'ENFP',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'estj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'estp',\n",
       " 'istp',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'esfp',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'esfp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'intj',\n",
       " 'esfj',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'estj',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'estp',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'estp',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'esfp',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'esfp',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'esfj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'entp',\n",
       " 'estp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'istj',\n",
       " '1. 취미 - 음악 감상, 독서, 영화 감상 2. 어떨 때 어색한지 - 말투가 딱딱하거나, 내가 아는 정보를 모르는 사람과 대화할 때 3. 어색함 해결 방법 - 음악, 영화, 책으로 공감대를 형성하거나, 내가 아는 정보를 공유해 주면서 4. 좋아하는 영화 - 마블 시리즈, 해리 포터 시리즈 5. 감동 포인트 - 인간관계에서 배려해 주는 모습, 연인 관계에서는 함께 웃는 모습 6. 설렘 포인트 - 상대방의 배려, 나와 같은 취향, 나에게만 웃어주는 모습 7. 갈등 해결 방법 - 서로의 입장을 이해하고, 대화로 풀어나가기 8. 주량 - 소주 2병 9. 좋아하는 음악 - 발라드, 인디밴드 10. 나 자신에게 칭찬 한마디 - \"수고했어, 오늘도\"',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'intj',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'estp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'esfj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'intp',\n",
       " 'intp',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'ENFP',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'esfj',\n",
       " 'istp',\n",
       " 'intp',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'esfj',\n",
       " 'enfj',\n",
       " 'esfj',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'infj',\n",
       " 'estp',\n",
       " 'estp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'isfp',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'estj',\n",
       " 'intp',\n",
       " 'esfp',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'istp',\n",
       " 'enfp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'intp',\n",
       " 'intj',\n",
       " 'intj',\n",
       " '1. ENFP',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'isfp',\n",
       " 'esfp',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'ENFJ',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'intp',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'intp',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'esfp',\n",
       " 'enfj',\n",
       " 'entj',\n",
       " 'istp',\n",
       " 'estj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'intp',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'estp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'infj',\n",
       " 'estj',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'esfp',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'istp',\n",
       " 'enfj',\n",
       " 'infp',\n",
       " 'enfj',\n",
       " 'enfj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'esfj',\n",
       " 'entp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'istp',\n",
       " 'esfj',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'istp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'isfp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'esfp',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'isfj',\n",
       " 'entp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'estp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'infj',\n",
       " 'entj',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'infj',\n",
       " 'enfp',\n",
       " 'estj',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'estj',\n",
       " 'isfp',\n",
       " 'enfj',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'intp',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'entp',\n",
       " 'enfj',\n",
       " 'estp',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'isfp',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'istj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'enfp',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'estp',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'entj',\n",
       " 'enfj',\n",
       " 'infj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'isfp',\n",
       " 'isfj',\n",
       " 'infj',\n",
       " 'intj',\n",
       " 'estj',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'isfp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'isfj',\n",
       " 'infp',\n",
       " 'infj',\n",
       " 'estj',\n",
       " 'entj',\n",
       " 'intj',\n",
       " 'esfp',\n",
       " 'entj',\n",
       " 'isfp',\n",
       " 'intj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'intp',\n",
       " 'istp',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'entj',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'enfj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'esfp',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'enfj',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'isfj',\n",
       " 'istj',\n",
       " 'entj',\n",
       " 'isfj',\n",
       " 'enfp',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'entp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'esfj',\n",
       " 'estj',\n",
       " 'enfp',\n",
       " 'enfp',\n",
       " 'estp',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infj와 estj의 친구 혹은 연인 관계는 정말 재밌을 거예요![SEP] infj는 estj의 현실적인 면과 estj는 infj의 감정적인 면을 서로 배울 수 있는 좋은 관계가 될 수 있어요. infj가 estj를 좋아하는 이유는 estj의 능력과 성실함, 계획적임을 좋아하고, estj가 infj를 좋아하는 이유는 infj의 감성과 창의성, 예술성을 좋아해요. infj와 estj는 서로의 장점을 존중해 주고, 단점을 보완해 주는 좋은 관계를 이룰 수 있어요![SEP]',\n",
       " 'entp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'enfp',\n",
       " 'enfj',\n",
       " 'esfp',\n",
       " 'isfj',\n",
       " 'entj',\n",
       " 'intp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'estj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'infp',\n",
       " 'istj',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'estp',\n",
       " 'infp',\n",
       " 'isfj',\n",
       " 'intj',\n",
       " 'intj',\n",
       " 'infp',\n",
       " 'infp',\n",
       " 'enfp',\n",
       " 'intj',\n",
       " 'infj',\n",
       " 'istp',\n",
       " 'infj',\n",
       " 'infj',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11294173829990449"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(mbtis, mbti_list)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4188"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mbti_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
