{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from ./mbti-senti_model/unsloth.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Mbti Model\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  14:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 128255\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Mbti Model\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: PAD token        = 128255 '<|reserved_special_token_250|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4403.49 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    10.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128255', 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Mbti Model', 'general.type': 'model', 'general.size_label': '8.0B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "model_path='./mbti-senti_model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = Llama(\n",
    "    model_path='./mbti-senti_model/unsloth.Q4_K_M.gguf', #다운로드받은 모델의 위치\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=33        # Number of model layers to offload to GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '공포',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '혐오',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '놀람',\n",
       " '공포',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '중립',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '공포',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '공포',\n",
       " '중립',\n",
       " '중립',\n",
       " '공포',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '분노',\n",
       " '공포',\n",
       " '분노',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '공포',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '공포',\n",
       " '혐오',\n",
       " '분노',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '놀람',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '분노',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '공포',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '공포',\n",
       " '공포',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '공포',\n",
       " '분노',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '공포',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '분노',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '행복',\n",
       " '공포',\n",
       " '공포',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '공포',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '중립',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '공포',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '공포',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '공포',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '공포',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '혐오',\n",
       " '공포',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '공포',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '공포',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '혐오',\n",
       " '공포',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '공포',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '공포',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '공포',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '분노',\n",
       " '놀람',\n",
       " '공포',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '혐오',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '혐오',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '혐오',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./senti.csv', encoding='UTF-8')\n",
    "\n",
    "sampled_df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "texts  = list(sampled_df['text'])\n",
    "sentis = list(sampled_df['senti'])\n",
    "\n",
    "sentis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py:1129: RuntimeWarning: Detected duplicate leading \"<|begin_of_text|>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     116.37 ms /    90 tokens (    1.29 ms per token,   773.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.63 ms /     2 runs   (   16.31 ms per token,    61.30 tokens per second)\n",
      "llama_print_timings:       total time =     149.93 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.36 ms /    25 tokens (    1.17 ms per token,   851.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      79.98 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.17 ms /    18 tokens (    1.45 ms per token,   687.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.08 ms /     3 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      76.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.89 ms /     9 tokens (    3.10 ms per token,   322.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.10 ms /     3 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    23 tokens (    1.17 ms per token,   857.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.23 ms /    10 tokens (    2.62 ms per token,   381.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.24 tokens per second)\n",
      "llama_print_timings:       total time =      59.88 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    14 tokens (    1.92 ms per token,   521.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    16 tokens (    1.69 ms per token,   592.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.04 ms /    18 tokens (    1.45 ms per token,   691.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      59.79 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.21 ms /    19 tokens (    1.38 ms per token,   724.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.10 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      77.12 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.93 ms /    26 tokens (    1.15 ms per token,   868.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      63.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    16 tokens (    1.67 ms per token,   598.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.01 ms /     3 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      76.96 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    23 tokens (    1.15 ms per token,   867.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.17 ms /    19 tokens (    1.38 ms per token,   725.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.02 ms /     3 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      76.33 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.05 ms /    29 tokens (    1.04 ms per token,   965.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.15 ms /     3 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      80.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.50 ms /    25 tokens (    1.18 ms per token,   847.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      62.99 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    11 tokens (    2.39 ms per token,   418.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.01 ms /     3 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    13 tokens (    2.05 ms per token,   487.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.64 ms /     2 runs   (   16.32 ms per token,    61.27 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      25.97 ms /    18 tokens (    1.44 ms per token,   693.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      60.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    13 tokens (    2.04 ms per token,   490.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.00 ms /     3 runs   (   16.33 ms per token,    61.23 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.04 ms /    18 tokens (    1.45 ms per token,   691.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.65 ms /     2 runs   (   16.32 ms per token,    61.26 tokens per second)\n",
      "llama_print_timings:       total time =      59.33 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.00 ms /    18 tokens (    1.44 ms per token,   692.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      59.56 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.49 ms /    25 tokens (    1.18 ms per token,   847.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      62.84 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.78 ms /    28 tokens (    1.06 ms per token,   940.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      80.54 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.13 ms /    19 tokens (    1.38 ms per token,   727.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.01 ms /     3 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      76.35 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    16 tokens (    1.67 ms per token,   597.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.64 ms /     2 runs   (   16.32 ms per token,    61.28 tokens per second)\n",
      "llama_print_timings:       total time =      59.82 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.34 ms /    37 tokens (    0.90 ms per token,  1109.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      67.34 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    22 tokens (    1.20 ms per token,   831.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      76.86 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.32 ms /    21 tokens (    1.25 ms per token,   797.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.07 ms /     3 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      76.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.00 ms /    18 tokens (    1.44 ms per token,   692.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.67 ms /     2 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      59.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    22 tokens (    1.20 ms per token,   832.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      60.14 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    24 tokens (    1.11 ms per token,   899.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.73 ms /    28 tokens (    1.06 ms per token,   941.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.83 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    24 tokens (    1.11 ms per token,   898.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.34 ms /    21 tokens (    1.25 ms per token,   797.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    16 tokens (    1.68 ms per token,   595.73 tokens per second)\n",
      "llama_print_timings:        eval time =      48.99 ms /     3 runs   (   16.33 ms per token,    61.24 tokens per second)\n",
      "llama_print_timings:       total time =      77.13 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.64 ms /    25 tokens (    1.19 ms per token,   843.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      62.95 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    21 tokens (    1.25 ms per token,   798.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    23 tokens (    1.16 ms per token,   859.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.54 ms /    24 tokens (    1.11 ms per token,   904.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    14 tokens (    1.90 ms per token,   525.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.62 ms /     2 runs   (   16.31 ms per token,    61.31 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    24 tokens (    1.11 ms per token,   898.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    31 tokens (    0.98 ms per token,  1018.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      64.02 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.05 ms /    18 tokens (    1.45 ms per token,   691.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.64 ms /     2 runs   (   16.32 ms per token,    61.28 tokens per second)\n",
      "llama_print_timings:       total time =      59.75 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    22 tokens (    1.20 ms per token,   832.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.40 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.47 ms /    22 tokens (    1.20 ms per token,   831.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.20 ms /    20 tokens (    1.31 ms per token,   763.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.09 ms /     3 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      76.89 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    23 tokens (    1.16 ms per token,   864.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.18 ms /    19 tokens (    1.38 ms per token,   725.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      59.79 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      25.91 ms /    17 tokens (    1.52 ms per token,   656.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    24 tokens (    1.11 ms per token,   903.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.19 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.22 ms /    12 tokens (    2.19 ms per token,   457.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.65 ms /     2 runs   (   16.32 ms per token,    61.26 tokens per second)\n",
      "llama_print_timings:       total time =      60.06 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      25.83 ms /    17 tokens (    1.52 ms per token,   658.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      59.13 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    13 tokens (    2.05 ms per token,   487.77 tokens per second)\n",
      "llama_print_timings:        eval time =      48.98 ms /     3 runs   (   16.33 ms per token,    61.25 tokens per second)\n",
      "llama_print_timings:       total time =      76.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.18 ms /    30 tokens (    1.01 ms per token,   993.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      81.29 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.10 ms /    18 tokens (    1.45 ms per token,   689.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.65 ms /     2 runs   (   16.33 ms per token,    61.25 tokens per second)\n",
      "llama_print_timings:       total time =      59.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    23 tokens (    1.16 ms per token,   862.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    22 tokens (    1.20 ms per token,   832.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.51 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.85 ms /    28 tokens (    1.07 ms per token,   937.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      80.35 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    14 tokens (    1.91 ms per token,   524.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.65 ms /     2 runs   (   16.32 ms per token,    61.26 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      25.91 ms /    17 tokens (    1.52 ms per token,   656.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.65 ms /     2 runs   (   16.33 ms per token,    61.25 tokens per second)\n",
      "llama_print_timings:       total time =      59.35 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    22 tokens (    1.20 ms per token,   834.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      59.86 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.20 ms /    21 tokens (    1.25 ms per token,   801.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      76.79 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.14 ms /    20 tokens (    1.31 ms per token,   764.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.23 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.16 ms /    30 tokens (    1.01 ms per token,   994.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      64.08 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.09 ms /    29 tokens (    1.04 ms per token,   963.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.15 ms /     3 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      80.09 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.52 ms /    22 tokens (    1.21 ms per token,   829.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.60 ms /    40 tokens (    0.84 ms per token,  1190.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      84.30 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.66 ms /    26 tokens (    1.14 ms per token,   876.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      63.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    21 tokens (    1.26 ms per token,   792.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    11 tokens (    2.40 ms per token,   417.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.67 ms /     2 runs   (   16.33 ms per token,    61.23 tokens per second)\n",
      "llama_print_timings:       total time =      59.51 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.53 ms /    25 tokens (    1.18 ms per token,   846.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      63.37 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    22 tokens (    1.20 ms per token,   832.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    24 tokens (    1.11 ms per token,   897.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.10 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.07 ms /    18 tokens (    1.45 ms per token,   690.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.23 tokens per second)\n",
      "llama_print_timings:       total time =      59.89 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.14 ms /    37 tokens (    0.90 ms per token,  1116.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      67.15 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      32.95 ms /    33 tokens (    1.00 ms per token,  1001.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      83.18 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.09 ms /    18 tokens (    1.45 ms per token,   689.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      59.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    23 tokens (    1.16 ms per token,   865.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    23 tokens (    1.16 ms per token,   864.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      59.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    14 tokens (    1.91 ms per token,   524.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.00 ms /     3 runs   (   16.33 ms per token,    61.22 tokens per second)\n",
      "llama_print_timings:       total time =      76.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.39 ms /    49 tokens (    0.84 ms per token,  1183.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      92.57 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.98 ms /    47 tokens (    0.77 ms per token,  1306.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      69.21 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.86 ms /    25 tokens (    1.19 ms per token,   837.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      63.40 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.74 ms /    25 tokens (    1.19 ms per token,   840.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      80.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    20 tokens (    1.33 ms per token,   752.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    13 tokens (    2.05 ms per token,   487.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      59.79 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.13 ms /    17 tokens (    1.54 ms per token,   650.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      59.47 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.22 ms /    19 tokens (    1.38 ms per token,   724.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.08 ms /     3 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      76.70 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    12 tokens (    2.20 ms per token,   454.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.34 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      60.07 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    24 tokens (    1.12 ms per token,   893.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      76.99 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    24 tokens (    1.12 ms per token,   894.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.35 ms /    21 tokens (    1.25 ms per token,   797.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    15 tokens (    1.80 ms per token,   556.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.05 ms /     3 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.62 ms /    25 tokens (    1.18 ms per token,   844.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      62.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    22 tokens (    1.21 ms per token,   827.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    22 tokens (    1.21 ms per token,   827.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.40 ms /    20 tokens (    1.32 ms per token,   757.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.67 ms /     2 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    20 tokens (    1.32 ms per token,   760.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      59.96 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    13 tokens (    2.05 ms per token,   487.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      60.01 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.54 ms /    21 tokens (    1.26 ms per token,   791.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      59.86 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    31 tokens (    0.98 ms per token,  1020.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      80.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.21 ms /    19 tokens (    1.38 ms per token,   724.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.07 ms /     3 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      76.72 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.56 ms /    25 tokens (    1.18 ms per token,   845.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      63.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    31 tokens (    0.99 ms per token,  1011.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      64.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    16 tokens (    1.68 ms per token,   593.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.67 ms /     2 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.89 ms /    26 tokens (    1.15 ms per token,   869.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      80.72 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.91 ms /    27 tokens (    1.11 ms per token,   902.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      63.12 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    14 tokens (    1.92 ms per token,   521.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.32 ms /    10 tokens (    2.63 ms per token,   379.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.71 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    21 tokens (    1.26 ms per token,   791.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.49 ms /    12 tokens (    2.21 ms per token,   452.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.68 ms /    25 tokens (    1.19 ms per token,   842.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.78 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    32 tokens (    0.96 ms per token,  1045.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      64.33 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    14 tokens (    1.91 ms per token,   523.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      60.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    16 tokens (    1.69 ms per token,   591.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    15 tokens (    1.80 ms per token,   555.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      76.83 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.33 ms /    19 tokens (    1.39 ms per token,   721.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.07 ms /     3 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      76.30 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.96 ms /    26 tokens (    1.15 ms per token,   867.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      63.71 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    13 tokens (    2.06 ms per token,   485.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.34 ms /    20 tokens (    1.32 ms per token,   759.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      76.23 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.92 ms /    27 tokens (    1.11 ms per token,   902.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      63.46 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.78 ms /    27 tokens (    1.10 ms per token,   906.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.82 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    30 tokens (    1.01 ms per token,   987.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      80.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.47 ms /    20 tokens (    1.32 ms per token,   755.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      59.83 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    24 tokens (    1.12 ms per token,   891.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.27 ms /    19 tokens (    1.38 ms per token,   723.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.02 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    21 tokens (    1.26 ms per token,   793.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    12 tokens (    2.20 ms per token,   455.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      59.99 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.92 ms /    27 tokens (    1.11 ms per token,   902.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.83 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.97 ms /    27 tokens (    1.11 ms per token,   900.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      63.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    13 tokens (    2.06 ms per token,   486.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    14 tokens (    1.91 ms per token,   522.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.03 ms /     3 runs   (   16.34 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      76.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.33 ms /    18 tokens (    1.46 ms per token,   683.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    13 tokens (    2.05 ms per token,   487.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.24 tokens per second)\n",
      "llama_print_timings:       total time =      59.80 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    15 tokens (    1.80 ms per token,   557.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.25 tokens per second)\n",
      "llama_print_timings:       total time =      60.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    13 tokens (    2.06 ms per token,   485.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.68 ms /     2 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    14 tokens (    1.91 ms per token,   523.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.35 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      59.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    15 tokens (    1.80 ms per token,   556.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.03 ms /     3 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    15 tokens (    1.81 ms per token,   553.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.02 ms /     3 runs   (   16.34 ms per token,    61.20 tokens per second)\n",
      "llama_print_timings:       total time =      77.14 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    11 tokens (    2.39 ms per token,   418.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.07 ms /     3 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      76.53 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.85 ms /    27 tokens (    1.11 ms per token,   904.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.04 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.32 ms /    18 tokens (    1.46 ms per token,   683.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.09 ms /     3 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      76.40 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    20 tokens (    1.32 ms per token,   755.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      59.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    24 tokens (    1.12 ms per token,   889.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    18 tokens (    1.46 ms per token,   685.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.09 ms /     3 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      76.09 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    23 tokens (    1.17 ms per token,   857.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.99 ms /    27 tokens (    1.11 ms per token,   900.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      64.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    30 tokens (    1.01 ms per token,   987.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      81.27 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    21 tokens (    1.26 ms per token,   795.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.12 ms /    18 tokens (    1.45 ms per token,   689.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      59.15 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    21 tokens (    1.26 ms per token,   794.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    24 tokens (    1.11 ms per token,   898.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      59.97 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    14 tokens (    1.92 ms per token,   521.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.77 ms /    26 tokens (    1.15 ms per token,   873.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      80.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    15 tokens (    1.82 ms per token,   550.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    29 tokens (    1.05 ms per token,   954.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      64.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    18 tokens (    1.46 ms per token,   685.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.08 ms /     3 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      76.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    29 tokens (    1.04 ms per token,   957.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      81.11 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.12 ms /    17 tokens (    1.54 ms per token,   650.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.10 ms /     3 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      76.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.94 ms /    27 tokens (    1.11 ms per token,   901.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      80.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.03 ms /    17 tokens (    1.53 ms per token,   653.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      76.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    22 tokens (    1.21 ms per token,   827.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.82 ms /    25 tokens (    1.19 ms per token,   838.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      63.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.26 ms /    19 tokens (    1.38 ms per token,   723.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.23 ms /    10 tokens (    2.62 ms per token,   381.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      59.39 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.27 ms /    28 tokens (    1.08 ms per token,   924.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      63.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.05 ms /    28 tokens (    1.07 ms per token,   931.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      63.60 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    24 tokens (    1.12 ms per token,   891.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.52 ms /    42 tokens (    0.85 ms per token,  1182.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      85.98 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    23 tokens (    1.18 ms per token,   850.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    17 tokens (    1.54 ms per token,   647.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.18 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.04 ms /    27 tokens (    1.11 ms per token,   898.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      63.33 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.80 ms /    26 tokens (    1.15 ms per token,   872.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      63.48 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      25.97 ms /    17 tokens (    1.53 ms per token,   654.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.06 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    14 tokens (    1.91 ms per token,   522.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    16 tokens (    1.69 ms per token,   592.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.67 ms /     2 runs   (   16.34 ms per token,    61.21 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.37 ms /    36 tokens (    0.93 ms per token,  1078.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      83.57 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    15 tokens (    1.80 ms per token,   554.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    23 tokens (    1.16 ms per token,   859.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.07 ms /    18 tokens (    1.45 ms per token,   690.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      59.18 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.85 ms /    27 tokens (    1.11 ms per token,   904.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      80.24 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.31 ms /    19 tokens (    1.38 ms per token,   722.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    24 tokens (    1.12 ms per token,   890.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.08 ms /    28 tokens (    1.07 ms per token,   930.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      80.29 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    23 tokens (    1.17 ms per token,   858.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      60.64 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.78 ms /    25 tokens (    1.19 ms per token,   839.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      80.18 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    13 tokens (    2.06 ms per token,   486.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.66 ms /     2 runs   (   16.33 ms per token,    61.23 tokens per second)\n",
      "llama_print_timings:       total time =      60.11 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    23 tokens (    1.17 ms per token,   856.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      76.75 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    14 tokens (    1.92 ms per token,   522.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.17 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    13 tokens (    2.05 ms per token,   487.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.69 ms /     2 runs   (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.17 ms /    34 tokens (    0.98 ms per token,  1025.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      66.87 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      32.94 ms /    33 tokens (    1.00 ms per token,  1001.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      83.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.04 ms /    17 tokens (    1.53 ms per token,   652.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.48 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    23 tokens (    1.16 ms per token,   858.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      59.90 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.76 ms /    25 tokens (    1.19 ms per token,   840.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      63.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    24 tokens (    1.12 ms per token,   896.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.92 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.82 ms /    26 tokens (    1.15 ms per token,   871.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      63.64 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    19 tokens (    1.38 ms per token,   722.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.06 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.37 ms /    19 tokens (    1.39 ms per token,   720.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.09 ms /     3 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    13 tokens (    2.06 ms per token,   484.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.94 ms /    26 tokens (    1.15 ms per token,   868.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      63.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    13 tokens (    2.06 ms per token,   486.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.64 ms /    41 tokens (    0.87 ms per token,  1150.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      69.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    24 tokens (    1.13 ms per token,   888.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    12 tokens (    2.21 ms per token,   453.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      76.39 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.34 ms /    19 tokens (    1.39 ms per token,   721.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      76.36 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    15 tokens (    1.80 ms per token,   555.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    15 tokens (    1.80 ms per token,   554.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    19 tokens (    1.38 ms per token,   723.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      59.49 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    24 tokens (    1.12 ms per token,   895.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.38 ms /    12 tokens (    2.20 ms per token,   454.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      77.11 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    24 tokens (    1.12 ms per token,   893.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.15 ms /     3 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    12 tokens (    2.20 ms per token,   454.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.03 ms /     3 runs   (   16.34 ms per token,    61.18 tokens per second)\n",
      "llama_print_timings:       total time =      76.89 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    14 tokens (    1.92 ms per token,   521.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    11 tokens (    2.40 ms per token,   416.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.07 ms /     3 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      76.90 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17167.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.28 ms /    19 tokens (    1.38 ms per token,   723.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      76.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    24 tokens (    1.12 ms per token,   894.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.20 ms /    34 tokens (    0.98 ms per token,  1024.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      83.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    22 tokens (    1.20 ms per token,   829.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      76.86 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.93 ms /    27 tokens (    1.11 ms per token,   902.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      80.78 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.05 ms /    27 tokens (    1.11 ms per token,   898.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      80.31 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    29 tokens (    1.05 ms per token,   951.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      80.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    22 tokens (    1.22 ms per token,   822.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    11 tokens (    2.40 ms per token,   416.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.22 ms /    18 tokens (    1.46 ms per token,   686.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.10 ms /     3 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      76.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    20 tokens (    1.32 ms per token,   756.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.96 ms /    26 tokens (    1.15 ms per token,   867.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      63.58 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.20 ms /    19 tokens (    1.38 ms per token,   725.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.78 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.44 ms /    20 tokens (    1.32 ms per token,   756.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.84 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    21 tokens (    1.26 ms per token,   791.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      77.28 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    20 tokens (    1.32 ms per token,   757.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.81 ms /    26 tokens (    1.15 ms per token,   872.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      80.19 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    12 tokens (    2.21 ms per token,   453.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.08 ms /     3 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      76.77 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.26 ms /    19 tokens (    1.38 ms per token,   723.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      59.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    29 tokens (    1.06 ms per token,   947.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      65.10 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    21 tokens (    1.26 ms per token,   791.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    31 tokens (    0.99 ms per token,  1012.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      80.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    32 tokens (    0.96 ms per token,  1044.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      80.66 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    22 tokens (    1.21 ms per token,   826.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      60.30 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.80 ms /    26 tokens (    1.15 ms per token,   872.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      79.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    16 tokens (    1.70 ms per token,   589.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    14 tokens (    1.93 ms per token,   518.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    20 tokens (    1.32 ms per token,   756.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      59.52 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    21 tokens (    1.26 ms per token,   790.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    16 tokens (    1.69 ms per token,   591.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.06 ms /     3 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.14 ms /    17 tokens (    1.54 ms per token,   650.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.95 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.20 ms /    18 tokens (    1.46 ms per token,   687.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      59.30 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    22 tokens (    1.21 ms per token,   827.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      77.28 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    15 tokens (    1.80 ms per token,   555.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      77.30 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    22 tokens (    1.21 ms per token,   824.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.84 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    15 tokens (    1.81 ms per token,   553.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    19 tokens (    1.39 ms per token,   719.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    14 tokens (    1.92 ms per token,   522.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    30 tokens (    1.02 ms per token,   983.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      80.57 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.32 ms /    19 tokens (    1.39 ms per token,   721.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      59.51 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    21 tokens (    1.26 ms per token,   792.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      59.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.07 ms /    39 tokens (    0.87 ms per token,  1144.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      84.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.49 ms /    20 tokens (    1.32 ms per token,   755.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      76.70 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    29 tokens (    1.05 ms per token,   948.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      64.64 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    22 tokens (    1.21 ms per token,   824.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    29 tokens (    1.05 ms per token,   953.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      81.00 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    21 tokens (    1.26 ms per token,   792.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.21 ms /    18 tokens (    1.46 ms per token,   686.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      76.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.23 ms /    18 tokens (    1.46 ms per token,   686.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    21 tokens (    1.26 ms per token,   792.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    17 tokens (    1.54 ms per token,   647.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.15 ms /     3 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      76.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    19 tokens (    1.39 ms per token,   720.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      59.70 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.65 ms /    38 tokens (    0.89 ms per token,  1129.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      67.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    18 tokens (    1.47 ms per token,   681.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      76.91 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.31 ms /    17 tokens (    1.55 ms per token,   646.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.09 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    23 tokens (    1.17 ms per token,   855.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.24 ms /    17 tokens (    1.54 ms per token,   647.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      59.26 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    16 tokens (    1.69 ms per token,   590.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    23 tokens (    1.17 ms per token,   858.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      77.08 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    24 tokens (    1.12 ms per token,   891.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    15 tokens (    1.80 ms per token,   554.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    18 tokens (    1.47 ms per token,   681.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      60.18 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    24 tokens (    1.13 ms per token,   887.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    12 tokens (    2.21 ms per token,   451.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.16 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.86 ms /    25 tokens (    1.19 ms per token,   837.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      63.35 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.13 ms /    28 tokens (    1.08 ms per token,   929.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      63.55 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.77 ms /    42 tokens (    0.85 ms per token,  1174.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      86.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    20 tokens (    1.32 ms per token,   756.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    13 tokens (    2.06 ms per token,   485.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.22 ms /    28 tokens (    1.08 ms per token,   926.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      80.18 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.62 ms /    41 tokens (    0.87 ms per token,  1151.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      69.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    21 tokens (    1.27 ms per token,   786.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      59.89 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.85 ms /    41 tokens (    0.87 ms per token,  1143.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      69.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    22 tokens (    1.22 ms per token,   818.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    20 tokens (    1.33 ms per token,   752.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    20 tokens (    1.33 ms per token,   751.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      59.99 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    21 tokens (    1.27 ms per token,   788.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      76.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.35 ms /    18 tokens (    1.46 ms per token,   683.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.15 ms /     3 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      76.71 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    21 tokens (    1.27 ms per token,   787.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      76.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    23 tokens (    1.17 ms per token,   853.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.37 ms /    35 tokens (    0.95 ms per token,  1048.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      66.83 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    16 tokens (    1.69 ms per token,   590.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    29 tokens (    1.05 ms per token,   948.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      64.13 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    24 tokens (    1.12 ms per token,   889.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.14 ms /    27 tokens (    1.12 ms per token,   895.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      63.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.09 ms /    28 tokens (    1.07 ms per token,   930.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      80.70 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    24 tokens (    1.13 ms per token,   888.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      77.02 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    21 tokens (    1.27 ms per token,   788.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.17 ms /    33 tokens (    1.01 ms per token,   994.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      67.37 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    13 tokens (    2.07 ms per token,   483.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.11 ms /     3 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    20 tokens (    1.33 ms per token,   752.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.87 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    28 tokens (    1.08 ms per token,   923.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      63.89 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    16 tokens (    1.70 ms per token,   589.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    13 tokens (    2.06 ms per token,   486.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.36 ms per token,    61.14 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.37 ms /    20 tokens (    1.32 ms per token,   758.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      59.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    24 tokens (    1.12 ms per token,   890.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.40 ms /    46 tokens (    0.79 ms per token,  1263.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      69.85 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    22 tokens (    1.21 ms per token,   824.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    12 tokens (    2.20 ms per token,   453.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.07 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    15 tokens (    1.80 ms per token,   554.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    16 tokens (    1.70 ms per token,   588.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      77.11 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.14 ms /    26 tokens (    1.16 ms per token,   862.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      63.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    24 tokens (    1.12 ms per token,   889.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    15 tokens (    1.81 ms per token,   553.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.71 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    23 tokens (    1.17 ms per token,   851.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.52 ms /    20 tokens (    1.33 ms per token,   754.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    22 tokens (    1.21 ms per token,   824.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    22 tokens (    1.21 ms per token,   827.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    23 tokens (    1.17 ms per token,   857.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    11 tokens (    2.41 ms per token,   415.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      76.30 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    18 tokens (    1.46 ms per token,   682.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    16 tokens (    1.70 ms per token,   589.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.89 ms /    25 tokens (    1.20 ms per token,   836.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      80.53 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    22 tokens (    1.22 ms per token,   820.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    11 tokens (    2.41 ms per token,   414.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      76.43 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    22 tokens (    1.22 ms per token,   821.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.37 ms /    18 tokens (    1.46 ms per token,   682.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      76.87 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    22 tokens (    1.22 ms per token,   820.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.23 ms /    33 tokens (    1.01 ms per token,   993.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      83.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    13 tokens (    2.06 ms per token,   485.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      59.96 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    15 tokens (    1.80 ms per token,   554.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    24 tokens (    1.12 ms per token,   892.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.33 ms /    35 tokens (    0.95 ms per token,  1050.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      67.28 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.80 ms /    38 tokens (    0.89 ms per token,  1124.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      67.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    10 tokens (    2.64 ms per token,   378.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    14 tokens (    1.92 ms per token,   520.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    24 tokens (    1.13 ms per token,   885.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    16 tokens (    1.70 ms per token,   588.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.12 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    11 tokens (    2.41 ms per token,   415.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    29 tokens (    1.05 ms per token,   950.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    14 tokens (    1.93 ms per token,   519.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    16 tokens (    1.70 ms per token,   588.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    24 tokens (    1.13 ms per token,   888.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    13 tokens (    2.06 ms per token,   485.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      76.81 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    14 tokens (    1.92 ms per token,   520.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    29 tokens (    1.05 ms per token,   953.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      80.84 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    24 tokens (    1.13 ms per token,   885.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    23 tokens (    1.17 ms per token,   851.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    12 tokens (    2.22 ms per token,   450.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.33 ms /    17 tokens (    1.55 ms per token,   645.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      59.47 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    23 tokens (    1.17 ms per token,   854.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    23 tokens (    1.17 ms per token,   853.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      76.94 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.07 ms /    26 tokens (    1.16 ms per token,   864.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      80.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.72 ms /    38 tokens (    0.89 ms per token,  1126.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      67.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.54 ms /    37 tokens (    0.91 ms per token,  1103.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      67.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.47 ms /    35 tokens (    0.96 ms per token,  1045.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    14 tokens (    1.92 ms per token,   520.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.70 ms /     2 runs   (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.27 ms /    19 tokens (    1.38 ms per token,   723.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      59.61 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    20 tokens (    1.33 ms per token,   753.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    29 tokens (    1.05 ms per token,   950.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      63.87 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.09 ms /    26 tokens (    1.16 ms per token,   864.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      80.32 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    18 tokens (    1.47 ms per token,   681.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      59.67 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.34 ms /    33 tokens (    1.01 ms per token,   989.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      83.75 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    19 tokens (    1.39 ms per token,   718.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      76.67 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.08 ms /    26 tokens (    1.16 ms per token,   864.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      63.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    15 tokens (    1.82 ms per token,   549.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.06 ms /    25 tokens (    1.20 ms per token,   831.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      80.80 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    28 tokens (    1.08 ms per token,   922.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      81.17 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    14 tokens (    1.93 ms per token,   518.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    24 tokens (    1.13 ms per token,   885.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    28 tokens (    1.08 ms per token,   923.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      63.68 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    11 tokens (    2.40 ms per token,   417.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      59.63 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.47 ms /    30 tokens (    1.02 ms per token,   984.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      63.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.15 ms /    27 tokens (    1.12 ms per token,   895.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      80.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    20 tokens (    1.33 ms per token,   751.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   780.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    20 tokens (    1.33 ms per token,   753.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      76.68 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.93 ms /    25 tokens (    1.20 ms per token,   835.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      80.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    13 tokens (    2.07 ms per token,   483.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    15 tokens (    1.81 ms per token,   552.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.72 ms /     2 runs   (   16.36 ms per token,    61.13 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    19 tokens (    1.39 ms per token,   717.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      59.81 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.38 ms /    19 tokens (    1.39 ms per token,   720.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      59.63 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    21 tokens (    1.27 ms per token,   788.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    23 tokens (    1.17 ms per token,   853.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.47 ms /    11 tokens (    2.41 ms per token,   415.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.12 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    22 tokens (    1.21 ms per token,   824.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    23 tokens (    1.17 ms per token,   854.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    19 tokens (    1.40 ms per token,   715.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    32 tokens (    0.97 ms per token,  1034.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      65.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.27 ms /    17 tokens (    1.55 ms per token,   647.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      59.41 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    16 tokens (    1.70 ms per token,   589.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    19 tokens (    1.39 ms per token,   718.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      59.87 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    15 tokens (    1.82 ms per token,   549.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    30 tokens (    1.01 ms per token,   985.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      64.17 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    22 tokens (    1.22 ms per token,   818.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    28 tokens (    1.08 ms per token,   922.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      81.21 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    18 tokens (    1.47 ms per token,   681.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    23 tokens (    1.17 ms per token,   852.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.93 ms /    25 tokens (    1.20 ms per token,   835.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      80.82 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    19 tokens (    1.39 ms per token,   719.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      76.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.73 ms /    38 tokens (    0.89 ms per token,  1126.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      68.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.31 ms /    46 tokens (    0.79 ms per token,  1266.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      70.47 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    14 tokens (    1.93 ms per token,   519.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.12 ms /     3 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    14 tokens (    1.92 ms per token,   519.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    15 tokens (    1.81 ms per token,   553.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.77 ms /    41 tokens (    0.87 ms per token,  1146.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      69.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.40 ms /    18 tokens (    1.47 ms per token,   681.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    18 tokens (    1.46 ms per token,   682.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      76.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    21 tokens (    1.27 ms per token,   786.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    32 tokens (    0.96 ms per token,  1038.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      81.10 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    22 tokens (    1.22 ms per token,   821.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    32 tokens (    0.96 ms per token,  1038.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      81.01 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    15 tokens (    1.82 ms per token,   549.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    23 tokens (    1.17 ms per token,   851.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.44 ms /    18 tokens (    1.47 ms per token,   680.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.17 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      76.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    16 tokens (    1.70 ms per token,   586.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    15 tokens (    1.81 ms per token,   551.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    39 tokens (    0.87 ms per token,  1147.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      84.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    24 tokens (    1.13 ms per token,   888.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.26 ms /    18 tokens (    1.46 ms per token,   685.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      59.86 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    30 tokens (    1.02 ms per token,   981.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      63.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.85 ms /    41 tokens (    0.87 ms per token,  1143.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      69.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.23 ms /    18 tokens (    1.46 ms per token,   686.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      76.77 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.22 ms /    17 tokens (    1.54 ms per token,   648.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    18 tokens (    1.46 ms per token,   685.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    14 tokens (    1.92 ms per token,   520.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.36 ms /    46 tokens (    0.79 ms per token,  1265.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      70.71 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    15 tokens (    1.81 ms per token,   552.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.36 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    12 tokens (    2.21 ms per token,   453.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      59.67 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    21 tokens (    1.27 ms per token,   786.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    23 tokens (    1.17 ms per token,   852.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    12 tokens (    2.22 ms per token,   450.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.10 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    29 tokens (    1.05 ms per token,   948.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      81.15 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    11 tokens (    2.41 ms per token,   414.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.13 ms /     3 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.28 ms /    28 tokens (    1.08 ms per token,   924.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      64.05 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    29 tokens (    1.05 ms per token,   948.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.09 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    14 tokens (    1.93 ms per token,   518.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    30 tokens (    1.02 ms per token,   977.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      63.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    12 tokens (    2.22 ms per token,   451.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    24 tokens (    1.13 ms per token,   888.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.05 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    23 tokens (    1.17 ms per token,   854.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.26 ms /    17 tokens (    1.54 ms per token,   647.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.27 ms /    17 tokens (    1.55 ms per token,   647.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.24 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    14 tokens (    1.93 ms per token,   519.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    24 tokens (    1.12 ms per token,   892.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    16 tokens (    1.70 ms per token,   589.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.73 ms /     2 runs   (   16.37 ms per token,    61.11 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    17 tokens (    1.54 ms per token,   647.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.03 ms /    25 tokens (    1.20 ms per token,   832.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      80.76 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    11 tokens (    2.42 ms per token,   413.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    20 tokens (    1.33 ms per token,   750.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      77.06 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    11 tokens (    2.42 ms per token,   413.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    21 tokens (    1.27 ms per token,   786.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.77 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.55 ms /    36 tokens (    0.93 ms per token,  1073.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      84.17 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    17 tokens (    1.54 ms per token,   647.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    18 tokens (    1.47 ms per token,   681.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.07 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    14 tokens (    1.92 ms per token,   520.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.14 ms /     3 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      76.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    30 tokens (    1.02 ms per token,   981.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    17 tokens (    1.56 ms per token,   641.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    23 tokens (    1.18 ms per token,   846.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    20 tokens (    1.33 ms per token,   750.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.29 ms /    33 tokens (    1.01 ms per token,   991.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      67.36 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    14 tokens (    1.94 ms per token,   516.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    16 tokens (    1.70 ms per token,   589.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.08 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    22 tokens (    1.21 ms per token,   823.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.87 ms /    39 tokens (    0.87 ms per token,  1151.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      67.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    19 tokens (    1.39 ms per token,   718.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    22 tokens (    1.22 ms per token,   821.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.26 ms /    18 tokens (    1.46 ms per token,   685.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.23 ms /    17 tokens (    1.54 ms per token,   647.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    19 tokens (    1.39 ms per token,   719.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      59.78 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    21 tokens (    1.28 ms per token,   782.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    24 tokens (    1.13 ms per token,   884.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    16 tokens (    1.70 ms per token,   587.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.12 ms /    26 tokens (    1.16 ms per token,   863.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      80.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.24 ms /    26 tokens (    1.16 ms per token,   859.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      64.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.40 ms /    10 tokens (    2.64 ms per token,   378.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.11 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.25 ms /    18 tokens (    1.46 ms per token,   685.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.16 ms /     3 runs   (   16.39 ms per token,    61.02 tokens per second)\n",
      "llama_print_timings:       total time =      76.90 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    16 tokens (    1.71 ms per token,   585.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    13 tokens (    2.07 ms per token,   483.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    22 tokens (    1.22 ms per token,   820.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    26 tokens (    1.17 ms per token,   857.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      63.66 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    11 tokens (    2.42 ms per token,   412.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.02 ms /    25 tokens (    1.20 ms per token,   832.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      80.31 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    27 tokens (    1.12 ms per token,   890.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      63.77 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    16 tokens (    1.71 ms per token,   585.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    21 tokens (    1.28 ms per token,   781.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    15 tokens (    1.82 ms per token,   548.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.37 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    30 tokens (    1.02 ms per token,   975.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    30 tokens (    1.02 ms per token,   979.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      81.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.18 ms /    25 tokens (    1.21 ms per token,   828.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    13 tokens (    2.08 ms per token,   479.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.29 ms /    26 tokens (    1.17 ms per token,   858.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      80.22 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    27 tokens (    1.12 ms per token,   890.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      80.38 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.39 ms /    17 tokens (    1.55 ms per token,   644.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      59.55 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    23 tokens (    1.17 ms per token,   852.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.31 ms /    17 tokens (    1.55 ms per token,   646.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    14 tokens (    1.93 ms per token,   518.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    29 tokens (    1.06 ms per token,   947.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      65.30 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    27 tokens (    1.12 ms per token,   889.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.18 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    31 tokens (    1.00 ms per token,  1003.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    22 tokens (    1.23 ms per token,   816.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    24 tokens (    1.13 ms per token,   882.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    12 tokens (    2.23 ms per token,   448.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.07 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    17 tokens (    1.56 ms per token,   642.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    24 tokens (    1.13 ms per token,   882.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    15 tokens (    1.82 ms per token,   549.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.12 ms /    25 tokens (    1.20 ms per token,   830.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.36 ms /    18 tokens (    1.46 ms per token,   682.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.07 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    23 tokens (    1.18 ms per token,   850.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    17 tokens (    1.55 ms per token,   643.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    24 tokens (    1.14 ms per token,   878.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    22 tokens (    1.23 ms per token,   814.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    22 tokens (    1.23 ms per token,   816.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    21 tokens (    1.28 ms per token,   781.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    18 tokens (    1.48 ms per token,   676.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    14 tokens (    1.94 ms per token,   516.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    20 tokens (    1.33 ms per token,   750.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    14 tokens (    1.93 ms per token,   517.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.30 ms /    18 tokens (    1.46 ms per token,   684.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      76.39 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    14 tokens (    1.93 ms per token,   517.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    31 tokens (    0.99 ms per token,  1005.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      81.75 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.06 ms /    31 tokens (    1.00 ms per token,   998.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      64.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    15 tokens (    1.82 ms per token,   549.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    20 tokens (    1.34 ms per token,   748.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.30 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    28 tokens (    1.09 ms per token,   918.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.76 ms /    30 tokens (    1.03 ms per token,   975.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    21 tokens (    1.28 ms per token,   781.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    31 tokens (    1.00 ms per token,  1002.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    11 tokens (    2.42 ms per token,   412.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      76.95 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.23 ms /    40 tokens (    0.86 ms per token,  1168.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      67.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    19 tokens (    1.40 ms per token,   713.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.80 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    30 tokens (    1.03 ms per token,   971.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      81.73 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.86 ms /    37 tokens (    0.92 ms per token,  1092.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      67.22 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    16 tokens (    1.69 ms per token,   590.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    21 tokens (    1.27 ms per token,   785.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    23 tokens (    1.18 ms per token,   845.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    18 tokens (    1.47 ms per token,   680.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    20 tokens (    1.33 ms per token,   751.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    21 tokens (    1.28 ms per token,   782.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      59.95 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.25 ms /    26 tokens (    1.16 ms per token,   859.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.19 ms /    26 tokens (    1.16 ms per token,   861.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      80.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    13 tokens (    2.08 ms per token,   480.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.13 ms /    25 tokens (    1.21 ms per token,   829.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      64.93 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    14 tokens (    1.94 ms per token,   516.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    11 tokens (    2.42 ms per token,   412.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    21 tokens (    1.27 ms per token,   785.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      59.88 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    20 tokens (    1.33 ms per token,   752.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.06 ms /    26 tokens (    1.16 ms per token,   864.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    15 tokens (    1.82 ms per token,   548.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    24 tokens (    1.14 ms per token,   878.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    19 tokens (    1.40 ms per token,   714.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    24 tokens (    1.13 ms per token,   883.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    21 tokens (    1.28 ms per token,   782.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.16 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.38 ms /    17 tokens (    1.55 ms per token,   644.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      59.52 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    12 tokens (    2.22 ms per token,   451.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.20 ms /    25 tokens (    1.21 ms per token,   827.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    18 tokens (    1.48 ms per token,   675.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      59.84 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    21 tokens (    1.28 ms per token,   783.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    19 tokens (    1.40 ms per token,   715.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    23 tokens (    1.18 ms per token,   848.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    22 tokens (    1.22 ms per token,   818.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    22 tokens (    1.22 ms per token,   820.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    23 tokens (    1.17 ms per token,   851.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    10 tokens (    2.70 ms per token,   369.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.44 ms /    17 tokens (    1.56 ms per token,   642.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    23 tokens (    1.18 ms per token,   848.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    17 tokens (    1.55 ms per token,   643.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    22 tokens (    1.22 ms per token,   817.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    24 tokens (    1.13 ms per token,   887.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.29 ms /    26 tokens (    1.17 ms per token,   858.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      81.59 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    19 tokens (    1.41 ms per token,   711.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    24 tokens (    1.14 ms per token,   880.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    21 tokens (    1.28 ms per token,   783.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.62 ms /    35 tokens (    0.96 ms per token,  1041.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    23 tokens (    1.18 ms per token,   850.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    22 tokens (    1.22 ms per token,   818.79 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    14 tokens (    1.95 ms per token,   513.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    17 tokens (    1.56 ms per token,   639.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      76.72 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    24 tokens (    1.14 ms per token,   879.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    31 tokens (    1.00 ms per token,  1001.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      81.27 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    17 tokens (    1.55 ms per token,   643.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    11 tokens (    2.43 ms per token,   412.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    18 tokens (    1.47 ms per token,   678.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      59.84 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    14 tokens (    1.93 ms per token,   517.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    11 tokens (    2.41 ms per token,   414.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      76.94 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    27 tokens (    1.12 ms per token,   891.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      63.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    20 tokens (    1.34 ms per token,   747.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.11 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    24 tokens (    1.14 ms per token,   879.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.67 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    32 tokens (    0.97 ms per token,  1027.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.85 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    24 tokens (    1.13 ms per token,   881.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    14 tokens (    1.94 ms per token,   515.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    23 tokens (    1.18 ms per token,   849.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    23 tokens (    1.18 ms per token,   848.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    22 tokens (    1.22 ms per token,   819.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    21 tokens (    1.28 ms per token,   783.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    20 tokens (    1.33 ms per token,   749.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    12 tokens (    2.23 ms per token,   447.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    29 tokens (    1.06 ms per token,   944.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      81.65 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    21 tokens (    1.28 ms per token,   782.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.18 ms /    25 tokens (    1.21 ms per token,   828.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      63.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    28 tokens (    1.09 ms per token,   918.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.19 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.11 ms /    25 tokens (    1.20 ms per token,   830.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      63.83 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    20 tokens (    1.34 ms per token,   745.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    18 tokens (    1.48 ms per token,   677.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    22 tokens (    1.23 ms per token,   815.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    21 tokens (    1.28 ms per token,   782.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.13 ms /    25 tokens (    1.21 ms per token,   829.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      81.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    20 tokens (    1.34 ms per token,   748.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    19 tokens (    1.40 ms per token,   713.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    29 tokens (    1.06 ms per token,   946.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.79 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    27 tokens (    1.12 ms per token,   889.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      81.38 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   742.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    18 tokens (    1.48 ms per token,   677.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      76.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    20 tokens (    1.34 ms per token,   746.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.10 ms /    25 tokens (    1.20 ms per token,   830.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      63.53 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    20 tokens (    1.33 ms per token,   749.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    21 tokens (    1.27 ms per token,   784.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      76.90 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    22 tokens (    1.22 ms per token,   818.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    22 tokens (    1.22 ms per token,   818.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    16 tokens (    1.71 ms per token,   586.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    17 tokens (    1.56 ms per token,   642.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    18 tokens (    1.49 ms per token,   669.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    20 tokens (    1.34 ms per token,   744.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    19 tokens (    1.40 ms per token,   713.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    31 tokens (    1.00 ms per token,   996.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      81.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    15 tokens (    1.82 ms per token,   548.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    24 tokens (    1.15 ms per token,   870.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    23 tokens (    1.18 ms per token,   848.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    14 tokens (    1.93 ms per token,   517.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    19 tokens (    1.40 ms per token,   713.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    23 tokens (    1.18 ms per token,   850.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.04 ms /    31 tokens (    1.00 ms per token,   998.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      65.39 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   780.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    29 tokens (    1.06 ms per token,   943.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      64.23 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.58 ms /    35 tokens (    0.96 ms per token,  1042.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      83.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    19 tokens (    1.41 ms per token,   711.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.16 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.96 ms /    31 tokens (    1.00 ms per token,  1001.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      81.01 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    32 tokens (    0.97 ms per token,  1028.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      81.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.26 ms /    25 tokens (    1.21 ms per token,   826.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      63.69 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    22 tokens (    1.23 ms per token,   815.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    27 tokens (    1.13 ms per token,   886.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      80.92 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    16 tokens (    1.72 ms per token,   581.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      80.61 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    19 tokens (    1.40 ms per token,   712.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.40 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    23 tokens (    1.18 ms per token,   847.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    24 tokens (    1.13 ms per token,   882.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    13 tokens (    2.08 ms per token,   481.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    20 tokens (    1.33 ms per token,   753.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      76.49 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    22 tokens (    1.23 ms per token,   814.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    16 tokens (    1.71 ms per token,   585.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      79.20 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    16 tokens (    1.71 ms per token,   583.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.75 ms /     2 runs   (   16.38 ms per token,    61.06 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.16 ms /    25 tokens (    1.21 ms per token,   828.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      81.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    16 tokens (    1.71 ms per token,   585.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    19 tokens (    1.40 ms per token,   712.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    19 tokens (    1.40 ms per token,   715.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      76.61 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    14 tokens (    1.94 ms per token,   515.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    18 tokens (    1.48 ms per token,   677.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      59.97 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    29 tokens (    1.05 ms per token,   949.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      80.72 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    13 tokens (    2.10 ms per token,   476.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    30 tokens (    1.03 ms per token,   973.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      64.09 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    16 tokens (    1.71 ms per token,   585.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    15 tokens (    1.83 ms per token,   547.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    23 tokens (    1.18 ms per token,   848.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    15 tokens (    1.83 ms per token,   547.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.44 ms /    17 tokens (    1.56 ms per token,   642.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      59.72 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    28 tokens (    1.08 ms per token,   923.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      63.60 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    11 tokens (    2.43 ms per token,   412.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      76.72 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    14 tokens (    1.94 ms per token,   514.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    23 tokens (    1.18 ms per token,   847.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    22 tokens (    1.22 ms per token,   816.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    29 tokens (    1.06 ms per token,   944.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      80.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    24 tokens (    1.13 ms per token,   881.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.41 ms /    52 tokens (    0.82 ms per token,  1225.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      75.97 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.34 ms /    17 tokens (    1.55 ms per token,   645.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      59.75 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    21 tokens (    1.28 ms per token,   780.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    15 tokens (    1.82 ms per token,   549.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    19 tokens (    1.40 ms per token,   714.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    27 tokens (    1.12 ms per token,   889.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.90 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    15 tokens (    1.82 ms per token,   549.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    23 tokens (    1.19 ms per token,   842.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    12 tokens (    2.23 ms per token,   447.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.02 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    29 tokens (    1.06 ms per token,   944.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      81.57 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    28 tokens (    1.09 ms per token,   918.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      64.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.07 ms /    25 tokens (    1.20 ms per token,   831.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      81.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   676.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    15 tokens (    1.83 ms per token,   547.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.16 ms /    25 tokens (    1.21 ms per token,   828.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      64.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.96 ms /    30 tokens (    1.03 ms per token,   969.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    24 tokens (    1.13 ms per token,   885.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.07 ms /    25 tokens (    1.20 ms per token,   831.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      78.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.46 ms /    17 tokens (    1.56 ms per token,   642.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    23 tokens (    1.18 ms per token,   848.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.18 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    28 tokens (    1.09 ms per token,   916.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    22 tokens (    1.22 ms per token,   820.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    24 tokens (    1.13 ms per token,   885.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.17 ms /    26 tokens (    1.16 ms per token,   861.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      80.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   781.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    20 tokens (    1.33 ms per token,   750.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    14 tokens (    1.94 ms per token,   514.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    14 tokens (    1.93 ms per token,   517.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.74 ms /     2 runs   (   16.37 ms per token,    61.09 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.59 ms /    36 tokens (    0.93 ms per token,  1071.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      66.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    28 tokens (    1.09 ms per token,   917.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      64.71 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    17 tokens (    1.55 ms per token,   643.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    16 tokens (    1.70 ms per token,   588.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.25 ms /    25 tokens (    1.21 ms per token,   826.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      80.90 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.22 ms /    25 tokens (    1.21 ms per token,   827.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      80.46 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.25 ms /    25 tokens (    1.21 ms per token,   826.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.67 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    12 tokens (    2.23 ms per token,   449.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    24 tokens (    1.13 ms per token,   883.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    13 tokens (    2.07 ms per token,   482.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    12 tokens (    2.22 ms per token,   449.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    12 tokens (    2.23 ms per token,   449.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    12 tokens (    2.23 ms per token,   448.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    13 tokens (    2.08 ms per token,   481.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      76.90 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      63.72 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.18 ms /    25 tokens (    1.21 ms per token,   828.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      81.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    20 tokens (    1.33 ms per token,   749.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      76.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    19 tokens (    1.40 ms per token,   712.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    23 tokens (    1.18 ms per token,   846.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    13 tokens (    2.08 ms per token,   481.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.18 ms /     3 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    23 tokens (    1.18 ms per token,   848.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    27 tokens (    1.12 ms per token,   890.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      63.74 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    32 tokens (    0.97 ms per token,  1027.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      64.31 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    23 tokens (    1.18 ms per token,   846.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    29 tokens (    1.05 ms per token,   951.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      64.41 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    26 tokens (    1.17 ms per token,   854.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      64.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    20 tokens (    1.34 ms per token,   744.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    12 tokens (    2.24 ms per token,   446.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      76.99 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.92 ms /    30 tokens (    1.03 ms per token,   970.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      64.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    30 tokens (    1.02 ms per token,   977.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      64.84 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    14 tokens (    1.94 ms per token,   514.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.64 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    17 tokens (    1.56 ms per token,   641.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.43 ms /    34 tokens (    0.98 ms per token,  1016.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      67.20 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.15 ms /    25 tokens (    1.21 ms per token,   829.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      80.91 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    19 tokens (    1.40 ms per token,   712.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    28 tokens (    1.09 ms per token,   916.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      63.76 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    16 tokens (    1.71 ms per token,   585.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.22 ms /     3 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    11 tokens (    2.43 ms per token,   411.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    23 tokens (    1.18 ms per token,   848.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    15 tokens (    1.82 ms per token,   549.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    13 tokens (    2.09 ms per token,   478.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    19 tokens (    1.40 ms per token,   713.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    15 tokens (    1.83 ms per token,   547.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    15 tokens (    1.82 ms per token,   548.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    23 tokens (    1.18 ms per token,   847.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19801.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    27 tokens (    1.13 ms per token,   887.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      81.69 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    16 tokens (    1.71 ms per token,   585.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    15 tokens (    1.83 ms per token,   547.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    11 tokens (    2.43 ms per token,   411.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    15 tokens (    1.83 ms per token,   547.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.20 ms /     3 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.75 ms /    15 tokens (    1.85 ms per token,   540.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.44 ms /    17 tokens (    1.56 ms per token,   643.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    21 tokens (    1.27 ms per token,   785.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    20 tokens (    1.34 ms per token,   748.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      76.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    22 tokens (    1.23 ms per token,   816.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    20 tokens (    1.34 ms per token,   747.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    21 tokens (    1.30 ms per token,   770.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    26 tokens (    1.17 ms per token,   857.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      81.35 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    28 tokens (    1.09 ms per token,   915.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      81.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    12 tokens (    2.24 ms per token,   446.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.09 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    21 tokens (    1.28 ms per token,   778.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.12 ms /    25 tokens (    1.20 ms per token,   829.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      63.80 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    29 tokens (    1.06 ms per token,   946.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      64.60 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.55 ms /    33 tokens (    1.02 ms per token,   983.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      66.89 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    11 tokens (    2.43 ms per token,   412.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.19 ms /     3 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      76.61 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   814.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    38 tokens (    0.89 ms per token,  1118.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      84.09 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    29 tokens (    1.07 ms per token,   934.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      81.25 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    26 tokens (    1.17 ms per token,   854.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.39 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    22 tokens (    1.22 ms per token,   818.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      59.73 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    24 tokens (    1.15 ms per token,   871.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    39 tokens (    0.88 ms per token,  1134.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      85.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    10 tokens (    2.68 ms per token,   373.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    22 tokens (    1.22 ms per token,   816.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.47 ms /    17 tokens (    1.56 ms per token,   642.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    16 tokens (    1.71 ms per token,   585.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    22 tokens (    1.22 ms per token,   817.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    15 tokens (    1.83 ms per token,   546.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.42 ms /    17 tokens (    1.55 ms per token,   643.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    11 tokens (    2.43 ms per token,   411.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.04 tokens per second)\n",
      "llama_print_timings:       total time =      60.14 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    26 tokens (    1.17 ms per token,   857.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.34 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    17 tokens (    1.55 ms per token,   643.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.30 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    29 tokens (    1.06 ms per token,   944.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.43 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.76 ms /    35 tokens (    0.96 ms per token,  1036.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      67.30 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    21 tokens (    1.28 ms per token,   781.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    14 tokens (    1.93 ms per token,   517.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.58 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    10 tokens (    2.65 ms per token,   376.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      59.96 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.29 ms /    25 tokens (    1.21 ms per token,   825.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      80.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   813.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    19 tokens (    1.41 ms per token,   709.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    14 tokens (    1.93 ms per token,   517.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.48 ms /    18 tokens (    1.47 ms per token,   679.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.24 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      76.35 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    24 tokens (    1.13 ms per token,   882.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    18 tokens (    1.48 ms per token,   674.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    24 tokens (    1.14 ms per token,   879.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   813.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    30 tokens (    1.03 ms per token,   970.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.18 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    27 tokens (    1.12 ms per token,   890.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      80.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.43 ms /    17 tokens (    1.55 ms per token,   643.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      59.66 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    32 tokens (    0.97 ms per token,  1027.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.52 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    12 tokens (    2.24 ms per token,   446.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.94 ms /    48 tokens (    0.77 ms per token,  1299.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      87.79 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.07 ms /    25 tokens (    1.20 ms per token,   831.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      82.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    14 tokens (    1.95 ms per token,   514.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    20 tokens (    1.34 ms per token,   745.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    27 tokens (    1.13 ms per token,   885.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      64.04 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    10 tokens (    2.66 ms per token,   376.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      59.89 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    23 tokens (    1.18 ms per token,   848.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.49 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.53 ms /    19 tokens (    1.40 ms per token,   716.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    11 tokens (    2.43 ms per token,   411.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    18 tokens (    1.48 ms per token,   677.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      76.89 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    27 tokens (    1.14 ms per token,   878.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    19 tokens (    1.41 ms per token,   711.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    24 tokens (    1.14 ms per token,   873.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    26 tokens (    1.17 ms per token,   852.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    12 tokens (    2.24 ms per token,   446.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    21 tokens (    1.28 ms per token,   781.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    21 tokens (    1.28 ms per token,   778.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    16 tokens (    1.71 ms per token,   585.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    15 tokens (    1.82 ms per token,   548.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.58 ms /    34 tokens (    0.99 ms per token,  1012.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      67.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.01 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    27 tokens (    1.13 ms per token,   887.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.04 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    27 tokens (    1.12 ms per token,   890.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      80.50 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.24 ms /    25 tokens (    1.21 ms per token,   826.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.37 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    21 tokens (    1.28 ms per token,   778.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.38 ms /    32 tokens (    0.98 ms per token,  1019.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      82.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    13 tokens (    2.08 ms per token,   481.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.21 ms /     3 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.64 ms /    46 tokens (    0.80 ms per token,  1255.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      86.92 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      65.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   814.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      63.89 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    20 tokens (    1.34 ms per token,   745.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    25 tokens (    1.22 ms per token,   821.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.84 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    15 tokens (    1.83 ms per token,   546.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.80 ms /    35 tokens (    0.97 ms per token,  1035.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      67.51 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    14 tokens (    1.93 ms per token,   517.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    61.00 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    12 tokens (    2.23 ms per token,   449.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.38 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.19 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    22 tokens (    1.23 ms per token,   814.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.36 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    38 tokens (    0.90 ms per token,  1116.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      84.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    21 tokens (    1.28 ms per token,   781.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    22 tokens (    1.23 ms per token,   813.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    22 tokens (    1.22 ms per token,   819.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    13 tokens (    2.08 ms per token,   480.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.13 ms /    38 tokens (    0.90 ms per token,  1113.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      67.55 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    21 tokens (    1.28 ms per token,   782.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    12 tokens (    2.25 ms per token,   444.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.40 ms /    18 tokens (    1.47 ms per token,   681.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      59.58 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    20 tokens (    1.34 ms per token,   746.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    30 tokens (    1.03 ms per token,   968.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.13 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    21 tokens (    1.28 ms per token,   779.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.27 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    23 tokens (    1.18 ms per token,   846.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.19 ms /    25 tokens (    1.21 ms per token,   828.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.04 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.88 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    19 tokens (    1.40 ms per token,   715.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      59.94 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    25 tokens (    1.21 ms per token,   824.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    27 tokens (    1.13 ms per token,   885.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      81.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    11 tokens (    2.43 ms per token,   411.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    27 tokens (    1.13 ms per token,   887.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      81.40 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    13 tokens (    2.08 ms per token,   481.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.25 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    10 tokens (    2.66 ms per token,   376.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    28 tokens (    1.09 ms per token,   918.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      64.00 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17094.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    19 tokens (    1.41 ms per token,   711.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.76 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    20 tokens (    1.34 ms per token,   744.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      81.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.13 ms /    25 tokens (    1.21 ms per token,   829.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    17 tokens (    1.56 ms per token,   641.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    17 tokens (    1.56 ms per token,   639.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    15 tokens (    1.83 ms per token,   547.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    16 tokens (    1.71 ms per token,   585.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.23 ms /     3 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    27 tokens (    1.13 ms per token,   887.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      64.45 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    30 tokens (    1.03 ms per token,   974.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      64.44 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    27 tokens (    1.13 ms per token,   885.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.62 ms /    34 tokens (    0.99 ms per token,  1011.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      67.71 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    13 tokens (    2.08 ms per token,   480.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.76 ms /     2 runs   (   16.38 ms per token,    61.05 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.77 ms /     2 runs   (   16.39 ms per token,    61.03 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    26 tokens (    1.17 ms per token,   856.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   814.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    20 tokens (    1.34 ms per token,   744.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    23 tokens (    1.19 ms per token,   843.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    15 tokens (    1.83 ms per token,   546.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    14 tokens (    1.94 ms per token,   514.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    19 tokens (    1.41 ms per token,   711.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      76.81 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.45 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    17 tokens (    1.56 ms per token,   639.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    24 tokens (    1.14 ms per token,   879.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    21 tokens (    1.29 ms per token,   773.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    37 tokens (    0.92 ms per token,  1085.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      68.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      63.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.86 ms /    35 tokens (    0.97 ms per token,  1033.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      67.16 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    21 tokens (    1.28 ms per token,   779.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    27 tokens (    1.14 ms per token,   875.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.69 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      64.99 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.14 ms /    25 tokens (    1.21 ms per token,   829.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      81.09 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   743.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.39 ms /    38 tokens (    0.91 ms per token,  1104.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      84.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    19 tokens (    1.41 ms per token,   708.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    14 tokens (    1.95 ms per token,   513.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.93 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.84 ms /    27 tokens (    1.14 ms per token,   875.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.85 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.49 ms /    26 tokens (    1.17 ms per token,   852.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      80.57 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    15 tokens (    1.83 ms per token,   546.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.78 ms /     2 runs   (   16.39 ms per token,    61.01 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    30 tokens (    1.03 ms per token,   968.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.33 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    23 tokens (    1.20 ms per token,   833.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.70 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.03 ms /    30 tokens (    1.03 ms per token,   966.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      64.88 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    26 tokens (    1.17 ms per token,   854.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.96 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    26 tokens (    1.17 ms per token,   854.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      63.75 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    19 tokens (    1.42 ms per token,   705.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    16 tokens (    1.71 ms per token,   583.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.16 ms /    25 tokens (    1.21 ms per token,   828.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      80.76 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      63.72 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.78 ms /    28 tokens (    1.10 ms per token,   909.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.89 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    16 tokens (    1.70 ms per token,   587.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    11 tokens (    2.43 ms per token,   411.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    20 tokens (    1.34 ms per token,   746.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    28 tokens (    1.10 ms per token,   906.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.26 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    27 tokens (    1.13 ms per token,   882.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    21 tokens (    1.28 ms per token,   782.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    11 tokens (    2.43 ms per token,   411.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    28 tokens (    1.09 ms per token,   916.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.34 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    15 tokens (    1.84 ms per token,   544.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    28 tokens (    1.10 ms per token,   912.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    14 tokens (    1.93 ms per token,   516.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    23 tokens (    1.18 ms per token,   846.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.35 ms /    32 tokens (    0.98 ms per token,  1020.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.92 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    12 tokens (    2.25 ms per token,   444.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    22 tokens (    1.23 ms per token,   812.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    18 tokens (    1.48 ms per token,   675.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    18 tokens (    1.48 ms per token,   675.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    16 tokens (    1.71 ms per token,   584.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    19 tokens (    1.41 ms per token,   711.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    27 tokens (    1.14 ms per token,   876.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      64.15 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   822.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.24 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    23 tokens (    1.20 ms per token,   835.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    15 tokens (    1.83 ms per token,   547.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    18 tokens (    1.48 ms per token,   675.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.03 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    20 tokens (    1.34 ms per token,   746.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    18 tokens (    1.50 ms per token,   666.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    10 tokens (    2.68 ms per token,   373.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    27 tokens (    1.13 ms per token,   884.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.56 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    26 tokens (    1.17 ms per token,   855.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    22 tokens (    1.24 ms per token,   806.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.87 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.27 ms /    25 tokens (    1.21 ms per token,   826.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    14 tokens (    1.95 ms per token,   512.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    13 tokens (    2.09 ms per token,   478.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    19 tokens (    1.40 ms per token,   714.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   781.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      59.85 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    21 tokens (    1.29 ms per token,   772.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.92 ms /    27 tokens (    1.15 ms per token,   873.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      82.08 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.14 ms /    37 tokens (    0.92 ms per token,  1083.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      68.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16304.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.03 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    13 tokens (    2.09 ms per token,   477.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    19 tokens (    1.41 ms per token,   710.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    20 tokens (    1.34 ms per token,   746.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    20 tokens (    1.34 ms per token,   747.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.81 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    14 tokens (    1.94 ms per token,   514.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    20 tokens (    1.34 ms per token,   746.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    26 tokens (    1.17 ms per token,   853.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    29 tokens (    1.07 ms per token,   936.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.90 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    29 tokens (    1.07 ms per token,   937.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =      66.21 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.34 ms /    40 tokens (    0.86 ms per token,  1164.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      68.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    24 tokens (    1.14 ms per token,   875.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    40 tokens (    0.86 ms per token,  1160.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      68.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    29 tokens (    1.07 ms per token,   931.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      65.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    26 tokens (    1.17 ms per token,   851.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.21 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    17 tokens (    1.56 ms per token,   641.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   852.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    31 tokens (    1.00 ms per token,   995.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      82.21 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    15 tokens (    1.83 ms per token,   545.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      62.15 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    24 tokens (    1.14 ms per token,   879.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    17 tokens (    1.56 ms per token,   639.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.48 ms per token,   673.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      76.64 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    20 tokens (    1.36 ms per token,   733.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    29 tokens (    1.06 ms per token,   939.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.67 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    16 tokens (    1.71 ms per token,   584.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    35 tokens (    0.97 ms per token,  1032.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    20 tokens (    1.35 ms per token,   739.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    23 tokens (    1.19 ms per token,   838.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.21 ms /    31 tokens (    1.01 ms per token,   993.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      81.57 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    18 tokens (    1.48 ms per token,   675.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    17 tokens (    1.57 ms per token,   638.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    26 tokens (    1.17 ms per token,   857.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.10 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    15 tokens (    1.84 ms per token,   543.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    19 tokens (    1.41 ms per token,   710.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.03 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    18 tokens (    1.48 ms per token,   675.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    30 tokens (    1.03 ms per token,   966.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.17 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.30 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.37 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    15 tokens (    1.82 ms per token,   548.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    17 tokens (    1.56 ms per token,   639.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    31 tokens (    1.01 ms per token,   991.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      65.48 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    27 tokens (    1.13 ms per token,   882.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.03 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.25 ms /    25 tokens (    1.21 ms per token,   826.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.60 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.37 ms /    32 tokens (    0.98 ms per token,  1020.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      83.55 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.28 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    10 tokens (    2.66 ms per token,   375.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    19 tokens (    1.41 ms per token,   711.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      78.75 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    18 tokens (    1.48 ms per token,   677.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    21 tokens (    1.29 ms per token,   775.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    24 tokens (    1.15 ms per token,   873.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    30 tokens (    1.04 ms per token,   961.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.84 ms /    47 tokens (    0.78 ms per token,  1275.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      71.45 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    20 tokens (    1.36 ms per token,   735.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.82 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.60 ms /    33 tokens (    1.02 ms per token,   982.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      67.54 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    19 tokens (    1.42 ms per token,   704.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    12 tokens (    2.25 ms per token,   445.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    24 tokens (    1.14 ms per token,   878.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    13 tokens (    2.09 ms per token,   479.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    16 tokens (    1.71 ms per token,   584.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      78.19 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    17 tokens (    1.56 ms per token,   641.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    13 tokens (    2.09 ms per token,   479.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.29 ms /    32 tokens (    0.98 ms per token,  1022.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      82.05 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    22 tokens (    1.23 ms per token,   812.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.50 ms /    17 tokens (    1.56 ms per token,   641.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    13 tokens (    2.09 ms per token,   477.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    13 tokens (    2.08 ms per token,   479.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    15 tokens (    1.82 ms per token,   547.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.98 tokens per second)\n",
      "llama_print_timings:       total time =      60.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    30 tokens (    1.04 ms per token,   965.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      82.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    25 tokens (    1.21 ms per token,   825.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.00 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    27 tokens (    1.14 ms per token,   880.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.69 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    14 tokens (    1.95 ms per token,   513.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      65.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.19 ms /    25 tokens (    1.21 ms per token,   827.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      80.85 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.06 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    19 tokens (    1.42 ms per token,   703.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      65.00 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.63 ms /    24 tokens (    1.15 ms per token,   868.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      62.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.22 ms /    25 tokens (    1.21 ms per token,   827.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      63.92 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    11 tokens (    2.45 ms per token,   408.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    25 tokens (    1.22 ms per token,   817.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      80.90 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    20 tokens (    1.35 ms per token,   741.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    12 tokens (    2.24 ms per token,   445.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    28 tokens (    1.09 ms per token,   913.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.85 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    24 tokens (    1.14 ms per token,   879.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    23 tokens (    1.19 ms per token,   842.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   850.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.72 ms /     3 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      82.02 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    15 tokens (    1.83 ms per token,   546.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    19 tokens (    1.41 ms per token,   708.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.53 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    19 tokens (    1.41 ms per token,   709.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.24 ms /    25 tokens (    1.21 ms per token,   826.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      63.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.40 ms /    37 tokens (    0.93 ms per token,  1075.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      68.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    29 tokens (    1.06 ms per token,   939.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.33 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    19 tokens (    1.42 ms per token,   706.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    19 tokens (    1.41 ms per token,   707.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    17 tokens (    1.57 ms per token,   637.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    13 tokens (    2.10 ms per token,   476.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.85 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    25 tokens (    1.21 ms per token,   824.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      81.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    14 tokens (    1.94 ms per token,   514.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    26 tokens (    1.17 ms per token,   854.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.79 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   706.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     3 runs   (    0.07 ms per token, 14423.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    20 tokens (    1.36 ms per token,   735.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16736.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      79.36 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    11 tokens (    2.44 ms per token,   410.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    11 tokens (    2.43 ms per token,   412.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    15 tokens (    1.82 ms per token,   548.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      62.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    13 tokens (    2.09 ms per token,   478.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.29 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.19 ms /    25 tokens (    1.21 ms per token,   828.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      63.84 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    17 tokens (    1.57 ms per token,   636.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    22 tokens (    1.26 ms per token,   796.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.88 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    10 tokens (    2.67 ms per token,   374.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.04 ms /    30 tokens (    1.03 ms per token,   966.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      64.27 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   822.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   743.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    19 tokens (    1.41 ms per token,   707.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.40 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    11 tokens (    2.44 ms per token,   409.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.16 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    16 tokens (    1.71 ms per token,   583.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.78 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    26 tokens (    1.17 ms per token,   854.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    19 tokens (    1.40 ms per token,   713.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    26 tokens (    1.17 ms per token,   854.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.90 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    21 tokens (    1.29 ms per token,   778.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    32 tokens (    0.97 ms per token,  1025.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      65.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    18 tokens (    1.50 ms per token,   668.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    26 tokens (    1.17 ms per token,   854.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.68 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.04 ms /    30 tokens (    1.03 ms per token,   966.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      81.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    24 tokens (    1.14 ms per token,   877.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    18 tokens (    1.50 ms per token,   668.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    22 tokens (    1.24 ms per token,   805.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19900.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.36 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.24 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    12 tokens (    2.23 ms per token,   447.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      59.99 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    11 tokens (    2.44 ms per token,   409.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.13 ms /    47 tokens (    0.79 ms per token,  1265.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      71.64 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    31 tokens (    1.00 ms per token,   997.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      65.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    26 tokens (    1.18 ms per token,   847.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      81.47 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    20 tokens (    1.35 ms per token,   742.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   850.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.40 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    13 tokens (    2.10 ms per token,   476.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    10 tokens (    2.68 ms per token,   372.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   476.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    29 tokens (    1.07 ms per token,   936.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      65.18 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    15 tokens (    1.83 ms per token,   545.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.14 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    26 tokens (    1.17 ms per token,   854.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      80.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.64 ms /    33 tokens (    1.02 ms per token,   980.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.00 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    26 tokens (    1.17 ms per token,   853.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.51 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    10 tokens (    2.67 ms per token,   375.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.67 ms /     3 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      78.27 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    24 tokens (    1.14 ms per token,   877.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    11 tokens (    2.44 ms per token,   409.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    22 tokens (    1.23 ms per token,   814.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.40 ms /    32 tokens (    0.98 ms per token,  1019.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      65.02 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    23 tokens (    1.18 ms per token,   843.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      61.66 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.86 ms /    36 tokens (    0.94 ms per token,  1063.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      84.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    13 tokens (    2.11 ms per token,   474.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    16 tokens (    1.72 ms per token,   580.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    28 tokens (    1.10 ms per token,   910.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    22 tokens (    1.23 ms per token,   815.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    15 tokens (    1.84 ms per token,   542.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.87 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    13 tokens (    2.10 ms per token,   476.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    16 tokens (    1.71 ms per token,   583.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    19 tokens (    1.41 ms per token,   711.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.64 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    23 tokens (    1.18 ms per token,   844.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    21 tokens (    1.28 ms per token,   781.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.85 ms /    30 tokens (    1.03 ms per token,   972.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    13 tokens (    2.10 ms per token,   476.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    19 tokens (    1.42 ms per token,   706.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    16 tokens (    1.73 ms per token,   577.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.95 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.88 ms /    34 tokens (    1.00 ms per token,  1003.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      84.87 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    31 tokens (    1.01 ms per token,   994.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      65.23 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    11 tokens (    2.44 ms per token,   410.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    13 tokens (    2.09 ms per token,   478.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    11 tokens (    2.44 ms per token,   409.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.23 ms /    36 tokens (    0.95 ms per token,  1051.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      67.60 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    17 tokens (    1.57 ms per token,   636.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.68 ms /    41 tokens (    0.89 ms per token,  1117.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      87.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    33 tokens (    1.03 ms per token,   971.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.99 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    18 tokens (    1.48 ms per token,   676.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    19 tokens (    1.40 ms per token,   712.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    27 tokens (    1.13 ms per token,   881.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    14 tokens (    1.97 ms per token,   508.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    13 tokens (    2.10 ms per token,   476.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    25 tokens (    1.22 ms per token,   821.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    28 tokens (    1.10 ms per token,   911.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      80.99 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      64.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    23 tokens (    1.19 ms per token,   839.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    11 tokens (    2.46 ms per token,   407.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.21 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    18 tokens (    1.50 ms per token,   668.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    17 tokens (    1.58 ms per token,   633.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    22 tokens (    1.23 ms per token,   811.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   708.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    29 tokens (    1.06 ms per token,   939.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    26 tokens (    1.18 ms per token,   848.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      80.84 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 16000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    17 tokens (    1.57 ms per token,   637.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    28 tokens (    1.10 ms per token,   910.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.74 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.83 ms /    33 tokens (    1.03 ms per token,   975.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      68.08 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.82 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    10 tokens (    2.69 ms per token,   371.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    17 tokens (    1.58 ms per token,   633.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    25 tokens (    1.22 ms per token,   818.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      81.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    19 tokens (    1.42 ms per token,   703.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.24 ms per token,   809.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16304.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      62.23 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    14 tokens (    1.94 ms per token,   515.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.84 ms /    35 tokens (    0.97 ms per token,  1034.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.05 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    20 tokens (    1.35 ms per token,   740.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.40 ms /    38 tokens (    0.91 ms per token,  1104.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      68.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    23 tokens (    1.19 ms per token,   842.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    20 tokens (    1.35 ms per token,   738.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    17 tokens (    1.57 ms per token,   637.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   775.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    22 tokens (    1.23 ms per token,   811.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.77 ms /     3 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      79.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    26 tokens (    1.17 ms per token,   851.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.88 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   477.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    18 tokens (    1.49 ms per token,   672.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    19 tokens (    1.41 ms per token,   708.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    18 tokens (    1.48 ms per token,   674.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.09 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    28 tokens (    1.09 ms per token,   914.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.45 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   477.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      63.81 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 16260.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    25 tokens (    1.22 ms per token,   821.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    15 tokens (    1.83 ms per token,   547.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      62.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    24 tokens (    1.15 ms per token,   871.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    22 tokens (    1.23 ms per token,   810.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.52 ms /    17 tokens (    1.56 ms per token,   641.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.05 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    14 tokens (    1.98 ms per token,   506.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    24 tokens (    1.15 ms per token,   873.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.35 ms /    41 tokens (    0.89 ms per token,  1127.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      86.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    30 tokens (    1.03 ms per token,   969.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.89 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    11 tokens (    2.45 ms per token,   408.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    15 tokens (    1.84 ms per token,   542.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    40 tokens (    0.86 ms per token,  1161.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      68.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    26 tokens (    1.18 ms per token,   850.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    23 tokens (    1.19 ms per token,   840.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.57 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    14 tokens (    1.95 ms per token,   513.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    30 tokens (    1.03 ms per token,   969.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      65.30 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.70 ms /    24 tokens (    1.15 ms per token,   866.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.27 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.64 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15789.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    27 tokens (    1.13 ms per token,   882.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      64.88 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    19 tokens (    1.40 ms per token,   714.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    35 tokens (    0.97 ms per token,  1030.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      67.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    20 tokens (    1.35 ms per token,   742.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.86 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.07 ms per token,   938.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      82.52 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.03 ms /    36 tokens (    0.95 ms per token,  1057.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      68.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    17 tokens (    1.56 ms per token,   641.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      59.82 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    27 tokens (    1.13 ms per token,   883.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.25 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    11 tokens (    2.46 ms per token,   406.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    20 tokens (    1.34 ms per token,   744.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    23 tokens (    1.19 ms per token,   842.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.74 ms /     3 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.49 ms per token,   673.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.72 ms /    33 tokens (    1.02 ms per token,   978.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.27 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    37 tokens (    0.92 ms per token,  1084.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      67.83 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    26 tokens (    1.18 ms per token,   848.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.42 ms /    38 tokens (    0.91 ms per token,  1103.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      85.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    24 tokens (    1.15 ms per token,   869.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    27 tokens (    1.14 ms per token,   875.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      65.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.78 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    28 tokens (    1.10 ms per token,   905.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      64.38 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    24 tokens (    1.15 ms per token,   868.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.55 ms /    39 tokens (    0.89 ms per token,  1128.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    13 tokens (    2.09 ms per token,   478.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    28 tokens (    1.09 ms per token,   915.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      63.94 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    13 tokens (    2.10 ms per token,   477.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.18 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    20 tokens (    1.35 ms per token,   738.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    30 tokens (    1.03 ms per token,   968.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.32 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    21 tokens (    1.28 ms per token,   781.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    26 tokens (    1.17 ms per token,   854.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      63.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    12 tokens (    2.26 ms per token,   442.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    27 tokens (    1.13 ms per token,   881.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.35 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.45 ms /    17 tokens (    1.56 ms per token,   642.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      59.82 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    19 tokens (    1.41 ms per token,   710.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      59.85 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.78 ms /    28 tokens (    1.10 ms per token,   909.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      65.17 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    28 tokens (    1.09 ms per token,   919.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.39 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.23 ms per token,   809.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    37 tokens (    0.92 ms per token,  1083.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      67.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    24 tokens (    1.15 ms per token,   871.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      79.44 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.14 ms /    31 tokens (    1.00 ms per token,   995.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    14 tokens (    1.95 ms per token,   512.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.23 ms /    25 tokens (    1.21 ms per token,   826.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      63.57 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    20 tokens (    1.35 ms per token,   739.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    19 tokens (    1.42 ms per token,   702.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.28 ms /    37 tokens (    0.93 ms per token,  1079.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      67.89 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    19 tokens (    1.41 ms per token,   708.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    28 tokens (    1.10 ms per token,   911.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.00 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /     9 tokens (    2.98 ms per token,   336.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    24 tokens (    1.14 ms per token,   878.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.41 ms /    32 tokens (    0.98 ms per token,  1018.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.77 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    27 tokens (    1.13 ms per token,   882.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   707.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    15 tokens (    1.83 ms per token,   545.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      62.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      63.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15789.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    19 tokens (    1.41 ms per token,   708.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    30 tokens (    1.03 ms per token,   971.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.46 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.79 ms /    15 tokens (    1.85 ms per token,   539.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.75 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    22 tokens (    1.24 ms per token,   805.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    16 tokens (    1.72 ms per token,   581.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    29 tokens (    1.07 ms per token,   937.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.99 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      63.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    15 tokens (    1.83 ms per token,   545.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    10 tokens (    2.67 ms per token,   374.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      63.85 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    27 tokens (    1.13 ms per token,   882.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      81.45 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    10 tokens (    2.67 ms per token,   375.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    19 tokens (    1.41 ms per token,   710.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    24 tokens (    1.14 ms per token,   875.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      62.51 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    16 tokens (    1.71 ms per token,   583.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.55 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    21 tokens (    1.29 ms per token,   777.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    25 tokens (    1.23 ms per token,   815.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.70 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.07 ms per token,   938.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.78 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    21 tokens (    1.30 ms per token,   770.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    15 tokens (    1.84 ms per token,   542.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    10 tokens (    2.68 ms per token,   373.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    21 tokens (    1.29 ms per token,   777.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    22 tokens (    1.23 ms per token,   810.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.36 ms /    32 tokens (    0.98 ms per token,  1020.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      82.22 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    32 tokens (    0.97 ms per token,  1026.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.66 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.72 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    12 tokens (    2.24 ms per token,   445.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.03 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    20 tokens (    1.35 ms per token,   743.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.39 ms /    39 tokens (    0.88 ms per token,  1134.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      67.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    15 tokens (    1.84 ms per token,   542.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    55 tokens (    0.79 ms per token,  1258.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.60 ms /     2 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    16 tokens (    1.72 ms per token,   581.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.54 ms /    40 tokens (    0.86 ms per token,  1158.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      85.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    16 tokens (    1.72 ms per token,   581.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    22 tokens (    1.24 ms per token,   804.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    26 tokens (    1.17 ms per token,   854.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      80.91 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    18 tokens (    1.50 ms per token,   668.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   814.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    13 tokens (    2.09 ms per token,   478.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    17 tokens (    1.56 ms per token,   640.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.00 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    19 tokens (    1.41 ms per token,   708.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    19 tokens (    1.41 ms per token,   707.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    15 tokens (    1.83 ms per token,   545.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    22 tokens (    1.24 ms per token,   808.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.22 ms /    36 tokens (    0.95 ms per token,  1052.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =      68.38 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    17 tokens (    1.57 ms per token,   638.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.28 ms /    37 tokens (    0.93 ms per token,  1079.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      68.09 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    15 tokens (    1.83 ms per token,   545.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    18 tokens (    1.48 ms per token,   675.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    26 tokens (    1.18 ms per token,   847.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      65.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.82 ms /    16 tokens (    1.74 ms per token,   575.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.66 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    13 tokens (    2.10 ms per token,   477.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.95 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    22 tokens (    1.23 ms per token,   811.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      61.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    22 tokens (    1.23 ms per token,   815.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    23 tokens (    1.19 ms per token,   841.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    24 tokens (    1.15 ms per token,   869.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.53 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.85 ms /    28 tokens (    1.10 ms per token,   907.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      65.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    24 tokens (    1.14 ms per token,   876.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.66 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    24 tokens (    1.14 ms per token,   875.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    29 tokens (    1.07 ms per token,   938.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.73 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.32 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    28 tokens (    1.11 ms per token,   904.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      82.02 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.79 ms /    33 tokens (    1.02 ms per token,   976.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      67.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    30 tokens (    1.03 ms per token,   967.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.57 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    21 tokens (    1.30 ms per token,   771.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    23 tokens (    1.20 ms per token,   834.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    15 tokens (    1.84 ms per token,   542.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    17 tokens (    1.58 ms per token,   632.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    25 tokens (    1.21 ms per token,   823.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      80.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    12 tokens (    2.25 ms per token,   444.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    19 tokens (    1.40 ms per token,   712.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.27 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    15 tokens (    1.84 ms per token,   543.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      79.02 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.48 ms /    43 tokens (    0.85 ms per token,  1178.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      69.93 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    12 tokens (    2.25 ms per token,   445.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.80 ms /    27 tokens (    1.14 ms per token,   876.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      82.17 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    23 tokens (    1.18 ms per token,   844.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    28 tokens (    1.10 ms per token,   911.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.71 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      79.16 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    26 tokens (    1.19 ms per token,   841.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.06 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.53 ms /    40 tokens (    0.86 ms per token,  1158.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      85.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16042.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.90 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   477.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   677.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.85 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    30 tokens (    1.04 ms per token,   961.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    34 tokens (    1.00 ms per token,  1000.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      67.52 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    11 tokens (    2.45 ms per token,   408.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15706.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.81 ms /    33 tokens (    1.02 ms per token,   976.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      67.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   634.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    20 tokens (    1.35 ms per token,   740.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 16064.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    28 tokens (    1.10 ms per token,   908.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      82.11 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    17 tokens (    1.56 ms per token,   639.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    31 tokens (    1.01 ms per token,   994.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      65.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    11 tokens (    2.45 ms per token,   408.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    11 tokens (    2.44 ms per token,   409.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   707.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   822.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.12 ms /    37 tokens (    0.92 ms per token,  1084.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      67.55 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.04 ms /    35 tokens (    0.97 ms per token,  1028.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      67.57 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    21 tokens (    1.29 ms per token,   774.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.88 ms /    33 tokens (    1.03 ms per token,   974.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      68.33 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    21 tokens (    1.30 ms per token,   769.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    15 tokens (    1.84 ms per token,   544.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    20 tokens (    1.35 ms per token,   740.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    29 tokens (    1.08 ms per token,   929.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      82.51 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    18 tokens (    1.48 ms per token,   674.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    18 tokens (    1.48 ms per token,   674.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.13 ms /    48 tokens (    0.77 ms per token,  1292.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      88.06 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.93 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    20 tokens (    1.34 ms per token,   744.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    28 tokens (    1.10 ms per token,   909.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.54 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    32 tokens (    0.97 ms per token,  1026.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   837.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    25 tokens (    1.22 ms per token,   817.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.32 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    16 tokens (    1.71 ms per token,   583.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    23 tokens (    1.20 ms per token,   835.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.99 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    31 tokens (    1.01 ms per token,   994.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.56 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   838.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    14 tokens (    1.96 ms per token,   510.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.75 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.47 ms /    26 tokens (    1.17 ms per token,   853.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    13 tokens (    2.09 ms per token,   479.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.21 ms /    25 tokens (    1.21 ms per token,   827.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.32 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    19 tokens (    1.42 ms per token,   703.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    11 tokens (    2.44 ms per token,   409.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.27 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.09 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    37 tokens (    0.92 ms per token,  1084.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      67.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    22 tokens (    1.23 ms per token,   812.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      81.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    17 tokens (    1.58 ms per token,   631.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    15 tokens (    1.85 ms per token,   541.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    19 tokens (    1.41 ms per token,   708.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.47 ms /    26 tokens (    1.17 ms per token,   853.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      82.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    20 tokens (    1.34 ms per token,   747.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    11 tokens (    2.45 ms per token,   408.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    10 tokens (    2.68 ms per token,   373.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    33 tokens (    1.03 ms per token,   971.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.56 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    12 tokens (    2.25 ms per token,   445.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    30 tokens (    1.04 ms per token,   963.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      65.23 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    26 tokens (    1.18 ms per token,   847.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    14 tokens (    1.94 ms per token,   516.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    17 tokens (    1.56 ms per token,   641.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      76.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    24 tokens (    1.14 ms per token,   874.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      62.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.68 ms /    33 tokens (    1.02 ms per token,   979.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      84.52 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    12 tokens (    2.26 ms per token,   442.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    22 tokens (    1.24 ms per token,   807.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    19 tokens (    1.41 ms per token,   710.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    14 tokens (    1.96 ms per token,   510.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.58 ms /    38 tokens (    0.91 ms per token,  1098.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      85.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      81.12 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      62.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    23 tokens (    1.18 ms per token,   847.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    18 tokens (    1.48 ms per token,   675.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    21 tokens (    1.29 ms per token,   777.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16216.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   823.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      64.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.23 ms per token,   809.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    24 tokens (    1.14 ms per token,   874.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    30 tokens (    1.04 ms per token,   965.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.83 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    32 tokens (    0.98 ms per token,  1022.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.00 ms /    34 tokens (    1.00 ms per token,  1000.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      67.67 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    26 tokens (    1.18 ms per token,   848.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.67 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    24 tokens (    1.14 ms per token,   877.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      79.05 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    27 tokens (    1.13 ms per token,   884.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.44 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.85 ms /    27 tokens (    1.14 ms per token,   875.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =      66.15 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.40 ms /    43 tokens (    0.85 ms per token,  1181.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      70.51 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    20 tokens (    1.36 ms per token,   737.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.34 ms /    32 tokens (    0.98 ms per token,  1020.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      82.04 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    24 tokens (    1.15 ms per token,   871.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      78.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.61 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    29 tokens (    1.06 ms per token,   943.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.87 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.47 ms /    32 tokens (    0.98 ms per token,  1016.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      65.40 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    22 tokens (    1.24 ms per token,   805.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    36 tokens (    0.94 ms per token,  1058.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      68.07 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    20 tokens (    1.36 ms per token,   737.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    23 tokens (    1.19 ms per token,   841.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    16 tokens (    1.71 ms per token,   584.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    18 tokens (    1.48 ms per token,   674.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    20 tokens (    1.35 ms per token,   738.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    13 tokens (    2.09 ms per token,   478.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.68 ms /     3 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      78.76 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   742.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      80.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    15 tokens (    1.83 ms per token,   546.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    20 tokens (    1.34 ms per token,   743.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    20 tokens (    1.35 ms per token,   738.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.61 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    23 tokens (    1.19 ms per token,   842.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    38 tokens (    0.90 ms per token,  1114.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      68.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    24 tokens (    1.15 ms per token,   871.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.77 ms /    33 tokens (    1.02 ms per token,   977.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      68.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    24 tokens (    1.15 ms per token,   872.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    16 tokens (    1.72 ms per token,   581.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.80 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    31 tokens (    1.01 ms per token,   994.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.67 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    14 tokens (    1.94 ms per token,   515.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.67 ms /    33 tokens (    1.02 ms per token,   980.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.91 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    15 tokens (    1.84 ms per token,   542.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    18 tokens (    1.49 ms per token,   669.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    12 tokens (    2.25 ms per token,   445.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.56 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.44 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    13 tokens (    2.09 ms per token,   478.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.48 ms per token,   673.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    17 tokens (    1.56 ms per token,   639.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.86 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    23 tokens (    1.18 ms per token,   845.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    15 tokens (    1.85 ms per token,   541.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.23 ms /    30 tokens (    1.04 ms per token,   960.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      82.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    20 tokens (    1.34 ms per token,   747.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    28 tokens (    1.10 ms per token,   910.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      81.46 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    12 tokens (    2.24 ms per token,   446.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.01 ms /    35 tokens (    0.97 ms per token,  1029.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.33 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.90 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    17 tokens (    1.57 ms per token,   635.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.93 ms /    15 tokens (    1.86 ms per token,   537.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   853.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    24 tokens (    1.15 ms per token,   872.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.96 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.54 ms /    17 tokens (    1.56 ms per token,   640.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    27 tokens (    1.14 ms per token,   880.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      65.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.49 ms /    40 tokens (    0.86 ms per token,  1159.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      68.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    12 tokens (    2.26 ms per token,   442.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    17 tokens (    1.58 ms per token,   634.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =      62.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    23 tokens (    1.18 ms per token,   844.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.85 ms /    29 tokens (    1.06 ms per token,   940.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    35 tokens (    0.97 ms per token,  1026.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      84.58 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    19 tokens (    1.42 ms per token,   701.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    22 tokens (    1.24 ms per token,   803.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    31 tokens (    1.00 ms per token,  1000.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    22 tokens (    1.24 ms per token,   803.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.49 ms /    25 tokens (    1.22 ms per token,   819.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      80.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    16 tokens (    1.73 ms per token,   579.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    37 tokens (    0.92 ms per token,  1083.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.43 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    21 tokens (    1.29 ms per token,   778.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    27 tokens (    1.13 ms per token,   881.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    33 tokens (    1.02 ms per token,   976.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   545.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    22 tokens (    1.23 ms per token,   814.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.76 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    26 tokens (    1.17 ms per token,   852.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      64.92 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.78 ms /    16 tokens (    1.74 ms per token,   575.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   477.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.78 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      62.01 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    19 tokens (    1.40 ms per token,   714.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      76.86 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.73 ms per token,   579.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.23 ms per token,   809.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    23 tokens (    1.20 ms per token,   833.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.81 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.38 ms /    43 tokens (    0.85 ms per token,  1182.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      87.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.44 ms /    32 tokens (    0.98 ms per token,  1017.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      82.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.35 ms /    38 tokens (    0.90 ms per token,  1106.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      69.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    23 tokens (    1.19 ms per token,   840.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    22 tokens (    1.24 ms per token,   806.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   777.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.39 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    20 tokens (    1.34 ms per token,   746.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.27 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.78 ms /    27 tokens (    1.14 ms per token,   877.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      64.70 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    19 tokens (    1.42 ms per token,   704.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.38 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    22 tokens (    1.24 ms per token,   803.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.59 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    13 tokens (    2.09 ms per token,   478.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.84 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.12 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    19 tokens (    1.41 ms per token,   708.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    16 tokens (    1.71 ms per token,   583.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    15 tokens (    1.83 ms per token,   547.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    17 tokens (    1.59 ms per token,   627.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.33 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   636.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.73 ms /    15 tokens (    1.85 ms per token,   540.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      62.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    10 tokens (    2.67 ms per token,   374.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    15 tokens (    1.83 ms per token,   545.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      78.58 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    23 tokens (    1.20 ms per token,   834.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    27 tokens (    1.14 ms per token,   880.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    20 tokens (    1.36 ms per token,   734.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.63 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    25 tokens (    1.22 ms per token,   821.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.20 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.76 ms /    33 tokens (    1.02 ms per token,   977.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      85.52 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    22 tokens (    1.24 ms per token,   809.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    24 tokens (    1.15 ms per token,   872.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    17 tokens (    1.57 ms per token,   637.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.13 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.50 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    20 tokens (    1.35 ms per token,   742.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.72 ms /     3 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      78.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    23 tokens (    1.19 ms per token,   840.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    28 tokens (    1.11 ms per token,   903.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      82.11 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    14 tokens (    1.95 ms per token,   514.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    22 tokens (    1.23 ms per token,   811.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    14 tokens (    1.96 ms per token,   510.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    11 tokens (    2.46 ms per token,   406.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.40 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    26 tokens (    1.17 ms per token,   852.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.47 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    11 tokens (    2.44 ms per token,   410.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    10 tokens (    2.68 ms per token,   373.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    22 tokens (    1.24 ms per token,   808.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      62.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   781.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    16 tokens (    1.71 ms per token,   585.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.49 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.32 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    16 tokens (    1.72 ms per token,   581.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   513.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      62.30 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    19 tokens (    1.40 ms per token,   715.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      76.92 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    26 tokens (    1.17 ms per token,   854.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      63.83 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    25 tokens (    1.22 ms per token,   820.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.36 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   822.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      82.08 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.93 ms /    34 tokens (    1.00 ms per token,  1002.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      68.07 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    29 tokens (    1.08 ms per token,   929.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.31 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    19 tokens (    1.42 ms per token,   705.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    21 tokens (    1.29 ms per token,   774.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.51 ms /    42 tokens (    0.87 ms per token,  1150.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      70.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.96 ms /    40 tokens (    0.87 ms per token,  1144.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      68.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    13 tokens (    2.10 ms per token,   475.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.58 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    22 tokens (    1.23 ms per token,   814.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    17 tokens (    1.59 ms per token,   629.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    27 tokens (    1.13 ms per token,   883.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.40 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    26 tokens (    1.18 ms per token,   849.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    16 tokens (    1.72 ms per token,   581.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.92 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    21 tokens (    1.28 ms per token,   782.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.71 ms /    16 tokens (    1.73 ms per token,   577.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.71 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    29 tokens (    1.07 ms per token,   937.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.17 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    26 tokens (    1.17 ms per token,   851.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.22 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.82 ms /    15 tokens (    1.85 ms per token,   539.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    12 tokens (    2.23 ms per token,   447.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.38 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    23 tokens (    1.18 ms per token,   845.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      78.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.23 ms /    25 tokens (    1.21 ms per token,   826.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      80.90 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.95 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    21 tokens (    1.29 ms per token,   774.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    38 tokens (    0.90 ms per token,  1105.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      68.81 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    20 tokens (    1.34 ms per token,   743.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    34 tokens (    1.00 ms per token,   999.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    25 tokens (    1.25 ms per token,   802.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      65.43 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.58 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    24 tokens (    1.14 ms per token,   873.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      79.07 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    13 tokens (    2.09 ms per token,   479.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    19 tokens (    1.41 ms per token,   711.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    25 tokens (    1.22 ms per token,   819.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.61 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.80 ms /    24 tokens (    1.16 ms per token,   863.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      62.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    19 tokens (    1.41 ms per token,   707.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    16 tokens (    1.70 ms per token,   586.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    34 tokens (    1.00 ms per token,  1000.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      68.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   850.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.09 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    13 tokens (    2.09 ms per token,   477.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    29 tokens (    1.07 ms per token,   937.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.79 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    12 tokens (    2.27 ms per token,   439.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      63.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    20 tokens (    1.35 ms per token,   741.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.18 ms /     2 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    10 tokens (    2.66 ms per token,   375.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.38 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    23 tokens (    1.19 ms per token,   843.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    20 tokens (    1.35 ms per token,   740.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    11 tokens (    2.44 ms per token,   410.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    11 tokens (    2.46 ms per token,   407.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.57 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    14 tokens (    1.96 ms per token,   509.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.69 ms /    15 tokens (    1.85 ms per token,   541.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.24 ms /    25 tokens (    1.21 ms per token,   826.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    21 tokens (    1.31 ms per token,   761.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      79.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    31 tokens (    1.01 ms per token,   991.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.21 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.37 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.98 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    19 tokens (    1.42 ms per token,   705.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.35 ms /    31 tokens (    1.01 ms per token,   988.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.95 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    26 tokens (    1.18 ms per token,   847.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      64.96 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.80 ms /    34 tokens (    0.99 ms per token,  1005.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    14 tokens (    1.96 ms per token,   509.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.09 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    12 tokens (    2.24 ms per token,   445.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    16 tokens (    1.72 ms per token,   580.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    20 tokens (    1.35 ms per token,   743.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.52 ms /    40 tokens (    0.86 ms per token,  1158.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      69.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.78 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    14 tokens (    1.97 ms per token,   507.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    12 tokens (    2.24 ms per token,   445.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    24 tokens (    1.14 ms per token,   880.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.58 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    27 tokens (    1.14 ms per token,   878.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    18 tokens (    1.49 ms per token,   672.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    28 tokens (    1.09 ms per token,   914.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    24 tokens (    1.14 ms per token,   878.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    22 tokens (    1.24 ms per token,   805.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    15 tokens (    1.84 ms per token,   542.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      62.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    19 tokens (    1.41 ms per token,   707.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    30 tokens (    1.04 ms per token,   963.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      82.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    24 tokens (    1.15 ms per token,   872.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    20 tokens (    1.37 ms per token,   730.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      81.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.52 ms /    17 tokens (    1.56 ms per token,   641.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    24 tokens (    1.15 ms per token,   871.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    23 tokens (    1.20 ms per token,   833.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    31 tokens (    1.01 ms per token,   991.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.60 ms per token,    60.23 tokens per second)\n",
      "llama_print_timings:       total time =      65.97 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    29 tokens (    1.06 ms per token,   939.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    13 tokens (    2.10 ms per token,   476.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.26 ms /     3 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    27 tokens (    1.14 ms per token,   876.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      65.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      65.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    30 tokens (    1.03 ms per token,   971.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    21 tokens (    1.30 ms per token,   771.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    25 tokens (    1.22 ms per token,   817.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      64.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.48 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      64.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.92 ms /    34 tokens (    1.00 ms per token,  1002.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      67.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      81.39 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.59 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.70 ms /    16 tokens (    1.73 ms per token,   577.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    17 tokens (    1.57 ms per token,   636.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    30 tokens (    1.03 ms per token,   969.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.17 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.38 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    24 tokens (    1.14 ms per token,   876.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    12 tokens (    2.25 ms per token,   444.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.36 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.39 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    19 tokens (    1.43 ms per token,   698.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    26 tokens (    1.17 ms per token,   857.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      63.82 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    19 tokens (    1.42 ms per token,   705.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.76 ms /    27 tokens (    1.14 ms per token,   877.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      82.11 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    23 tokens (    1.19 ms per token,   841.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   822.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     3 runs   (    0.07 ms per token, 15228.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    13 tokens (    2.11 ms per token,   473.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      62.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    19 tokens (    1.41 ms per token,   708.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    28 tokens (    1.10 ms per token,   907.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      81.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    20 tokens (    1.35 ms per token,   739.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.46 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      64.40 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.17 ms /    25 tokens (    1.21 ms per token,   828.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    18 tokens (    1.51 ms per token,   663.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    22 tokens (    1.24 ms per token,   806.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    24 tokens (    1.14 ms per token,   874.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    26 tokens (    1.17 ms per token,   852.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.29 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    16 tokens (    1.71 ms per token,   583.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    12 tokens (    2.24 ms per token,   446.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    25 tokens (    1.22 ms per token,   817.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.57 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    25 tokens (    1.23 ms per token,   814.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    13 tokens (    2.09 ms per token,   478.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    28 tokens (    1.10 ms per token,   912.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    19 tokens (    1.42 ms per token,   706.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.30 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    22 tokens (    1.24 ms per token,   807.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    11 tokens (    2.44 ms per token,   409.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    24 tokens (    1.14 ms per token,   879.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    20 tokens (    1.37 ms per token,   732.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    24 tokens (    1.15 ms per token,   869.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    10 tokens (    2.67 ms per token,   374.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.10 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      64.99 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    33 tokens (    1.03 ms per token,   973.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.79 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    21 tokens (    1.29 ms per token,   772.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    27 tokens (    1.14 ms per token,   879.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      62.27 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.68 ms /     3 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      79.08 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    21 tokens (    1.28 ms per token,   779.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    22 tokens (    1.23 ms per token,   811.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    23 tokens (    1.20 ms per token,   833.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.24 ms per token,   809.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    17 tokens (    1.58 ms per token,   634.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    31 tokens (    1.00 ms per token,   995.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    29 tokens (    1.07 ms per token,   936.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      81.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.49 ms per token,   673.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    25 tokens (    1.23 ms per token,   814.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      65.27 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    22 tokens (    1.22 ms per token,   816.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    20 tokens (    1.35 ms per token,   739.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    15 tokens (    1.84 ms per token,   543.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      79.34 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    34 tokens (    1.00 ms per token,  1000.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      67.97 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    25 tokens (    1.22 ms per token,   821.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.24 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.37 ms /    49 tokens (    0.86 ms per token,  1156.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      76.61 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    25 tokens (    1.21 ms per token,   823.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.14 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.43 ms /    31 tokens (    1.01 ms per token,   986.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      82.68 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    11 tokens (    2.45 ms per token,   407.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.06 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 17021.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    15 tokens (    1.83 ms per token,   547.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    16 tokens (    1.72 ms per token,   582.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    16 tokens (    1.73 ms per token,   577.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      62.33 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    20 tokens (    1.34 ms per token,   743.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    27 tokens (    1.13 ms per token,   881.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.59 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.32 ms /    32 tokens (    0.98 ms per token,  1021.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.70 ms /     3 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      82.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    15 tokens (    1.85 ms per token,   541.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.67 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.86 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    28 tokens (    1.10 ms per token,   912.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.93 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    24 tokens (    1.15 ms per token,   871.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    11 tokens (    2.45 ms per token,   408.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    17 tokens (    1.57 ms per token,   637.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    11 tokens (    2.43 ms per token,   411.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    17 tokens (    1.57 ms per token,   638.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    15 tokens (    1.85 ms per token,   540.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    31 tokens (    1.01 ms per token,   990.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      65.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    23 tokens (    1.19 ms per token,   842.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      79.16 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    18 tokens (    1.48 ms per token,   675.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    16 tokens (    1.71 ms per token,   584.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   708.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.73 ms per token,   579.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    11 tokens (    2.45 ms per token,   407.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.59 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    26 tokens (    1.18 ms per token,   845.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      65.16 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.48 ms /    49 tokens (    0.87 ms per token,  1153.62 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      76.11 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17094.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    21 tokens (    1.31 ms per token,   763.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      79.11 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    21 tokens (    1.28 ms per token,   779.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    13 tokens (    2.09 ms per token,   478.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    18 tokens (    1.50 ms per token,   668.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    38 tokens (    0.90 ms per token,  1105.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      68.92 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    40 tokens (    0.86 ms per token,  1166.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      84.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    27 tokens (    1.14 ms per token,   878.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.72 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    16 tokens (    1.72 ms per token,   583.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    18 tokens (    1.48 ms per token,   676.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.78 ms /    16 tokens (    1.74 ms per token,   575.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    27 tokens (    1.14 ms per token,   879.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    12 tokens (    2.27 ms per token,   440.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =      62.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    12 tokens (    2.23 ms per token,   447.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.26 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    24 tokens (    1.15 ms per token,   867.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.62 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    11 tokens (    2.44 ms per token,   409.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    30 tokens (    1.04 ms per token,   965.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.84 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    21 tokens (    1.29 ms per token,   772.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    23 tokens (    1.19 ms per token,   839.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.77 ms /    15 tokens (    1.85 ms per token,   540.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    27 tokens (    1.14 ms per token,   880.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.00 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    17 tokens (    1.57 ms per token,   635.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.59 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.09 ms /    30 tokens (    1.04 ms per token,   965.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      82.06 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    19 tokens (    1.43 ms per token,   701.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    16 tokens (    1.71 ms per token,   584.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    12 tokens (    2.28 ms per token,   439.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    10 tokens (    2.68 ms per token,   373.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    18 tokens (    1.49 ms per token,   670.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    27 tokens (    1.14 ms per token,   880.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      65.35 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    19 tokens (    1.41 ms per token,   711.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    18 tokens (    1.48 ms per token,   675.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    13 tokens (    2.10 ms per token,   476.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    17 tokens (    1.57 ms per token,   635.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    26 tokens (    1.17 ms per token,   852.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      80.75 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    22 tokens (    1.24 ms per token,   804.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    16 tokens (    1.73 ms per token,   579.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.55 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    29 tokens (    1.07 ms per token,   938.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    17 tokens (    1.60 ms per token,   626.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.62 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   780.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    19 tokens (    1.41 ms per token,   710.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.25 ms /    25 tokens (    1.21 ms per token,   826.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      63.88 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    18 tokens (    1.49 ms per token,   668.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    25 tokens (    1.22 ms per token,   821.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      63.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     4 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    16 tokens (    1.73 ms per token,   577.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      79.13 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    29 tokens (    1.07 ms per token,   934.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.35 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17094.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    25 tokens (    1.23 ms per token,   815.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    16 tokens (    1.72 ms per token,   581.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    26 tokens (    1.17 ms per token,   852.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.66 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    18 tokens (    1.48 ms per token,   676.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.33 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.68 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    20 tokens (    1.37 ms per token,   731.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.86 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    22 tokens (    1.23 ms per token,   812.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    30 tokens (    1.04 ms per token,   963.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      65.59 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.33 ms /    32 tokens (    0.98 ms per token,  1021.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.24 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    35 tokens (    0.97 ms per token,  1029.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      67.83 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    17 tokens (    1.57 ms per token,   637.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    14 tokens (    1.97 ms per token,   506.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      78.24 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16736.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    13 tokens (    2.10 ms per token,   475.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    23 tokens (    1.19 ms per token,   842.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    13 tokens (    2.09 ms per token,   478.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    19 tokens (    1.41 ms per token,   710.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.24 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    33 tokens (    1.04 ms per token,   963.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      68.63 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    23 tokens (    1.18 ms per token,   846.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.43 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    32 tokens (    0.98 ms per token,  1023.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      64.98 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.18 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    23 tokens (    1.19 ms per token,   842.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.37 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    24 tokens (    1.15 ms per token,   870.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      62.13 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    10 tokens (    2.66 ms per token,   375.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    19 tokens (    1.41 ms per token,   709.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    25 tokens (    1.22 ms per token,   817.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      81.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.65 ms /    40 tokens (    0.87 ms per token,  1154.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      69.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    24 tokens (    1.15 ms per token,   869.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      62.35 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    23 tokens (    1.19 ms per token,   837.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    22 tokens (    1.25 ms per token,   800.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.80 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    15 tokens (    1.84 ms per token,   544.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.88 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    19 tokens (    1.43 ms per token,   700.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    23 tokens (    1.18 ms per token,   845.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    27 tokens (    1.13 ms per token,   882.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    18 tokens (    1.50 ms per token,   667.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    19 tokens (    1.42 ms per token,   705.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      76.98 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.01 ms /    28 tokens (    1.11 ms per token,   902.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    18 tokens (    1.48 ms per token,   677.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.85 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    22 tokens (    1.25 ms per token,   797.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    11 tokens (    2.45 ms per token,   407.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    16 tokens (    1.71 ms per token,   583.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    16 tokens (    1.71 ms per token,   584.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      61.95 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    14 tokens (    1.95 ms per token,   511.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    14 tokens (    1.96 ms per token,   509.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      62.01 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    19 tokens (    1.41 ms per token,   708.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    11 tokens (    2.44 ms per token,   410.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   809.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    17 tokens (    1.56 ms per token,   640.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.07 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    19 tokens (    1.42 ms per token,   706.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    22 tokens (    1.24 ms per token,   806.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   707.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   634.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    25 tokens (    1.22 ms per token,   820.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      64.03 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    31 tokens (    1.01 ms per token,   994.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      65.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    20 tokens (    1.36 ms per token,   733.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    22 tokens (    1.24 ms per token,   805.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    14 tokens (    1.97 ms per token,   508.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    26 tokens (    1.18 ms per token,   846.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.46 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    30 tokens (    1.04 ms per token,   964.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      65.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    21 tokens (    1.30 ms per token,   770.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    26 tokens (    1.17 ms per token,   852.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.28 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.48 ms per token,   673.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    14 tokens (    1.95 ms per token,   513.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    21 tokens (    1.29 ms per token,   773.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      78.49 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    12 tokens (    2.25 ms per token,   444.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    25 tokens (    1.21 ms per token,   824.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.13 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.86 ms /    16 tokens (    1.74 ms per token,   574.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.88 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.54 ms /    40 tokens (    0.86 ms per token,  1158.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.32 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    26 tokens (    1.18 ms per token,   846.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      65.21 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    22 tokens (    1.24 ms per token,   805.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.59 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.80 ms /     2 runs   (   16.40 ms per token,    60.97 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.76 ms /    28 tokens (    1.10 ms per token,   910.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.35 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    22 tokens (    1.23 ms per token,   815.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    37 tokens (    0.92 ms per token,  1083.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.08 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    29 tokens (    1.07 ms per token,   936.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.79 ms /     3 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      83.12 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    18 tokens (    1.48 ms per token,   675.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    22 tokens (    1.23 ms per token,   811.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    19 tokens (    1.42 ms per token,   704.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.33 ms /    31 tokens (    1.01 ms per token,   989.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      65.46 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    14 tokens (    1.95 ms per token,   512.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    16 tokens (    1.73 ms per token,   578.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    18 tokens (    1.51 ms per token,   663.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    32 tokens (    0.98 ms per token,  1022.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      65.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    22 tokens (    1.25 ms per token,   800.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.53 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    24 tokens (    1.15 ms per token,   871.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.69 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    27 tokens (    1.14 ms per token,   878.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      82.21 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    27 tokens (    1.13 ms per token,   882.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.82 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    19 tokens (    1.41 ms per token,   710.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.00 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    24 tokens (    1.15 ms per token,   870.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.28 ms /    39 tokens (    0.88 ms per token,  1137.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      68.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    18 tokens (    1.48 ms per token,   673.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.43 ms /    38 tokens (    0.91 ms per token,  1103.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      85.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.03 ms /    34 tokens (    1.00 ms per token,   999.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      67.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   635.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    12 tokens (    2.26 ms per token,   442.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    13 tokens (    2.10 ms per token,   476.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    17 tokens (    1.56 ms per token,   640.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    16 tokens (    1.71 ms per token,   583.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    25 tokens (    1.21 ms per token,   823.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      80.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    20 tokens (    1.35 ms per token,   738.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.24 ms /    32 tokens (    0.98 ms per token,  1024.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      65.32 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    25 tokens (    1.22 ms per token,   819.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    29 tokens (    1.07 ms per token,   931.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      65.02 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    14 tokens (    1.95 ms per token,   514.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    18 tokens (    1.48 ms per token,   673.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16216.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      59.99 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    22 tokens (    1.24 ms per token,   807.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.48 ms per token,   673.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      81.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    28 tokens (    1.09 ms per token,   914.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.46 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.35 ms /    32 tokens (    0.98 ms per token,  1020.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    22 tokens (    1.24 ms per token,   808.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    29 tokens (    1.06 ms per token,   944.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.43 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    21 tokens (    1.30 ms per token,   770.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    12 tokens (    2.26 ms per token,   442.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    16 tokens (    1.72 ms per token,   580.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.79 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    27 tokens (    1.14 ms per token,   880.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.12 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    10 tokens (    2.67 ms per token,   373.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    15 tokens (    1.83 ms per token,   547.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.11 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.22 ms /    29 tokens (    1.08 ms per token,   928.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      82.35 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.80 ms /    28 tokens (    1.10 ms per token,   909.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.90 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    17 tokens (    1.57 ms per token,   637.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    23 tokens (    1.18 ms per token,   844.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.54 ms /    17 tokens (    1.56 ms per token,   640.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    29 tokens (    1.07 ms per token,   934.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      82.73 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.87 ms /    34 tokens (    1.00 ms per token,  1003.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      85.07 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    17 tokens (    1.58 ms per token,   632.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.30 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    22 tokens (    1.24 ms per token,   809.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    13 tokens (    2.09 ms per token,   479.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    24 tokens (    1.14 ms per token,   879.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    21 tokens (    1.30 ms per token,   770.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    25 tokens (    1.21 ms per token,   823.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.30 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16528.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    22 tokens (    1.25 ms per token,   799.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      79.28 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    30 tokens (    1.04 ms per token,   962.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      65.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    33 tokens (    1.03 ms per token,   971.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      68.10 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    26 tokens (    1.17 ms per token,   855.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.31 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      65.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    23 tokens (    1.19 ms per token,   842.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    25 tokens (    1.21 ms per token,   823.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.04 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    16 tokens (    1.71 ms per token,   584.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.94 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    26 tokens (    1.18 ms per token,   850.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.12 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      80.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    27 tokens (    1.14 ms per token,   876.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.69 ms /     3 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      82.27 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    19 tokens (    1.42 ms per token,   705.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.55 ms /    17 tokens (    1.56 ms per token,   640.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.41 ms /    31 tokens (    1.01 ms per token,   987.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      65.59 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    28 tokens (    1.11 ms per token,   900.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.42 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    20 tokens (    1.36 ms per token,   734.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    18 tokens (    1.50 ms per token,   667.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.28 ms /    25 tokens (    1.21 ms per token,   825.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.33 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    25 tokens (    1.22 ms per token,   820.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.27 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    25 tokens (    1.21 ms per token,   825.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.31 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    22 tokens (    1.23 ms per token,   811.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    28 tokens (    1.10 ms per token,   906.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.82 ms /    15 tokens (    1.85 ms per token,   539.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      62.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    18 tokens (    1.49 ms per token,   669.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    14 tokens (    1.95 ms per token,   513.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.04 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    22 tokens (    1.24 ms per token,   809.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    21 tokens (    1.30 ms per token,   767.21 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    18 tokens (    1.49 ms per token,   672.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    19 tokens (    1.40 ms per token,   711.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    19 tokens (    1.42 ms per token,   703.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    16 tokens (    1.73 ms per token,   578.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.67 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    36 tokens (    0.94 ms per token,  1058.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      67.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.75 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    30 tokens (    1.04 ms per token,   963.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.46 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    20 tokens (    1.36 ms per token,   735.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    29 tokens (    1.07 ms per token,   934.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      82.21 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    13 tokens (    2.10 ms per token,   477.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    30 tokens (    1.04 ms per token,   964.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.57 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      65.95 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    20 tokens (    1.34 ms per token,   744.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    14 tokens (    1.97 ms per token,   508.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    27 tokens (    1.14 ms per token,   879.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.90 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    20 tokens (    1.35 ms per token,   739.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    28 tokens (    1.10 ms per token,   911.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.80 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.08 ms /    46 tokens (    0.81 ms per token,  1240.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      70.93 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    22 tokens (    1.24 ms per token,   807.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    15 tokens (    1.84 ms per token,   542.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    20 tokens (    1.35 ms per token,   738.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    29 tokens (    1.07 ms per token,   936.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      82.85 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    28 tokens (    1.10 ms per token,   911.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.07 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    25 tokens (    1.21 ms per token,   823.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      80.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    19 tokens (    1.42 ms per token,   702.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    25 tokens (    1.22 ms per token,   817.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.54 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.49 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      62.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      64.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    18 tokens (    1.49 ms per token,   669.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    19 tokens (    1.41 ms per token,   709.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.40 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    14 tokens (    1.96 ms per token,   510.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.33 ms /    37 tokens (    0.93 ms per token,  1077.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      85.27 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.28 ms /    38 tokens (    0.90 ms per token,  1108.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      85.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    24 tokens (    1.16 ms per token,   865.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    24 tokens (    1.15 ms per token,   867.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    20 tokens (    1.35 ms per token,   739.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    21 tokens (    1.29 ms per token,   774.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.25 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      62.26 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    27 tokens (    1.13 ms per token,   883.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.10 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    13 tokens (    2.11 ms per token,   473.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.32 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    22 tokens (    1.24 ms per token,   805.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.69 ms /    34 tokens (    0.99 ms per token,  1009.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      67.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    16 tokens (    1.72 ms per token,   581.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.04 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    24 tokens (    1.15 ms per token,   870.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      62.03 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    22 tokens (    1.24 ms per token,   809.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.06 ms per token,   938.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    24 tokens (    1.15 ms per token,   865.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      62.21 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.17 ms /    35 tokens (    0.98 ms per token,  1024.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      85.33 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    10 tokens (    2.67 ms per token,   374.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    17 tokens (    1.56 ms per token,   639.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    15 tokens (    1.84 ms per token,   542.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    14 tokens (    1.96 ms per token,   511.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      59.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    12 tokens (    2.25 ms per token,   445.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    21 tokens (    1.28 ms per token,   780.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    12 tokens (    2.24 ms per token,   446.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    23 tokens (    1.19 ms per token,   836.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      79.67 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    16 tokens (    1.72 ms per token,   581.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.68 ms /     3 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      78.88 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    22 tokens (    1.24 ms per token,   809.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    17 tokens (    1.58 ms per token,   634.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   705.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    15 tokens (    1.85 ms per token,   541.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      79.42 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    17 tokens (    1.58 ms per token,   633.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    33 tokens (    1.03 ms per token,   971.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      84.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   837.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    21 tokens (    1.31 ms per token,   763.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    27 tokens (    1.14 ms per token,   877.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.42 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.83 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    26 tokens (    1.17 ms per token,   851.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.72 ms per token,   579.75 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      61.86 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    26 tokens (    1.17 ms per token,   851.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.62 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    15 tokens (    1.84 ms per token,   543.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    12 tokens (    2.24 ms per token,   446.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    29 tokens (    1.07 ms per token,   936.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      65.73 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.31 ms /    38 tokens (    0.90 ms per token,  1107.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      68.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    12 tokens (    2.24 ms per token,   446.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    20 tokens (    1.35 ms per token,   741.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.69 ms /    16 tokens (    1.73 ms per token,   577.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    21 tokens (    1.31 ms per token,   766.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    20 tokens (    1.35 ms per token,   738.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.10 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   853.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      63.97 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    25 tokens (    1.22 ms per token,   817.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      78.70 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    11 tokens (    2.44 ms per token,   410.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    37 tokens (    0.92 ms per token,  1087.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      85.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    24 tokens (    1.15 ms per token,   867.40 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      62.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    16 tokens (    1.71 ms per token,   584.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    21 tokens (    1.29 ms per token,   778.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      61.80 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    20 tokens (    1.35 ms per token,   739.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    14 tokens (    1.96 ms per token,   511.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    28 tokens (    1.10 ms per token,   910.72 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      64.66 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    11 tokens (    2.45 ms per token,   408.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    21 tokens (    1.29 ms per token,   773.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      79.16 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    12 tokens (    2.25 ms per token,   444.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    15 tokens (    1.83 ms per token,   546.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   742.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.63 ms /    24 tokens (    1.15 ms per token,   868.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      61.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    11 tokens (    2.46 ms per token,   406.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.07 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    28 tokens (    1.10 ms per token,   911.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.75 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    24 tokens (    1.14 ms per token,   876.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    13 tokens (    2.12 ms per token,   471.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.81 ms /    16 tokens (    1.74 ms per token,   575.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    27 tokens (    1.14 ms per token,   878.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.25 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    30 tokens (    1.03 ms per token,   968.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    26 tokens (    1.18 ms per token,   850.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.13 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    18 tokens (    1.49 ms per token,   668.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    20 tokens (    1.35 ms per token,   739.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    21 tokens (    1.29 ms per token,   777.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   823.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    12 tokens (    2.27 ms per token,   439.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.86 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.56 ms /    32 tokens (    0.99 ms per token,  1014.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      82.25 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    22 tokens (    1.24 ms per token,   806.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    18 tokens (    1.50 ms per token,   666.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    15 tokens (    1.85 ms per token,   541.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    33 tokens (    1.02 ms per token,   976.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      68.18 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    14 tokens (    1.95 ms per token,   514.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    15 tokens (    1.84 ms per token,   544.33 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.42 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    13 tokens (    2.09 ms per token,   478.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    23 tokens (    1.18 ms per token,   843.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.40 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      62.09 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    12 tokens (    2.26 ms per token,   441.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.19 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.42 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.86 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.92 ms /    29 tokens (    1.07 ms per token,   938.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    11 tokens (    2.47 ms per token,   404.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    17 tokens (    1.58 ms per token,   631.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    11 tokens (    2.47 ms per token,   404.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.66 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    14 tokens (    1.97 ms per token,   508.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.66 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    24 tokens (    1.15 ms per token,   870.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      62.10 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.06 ms per token,   938.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.15 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    29 tokens (    1.07 ms per token,   932.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      65.30 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    10 tokens (    2.67 ms per token,   374.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.15 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.51 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    30 tokens (    1.04 ms per token,   962.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      82.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    25 tokens (    1.22 ms per token,   821.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.24 ms /    25 tokens (    1.21 ms per token,   826.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.83 ms /    33 tokens (    1.03 ms per token,   975.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      67.97 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    18 tokens (    1.49 ms per token,   670.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.14 ms /     2 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.66 ms /    35 tokens (    0.96 ms per token,  1039.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      83.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    18 tokens (    1.51 ms per token,   664.26 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    22 tokens (    1.26 ms per token,   795.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    22 tokens (    1.23 ms per token,   812.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.07 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.72 ms /    34 tokens (    0.99 ms per token,  1008.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      67.39 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    27 tokens (    1.15 ms per token,   870.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      65.10 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    26 tokens (    1.17 ms per token,   858.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      80.99 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     4 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    18 tokens (    1.51 ms per token,   663.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.87 ms /     3 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =      79.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    25 tokens (    1.22 ms per token,   819.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.33 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    14 tokens (    1.94 ms per token,   514.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    11 tokens (    2.44 ms per token,   410.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    24 tokens (    1.14 ms per token,   873.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.30 ms /    38 tokens (    0.90 ms per token,  1107.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      67.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    22 tokens (    1.23 ms per token,   812.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    14 tokens (    1.96 ms per token,   510.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.09 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.57 ms /    42 tokens (    0.87 ms per token,  1148.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      87.16 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.19 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    11 tokens (    2.44 ms per token,   409.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.60 ms /    17 tokens (    1.56 ms per token,   639.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.11 ms /    30 tokens (    1.04 ms per token,   964.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.69 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    12 tokens (    2.24 ms per token,   446.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    26 tokens (    1.17 ms per token,   851.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.54 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16460.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.80 ms /    23 tokens (    1.21 ms per token,   827.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    14 tokens (    1.96 ms per token,   510.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   842.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      62.39 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.74 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.00 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    26 tokens (    1.17 ms per token,   851.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.35 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    23 tokens (    1.19 ms per token,   841.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      78.62 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    18 tokens (    1.49 ms per token,   670.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    15 tokens (    1.85 ms per token,   540.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.88 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    16 tokens (    1.73 ms per token,   579.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    12 tokens (    2.25 ms per token,   443.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    29 tokens (    1.07 ms per token,   933.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      65.24 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    13 tokens (    2.09 ms per token,   478.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    18 tokens (    1.49 ms per token,   672.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     3 runs   (    0.07 ms per token, 15000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.35 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   853.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.62 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    24 tokens (    1.14 ms per token,   874.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.48 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    30 tokens (    1.04 ms per token,   966.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.04 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    25 tokens (    1.22 ms per token,   818.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   705.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    25 tokens (    1.22 ms per token,   821.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      81.30 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.91 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    23 tokens (    1.18 ms per token,   846.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    12 tokens (    2.25 ms per token,   444.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.60 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    22 tokens (    1.24 ms per token,   809.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.33 ms /    31 tokens (    1.01 ms per token,   989.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.94 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.40 ms /    32 tokens (    0.98 ms per token,  1019.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      82.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    29 tokens (    1.07 ms per token,   933.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.55 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    15 tokens (    1.84 ms per token,   542.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    17 tokens (    1.57 ms per token,   638.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      59.92 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    29 tokens (    1.07 ms per token,   936.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      81.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    24 tokens (    1.14 ms per token,   875.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    22 tokens (    1.23 ms per token,   810.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.73 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    27 tokens (    1.13 ms per token,   884.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.08 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    13 tokens (    2.11 ms per token,   474.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.86 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    22 tokens (    1.24 ms per token,   809.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    20 tokens (    1.34 ms per token,   744.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    31 tokens (    1.00 ms per token,   995.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      82.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.23 ms /    31 tokens (    1.01 ms per token,   992.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    19 tokens (    1.43 ms per token,   701.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      61.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    40 tokens (    0.86 ms per token,  1161.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      84.77 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   707.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    19 tokens (    1.41 ms per token,   708.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    19 tokens (    1.43 ms per token,   701.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    19 tokens (    1.41 ms per token,   707.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      76.98 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.32 ms /    32 tokens (    0.98 ms per token,  1021.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      82.48 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    23 tokens (    1.20 ms per token,   830.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      79.37 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    34 tokens (    0.99 ms per token,  1006.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      67.77 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    31 tokens (    1.00 ms per token,   995.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      82.30 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    12 tokens (    2.24 ms per token,   447.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    16 tokens (    1.73 ms per token,   578.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.65 ms /    40 tokens (    0.87 ms per token,  1154.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      69.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    21 tokens (    1.28 ms per token,   779.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    11 tokens (    2.44 ms per token,   409.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.22 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    26 tokens (    1.18 ms per token,   848.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.38 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    14 tokens (    1.96 ms per token,   509.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.47 ms /    25 tokens (    1.22 ms per token,   820.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.80 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    20 tokens (    1.35 ms per token,   742.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    16 tokens (    1.71 ms per token,   585.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    22 tokens (    1.24 ms per token,   804.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.43 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    11 tokens (    2.45 ms per token,   407.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    23 tokens (    1.20 ms per token,   834.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      79.25 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    20 tokens (    1.35 ms per token,   738.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    28 tokens (    1.10 ms per token,   910.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      81.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    27 tokens (    1.14 ms per token,   874.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.62 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.07 ms /    36 tokens (    0.95 ms per token,  1056.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      68.24 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    19 tokens (    1.42 ms per token,   702.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    14 tokens (    1.96 ms per token,   509.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    19 tokens (    1.43 ms per token,   697.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    16 tokens (    1.71 ms per token,   584.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      78.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    14 tokens (    1.96 ms per token,   509.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.11 ms /    29 tokens (    1.07 ms per token,   932.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      82.50 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    20 tokens (    1.34 ms per token,   743.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    22 tokens (    1.24 ms per token,   809.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    13 tokens (    2.09 ms per token,   478.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.34 ms /    32 tokens (    0.98 ms per token,  1020.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      66.18 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    12 tokens (    2.24 ms per token,   446.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    23 tokens (    1.19 ms per token,   839.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   706.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    12 tokens (    2.25 ms per token,   444.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    13 tokens (    2.10 ms per token,   476.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   637.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    13 tokens (    2.09 ms per token,   478.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    28 tokens (    1.09 ms per token,   913.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.33 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    19 tokens (    1.43 ms per token,   699.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    23 tokens (    1.19 ms per token,   843.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    35 tokens (    0.97 ms per token,  1032.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      84.73 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.54 ms /    31 tokens (    1.02 ms per token,   982.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      82.45 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    23 tokens (    1.20 ms per token,   834.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      79.14 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    18 tokens (    1.50 ms per token,   667.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    35 tokens (    0.97 ms per token,  1029.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      84.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    23 tokens (    1.20 ms per token,   836.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      78.75 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    22 tokens (    1.24 ms per token,   803.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.72 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    27 tokens (    1.14 ms per token,   874.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.25 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    27 tokens (    1.14 ms per token,   875.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    30 tokens (    1.04 ms per token,   959.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      65.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /     8 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      78.09 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    25 tokens (    1.23 ms per token,   813.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    11 tokens (    2.44 ms per token,   409.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17094.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    22 tokens (    1.24 ms per token,   807.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    25 tokens (    1.23 ms per token,   815.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      65.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.31 ms /    31 tokens (    1.01 ms per token,   990.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      64.94 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.53 ms /    32 tokens (    0.99 ms per token,  1015.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      82.08 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    15 tokens (    1.83 ms per token,   546.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    10 tokens (    2.67 ms per token,   374.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.04 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    12 tokens (    2.24 ms per token,   446.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.52 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    11 tokens (    2.44 ms per token,   409.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.79 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      61.62 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.47 ms /    29 tokens (    1.09 ms per token,   921.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      65.25 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    22 tokens (    1.23 ms per token,   815.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      82.37 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.76 ms /    27 tokens (    1.14 ms per token,   877.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      64.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    21 tokens (    1.28 ms per token,   780.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.68 ms /     3 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    22 tokens (    1.24 ms per token,   806.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      62.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    18 tokens (    1.48 ms per token,   674.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      59.97 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    14 tokens (    1.94 ms per token,   514.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.04 ms /    29 tokens (    1.07 ms per token,   934.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      65.05 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    19 tokens (    1.43 ms per token,   701.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      62.08 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    20 tokens (    1.35 ms per token,   742.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    30 tokens (    1.04 ms per token,   962.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.14 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     3 runs   (    0.07 ms per token, 14150.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    16 tokens (    1.72 ms per token,   580.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      62.21 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    21 tokens (    1.30 ms per token,   769.54 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    27 tokens (    1.13 ms per token,   883.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.56 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.78 ms /    28 tokens (    1.10 ms per token,   909.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.87 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    26 tokens (    1.18 ms per token,   847.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      65.20 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    31 tokens (    1.01 ms per token,   991.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.56 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.75 ms /    23 tokens (    1.21 ms per token,   828.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      62.24 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    10 tokens (    2.70 ms per token,   370.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    19 tokens (    1.42 ms per token,   703.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.49 ms /    25 tokens (    1.22 ms per token,   819.83 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      64.60 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.81 ms /    24 tokens (    1.16 ms per token,   863.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    17 tokens (    1.57 ms per token,   635.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    24 tokens (    1.15 ms per token,   868.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.82 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.39 ms /    25 tokens (    1.22 ms per token,   822.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      80.91 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    19 tokens (    1.42 ms per token,   705.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.40 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.73 ms /    23 tokens (    1.21 ms per token,   829.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      62.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.72 ms /    26 tokens (    1.18 ms per token,   846.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.90 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    38 tokens (    0.90 ms per token,  1109.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.74 ms /     3 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      85.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    21 tokens (    1.29 ms per token,   772.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   775.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15789.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    20 tokens (    1.35 ms per token,   740.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    25 tokens (    1.21 ms per token,   824.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    18 tokens (    1.50 ms per token,   667.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    28 tokens (    1.10 ms per token,   909.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.81 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.76 ms /    24 tokens (    1.16 ms per token,   864.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      62.53 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    14 tokens (    1.97 ms per token,   508.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    28 tokens (    1.10 ms per token,   906.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      82.95 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.53 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      64.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    26 tokens (    1.17 ms per token,   855.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      63.94 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    18 tokens (    1.52 ms per token,   659.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.26 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    19 tokens (    1.43 ms per token,   700.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      79.12 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    26 tokens (    1.18 ms per token,   850.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.48 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    30 tokens (    1.03 ms per token,   967.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /     8 tokens (    5.45 ms per token,   183.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.23 ms /     2 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.91 ms /    24 tokens (    1.16 ms per token,   860.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    20 tokens (    1.36 ms per token,   736.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.53 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 15810.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    11 tokens (    2.44 ms per token,   410.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    20 tokens (    1.35 ms per token,   741.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    19 tokens (    1.42 ms per token,   703.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    31 tokens (    1.00 ms per token,   995.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.67 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.94 ms /    14 tokens (    2.00 ms per token,   501.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    24 tokens (    1.15 ms per token,   873.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.32 ms /    31 tokens (    1.01 ms per token,   989.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.71 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    19 tokens (    1.41 ms per token,   708.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    19 tokens (    1.42 ms per token,   705.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.75 ms /    35 tokens (    0.96 ms per token,  1037.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      67.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    14 tokens (    1.96 ms per token,   509.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      62.26 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.74 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    21 tokens (    1.28 ms per token,   780.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      77.34 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    26 tokens (    1.17 ms per token,   854.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      80.80 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.47 ms /    31 tokens (    1.02 ms per token,   985.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      65.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.40 ms /    31 tokens (    1.01 ms per token,   987.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      65.48 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    27 tokens (    1.13 ms per token,   883.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.19 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    23 tokens (    1.19 ms per token,   837.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.90 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    22 tokens (    1.24 ms per token,   808.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    24 tokens (    1.14 ms per token,   879.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    28 tokens (    1.10 ms per token,   908.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      81.89 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.73 ms /    15 tokens (    1.85 ms per token,   540.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    21 tokens (    1.30 ms per token,   770.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   512.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    22 tokens (    1.23 ms per token,   812.14 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.54 ms /    39 tokens (    0.89 ms per token,  1129.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      68.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    28 tokens (    1.09 ms per token,   913.60 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      65.93 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    28 tokens (    1.10 ms per token,   912.68 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      65.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    20 tokens (    1.34 ms per token,   744.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      77.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    24 tokens (    1.15 ms per token,   872.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    10 tokens (    2.67 ms per token,   373.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.14 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.81 ms /    33 tokens (    1.02 ms per token,   976.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      67.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.62 ms /    30 tokens (    1.05 ms per token,   948.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      66.41 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.07 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    21 tokens (    1.28 ms per token,   780.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    29 tokens (    1.07 ms per token,   933.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.95 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.76 ms /    27 tokens (    1.14 ms per token,   877.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      81.48 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    12 tokens (    2.24 ms per token,   446.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   636.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    13 tokens (    2.09 ms per token,   477.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    18 tokens (    1.50 ms per token,   667.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    25 tokens (    1.22 ms per token,   817.98 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      64.77 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.32 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    20 tokens (    1.34 ms per token,   743.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.40 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    13 tokens (    2.09 ms per token,   477.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.82 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.37 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    17 tokens (    1.58 ms per token,   634.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.15 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    13 tokens (    2.10 ms per token,   476.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    19 tokens (    1.41 ms per token,   708.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.56 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   809.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      77.97 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.61 ms /    39 tokens (    0.89 ms per token,  1127.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      68.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    20 tokens (    1.36 ms per token,   736.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    20 tokens (    1.36 ms per token,   735.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    19 tokens (    1.43 ms per token,   701.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.83 ms /    24 tokens (    1.16 ms per token,   862.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      62.31 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    20 tokens (    1.35 ms per token,   743.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    31 tokens (    1.01 ms per token,   993.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      64.83 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    18 tokens (    1.49 ms per token,   669.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    14 tokens (    1.95 ms per token,   513.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.07 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    17 tokens (    1.58 ms per token,   634.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.12 ms /    36 tokens (    0.95 ms per token,  1055.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      67.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    17 tokens (    1.57 ms per token,   637.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   850.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.76 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    17 tokens (    1.57 ms per token,   636.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    25 tokens (    1.23 ms per token,   814.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.43 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    20 tokens (    1.35 ms per token,   739.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.68 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    26 tokens (    1.18 ms per token,   849.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      82.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    12 tokens (    2.26 ms per token,   441.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.69 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    27 tokens (    1.13 ms per token,   882.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      63.96 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    18 tokens (    1.50 ms per token,   667.31 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.84 ms /    34 tokens (    1.00 ms per token,  1004.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      85.44 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    18 tokens (    1.48 ms per token,   674.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    23 tokens (    1.20 ms per token,   835.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.04 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.39 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      80.95 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       1.05 ms /    19 runs   (    0.06 ms per token, 18060.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    11 tokens (    2.44 ms per token,   409.00 tokens per second)\n",
      "llama_print_timings:        eval time =     297.01 ms /    18 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     331.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    13 tokens (    2.10 ms per token,   476.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    18 tokens (    1.48 ms per token,   673.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    28 tokens (    1.09 ms per token,   915.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.95 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    22 tokens (    1.24 ms per token,   803.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      79.23 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    27 tokens (    1.14 ms per token,   876.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      81.17 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    19 tokens (    1.42 ms per token,   703.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.42 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16528.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    31 tokens (    1.01 ms per token,   991.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      83.36 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    29 tokens (    1.06 ms per token,   941.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      65.09 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    24 tokens (    1.14 ms per token,   874.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    25 tokens (    1.22 ms per token,   821.80 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      82.14 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.37 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    19 tokens (    1.41 ms per token,   707.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.23 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    23 tokens (    1.20 ms per token,   836.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    13 tokens (    2.10 ms per token,   476.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      81.72 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   742.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.95 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    11 tokens (    2.43 ms per token,   411.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    24 tokens (    1.15 ms per token,   871.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.81 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.67 ms /    31 tokens (    1.02 ms per token,   978.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      83.03 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    27 tokens (    1.14 ms per token,   876.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      82.04 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    13 tokens (    2.11 ms per token,   473.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.71 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    20 tokens (    1.36 ms per token,   736.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    28 tokens (    1.10 ms per token,   908.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      64.78 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      64.20 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.29 ms /    32 tokens (    0.98 ms per token,  1022.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.83 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.06 ms /    28 tokens (    1.11 ms per token,   901.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      65.24 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      78.82 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    20 tokens (    1.35 ms per token,   740.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /    12 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    10 tokens (    2.69 ms per token,   372.09 tokens per second)\n",
      "llama_print_timings:        eval time =     181.23 ms /    11 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     212.24 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    15 tokens (    1.85 ms per token,   540.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.69 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.00 ms /    34 tokens (    1.00 ms per token,  1000.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      67.56 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    28 tokens (    1.10 ms per token,   906.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.22 ms /    29 tokens (    1.08 ms per token,   929.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      82.02 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   822.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.92 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /    17 tokens (    1.56 ms per token,   639.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      81.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    24 tokens (    1.15 ms per token,   869.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    20 tokens (    1.36 ms per token,   737.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.66 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    21 tokens (    1.30 ms per token,   767.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     3 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.47 ms /    25 tokens (    1.22 ms per token,   820.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      63.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    25 tokens (    1.22 ms per token,   820.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    28 tokens (    1.10 ms per token,   910.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      65.01 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    12 tokens (    2.24 ms per token,   446.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.22 ms /    30 tokens (    1.04 ms per token,   961.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      82.84 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.81 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    16 tokens (    1.72 ms per token,   581.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    19 tokens (    1.42 ms per token,   701.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    30 tokens (    1.03 ms per token,   967.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      65.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    14 tokens (    1.97 ms per token,   508.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      62.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.43 ms /    39 tokens (    0.88 ms per token,  1132.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      68.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    23 tokens (    1.18 ms per token,   846.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    21 tokens (    1.29 ms per token,   778.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      63.81 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    16 tokens (    1.72 ms per token,   580.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.51 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    17 tokens (    1.58 ms per token,   634.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    17 tokens (    1.57 ms per token,   635.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    24 tokens (    1.14 ms per token,   873.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      62.33 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    18 tokens (    1.48 ms per token,   675.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    13 tokens (    2.11 ms per token,   474.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.78 ms /    27 tokens (    1.14 ms per token,   877.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.88 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    17 tokens (    1.57 ms per token,   635.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    25 tokens (    1.22 ms per token,   819.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.19 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    16 tokens (    1.72 ms per token,   582.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      62.01 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    22 tokens (    1.23 ms per token,   812.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    25 tokens (    1.22 ms per token,   817.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.45 ms /    32 tokens (    0.98 ms per token,  1017.36 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      65.91 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    30 tokens (    1.03 ms per token,   971.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.30 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    19 tokens (    1.42 ms per token,   706.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    22 tokens (    1.25 ms per token,   801.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    24 tokens (    1.15 ms per token,   869.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      62.01 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      76.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    20 tokens (    1.35 ms per token,   741.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    11 tokens (    2.45 ms per token,   408.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    15 tokens (    1.84 ms per token,   543.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      79.01 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    23 tokens (    1.19 ms per token,   839.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    29 tokens (    1.08 ms per token,   927.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.98 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.75 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    31 tokens (    1.01 ms per token,   994.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      82.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    14 tokens (    1.94 ms per token,   515.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    23 tokens (    1.21 ms per token,   829.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   809.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    22 tokens (    1.26 ms per token,   796.64 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.96 ms /    46 tokens (    0.80 ms per token,  1244.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.22 ms /     2 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      71.66 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    26 tokens (    1.18 ms per token,   846.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    28 tokens (    1.10 ms per token,   909.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.87 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    20 tokens (    1.36 ms per token,   735.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    11 tokens (    2.45 ms per token,   408.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.23 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    25 tokens (    1.23 ms per token,   815.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.65 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    27 tokens (    1.14 ms per token,   880.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.39 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    17 tokens (    1.58 ms per token,   631.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    30 tokens (    1.04 ms per token,   959.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      82.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    18 tokens (    1.48 ms per token,   674.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    20 tokens (    1.35 ms per token,   739.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    13 tokens (    2.10 ms per token,   475.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    27 tokens (    1.14 ms per token,   877.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      64.76 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    10 tokens (    2.68 ms per token,   373.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.30 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.87 ms /    34 tokens (    1.00 ms per token,  1003.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.76 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.55 ms /    32 tokens (    0.99 ms per token,  1014.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      65.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    20 tokens (    1.35 ms per token,   738.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.38 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.47 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    13 tokens (    2.09 ms per token,   478.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    20 tokens (    1.36 ms per token,   736.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    15 tokens (    1.84 ms per token,   544.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    19 tokens (    1.41 ms per token,   708.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.16 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    16 tokens (    1.72 ms per token,   581.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    22 tokens (    1.22 ms per token,   816.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.23 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    21 tokens (    1.30 ms per token,   771.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    22 tokens (    1.24 ms per token,   804.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =      62.69 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    20 tokens (    1.34 ms per token,   745.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    29 tokens (    1.07 ms per token,   937.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.06 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    18 tokens (    1.49 ms per token,   669.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    22 tokens (    1.24 ms per token,   809.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    14 tokens (    1.96 ms per token,   511.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    33 tokens (    1.03 ms per token,   970.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      67.38 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.57 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    13 tokens (    2.11 ms per token,   473.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.45 ms /    41 tokens (    0.89 ms per token,  1124.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      70.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    10 tokens (    2.69 ms per token,   371.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.59 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    23 tokens (    1.19 ms per token,   838.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.62 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.92 ms /    33 tokens (    1.03 ms per token,   972.85 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      68.07 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.79 ms /    16 tokens (    1.74 ms per token,   575.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   676.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.58 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    34 tokens (    0.99 ms per token,  1006.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      67.98 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    20 tokens (    1.35 ms per token,   738.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    20 tokens (    1.35 ms per token,   743.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.53 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      64.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    11 tokens (    2.46 ms per token,   406.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.64 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    15 tokens (    1.85 ms per token,   541.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    22 tokens (    1.24 ms per token,   806.57 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.37 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    21 tokens (    1.30 ms per token,   771.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.47 ms /    42 tokens (    0.87 ms per token,  1151.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      88.02 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    18 tokens (    1.50 ms per token,   668.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16736.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    13 tokens (    2.10 ms per token,   475.93 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    17 tokens (    1.59 ms per token,   630.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    14 tokens (    1.95 ms per token,   513.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.40 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    16 tokens (    1.73 ms per token,   578.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.78 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    18 tokens (    1.50 ms per token,   665.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.73 ms /    16 tokens (    1.73 ms per token,   577.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    20 tokens (    1.35 ms per token,   741.02 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.63 ms /    38 tokens (    0.91 ms per token,  1097.16 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      68.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    24 tokens (    1.15 ms per token,   867.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    22 tokens (    1.24 ms per token,   808.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.90 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    16 tokens (    1.72 ms per token,   580.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      62.09 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    12 tokens (    2.25 ms per token,   444.12 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    26 tokens (    1.17 ms per token,   853.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    29 tokens (    1.07 ms per token,   931.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      82.65 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.19 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    27 tokens (    1.14 ms per token,   877.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =      65.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    21 tokens (    1.28 ms per token,   779.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    20 tokens (    1.35 ms per token,   743.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.29 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    15 tokens (    1.83 ms per token,   545.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.53 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.39 ms /    38 tokens (    0.91 ms per token,  1104.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      69.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    20 tokens (    1.35 ms per token,   740.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    20 tokens (    1.35 ms per token,   738.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    25 tokens (    1.22 ms per token,   817.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      65.08 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.41 ms /    37 tokens (    0.93 ms per token,  1075.21 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      85.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      82.30 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      63.92 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    26 tokens (    1.18 ms per token,   848.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      64.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   822.18 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      65.11 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    11 tokens (    2.46 ms per token,   406.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    19 tokens (    1.42 ms per token,   704.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    12 tokens (    2.27 ms per token,   440.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    15 tokens (    1.84 ms per token,   542.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    15 tokens (    1.82 ms per token,   548.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    12 tokens (    2.25 ms per token,   444.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.49 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    36 tokens (    0.95 ms per token,  1057.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      68.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.70 ms /    33 tokens (    1.02 ms per token,   979.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      68.06 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    15 tokens (    1.84 ms per token,   543.50 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      62.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.77 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      77.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.60 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    29 tokens (    1.07 ms per token,   938.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.07 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    22 tokens (    1.24 ms per token,   806.45 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    12 tokens (    2.25 ms per token,   443.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    20 tokens (    1.36 ms per token,   736.76 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.31 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    20 tokens (    1.36 ms per token,   737.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    17 tokens (    1.57 ms per token,   635.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.24 ms /    31 tokens (    1.01 ms per token,   992.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.72 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      81.48 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    16 tokens (    1.73 ms per token,   578.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.25 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    15 tokens (    1.84 ms per token,   544.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    23 tokens (    1.18 ms per token,   847.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.37 ms /    39 tokens (    0.88 ms per token,  1134.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      67.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    53 tokens (    0.81 ms per token,  1232.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.41 ms /     2 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =      77.82 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    21 tokens (    1.29 ms per token,   773.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      77.93 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.52 ms /    40 tokens (    0.86 ms per token,  1158.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      85.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    18 tokens (    1.50 ms per token,   668.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    27 tokens (    1.14 ms per token,   879.11 tokens per second)\n",
      "llama_print_timings:        eval time =      33.11 ms /     2 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      65.38 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    19 tokens (    1.41 ms per token,   711.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.08 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    12 tokens (    2.25 ms per token,   443.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    21 tokens (    1.30 ms per token,   769.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    24 tokens (    1.15 ms per token,   870.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      79.01 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    11 tokens (    2.45 ms per token,   408.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    12 tokens (    2.24 ms per token,   445.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16853.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    23 tokens (    1.19 ms per token,   842.43 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      62.21 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.41 ms /    17 tokens (    1.55 ms per token,   643.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      59.81 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    28 tokens (    1.10 ms per token,   912.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.70 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    29 tokens (    1.07 ms per token,   935.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      64.98 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    18 tokens (    1.49 ms per token,   671.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    14 tokens (    1.94 ms per token,   514.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      78.48 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    23 tokens (    1.18 ms per token,   845.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.49 ms per token,   673.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    19 tokens (    1.45 ms per token,   691.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    25 tokens (    1.23 ms per token,   811.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      64.58 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    25 tokens (    1.22 ms per token,   819.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.36 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    19 tokens (    1.41 ms per token,   709.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    13 tokens (    2.10 ms per token,   475.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    25 tokens (    1.22 ms per token,   818.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      64.42 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    15 tokens (    1.83 ms per token,   545.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    24 tokens (    1.15 ms per token,   870.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.83 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   821.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      81.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    24 tokens (    1.15 ms per token,   867.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.98 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    12 tokens (    2.25 ms per token,   444.03 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    24 tokens (    1.15 ms per token,   872.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    30 tokens (    1.04 ms per token,   963.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      82.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.57 ms /    44 tokens (    0.83 ms per token,  1203.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      70.34 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    24 tokens (    1.15 ms per token,   870.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    20 tokens (    1.35 ms per token,   742.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.44 ms /    25 tokens (    1.22 ms per token,   821.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      64.96 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    23 tokens (    1.20 ms per token,   836.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.99 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   637.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.44 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    18 tokens (    1.51 ms per token,   662.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    24 tokens (    1.14 ms per token,   876.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.78 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    22 tokens (    1.23 ms per token,   813.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.63 ms /    23 tokens (    1.20 ms per token,   832.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.87 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    13 tokens (    2.10 ms per token,   475.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.62 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.79 ms /    26 tokens (    1.18 ms per token,   844.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      82.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    19 tokens (    1.41 ms per token,   710.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16216.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.80 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    19 tokens (    1.42 ms per token,   705.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.39 ms /    31 tokens (    1.01 ms per token,   987.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      65.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    24 tokens (    1.14 ms per token,   879.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      78.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    18 tokens (    1.48 ms per token,   674.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.59 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    13 tokens (    2.10 ms per token,   476.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    21 tokens (    1.29 ms per token,   773.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      61.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    14 tokens (    1.98 ms per token,   504.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.70 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    13 tokens (    2.09 ms per token,   477.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.26 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.19 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    22 tokens (    1.23 ms per token,   812.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.69 ms /     3 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      78.68 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    14 tokens (    1.95 ms per token,   512.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.31 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    14 tokens (    1.96 ms per token,   510.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    25 tokens (    1.22 ms per token,   821.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.33 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    30 tokens (    1.03 ms per token,   969.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.82 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    20 tokens (    1.36 ms per token,   734.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.94 ms /    33 tokens (    1.03 ms per token,   972.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      68.27 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    20 tokens (    1.36 ms per token,   735.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.59 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.69 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      78.42 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    21 tokens (    1.29 ms per token,   772.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      62.09 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    10 tokens (    2.69 ms per token,   371.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    22 tokens (    1.23 ms per token,   810.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    29 tokens (    1.06 ms per token,   939.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.67 ms /     3 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      82.76 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    13 tokens (    2.09 ms per token,   478.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    30 tokens (    1.04 ms per token,   961.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      65.15 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    20 tokens (    1.36 ms per token,   733.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    17 tokens (    1.58 ms per token,   633.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    22 tokens (    1.26 ms per token,   796.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.90 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    37 tokens (    0.93 ms per token,  1080.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      68.23 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    15 tokens (    1.84 ms per token,   542.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      62.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    20 tokens (    1.34 ms per token,   744.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      65.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    23 tokens (    1.18 ms per token,   847.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.60 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    34 tokens (    1.00 ms per token,  1000.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.46 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    12 tokens (    2.26 ms per token,   442.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    12 tokens (    2.26 ms per token,   442.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    14 tokens (    1.95 ms per token,   512.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    15 tokens (    1.83 ms per token,   546.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    24 tokens (    1.14 ms per token,   878.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.31 ms /    38 tokens (    0.90 ms per token,  1107.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      67.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    26 tokens (    1.17 ms per token,   855.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.37 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.61 ms /    40 tokens (    0.87 ms per token,  1155.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =      69.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.34 ms /    39 tokens (    0.88 ms per token,  1135.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      68.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    11 tokens (    2.45 ms per token,   407.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    35 tokens (    0.97 ms per token,  1030.08 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    15 tokens (    1.83 ms per token,   545.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.27 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    28 tokens (    1.10 ms per token,   907.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      81.99 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    20 tokens (    1.36 ms per token,   734.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    28 tokens (    1.10 ms per token,   905.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      82.74 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    26 tokens (    1.18 ms per token,   847.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.03 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    27 tokens (    1.14 ms per token,   873.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      65.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    17 tokens (    1.57 ms per token,   635.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.54 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    26 tokens (    1.18 ms per token,   851.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /     8 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
      "llama_print_timings:        eval time =      33.26 ms /     2 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =      77.81 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    18 tokens (    1.50 ms per token,   666.35 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.76 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.59 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      60.50 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    13 tokens (    2.10 ms per token,   476.68 tokens per second)\n",
      "llama_print_timings:        eval time =      49.33 ms /     3 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      78.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    24 tokens (    1.15 ms per token,   867.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.62 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    22 tokens (    1.23 ms per token,   810.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    15 tokens (    1.84 ms per token,   543.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    26 tokens (    1.17 ms per token,   855.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.36 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    19 tokens (    1.42 ms per token,   703.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.14 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    15 tokens (    1.84 ms per token,   543.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.60 ms /    42 tokens (    0.87 ms per token,  1147.48 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      70.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    13 tokens (    2.09 ms per token,   478.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    17 tokens (    1.58 ms per token,   634.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.30 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    18 tokens (    1.49 ms per token,   670.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    15 tokens (    1.83 ms per token,   546.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.25 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    23 tokens (    1.19 ms per token,   837.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    13 tokens (    2.11 ms per token,   473.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.42 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    25 tokens (    1.22 ms per token,   819.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.48 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.48 ms /    41 tokens (    0.89 ms per token,  1123.97 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      70.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    23 tokens (    1.20 ms per token,   833.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.24 ms /    36 tokens (    0.95 ms per token,  1051.46 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      68.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    25 tokens (    1.21 ms per token,   824.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.13 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    11 tokens (    2.45 ms per token,   407.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    20 tokens (    1.35 ms per token,   742.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    15 tokens (    1.84 ms per token,   542.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   677.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    27 tokens (    1.13 ms per token,   882.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.82 ms /    14 tokens (    1.99 ms per token,   503.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    22 tokens (    1.24 ms per token,   805.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    15 tokens (    1.84 ms per token,   543.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      62.16 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.09 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    16 tokens (    1.72 ms per token,   582.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   822.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.76 ms /     3 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =      82.03 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.62 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    20 tokens (    1.35 ms per token,   739.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    20 tokens (    1.34 ms per token,   746.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    12 tokens (    2.27 ms per token,   440.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    13 tokens (    2.10 ms per token,   476.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.76 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    19 tokens (    1.42 ms per token,   704.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    25 tokens (    1.22 ms per token,   818.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      64.51 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    14 tokens (    1.94 ms per token,   514.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.62 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.28 ms /    25 tokens (    1.21 ms per token,   825.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      64.07 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.31 ms /     3 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    22 tokens (    1.24 ms per token,   806.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    24 tokens (    1.14 ms per token,   875.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      78.67 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    14 tokens (    1.98 ms per token,   505.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    15 tokens (    1.82 ms per token,   547.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    12 tokens (    2.25 ms per token,   443.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.47 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    28 tokens (    1.10 ms per token,   908.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.70 ms /     3 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      82.92 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    30 tokens (    1.04 ms per token,   958.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      82.43 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 16042.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    23 tokens (    1.19 ms per token,   843.82 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      61.18 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    25 tokens (    1.23 ms per token,   816.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.99 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      61.67 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.69 ms /    16 tokens (    1.73 ms per token,   577.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16759.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    19 tokens (    1.43 ms per token,   698.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      61.79 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    13 tokens (    2.10 ms per token,   476.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    21 tokens (    1.29 ms per token,   772.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.66 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    33 tokens (    1.03 ms per token,   971.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      84.95 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    21 tokens (    1.29 ms per token,   773.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      59.99 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    16 tokens (    1.71 ms per token,   583.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.36 ms /    25 tokens (    1.21 ms per token,   823.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.45 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.14 ms /    29 tokens (    1.07 ms per token,   931.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.54 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    21 tokens (    1.30 ms per token,   769.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.23 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.57 ms /    32 tokens (    0.99 ms per token,  1013.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      82.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      79.19 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    21 tokens (    1.28 ms per token,   779.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.78 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    23 tokens (    1.19 ms per token,   839.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    14 tokens (    1.96 ms per token,   510.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   636.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    29 tokens (    1.07 ms per token,   938.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.60 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    24 tokens (    1.16 ms per token,   865.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.50 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    17 tokens (    1.58 ms per token,   631.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    14 tokens (    1.96 ms per token,   509.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.34 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    10 tokens (    2.69 ms per token,   372.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      61.78 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    19 tokens (    1.42 ms per token,   705.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.61 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.32 ms /    32 tokens (    0.98 ms per token,  1021.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      65.83 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.33 ms /    25 tokens (    1.21 ms per token,   824.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.62 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    18 tokens (    1.49 ms per token,   670.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.62 ms /    38 tokens (    0.91 ms per token,  1097.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      85.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    21 tokens (    1.28 ms per token,   779.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.17 ms /    38 tokens (    0.90 ms per token,  1111.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      67.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    26 tokens (    1.18 ms per token,   847.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.89 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    25 tokens (    1.22 ms per token,   820.34 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      64.23 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.77 ms /    23 tokens (    1.21 ms per token,   828.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      79.30 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    11 tokens (    2.47 ms per token,   404.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.17 ms /    35 tokens (    0.98 ms per token,  1024.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      85.45 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.00 ms /    33 tokens (    1.03 ms per token,   970.70 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      67.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    25 tokens (    1.22 ms per token,   816.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      82.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    21 tokens (    1.29 ms per token,   775.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    20 tokens (    1.35 ms per token,   740.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    21 tokens (    1.29 ms per token,   776.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.48 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      64.66 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    19 tokens (    1.43 ms per token,   697.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    28 tokens (    1.10 ms per token,   909.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      82.19 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    23 tokens (    1.19 ms per token,   842.15 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    22 tokens (    1.23 ms per token,   811.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    17 tokens (    1.61 ms per token,   620.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.65 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    12 tokens (    2.25 ms per token,   445.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    26 tokens (    1.19 ms per token,   843.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      82.22 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      64.26 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    12 tokens (    2.24 ms per token,   445.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /     9 tokens (    2.95 ms per token,   338.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     3 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    15 tokens (    1.83 ms per token,   545.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      62.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    23 tokens (    1.18 ms per token,   845.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      62.06 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16304.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    18 tokens (    1.50 ms per token,   668.52 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      61.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    29 tokens (    1.08 ms per token,   929.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      65.76 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    14 tokens (    1.94 ms per token,   515.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.72 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    26 tokens (    1.18 ms per token,   845.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      65.31 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.05 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.99 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    18 tokens (    1.48 ms per token,   675.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.31 ms /    25 tokens (    1.21 ms per token,   824.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      81.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    25 tokens (    1.23 ms per token,   816.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      65.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.35 ms /    25 tokens (    1.21 ms per token,   823.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      81.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.34 ms /    38 tokens (    0.90 ms per token,  1106.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      68.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    33 tokens (    1.03 ms per token,   967.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      85.53 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.74 ms /    27 tokens (    1.14 ms per token,   878.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.52 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    16 tokens (    1.72 ms per token,   581.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    14 tokens (    1.95 ms per token,   513.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.77 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    21 tokens (    1.29 ms per token,   775.71 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    28 tokens (    1.09 ms per token,   914.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      65.05 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    20 tokens (    1.35 ms per token,   740.63 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.51 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    12 tokens (    2.26 ms per token,   442.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    20 tokens (    1.34 ms per token,   743.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    23 tokens (    1.18 ms per token,   846.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    19 tokens (    1.41 ms per token,   709.30 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.21 ms /    22 tokens (    1.24 ms per token,   808.65 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      79.10 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    32 tokens (    0.97 ms per token,  1025.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      66.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    23 tokens (    1.19 ms per token,   836.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.11 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    14 tokens (    1.96 ms per token,   511.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   849.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      64.47 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    14 tokens (    1.97 ms per token,   507.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      62.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     4 runs   (    0.06 ms per token, 15686.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    24 tokens (    1.14 ms per token,   873.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.72 ms /     3 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      79.09 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     3 runs   (    0.07 ms per token, 14634.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    23 tokens (    1.19 ms per token,   842.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.28 ms /     2 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =      61.96 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    14 tokens (    1.96 ms per token,   511.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    28 tokens (    1.10 ms per token,   905.24 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      65.04 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.61 ms /    26 tokens (    1.18 ms per token,   849.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      65.26 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.46 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.49 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.26 ms /    25 tokens (    1.21 ms per token,   826.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      63.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     3 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =      62.58 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    16 tokens (    1.72 ms per token,   582.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.07 ms per token,   938.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      82.17 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    27 tokens (    1.14 ms per token,   874.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.20 ms /     2 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =      65.87 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    20 tokens (    1.35 ms per token,   741.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    37 tokens (    0.93 ms per token,  1080.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      85.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    26 tokens (    1.18 ms per token,   849.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      81.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    19 tokens (    1.42 ms per token,   704.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      61.68 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    23 tokens (    1.19 ms per token,   843.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    24 tokens (    1.15 ms per token,   871.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.53 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.37 ms /    26 tokens (    1.17 ms per token,   856.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.71 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.87 ms /    16 tokens (    1.74 ms per token,   574.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      62.10 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    24 tokens (    1.15 ms per token,   869.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      79.36 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   634.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    23 tokens (    1.19 ms per token,   841.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    15 tokens (    1.82 ms per token,   548.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.61 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    44 tokens (    0.84 ms per token,  1190.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      71.34 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    16 tokens (    1.72 ms per token,   580.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      79.69 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    20 tokens (    1.34 ms per token,   744.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.13 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      79.03 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    38 tokens (    0.90 ms per token,  1111.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.69 ms /     3 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =      85.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    17 tokens (    1.58 ms per token,   631.99 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.13 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    20 tokens (    1.35 ms per token,   740.91 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.51 ms /    32 tokens (    0.98 ms per token,  1015.62 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      83.05 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    22 tokens (    1.24 ms per token,   804.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    19 tokens (    1.43 ms per token,   698.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.72 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    11 tokens (    2.46 ms per token,   407.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    14 tokens (    1.96 ms per token,   509.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      62.23 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    31 tokens (    1.00 ms per token,   998.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.77 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.89 ms /    15 tokens (    1.86 ms per token,   537.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      79.14 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.94 ms /    35 tokens (    0.97 ms per token,  1031.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      85.03 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    20 tokens (    1.34 ms per token,   744.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    23 tokens (    1.19 ms per token,   838.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      62.05 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    34 tokens (    1.00 ms per token,  1003.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      68.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    14 tokens (    1.96 ms per token,   510.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      62.07 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    19 tokens (    1.41 ms per token,   710.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      78.45 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.71 ms /    24 tokens (    1.15 ms per token,   866.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      62.15 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    14 tokens (    1.97 ms per token,   508.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      79.12 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    34 tokens (    1.00 ms per token,  1000.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      68.36 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    20 tokens (    1.34 ms per token,   746.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.84 ms /    33 tokens (    1.03 ms per token,   975.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      67.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    18 tokens (    1.50 ms per token,   667.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.64 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    23 tokens (    1.19 ms per token,   836.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.63 ms /     3 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      79.29 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.03 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.81 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    27 tokens (    1.14 ms per token,   877.51 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16574.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    30 tokens (    1.03 ms per token,   967.06 tokens per second)\n",
      "llama_print_timings:        eval time =      33.24 ms /     2 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =      66.18 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    19 tokens (    1.41 ms per token,   707.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      61.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.80 ms /    24 tokens (    1.16 ms per token,   863.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.63 ms /    15 tokens (    1.84 ms per token,   542.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.88 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.11 ms /    29 tokens (    1.07 ms per token,   932.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    14 tokens (    1.96 ms per token,   511.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.18 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    27 tokens (    1.13 ms per token,   881.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.35 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    19 tokens (    1.42 ms per token,   704.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    31 tokens (    1.01 ms per token,   990.57 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      64.83 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    11 tokens (    2.45 ms per token,   408.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    17 tokens (    1.57 ms per token,   635.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    15 tokens (    1.82 ms per token,   548.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    16 tokens (    1.71 ms per token,   583.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    18 tokens (    1.49 ms per token,   670.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    14 tokens (    1.95 ms per token,   511.77 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.31 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    12 tokens (    2.26 ms per token,   443.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.70 ms /    24 tokens (    1.15 ms per token,   866.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.45 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    18 tokens (    1.49 ms per token,   670.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    13 tokens (    2.08 ms per token,   480.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    19 tokens (    1.41 ms per token,   708.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.37 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    28 tokens (    1.10 ms per token,   907.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.78 ms /     3 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      82.93 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    21 tokens (    1.30 ms per token,   770.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.74 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    22 tokens (    1.25 ms per token,   803.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    20 tokens (    1.36 ms per token,   736.92 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    21 tokens (    1.30 ms per token,   766.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    13 tokens (    2.11 ms per token,   473.90 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    18 tokens (    1.49 ms per token,   669.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      62.13 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    19 tokens (    1.41 ms per token,   708.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      60.55 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    19 tokens (    1.43 ms per token,   700.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    26 tokens (    1.18 ms per token,   850.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.47 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.64 ms /    14 tokens (    1.97 ms per token,   506.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    18 tokens (    1.48 ms per token,   674.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    17 tokens (    1.58 ms per token,   634.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    23 tokens (    1.19 ms per token,   838.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      77.86 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.64 ms /    40 tokens (    0.87 ms per token,  1154.87 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      68.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    19 tokens (    1.42 ms per token,   705.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.32 ms /    30 tokens (    1.04 ms per token,   957.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.26 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    24 tokens (    1.15 ms per token,   872.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    23 tokens (    1.19 ms per token,   840.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.54 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    21 tokens (    1.30 ms per token,   770.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.32 ms /    25 tokens (    1.21 ms per token,   824.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      81.72 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    12 tokens (    2.26 ms per token,   442.98 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15957.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    27 tokens (    1.15 ms per token,   868.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      65.73 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    23 tokens (    1.19 ms per token,   837.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.60 ms /     3 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      78.89 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    22 tokens (    1.23 ms per token,   811.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    11 tokens (    2.45 ms per token,   408.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    17 tokens (    1.58 ms per token,   632.32 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.57 ms /    39 tokens (    0.89 ms per token,  1128.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      85.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.29 ms /    32 tokens (    0.98 ms per token,  1022.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      66.38 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    12 tokens (    2.24 ms per token,   445.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    24 tokens (    1.15 ms per token,   872.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.11 ms /    30 tokens (    1.04 ms per token,   964.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    22 tokens (    1.23 ms per token,   810.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      77.89 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    24 tokens (    1.14 ms per token,   877.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.55 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      64.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    17 tokens (    1.58 ms per token,   634.66 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.09 ms /    30 tokens (    1.04 ms per token,   965.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.22 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.55 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    25 tokens (    1.23 ms per token,   815.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.83 ms /     3 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =      83.33 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    17 tokens (    1.57 ms per token,   636.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.83 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    14 tokens (    1.97 ms per token,   508.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    14 tokens (    1.97 ms per token,   506.40 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    25 tokens (    1.22 ms per token,   820.94 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      64.29 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.01 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.46 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    18 tokens (    1.50 ms per token,   667.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.41 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    18 tokens (    1.50 ms per token,   668.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    26 tokens (    1.17 ms per token,   852.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.49 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.23 ms per token,   809.81 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    10 tokens (    2.70 ms per token,   370.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.68 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    29 tokens (    1.07 ms per token,   933.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      81.78 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    18 tokens (    1.49 ms per token,   671.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.63 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    19 tokens (    1.42 ms per token,   704.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      60.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.16 ms /    47 tokens (    0.79 ms per token,  1264.77 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      70.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    14 tokens (    1.97 ms per token,   508.74 tokens per second)\n",
      "llama_print_timings:        eval time =      32.83 ms /     2 runs   (   16.41 ms per token,    60.92 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    30 tokens (    1.04 ms per token,   962.71 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      65.75 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    11 tokens (    2.44 ms per token,   409.67 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    31 tokens (    1.01 ms per token,   991.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      65.13 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    21 tokens (    1.32 ms per token,   760.37 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      62.69 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    16 tokens (    1.72 ms per token,   581.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   823.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      81.74 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    16 tokens (    1.73 ms per token,   578.49 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    23 tokens (    1.20 ms per token,   832.64 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    21 tokens (    1.30 ms per token,   770.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    29 tokens (    1.07 ms per token,   936.00 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      65.85 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   636.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      60.62 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      79.25 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    30 tokens (    1.04 ms per token,   959.63 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      65.80 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.17 ms /    22 tokens (    1.23 ms per token,   809.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    18 tokens (    1.50 ms per token,   668.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.50 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.98 ms /    15 tokens (    1.87 ms per token,   536.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      78.95 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.58 ms /    42 tokens (    0.87 ms per token,  1148.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      70.14 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    19 tokens (    1.41 ms per token,   708.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    15 tokens (    1.83 ms per token,   546.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.35 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    17 tokens (    1.59 ms per token,   628.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.86 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.97 ms /    11 tokens (    2.45 ms per token,   407.92 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      78.78 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.08 ms /    46 tokens (    0.81 ms per token,  1240.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      70.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    20 tokens (    1.36 ms per token,   734.30 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.53 ms /    32 tokens (    0.99 ms per token,  1015.07 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      66.37 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    26 tokens (    1.17 ms per token,   851.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      81.24 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.29 tokens per second)\n",
      "llama_print_timings:        eval time =      33.10 ms /     2 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =      62.06 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    18 tokens (    1.49 ms per token,   670.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   705.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.46 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    28 tokens (    1.10 ms per token,   912.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      64.68 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.61 ms /    18 tokens (    1.48 ms per token,   676.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      77.88 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    17 tokens (    1.56 ms per token,   640.08 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    18 tokens (    1.50 ms per token,   666.00 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.19 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    30 tokens (    1.04 ms per token,   961.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      64.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    11 tokens (    2.44 ms per token,   409.24 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.60 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15463.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.55 ms /    31 tokens (    1.02 ms per token,   982.41 tokens per second)\n",
      "llama_print_timings:        eval time =      33.21 ms /     2 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =      66.37 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    16 tokens (    1.72 ms per token,   581.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.29 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      78.01 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.22 ms per token,   816.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      64.18 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   635.09 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      61.42 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.06 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      78.10 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.43 ms /    31 tokens (    1.01 ms per token,   986.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      82.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.76 ms /    16 tokens (    1.74 ms per token,   576.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.89 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    18 tokens (    1.49 ms per token,   669.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.02 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.25 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.35 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.66 ms /    17 tokens (    1.57 ms per token,   637.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      77.76 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    14 tokens (    1.96 ms per token,   509.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      79.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    23 tokens (    1.20 ms per token,   836.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      78.31 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.72 ms per token,   579.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.57 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.86 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.49 ms /    26 tokens (    1.17 ms per token,   852.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      64.31 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    16 tokens (    1.73 ms per token,   579.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.71 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.85 ms /    34 tokens (    1.00 ms per token,  1004.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      85.10 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    26 tokens (    1.18 ms per token,   848.92 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      81.56 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    13 tokens (    2.11 ms per token,   474.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16877.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.53 ms /    39 tokens (    0.89 ms per token,  1129.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      86.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    18 tokens (    1.50 ms per token,   668.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      61.05 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.20 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    21 tokens (    1.28 ms per token,   779.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.91 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    17 tokens (    1.57 ms per token,   637.99 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      76.72 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    20 tokens (    1.36 ms per token,   737.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.61 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   636.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.27 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    16 tokens (    1.72 ms per token,   580.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =      62.43 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    16 tokens (    1.73 ms per token,   576.70 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      61.89 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.75 ms /    17 tokens (    1.57 ms per token,   635.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.44 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    24 tokens (    1.14 ms per token,   875.27 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      62.31 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   676.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.96 ms /    26 tokens (    1.19 ms per token,   839.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      82.13 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    23 tokens (    1.19 ms per token,   838.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    25 tokens (    1.22 ms per token,   821.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      81.77 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    35 tokens (    0.97 ms per token,  1030.38 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      67.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    23 tokens (    1.19 ms per token,   839.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      79.34 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    31 tokens (    1.01 ms per token,   991.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.91 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    14 tokens (    1.96 ms per token,   510.69 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    13 tokens (    2.11 ms per token,   473.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.62 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    21 tokens (    1.30 ms per token,   769.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.58 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.52 ms /    39 tokens (    0.89 ms per token,  1129.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      86.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    20 tokens (    1.36 ms per token,   737.33 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.89 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    21 tokens (    1.30 ms per token,   769.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.45 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    16 tokens (    1.71 ms per token,   584.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 19704.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    18 tokens (    1.48 ms per token,   673.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.43 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    21 tokens (    1.29 ms per token,   776.08 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      62.14 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    22 tokens (    1.24 ms per token,   807.37 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    24 tokens (    1.15 ms per token,   870.23 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      61.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.63 ms /    17 tokens (    1.57 ms per token,   638.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      59.91 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    21 tokens (    1.29 ms per token,   777.52 tokens per second)\n",
      "llama_print_timings:        eval time =      49.65 ms /     3 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =      78.69 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    21 tokens (    1.30 ms per token,   770.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    24 tokens (    1.14 ms per token,   878.64 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    22 tokens (    1.24 ms per token,   805.86 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.76 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    22 tokens (    1.25 ms per token,   797.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.70 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.30 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    10 tokens (    2.68 ms per token,   373.20 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.00 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    20 tokens (    1.35 ms per token,   740.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.34 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    19 tokens (    1.41 ms per token,   708.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.64 ms /    17 tokens (    1.57 ms per token,   638.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.86 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   636.85 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    15 tokens (    1.83 ms per token,   545.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    20 tokens (    1.36 ms per token,   734.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      78.28 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    12 tokens (    2.25 ms per token,   444.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    33 tokens (    1.02 ms per token,   976.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      84.55 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    16 tokens (    1.73 ms per token,   578.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.72 ms per token,   579.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.68 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.86 ms /    15 tokens (    1.86 ms per token,   538.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      62.38 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    19 tokens (    1.41 ms per token,   707.42 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.09 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    26 tokens (    1.18 ms per token,   845.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      81.71 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    23 tokens (    1.19 ms per token,   838.22 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    31 tokens (    1.00 ms per token,  1000.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      82.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    12 tokens (    2.29 ms per token,   437.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.72 ms /     3 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      79.24 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    27 tokens (    1.14 ms per token,   880.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      64.02 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    27 tokens (    1.14 ms per token,   880.22 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      81.71 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    29 tokens (    1.07 ms per token,   935.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      65.16 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      61.14 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.16 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.15 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    26 tokens (    1.18 ms per token,   846.85 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      81.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.51 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      63.93 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    21 tokens (    1.30 ms per token,   770.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.51 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    27 tokens (    1.14 ms per token,   876.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      64.80 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    10 tokens (    2.67 ms per token,   374.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.67 ms /     3 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    32 tokens (    0.97 ms per token,  1026.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.24 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    13 tokens (    2.10 ms per token,   475.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.59 ms /    49 tokens (    0.87 ms per token,  1150.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.27 ms /     2 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =      77.68 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.63 ms /    15 tokens (    1.84 ms per token,   542.81 tokens per second)\n",
      "llama_print_timings:        eval time =      32.79 ms /     2 runs   (   16.39 ms per token,    60.99 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      81.37 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    12 tokens (    2.24 ms per token,   446.31 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      78.05 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      81.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    12 tokens (    2.27 ms per token,   439.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    23 tokens (    1.19 ms per token,   837.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   635.16 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    13 tokens (    2.10 ms per token,   475.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.51 ms /    24 tokens (    1.15 ms per token,   872.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =      79.05 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    13 tokens (    2.10 ms per token,   477.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.58 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.80 ms /    33 tokens (    1.02 ms per token,   976.30 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      68.73 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.38 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      78.03 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.41 ms /    32 tokens (    0.98 ms per token,  1018.88 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      66.37 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.45 ms /    33 tokens (    1.01 ms per token,   986.55 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      67.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    14 tokens (    1.96 ms per token,   510.02 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    14 tokens (    1.94 ms per token,   514.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.43 ms /    16 tokens (    1.71 ms per token,   583.28 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    27 tokens (    1.15 ms per token,   872.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      65.16 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.12 tokens per second)\n",
      "llama_print_timings:        eval time =      33.09 ms /     2 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    11 tokens (    2.45 ms per token,   407.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    14 tokens (    1.97 ms per token,   508.00 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.43 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    15 tokens (    1.84 ms per token,   544.44 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      79.21 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.71 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    31 tokens (    1.01 ms per token,   994.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      65.25 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    13 tokens (    2.12 ms per token,   471.84 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.78 ms /    24 tokens (    1.16 ms per token,   864.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      62.06 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    14 tokens (    1.95 ms per token,   512.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.91 tokens per second)\n",
      "llama_print_timings:       total time =      60.85 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17937.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.58 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.21 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    21 tokens (    1.28 ms per token,   778.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    32 tokens (    0.97 ms per token,  1026.69 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      64.81 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.69 ms /    17 tokens (    1.57 ms per token,   637.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.66 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    29 tokens (    1.08 ms per token,   927.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      66.33 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    17 tokens (    1.58 ms per token,   631.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.28 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.40 ms /    31 tokens (    1.01 ms per token,   987.39 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      65.03 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17621.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.41 ms /    25 tokens (    1.22 ms per token,   822.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      82.45 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    24 tokens (    1.14 ms per token,   879.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.23 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    18 tokens (    1.49 ms per token,   671.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.00 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    20 tokens (    1.35 ms per token,   738.61 tokens per second)\n",
      "llama_print_timings:        eval time =      33.03 ms /     2 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      61.07 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    18 tokens (    1.49 ms per token,   670.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    26 tokens (    1.18 ms per token,   848.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      81.51 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    20 tokens (    1.36 ms per token,   734.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.00 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    24 tokens (    1.14 ms per token,   874.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      77.74 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.51 ms /    17 tokens (    1.56 ms per token,   641.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      60.11 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    22 tokens (    1.24 ms per token,   808.73 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      62.10 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      61.31 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.40 ms /    25 tokens (    1.22 ms per token,   822.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      81.06 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    26 tokens (    1.17 ms per token,   851.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      81.38 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    26 tokens (    1.18 ms per token,   849.90 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      65.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.65 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    18 tokens (    1.48 ms per token,   673.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      77.36 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.77 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    18 tokens (    1.50 ms per token,   665.24 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.16 ms /    13 tokens (    2.09 ms per token,   478.59 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.17 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    13 tokens (    2.10 ms per token,   475.82 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.87 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.32 ms /    37 tokens (    0.93 ms per token,  1077.96 tokens per second)\n",
      "llama_print_timings:        eval time =      33.33 ms /     2 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =      69.93 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    18 tokens (    1.48 ms per token,   677.07 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.41 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      28.05 ms /    15 tokens (    1.87 ms per token,   534.72 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      62.73 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    12 tokens (    2.24 ms per token,   446.36 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.71 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.69 ms /    15 tokens (    1.85 ms per token,   541.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      62.07 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    12 tokens (    2.25 ms per token,   445.43 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.37 ms /    38 tokens (    0.90 ms per token,  1105.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      86.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    21 tokens (    1.28 ms per token,   779.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.79 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    31 tokens (    1.01 ms per token,   991.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.16 ms /     2 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =      65.79 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.13 ms /    22 tokens (    1.23 ms per token,   810.91 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.65 ms /    10 tokens (    2.67 ms per token,   375.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      78.41 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.58 ms /     9 tokens (    2.95 ms per token,   338.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.22 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16483.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    16 tokens (    1.73 ms per token,   577.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.82 tokens per second)\n",
      "llama_print_timings:       total time =      62.51 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.86 ms /    15 tokens (    1.86 ms per token,   538.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.99 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.96 ms /    26 tokens (    1.19 ms per token,   839.93 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      65.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    11 tokens (    2.45 ms per token,   408.12 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      77.69 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    25 tokens (    1.23 ms per token,   815.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      81.95 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    22 tokens (    1.23 ms per token,   813.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.08 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.52 ms /    25 tokens (    1.22 ms per token,   819.03 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      64.27 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    21 tokens (    1.30 ms per token,   772.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.47 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    17 tokens (    1.57 ms per token,   636.25 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      77.49 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    28 tokens (    1.11 ms per token,   900.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.93 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    14 tokens (    1.95 ms per token,   512.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      78.06 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    19 tokens (    1.42 ms per token,   705.93 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    14 tokens (    1.96 ms per token,   509.61 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.77 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    19 tokens (    1.42 ms per token,   702.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   838.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.96 ms /    35 tokens (    0.97 ms per token,  1030.65 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      67.75 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.79 ms /    15 tokens (    1.85 ms per token,   539.80 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      62.02 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    14 tokens (    1.95 ms per token,   512.41 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19512.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    21 tokens (    1.29 ms per token,   776.34 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.74 tokens per second)\n",
      "llama_print_timings:        eval time =      33.13 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      62.28 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    15 tokens (    1.84 ms per token,   544.19 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      61.21 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   824.13 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      63.84 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.81 ms /    10 tokens (    2.68 ms per token,   372.98 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    17 tokens (    1.57 ms per token,   637.11 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      60.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    16 tokens (    1.72 ms per token,   580.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      61.49 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    29 tokens (    1.07 ms per token,   935.82 tokens per second)\n",
      "llama_print_timings:        eval time =      49.71 ms /     3 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =      82.76 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    29 tokens (    1.06 ms per token,   939.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      64.50 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    27 tokens (    1.14 ms per token,   877.56 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =      65.33 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    23 tokens (    1.18 ms per token,   844.28 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      77.80 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.10 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    11 tokens (    2.45 ms per token,   407.97 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      78.83 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    23 tokens (    1.19 ms per token,   839.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =      78.98 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    10 tokens (    2.69 ms per token,   371.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.34 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    17 tokens (    1.58 ms per token,   631.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.67 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.39 ms /    24 tokens (    1.14 ms per token,   876.23 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.77 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    23 tokens (    1.19 ms per token,   841.26 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    27 tokens (    1.13 ms per token,   883.91 tokens per second)\n",
      "llama_print_timings:        eval time =      49.61 ms /     3 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      82.15 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    23 tokens (    1.19 ms per token,   838.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      61.41 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      60.02 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.47 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.48 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    17 tokens (    1.58 ms per token,   634.80 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      61.36 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    23 tokens (    1.19 ms per token,   841.63 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.87 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    21 tokens (    1.29 ms per token,   775.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.31 ms /    14 tokens (    1.95 ms per token,   512.71 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =      61.38 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.71 ms /    14 tokens (    1.98 ms per token,   505.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      78.64 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.51 ms /    25 tokens (    1.22 ms per token,   819.46 tokens per second)\n",
      "llama_print_timings:        eval time =      49.59 ms /     3 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      81.39 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.77 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      62.51 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.34 ms /    25 tokens (    1.21 ms per token,   823.97 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      63.80 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    20 tokens (    1.35 ms per token,   740.60 tokens per second)\n",
      "llama_print_timings:        eval time =      49.39 ms /     3 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      78.19 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.72 ms /    15 tokens (    1.85 ms per token,   541.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      62.14 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    19 tokens (    1.42 ms per token,   704.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    15 tokens (    1.84 ms per token,   543.95 tokens per second)\n",
      "llama_print_timings:        eval time =      49.28 ms /     3 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      78.37 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.28 ms /    22 tokens (    1.24 ms per token,   806.42 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17964.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.37 ms /    30 tokens (    1.05 ms per token,   956.39 tokens per second)\n",
      "llama_print_timings:        eval time =      33.02 ms /     2 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      65.11 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    24 tokens (    1.14 ms per token,   875.59 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      60.84 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    24 tokens (    1.15 ms per token,   872.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      61.39 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    11 tokens (    2.47 ms per token,   404.66 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.89 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    17 tokens (    1.57 ms per token,   636.44 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.29 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.11 ms /    32 tokens (    0.97 ms per token,  1028.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.75 ms /     3 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      83.07 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.88 ms /    34 tokens (    1.00 ms per token,  1003.54 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      67.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.33 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.13 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    18 tokens (    1.49 ms per token,   672.65 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      61.80 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.80 ms /    29 tokens (    1.06 ms per token,   941.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.98 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17751.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    17 tokens (    1.58 ms per token,   632.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      61.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.70 ms /    13 tokens (    2.13 ms per token,   469.31 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      62.44 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.22 ms /    37 tokens (    0.92 ms per token,  1081.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      84.99 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.78 ms /    15 tokens (    1.85 ms per token,   540.02 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      62.59 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.98 ms /    20 tokens (    1.35 ms per token,   741.37 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    11 tokens (    2.44 ms per token,   409.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.37 ms /     3 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      77.84 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      79.23 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    24 tokens (    1.14 ms per token,   876.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.63 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.58 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      60.98 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    14 tokens (    1.95 ms per token,   513.38 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      61.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.53 ms /    35 tokens (    0.99 ms per token,  1013.55 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      69.00 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.62 ms /    17 tokens (    1.57 ms per token,   638.50 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      60.81 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.15 ms /    13 tokens (    2.09 ms per token,   478.84 tokens per second)\n",
      "llama_print_timings:        eval time =      49.32 ms /     3 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      77.20 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    24 tokens (    1.14 ms per token,   876.94 tokens per second)\n",
      "llama_print_timings:        eval time =      49.72 ms /     3 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      79.48 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    30 tokens (    1.03 ms per token,   970.47 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      64.97 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    26 tokens (    1.18 ms per token,   848.40 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.11 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.59 ms /    32 tokens (    0.99 ms per token,  1012.88 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      82.20 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.85 ms /    33 tokens (    1.03 ms per token,   974.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      68.13 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    21 tokens (    1.30 ms per token,   767.49 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.60 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      60.90 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    16 tokens (    1.72 ms per token,   579.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      79.06 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    32 tokens (    0.98 ms per token,  1023.67 tokens per second)\n",
      "llama_print_timings:        eval time =      33.01 ms /     2 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      65.39 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    28 tokens (    1.11 ms per token,   904.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      82.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    22 tokens (    1.24 ms per token,   807.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.76 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    22 tokens (    1.24 ms per token,   806.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      61.29 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      60.83 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    19 tokens (    1.41 ms per token,   709.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.53 ms /     3 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =      77.91 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    16 tokens (    1.71 ms per token,   583.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.51 ms /     3 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      78.59 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.59 ms /    17 tokens (    1.56 ms per token,   639.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      77.40 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    21 tokens (    1.29 ms per token,   774.96 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.04 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.82 ms /    23 tokens (    1.21 ms per token,   826.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      62.04 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.81 ms /    24 tokens (    1.16 ms per token,   863.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      61.57 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.71 ms /    15 tokens (    1.85 ms per token,   541.36 tokens per second)\n",
      "llama_print_timings:        eval time =      49.50 ms /     3 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =      78.52 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.60 ms /    32 tokens (    0.99 ms per token,  1012.66 tokens per second)\n",
      "llama_print_timings:        eval time =      33.17 ms /     2 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      66.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.99 ms /    48 tokens (    0.77 ms per token,  1297.72 tokens per second)\n",
      "llama_print_timings:        eval time =      49.79 ms /     3 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      89.05 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    23 tokens (    1.20 ms per token,   836.21 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.84 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.01 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   837.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.12 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16597.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.02 ms /    21 tokens (    1.29 ms per token,   777.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.90 ms /     3 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =      79.93 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    20 tokens (    1.34 ms per token,   744.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      61.19 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.89 ms /    18 tokens (    1.49 ms per token,   669.34 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.16 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.50 ms /    25 tokens (    1.22 ms per token,   819.81 tokens per second)\n",
      "llama_print_timings:        eval time =      49.73 ms /     3 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =      82.54 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.11 ms /    54 tokens (    0.80 ms per token,  1252.75 tokens per second)\n",
      "llama_print_timings:        eval time =      50.78 ms /     3 runs   (   16.93 ms per token,    59.08 tokens per second)\n",
      "llama_print_timings:       total time =      96.07 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.24 ms /    31 tokens (    1.01 ms per token,   992.29 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =      81.72 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.36 ms /    30 tokens (    1.05 ms per token,   956.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      65.28 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    30 tokens (    1.04 ms per token,   959.17 tokens per second)\n",
      "llama_print_timings:        eval time =      33.08 ms /     2 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      65.63 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    28 tokens (    1.10 ms per token,   912.20 tokens per second)\n",
      "llama_print_timings:        eval time =      32.96 ms /     2 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      64.69 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    15 tokens (    1.82 ms per token,   548.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.02 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.57 ms /    18 tokens (    1.48 ms per token,   677.53 tokens per second)\n",
      "llama_print_timings:        eval time =      32.87 ms /     2 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      60.47 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    20 tokens (    1.36 ms per token,   735.62 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      60.97 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    18 tokens (    1.50 ms per token,   667.58 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.54 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    20 tokens (    1.35 ms per token,   739.15 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      77.65 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.76 ms /    15 tokens (    1.85 ms per token,   540.35 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.55 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.77 ms /    33 tokens (    1.02 ms per token,   977.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      84.26 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.86 ms /    19 tokens (    1.41 ms per token,   707.48 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    21 tokens (    1.30 ms per token,   771.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.56 ms /     3 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      78.65 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.94 ms /    28 tokens (    1.11 ms per token,   904.89 tokens per second)\n",
      "llama_print_timings:        eval time =      32.90 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      64.84 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    18 tokens (    1.50 ms per token,   668.13 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      60.93 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.45 tokens per second)\n",
      "llama_print_timings:        eval time =      49.44 ms /     3 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =      81.13 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    19 tokens (    1.41 ms per token,   709.54 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      77.73 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    16 tokens (    1.72 ms per token,   582.60 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.70 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16806.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    17 tokens (    1.58 ms per token,   633.05 tokens per second)\n",
      "llama_print_timings:        eval time =      49.52 ms /     3 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =      78.38 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    24 tokens (    1.15 ms per token,   868.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.08 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.03 ms /    34 tokens (    1.00 ms per token,   999.09 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      84.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    34 tokens (    1.00 ms per token,   999.56 tokens per second)\n",
      "llama_print_timings:        eval time =      49.46 ms /     3 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      85.23 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    16 tokens (    1.72 ms per token,   583.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.84 ms /     2 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =      61.35 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    13 tokens (    2.12 ms per token,   471.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.81 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    11 tokens (    2.48 ms per token,   403.83 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    22 tokens (    1.24 ms per token,   808.73 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.51 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.85 ms /    33 tokens (    1.03 ms per token,   974.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.15 ms /     2 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =      68.55 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    16 tokens (    1.72 ms per token,   579.86 tokens per second)\n",
      "llama_print_timings:        eval time =      49.40 ms /     3 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      78.29 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    23 tokens (    1.20 ms per token,   831.50 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.56 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    14 tokens (    1.96 ms per token,   509.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.89 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    18 tokens (    1.50 ms per token,   668.28 tokens per second)\n",
      "llama_print_timings:        eval time =      32.82 ms /     2 runs   (   16.41 ms per token,    60.93 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    22 tokens (    1.24 ms per token,   805.89 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =      62.05 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    29 tokens (    1.07 ms per token,   935.76 tokens per second)\n",
      "llama_print_timings:        eval time =      32.92 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.96 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    34 tokens (    1.00 ms per token,  1000.56 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      67.62 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    22 tokens (    1.24 ms per token,   807.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    17 tokens (    1.58 ms per token,   631.10 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      77.71 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 16216.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.38 ms /    22 tokens (    1.24 ms per token,   803.42 tokens per second)\n",
      "llama_print_timings:        eval time =      33.19 ms /     2 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =      62.46 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    13 tokens (    2.08 ms per token,   480.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.34 ms /     3 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =      77.96 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.00 ms /    36 tokens (    0.94 ms per token,  1058.76 tokens per second)\n",
      "llama_print_timings:        eval time =      33.00 ms /     2 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =      67.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.66 ms /    16 tokens (    1.73 ms per token,   578.39 tokens per second)\n",
      "llama_print_timings:        eval time =      49.54 ms /     3 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =      78.86 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.07 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.75 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    15 tokens (    1.83 ms per token,   545.49 tokens per second)\n",
      "llama_print_timings:        eval time =      33.04 ms /     2 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =      61.97 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17391.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.96 ms /    22 tokens (    1.23 ms per token,   816.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      78.47 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17441.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    20 tokens (    1.35 ms per token,   742.25 tokens per second)\n",
      "llama_print_timings:        eval time =      33.05 ms /     2 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =      60.99 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    26 tokens (    1.18 ms per token,   849.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     3 runs   (    0.06 ms per token, 17045.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    21 tokens (    1.31 ms per token,   766.20 tokens per second)\n",
      "llama_print_timings:        eval time =      33.07 ms /     2 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =      61.69 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    10 tokens (    2.71 ms per token,   369.52 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      61.56 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    16 tokens (    1.72 ms per token,   582.14 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.64 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    30 tokens (    1.03 ms per token,   969.87 tokens per second)\n",
      "llama_print_timings:        eval time =      49.62 ms /     3 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =      81.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.68 ms /    16 tokens (    1.73 ms per token,   578.10 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.43 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      61.46 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    19 tokens (    1.42 ms per token,   706.32 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =      61.24 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.15 ms /    30 tokens (    1.04 ms per token,   963.11 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      82.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.74 ms /    18 tokens (    1.49 ms per token,   673.17 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      60.34 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    23 tokens (    1.18 ms per token,   844.78 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      61.52 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      28.17 ms /    16 tokens (    1.76 ms per token,   568.04 tokens per second)\n",
      "llama_print_timings:        eval time =      49.38 ms /     3 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =      79.57 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.88 ms /    28 tokens (    1.10 ms per token,   906.79 tokens per second)\n",
      "llama_print_timings:        eval time =      49.47 ms /     3 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      81.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.21 ms /    31 tokens (    1.01 ms per token,   993.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.75 ms /     3 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =      83.34 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    30 tokens (    1.04 ms per token,   963.73 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      65.57 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    11 tokens (    2.46 ms per token,   405.74 tokens per second)\n",
      "llama_print_timings:        eval time =      49.43 ms /     3 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =      78.20 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.62 ms /    15 tokens (    1.84 ms per token,   543.18 tokens per second)\n",
      "llama_print_timings:        eval time =      49.35 ms /     3 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    30 tokens (    1.04 ms per token,   963.70 tokens per second)\n",
      "llama_print_timings:        eval time =      49.55 ms /     3 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =      82.71 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19354.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    12 tokens (    2.24 ms per token,   446.15 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.88 tokens per second)\n",
      "llama_print_timings:       total time =      60.84 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.00 ms /    21 tokens (    1.29 ms per token,   777.86 tokens per second)\n",
      "llama_print_timings:        eval time =      32.95 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.32 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.53 ms /    15 tokens (    1.84 ms per token,   544.84 tokens per second)\n",
      "llama_print_timings:        eval time =      33.06 ms /     2 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =      62.08 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   853.05 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      64.49 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.40 ms /    14 tokens (    1.96 ms per token,   510.87 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    21 tokens (    1.29 ms per token,   775.17 tokens per second)\n",
      "llama_print_timings:        eval time =      49.42 ms /     3 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =      78.49 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    24 tokens (    1.15 ms per token,   872.06 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      61.90 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    20 tokens (    1.34 ms per token,   744.19 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.12 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.03 ms /    21 tokens (    1.29 ms per token,   776.89 tokens per second)\n",
      "llama_print_timings:        eval time =      49.66 ms /     3 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =      79.03 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    18 tokens (    1.49 ms per token,   672.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.91 ms /     2 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =      60.43 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18987.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.45 ms /    25 tokens (    1.22 ms per token,   820.96 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.59 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.15 ms /     3 runs   (    0.05 ms per token, 19480.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.80 ms /    27 tokens (    1.14 ms per token,   876.68 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =      64.27 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 17341.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.99 tokens per second)\n",
      "llama_print_timings:        eval time =      33.12 ms /     2 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =      61.33 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    31 tokens (    1.01 ms per token,   994.45 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =      65.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.04 ms /    20 tokens (    1.35 ms per token,   739.67 tokens per second)\n",
      "llama_print_timings:        eval time =      32.85 ms /     2 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =      60.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    11 tokens (    2.46 ms per token,   407.27 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =      78.11 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.93 ms /    19 tokens (    1.42 ms per token,   705.51 tokens per second)\n",
      "llama_print_timings:        eval time =      49.36 ms /     3 runs   (   16.45 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =      77.78 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 19108.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.32 ms /    13 tokens (    2.10 ms per token,   475.88 tokens per second)\n",
      "llama_print_timings:        eval time =      32.88 ms /     2 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =      60.88 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    36 tokens (    0.94 ms per token,  1058.29 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      68.51 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.99 ms /    12 tokens (    2.25 ms per token,   444.61 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.87 tokens per second)\n",
      "llama_print_timings:       total time =      61.06 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    22 tokens (    1.24 ms per token,   804.03 tokens per second)\n",
      "llama_print_timings:        eval time =      49.64 ms /     3 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =      79.00 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.58 ms /    26 tokens (    1.18 ms per token,   850.23 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      81.77 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.59 ms /    15 tokens (    1.84 ms per token,   543.75 tokens per second)\n",
      "llama_print_timings:        eval time =      49.48 ms /     3 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      78.97 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    26 tokens (    1.18 ms per token,   849.09 tokens per second)\n",
      "llama_print_timings:        eval time =      32.99 ms /     2 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =      65.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     4 runs   (    0.06 ms per token, 17167.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    28 tokens (    1.10 ms per token,   906.41 tokens per second)\n",
      "llama_print_timings:        eval time =      49.70 ms /     3 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =      83.50 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /     9 tokens (    2.97 ms per token,   336.22 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      60.78 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19138.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    24 tokens (    1.14 ms per token,   877.48 tokens per second)\n",
      "llama_print_timings:        eval time =      49.45 ms /     3 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      77.98 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    20 tokens (    1.34 ms per token,   745.27 tokens per second)\n",
      "llama_print_timings:        eval time =      32.89 ms /     2 runs   (   16.44 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =      60.57 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.77 ms /    17 tokens (    1.57 ms per token,   635.04 tokens per second)\n",
      "llama_print_timings:        eval time =      32.98 ms /     2 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =      61.16 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     3 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    10 tokens (    2.69 ms per token,   372.01 tokens per second)\n",
      "llama_print_timings:        eval time =      32.86 ms /     2 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      61.10 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.79 ms /    10 tokens (    2.68 ms per token,   373.32 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =      77.54 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     4 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.29 ms /    13 tokens (    2.10 ms per token,   476.43 tokens per second)\n",
      "llama_print_timings:        eval time =      49.58 ms /     3 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =      78.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    22 tokens (    1.24 ms per token,   808.79 tokens per second)\n",
      "llama_print_timings:        eval time =      32.93 ms /     2 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =      61.48 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.30 ms /    14 tokens (    1.95 ms per token,   512.78 tokens per second)\n",
      "llama_print_timings:        eval time =      49.30 ms /     3 runs   (   16.43 ms per token,    60.85 tokens per second)\n",
      "llama_print_timings:       total time =      77.94 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.88 ms /    15 tokens (    1.86 ms per token,   537.94 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      61.63 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 19047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.91 ms /    21 tokens (    1.28 ms per token,   780.26 tokens per second)\n",
      "llama_print_timings:        eval time =      49.41 ms /     3 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =      77.55 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     3 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    25 tokens (    1.22 ms per token,   822.83 tokens per second)\n",
      "llama_print_timings:        eval time =      32.94 ms /     2 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =      64.55 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     116.48 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     3 runs   (    0.06 ms per token, 15463.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      28.04 ms /    15 tokens (    1.87 ms per token,   534.95 tokens per second)\n",
      "llama_print_timings:        eval time =      32.97 ms /     2 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      62.89 ms /    17 tokens\n"
     ]
    }
   ],
   "source": [
    "output_sentis = []\n",
    "\n",
    "for text in texts:\n",
    "\n",
    "    PROMPT = \"정확한 챗봇으로서 상대방의 입력에 대해 감정을 맞추자. 모든 대답은 '행복', '분노', '슬픔', '중립', '혐오', '놀람', '공포' 중 하나로 대답해줘.\"\n",
    "    instruction = text\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    generation_kwargs = {\n",
    "        \"max_tokens\": 2048,\n",
    "        \"stop\": [\"<|eot_id|>\"],\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"echo\": True,  # 프롬프트를 출력에 포함합니다.\n",
    "    }\n",
    "\n",
    "    response_msg = model(prompt, **generation_kwargs)\n",
    "    output_senti = response_msg['choices'][0]['text'][len(prompt):]\n",
    "\n",
    "    output_sentis.append(output_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '공포',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '중립',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '분노',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '공포',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '공포',\n",
       " '분노',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '공포',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '행복',\n",
       " '공포',\n",
       " '공포',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '공포',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '중립',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '중립',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '공포',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '공포',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '분노',\n",
       " '혐오',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '혐오',\n",
       " '공포',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '공포',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '중립',\n",
       " '공포',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '행복',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '공포',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '행복',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '분노',\n",
       " '분노',\n",
       " '놀람',\n",
       " '중립',\n",
       " '분노',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '분노',\n",
       " '놀람',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '중립',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '중립',\n",
       " '분노',\n",
       " '행복',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '분노',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '혐오',\n",
       " '중립',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '놀람',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '공포',\n",
       " '놀람',\n",
       " '중립',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '혐오',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '놀람',\n",
       " '놀람',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '행복',\n",
       " '중립',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '혐오',\n",
       " '중립',\n",
       " '혐오',\n",
       " '행복',\n",
       " '분노',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '행복',\n",
       " '행복',\n",
       " '분노',\n",
       " '중립',\n",
       " '행복',\n",
       " '중립',\n",
       " '공포',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '혐오',\n",
       " '행복',\n",
       " '중립',\n",
       " '행복',\n",
       " '놀람',\n",
       " '분노',\n",
       " '중립',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '슬픔',\n",
       " '슬픔',\n",
       " '분노',\n",
       " '중립',\n",
       " '혐오',\n",
       " '분노',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '행복',\n",
       " '놀람',\n",
       " '혐오',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(sentis, output_sentis, labels=['행복', '분노', '슬픔', '중립', '혐오', '놀람', '공포'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>행복</td>\n",
       "      <td>0.701170</td>\n",
       "      <td>0.820864</td>\n",
       "      <td>0.756311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>분노</td>\n",
       "      <td>0.628521</td>\n",
       "      <td>0.545038</td>\n",
       "      <td>0.583810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>슬픔</td>\n",
       "      <td>0.538244</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.614887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>중립</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.602524</td>\n",
       "      <td>0.639331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>혐오</td>\n",
       "      <td>0.820580</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.736967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>놀람</td>\n",
       "      <td>0.777487</td>\n",
       "      <td>0.822715</td>\n",
       "      <td>0.799462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>공포</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>0.738255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class  Precision    Recall  F1 Score\n",
       "0    행복   0.701170  0.820864  0.756311\n",
       "1    분노   0.628521  0.545038  0.583810\n",
       "2    슬픔   0.538244  0.716981  0.614887\n",
       "3    중립   0.680927  0.602524  0.639331\n",
       "4    혐오   0.820580  0.668817  0.736967\n",
       "5    놀람   0.777487  0.822715  0.799462\n",
       "6    공포   0.993976  0.587189  0.738255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': ['행복', '분노', '슬픔', '중립', '혐오', '놀람', '공포'],\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892903225806452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(sentis, output_sentis)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "len(sentis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
