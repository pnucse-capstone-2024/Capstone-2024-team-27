{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from ./mbti-senti-empa_model/unsloth.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Mbti Senti_Model\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  14:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 128255\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Mbti Senti_Model\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: PAD token        = 128255 '<|reserved_special_token_250|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4403.49 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    10.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128255', 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Mbti Senti_Model', 'general.type': 'model', 'general.size_label': '8.0B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "model_path='./mbti-senti-empa_model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = Llama(\n",
    "    model_path='./mbti-senti-empa_model/unsloth.Q4_K_M.gguf', #다운로드받은 모델의 위치\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=33        # Number of model layers to offload to GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자기도 피곤하겠지만 행복한 하루 보내기를 바라.',\n",
       " '네가 그 선배를 좋아하는 만큼 불안이 클 것 같아 나도 마음이 쓰인다. 그동안 많이 고민하고 애태웠을 것 같네. 진심은 통한다고 하잖아, 네 말을 곡해해서 듣지는 않을 테니 너무 염려하지 마.',\n",
       " '그래, 중요한 건 너희가 앞으로 함께할 현재와 만들어갈 미래야. 그러니 일어나지 않을 일에 너무 연연하지 말거라. 그리고 현재에 충실하면 분명히 좋은 결과가 생길 거야.',\n",
       " '저야말로 영광이죠. 앞으로도 이렇게 좋은 일 생기면 언제든 공유해주세요.',\n",
       " '그런 일을 겪으면 누구나 크게 상처받아. 다리가 아팠던 만큼 알지도 못하면서 자기에게 뭐라고 했기 때문에 마음의 상처도 크겠지. 그 사람도 몰라서 그런 거니 당신이 이해해줘.',\n",
       " '우리 딸이 똘똘하고 현명하니 엄마 말을 네 나름대로 잘 소화한 것 같아 보기 좋구나. 그렇게 힘든 일을 이겨내며, 성장하는 모습을 보니 기특해!',\n",
       " '아이는 물론 고생한 아내의 수고를 잊지 않고 알아주는 너의 배려심이 눈부시게 두드러지는 순간이야. 두 사람이 함께한다면 아이도 걱정 없이 건강하게 잘 자랄 수 있을 거야. 다시 한번 아빠가 된 걸 축하해.',\n",
       " '어떤 사람을 만났기에 이런 반응을 보일까 너무 궁금하네.',\n",
       " '네가 힘들어 하던 그때가 생각 나는구나. 얼마나 상처가 컸으면 그 후로 다른 사람을 못 만나고 있겠니. 그 마음을 알 것 같아서 엄마도 무척 속상하네.',\n",
       " '그래 그렇게 그 상황을 이해하려 보면 화가 누그러질 거야. 좋은 감정으로 지내도 부족한 하루인데, 네 감정을 그런 부분까지 쓰지 않았으면 해. 우리 화내지 말고 그 사람들을 이해해보고 흘려 보내 버리자.',\n",
       " '나의 진심이 통해서 다행이다. 너의 문자를 받고 요즘 얼굴이 어두웠던 이유를 깨닫게 되었지. 신경 못 쓴 것 같아서 너무 미안한 마음뿐이었어.',\n",
       " '다 알고, 뻔하고, 지루한 얘기들을 몇 시간이고 들어주느라 네가 정말 지치고 열받겠구나. 엄마도 아빠에게 잡혀서 네 시간 동안 무한 반복되는 얘기를 들은 적이 있단다. 네가 얼마나 지옥 같은 심정이었을지 이해해.',\n",
       " '저도 당신에게 문자로 받은 내용이었지만 제가 되려 상처받을 정도였어요. 그러니 당신은 얼마나 견디기 힘들었겠어요. 정말 당신에게 힘을 주고 싶은 생각 뿐이었어요.',\n",
       " '어머나 언니 너무 축하해요. 작은아들 아직 졸업도 안 했잖아요.',\n",
       " '소중한 인연을 깊게 생각하며 노력하는 모습이 대견하고 멋있어. 이런 사려 깊은 마음이라면 앞으로 인생을 살아가는 데 큰 도움이 될 것 같아. 멀리 있어도 이렇게 같이 음식을 먹으면서 인연을 이어갈 수 있다는 게 신기하기도 하고 말이야.',\n",
       " '정말이야? 응원하는 팀이 진 것도 속상한데 옆에서 그렇게 행동했다니. 화날 만 하다. 그래서 넌 어떻게 했는데?',\n",
       " '당신은 20년이 넘는 시간 동안 육아와 공부, 일을 하면서 단 한 번도 쉬지 않았잖아. 그래서 난 당신이 누구보다 열심히 알차게 살았다고 생각해. 당신이 시간을 허비했다고 할 사람은 아무도 없으니까 당신도 자책하지 않아도 돼.',\n",
       " '나는 변할 수 있을 거라는 믿음이 백 프로 드는 걸요? 괜찮아질 테니 걱정 말아요.',\n",
       " '그런 말을 들으면 친구에게 크게 실망하게 되지. 그 말을 듣게 되었을 때 네 심정이 어땠을지 짐작도 가지 않는걸.',\n",
       " '그래? 몇 명이 같이 타는데? 혼자만 자꾸 낙오가 돼서 뒤따라 가는 거야?',\n",
       " '자기처럼 이렇게 아버지를 위하는 마음을 가진 딸도 흔치 않을 거야. 지금과 같은 마음을 아버지가 아시게 된다면 더 힘을 내시고 병도 이겨내실 수 있을 거야.',\n",
       " '그랬구나. 내 동생이 그동안 티를 안 내서 이렇게 힘들어하는지 몰랐네. 수험생인 네 입장에서 보면 충분히 힘들고도 남는 상황이라 누나도 마음이 안 좋다.',\n",
       " '그거 정말 재미있는 시간이었겠는걸? 오랜만에 친구를 만나면 시간 가는 줄 모르고 떠들게 되잖니. 엄마도 친구들을 만나면 하루 종일 떠들어도 끄떡없는걸.',\n",
       " '아빠는 갑자기 우리 아들이 용돈을 안 받고 직접 아르바이트해서 생활비를 벌겠다고 했을 때가 생각나네. 나는 그때 우리 아들이 정말 대단하구나 느꼈는걸. 내 아들도 정말 대단한 사람이야.',\n",
       " '자기는 어떻게 그렇게 좋은 생각을 할 수가 있는 건지 정말 대단해. 내가 친구라도 너무 기쁘고 행복해했을 것 같아. 친구의 진심 어린 문자를 받고 행복해 했을 자기가 떠올라서 나도 되려 기분이 좋아졌어.',\n",
       " '아냐, 그럴 땐 차라리 이렇게 털어놓는 게 감정에서 벗어나기도 좋지. 다음에도 고민이 생기면 언제든지 말해줘.',\n",
       " '물론 네가 남들보다 키가 작을 수는 있지. 하지만 그렇다고 해서 너라는 사람의 가치가 낮아지는 것은 아니야. 깊이 상처받아 한껏 움츠러든 네 모습을 보고 안타까운 마음에 하는 말이란다.',\n",
       " '감정화자씨가 평소에 화를 잘 내는 타입이 아닌 것을 알고 있었어요. 모든 사람에게 친절하게 대해주는 모습을 보면서 참 좋은 인성을 가진 사람이라고 생각했거든요. 근데 화가 많이 난 것은 종종 있었던 일인 것 같아 이해됐어요.',\n",
       " '넌 이제까지 너무나 잘해 왔어. 앞으로도 삶의 순간에 매번 지치고 쓰러지고 싶은 순간이 올 거야. 하지만 넌 반드시 이겨낼 거야. 바로 오늘처럼.',\n",
       " '그래. 원래 배움은 끝이 없고 생활의 지혜라는 건 이런 일을 겪으며 얻는 거라고 하잖아. 너에게 또 다른 배움의 기회라고 긍정적으로 받아들였으면 좋겠어.',\n",
       " '맞아. 자기가 겪는 기분을 내가 똑같이 느낄 수는 없지만. 우리 둘 다 오늘 만나는 것에 기대가 컸잖아. 나는 오늘 얼굴을 보고 얘기를 나눌 수 있다는 사실에 기대를 많이 했어. 완벽하진 않더라도.',\n",
       " '너무 놀라고 당황하면 그럴 수 있어요. 방법은 같이 찾아보면 되는 거니까 마음의 여유를 가지고 먼저 안정을 취했으면 좋겠어요. 사람이 실수도 하고 그러는 거죠, 이럴 때일수록 긍정적인 마음을 갖는다면 이겨낼 수 있어요.',\n",
       " '맞아. 별거 아닌지 결정하는 건 당사자의 몫이라고 생각해. 하지만 그 일로 자기가 계속 상처를 받지 않았으면 좋겠어. 뭘로 불리든 자기는 동명의 그 사람과는 정반대로 멋진 사람이니까.',\n",
       " '도움이 돼서 다행이야. 다음에도 혹시 불안한 일이 생기면 편안하게 내게 말해줘. 이야기를 털어놓는 것만으로도 어느 정도 감정이 진정될 때가 있더라고.',\n",
       " '그건 정말 스트레스겠더라, 내 동생도 규칙 힘들어하고 심지어 기숙사 룸메이트랑 사이가 안 좋았거든.',\n",
       " '누구나 다양한 방식으로 홀로서기를 연습하는 법이잖아요. 당장은 옛 연인 생각에 울적해서 더 부정적인 마음이 드는 것도 있을 거예요. 이 시기를 잘 통과하고 나면 감정화자씨는 혼자여서 더 멋지고 단단한 사람이 되리라 생각해요.',\n",
       " '나도 너처럼 실패해 본 경험이 있어서 너의 걱정되는 마음에 너무 공감돼. 그렇지만 곧 진행될 수강 정정 기간에 남은 시간표를 복구할 수 있는 기회가 있을 거야. 수강 신청 때 신청하지 못했던 과목들을 다시 신청할 수 있었거든.',\n",
       " '넌 이제 막 대학에 들어갔잖아. 모든 친구들과 친하게 지내고 싶었을 텐데, 갑자기 그런 일이 생겨서 정말 당황했겠구나. 상상만 해도 식은땀이 나는걸.',\n",
       " '그건 네가 진지하게 이 강아지를 대하고 있다는 방증이라고 생각해. 내가 보기에 너는 아주 좋은 주인이 될 것 같아. 그러니 너무 염려 말아.',\n",
       " '뭘, 나에게는 모든 게 다 소중한 너라는 거 잊지 마. 난 자기의 선택을 늘 존중해. 내가 곁에서 많이 도와주고 싶어.',\n",
       " '감정화자님에게 앞으로도 좋은 일만 생길 거예요. 상황은 점점 개선되어 그 전처럼 완벽하게 개선될 겁니다.',\n",
       " '감정화자씨 그 회사 어렵게 준비해서 겨우 들어간 회사잖아요.',\n",
       " '그래도 불행 중 다행으로 아무도 다치지 않았잖아? 결국 모두 멀쩡히 집으로 돌아갔으니까 그렇게 자책할 필요는 없어. 그리고 그 가족도 네가 고의로 그런 게 아니란 걸 분명 이해해 줄 거야.',\n",
       " '그럼! 전교 1등에 장학금에 효도까지 무려 일석삼조인걸? 부모님도 엄청 좋아하실 거야. 우리 다음 시험 확실하게 준비해서 절대 후회할 성적 만들지 말자!',\n",
       " '어느 정도 납득할 만한 수준의 차이였으면 네가 이렇게 놀라지는 않았을 텐데 말이야. 나도 신체 나이가 열살 늙었다고 들으면 넋이 나가서 혼비백산했을 거야. 갑자기 아저씨가 되다니 너무 슬프잖아.',\n",
       " '화목하고 좋은 가족에 새 식구가 들어왔으니, 더 화목해지겠구나! 정말 보기 좋고 부럽다.',\n",
       " '아빠 역시도 그런 연애를 해 봤었어, 그래서 네 심정이 얼마나 답답한지 충분히 이해한다. 사랑을 계속 증명해야 하는 상황도 답답할 테고, 네 노력을 알아주지 않아서 서운하기도 하겠지. 우리 아들이 마음고생을 많이 했을 것 같네.',\n",
       " '그래, 잘 생각했어! 제부랑 차분히 대화를 시도한다면 아마 제부도 충분히 잘 이해해줄 거야. 정확하게 분배가 안 되어있어서 제부도 혼란스러워 그런걸 테니 한번 얘기 잘 나눠봐.',\n",
       " '그래? 기분이 정말 좋았을 거 같다. 요즘엔 이웃끼리 교류가 없는 경우가 많잖아. 받았을 때의 기분이 이해 간다.',\n",
       " '왜 안 그러겠어, 누구나 그런 마음이 들 수밖에 없을 거야. 하지만 너무 마음 무겁게 생각하면서 자기가 속상해하는 일은 없었으면 좋겠어. 지금 당황스러운 그 상황도 힘들 텐데 자신을 비난하지는 말았으면 해.',\n",
       " '과장님이 그런 생각을 할 수밖에 없는 상황이라 이해가 되네요. 저도 이전에 이런 일을 겪은 적이 있는데 평정심을 찾는데 꽤 오랜 시간이 걸렸답니다. 하지만 속으로 상대를 원망할수록 저만 힘들어진다는 걸 그때 깨달았어요.',\n",
       " '우와, 자기야. 어떻게 그런 착한 생각을 했어? 비를 맞으면서 다른 사람에게 우산을 주고 오기 쉽지 않은데, 정말 존경스러워.',\n",
       " '운전면허를 따는데 시간이 대략 한 달 조금 넘게 걸리는 것 같아. 너가 지금 일을 한다면 야간반으로 운영되는 운전면허 학원을 다니는 게 어때?',\n",
       " '나도 얻어먹는데 같이 감사인사 드릴 수 있어야지. 언니한테 조금 도움이 된다면 더 좋고.',\n",
       " '작가님이 얼마나 열심히 공들여서 준비한 작품인지 옆에서 지켜본 사람으로서 마음이 너무 아프네요. 특히 시청률은 수치를 눈으로 볼 수 있는 것이니 더욱 신경 쓰이고 불안하시겠어요. 하지만 아직 섣불리 판단하긴 일러요.',\n",
       " '물론이죠. 비록 지금은 취미로 인한 작은 기쁨인 것 같겠지만 그런 사소한 즐거움이 쌓여 일상이 되잖아요. 행복한 일상은 인생의 고난을 이기는 힘이 되고 성장의 기회가 돼요. 그러니 본인의 힘을 기르기 위함이라 생각하며 자신에게 집중해 보아요.',\n",
       " '힘들고 괴로워도 꼭 돌아오겠다는 그 말을 믿고 견뎌 냈을 시간들이 유난히 아프게 느껴질 듯해. 깊이 사랑하고 아꼈던 만큼 크게 좌절하게 될 수밖에 없어서 많이 힘들었겠어. 어렵겠지만 기운 내고, 너무 슬퍼하지 않았으면 좋겠어.',\n",
       " '네가 그렇게 마음먹었다니 나도 다행이라는 생각이 든다. 그 상황에서도 집사람 걱정하고, 솔직하게 얘기하려는 걸 보니 너는 정말 좋은 남편인 것 같다. 부부 사이는 그렇게 서로에게 솔직할 때 더 단단해지는 것 같아.',\n",
       " '아이고, 우리 여보 상심이 너무 크겠어. 내가 직접 떠줬다고 진짜 행복해하고 좋아했는데. 그걸 지금 잃어버려서 마음이 찢어질 듯 아플 거 같아.',\n",
       " '동생이랑 싸운 것도 맘이 안 좋은데 엄마가 나한테만 뭐라고 하면 너무 서운하지. 그것도 항상 잘잘못은 따지기도 전에 너를 먼저 혼내신다면서 네가 충분히 상처받을 만해. 그런 일이 반복된다면 싸우기 시작하는 순간 혼날 생각에 두려움이 생길 것 같기도 해.',\n",
       " '다행이야. 지금처럼 마음을 좀 편하게 가지고 기다려보자. 마음이 가벼워지면 소화도 더 잘 될 수 있을 거야.',\n",
       " '왜 안 그러겠어. 당연히 그런 마음이 들 수밖에 없지. 우리 아들이 생각하기엔 그 친구들에 비해 노력하고 있지 않는다, 생각해서 부끄러운 거지?',\n",
       " '그래, 언제든 하고 싶은 이야기가 있으면 편하게 연락해.',\n",
       " '정말 기특하네! 보람찬 기분을 느낄 수 있도록 하면 칭찬을 자주 들을 수 있을 거야!',\n",
       " '일단 감정화자씨가 관계 개선의 의지가 있으니 서로 허심탄회하게 생각을 털어놓을 기회만 잡으면 잘 풀려나갈지도 몰라요.',\n",
       " '그래도 시부모님 앞인데 긴장하고 정신 차리면 실수도 많이 줄지 않을까요?',\n",
       " '아무래도 그렇지. 그래도 너무 불안해하지 말고 마음을 좀 편히 먹어봐. 부정적으로 생각하다 보면 오히려 소화도 더 잘 안되고 마음만 심란하잖아. 네 취업이 다 잘되기 위한 작은 액땜이라고 긍정적으로 생각해보는 건 어때?',\n",
       " '아냐, 내 작은 위로가 도움이 돼서 다행이야. 여러모로 마음고생이 심할 텐데 잘 추스르고 친구들과도 다시 잘 지내기를 바랄게!',\n",
       " '차장님 나름대로의 방법인가 본데 그게 사람들에게는 상처를 주나 보구나. 그나마 당신을 싫어해서 상처를 줄 생각으로 한 말은 아닌 것 같아 다행이다.',\n",
       " '글쎄요, 우리 사이가 어떤가 잘 모르겠네요. 그냥 철들 줄 모르는 나이 많은 아들 데리고 산다고 생각하고 있어요.',\n",
       " '당신 행복이 곧 내 행복이니 당신이 원하는 대로 해. 나는 꿀을 모아 오는 일벌처럼 열심히 돈을 벌게. 당신은 여왕벌처럼 풍요로운 마음으로 지내.',\n",
       " '분명히 잘할 거야, 엄마는 우리 딸 믿어. 우리 딸은 처음 하는 거라도 항상 용기 있고 훌륭하게 해내잖아, 엄마는 네가 너무 자랑스럽다.',\n",
       " '멋진 생일 선물을 받아서 얼마나 좋았을지 상상이 되네. 친구를 생각하는 그 마음에 나도 되려 감동받아서 울컥했어. 정말 친구와 당신의 우정은 본받아야겠다는 생각이 들어.',\n",
       " '대화가 잘되지 않으니 근심이 크겠구나. 그 나이엔 자기도 뭘 하고 싶은지 몰라서 답답해하는 경우가 많은 것 같아. 오히려 자꾸 묻기보다는 아이를 믿고 시간을 좀 주는 게 도움이 될 때가 있어.',\n",
       " '언니, 사람마다 중요하게 생각하는 가치가 다른 법인데 그걸로 이상하게 보는 게 이상한 거야. 그런 가방들로 증명하지 않아도 언니와 형부는 참 멋진 사람들인걸. 남의 시선을 의식하지 말고 지금 언니가 생각하는 중요한 가치를 우선하면 돼.',\n",
       " '걱정하지 마. 그 팀장이 이상한 거라니까? 아니 신입이면 더 챙겨주고 도와줘야지. 맨날 화만 내고!',\n",
       " '기대될만하지. 얼마나 고대하던 시간이니. 복직 준비는 잘 해놨어?',\n",
       " '나였어도 좋은 추천서를 받게 되면 많이 기쁠 것 같아. 나도 같은 학과를 전공하다 보니 부럽기도 하고, 자기가 얼마나 기쁠지 상상이가. 자기의 기쁜 마음이 너무나 공감이 된다.',\n",
       " '왜 그래 자기, 잘 다니고 있는 줄 알았는데 무슨 일 있어?',\n",
       " '그래. 그 옷을 결혼식에 못 입고 가게 된 건 아쉽지만 옷걸이가 중요하잖아. 비율이 좋은 너는 옷장에 있는 옷을 그대로 입더라도 예쁠 거야!',\n",
       " '뒤죽박죽 어지러워서 놀란 마음이 더 크게 와닿으셨죠? 근육통 처음 겪으시는 분들은 낯선 불편함이 크게 와닿아서 혼란스러우실만해요. 말로 듣는 것과 직접 겪어보시는 것의 차이가 크죠?',\n",
       " '당신이 요즘 나에게 말했던 게 다 생각나고 속상해하는 당신의 진심이 느껴져서 너무 안타까워요. 얼마나 힘들고 외로울까요. 당신을 돕고 싶어도 이렇게 문자로만 이야기할 수밖에 없는 현실이 더 슬프네요.',\n",
       " '오죽하겠어요. 그때 그 기억이 죽을 때까지 없어지진 않겠지요.',\n",
       " '바로 해결책을 찾다니 대단한데? 맞아 장사는 음식뿐만아니라 고객을 대하는 일도 중요하니까. 어려운 고민일 줄 알았는데 해결된 것 같아서 다행이다.',\n",
       " '당신은 항상 하기 싫은 일도 귀찮아하지 않고 하는 모습이 정말 대단해. 나도 당신의 그런 모습을 보면서 배우려고 항상 노력하게 되더라.',\n",
       " '과정이 조금 아쉽고 당황스러우셨겠지만, 결과적으로는 정말 잘하셨다고 생각해요. 그 순간에는 가슴이 철렁 내려앉는 것처럼 괴로우셨겠지만 이렇게 멋지게 이겨 내셨잖아요. 벌써 훌쩍 지나가 버린 시간이니 속상했던 건 마음에서 훌훌 날려 보내세요.',\n",
       " '그렇다면 다행인데, 직원이 구해지지 않아서 혼자 있으려니 정말 힘들 것 같아. 곧 직원 구해질 거야. 너무 스트레스라고 생각하지 말고, 주말에 나랑 같이 해소하도록 하자.',\n",
       " '안 그래도 그럴 생각이야. 형은 조금 진정됐다 하더라도 계속 조카 곁에 있을 거지? 형 이런 상황 생기면 긴장해서 잘 안 떠나잖아.',\n",
       " '네 잘못도 아닌데 그럴 필요가 뭐 있어. 아무도 너를 이상하게 생각할 사람 없을 거니까 너무 걱정하지 마. 역시 넌 마음이 넓어서 사람들을 잘 이해해 주는 거 같아.',\n",
       " '뭐? 너무 당황스러웠겠다. 지금은 괜찮아?',\n",
       " '네가 노력해 왔다는 거 나는 알아. 지난 3년간 잠도 줄이면서, 코피 흘리며 공부하던 네 모습을 생각하면 너 정말 열심히 살았어. 그런 네 모습은 본받고 싶은 정도로 멋있었어.',\n",
       " '응, 잘하고 와!',\n",
       " '자기 말대로 힘들게 취직까지 했는데 그런 말을 들어서 너무 속상하겠다. 형이 독립하고 싶은 욕구가 강해서 실수한 걸 테니 너무 마음에 담아두지 않았으면 좋겠어. 형도 분명 진심을 담아 한 소리가 아닐 거야.',\n",
       " '당신이 그런 생각을 해서 더 당황하고 있었구나. 우리 나이에는 잠깐씩 깜빡깜빡하는 건망증이 있지 않나? 다들 기억력에 자신 없어 하니까 너무 걱정할 필요는 없을 것 같아.',\n",
       " '나야말로 네가 마음이 어려울 때 나를 생각하고 연락해 줘서 너무 고마워. 앞으로도 마음이 복잡하거나 힘든 일 있으면 언제든지 연락해!',\n",
       " '그래. 그리고 남편도 평생 죄책감이 생길 수도 있어. 평소에 너한테 잘해주는 남편이니까 이번엔 서운하더라도 잘 이야기해서 풀었으면 좋겠어.',\n",
       " '마음을 조금 편안하게 가지시는 것도 좋을 것 같아요. 날씨도 궂고, 도로도 통제된 상황이니 감정화자씨의 잘못이 아니었다고 생각해요. 모두 감정화자씨의 상황을 고려하고 이해하고 계실 테니 감정화자씨도 마음을 내려놓으세요.',\n",
       " '저런, 새 차를 샀다고 좋아하던 네 모습에 덩달아 오빠도 기분이 좋아졌었는데. 그런 소중한 차에 냄새나는 김칫국이 스며들었으니 순간 얼마나 화가 나고 속상했을까. 혼자 어쩔 줄 모르는 널 생각하니 당장이라도 달려가서 해결해 주고 싶은데 일 때문에 어쩌지.',\n",
       " '우리 아들이 정말 크게 마음이 다쳤나 보구나. 그럼 충분히 그럴 수 있지, 너는 올바른 일이라고 생각해서 말린 건데. 친한 친구들이 너에게 화를 내고 다툼을 하게 되었으니 상처받는 게 당연해.',\n",
       " '시험 결과도 아직 안 나왔는데 재수해야겠다니 이게 무슨 말이야. 어떤 특별한 일이라도 있었던 거니?',\n",
       " '부장님도 자기가 얼마나 유능하고 실력 있는 사원인지 다 아실 거야. 그동안의 자기 실적이 다 말해주잖아. 다만 이번에는 부장님이 너무 조급해지셨는지 어깃장을 놓으시는 것 같아.',\n",
       " '더 열심히 하려고 잔업을 한 건데 곧바로 작업장에 갇히는 사고가 벌어져서 얼마나 화가 났겠어. 그 와중에도 지혜롭게 대처하려고 침착하게 생각하는 자기 모습이 대견하네. 나였으면 막막하고 화가 나서 아무것도 생각나지 않았을 텐데, 대단하다.',\n",
       " '아빠 입장에서는 같이 살던 딸이 남자 친구와 며칠씩 있다고 하니 무척 걱정되신 것 같아. 네 말대로 너도 나이가 있고 네 앞가림도 알아서 잘하겠지만 그래도 아빠는 걱정되실 거야. 하지만 네 말을 쭉 들어보니 잘 말씀드리면 아주 이해하기 힘든 부분은 아닐 거라 생각해.',\n",
       " '남자 친구도 너를 행복하게 만들어주고 싶었는데, 실수를 해서 속이 상할 거야.',\n",
       " '친구 엄마는 핸드폰 많이 한다고 엄청나게 혼냈는데, 엄마는 결국 친구가 남는 거라고 격려해 주셨잖아요. 그 모든 게 저에게는 인간관계를 이끌어갈 자양분이 되었어요. 엄마는 칭찬받아 마땅한 분이라고요.',\n",
       " '엎친 데 덮친 격으로 상황이 좋지 않게 흘러갔으니, 네가 지금 얼마나 괴롭고 비참할지 알겠어. 신체적 고통도 있지만, 정신적 고통도 무시할 수 없다는 거 알아. 그러니 내게 토로하면서 푸념해도 되고, 무섭다고 울어도 괜찮아.',\n",
       " '나도 기대할게! 잘 다녀와 자기야!',\n",
       " '네가 아무리 예약을 해도 어떻게든 남편이 피해 다니니 얼마나 더 속상하겠어. 남편이 귀찮아서 그러겠지 특별히 말 못 할 이유 때문에 피하는 것은 아닐 거야. 그러니 너무 속상해하지 마.',\n",
       " '엄마, 제가 미리 잘 살펴드리지 못해 죄송해요. 이제부터라도 엄마 마음 많이 챙겨 드릴게요.',\n",
       " '그래도 이렇게 마음을 단단히 먹고 앞날을 기약하는 게 정말 쉬운 일이 아닌데. 역시 너는 정말 대단하고 멋있는 동생이야!',\n",
       " '저런, 미리 조심해달라고 당부한 사항이 지켜지지 않아서 무척 당황스럽고 속상했겠다. 또 강제로 턱을 벌리는 과정도 너무 불쾌했을 것 같아.',\n",
       " '우리 품에만 두던 그 작은 아이가 하루하루 성장하면서 멀어지는 것 같아서 그런 걸 거예요. 정신적으로는 잘 성장하고 있으니 너무 염려 말아요 여보.',\n",
       " '욱하면 그럴 수 있죠. 근데 안 던졌으니까 결국엔 차분히 행동하신 것 같아요. 지금은 문제가 잘 해결됐어요?',\n",
       " '다음에는 꼭 확인 잘해달라고 얘기하고 말 심하게 한 것 같다고. 미안하다고 토닥토닥해주고 오자 원래 다 형제자매는 싸우면서 자라는 거라고 어른들이 늘 말씀하시잖아 괜찮을 거야. 동생도.',\n",
       " '마음이 너무 안 좋았겠다. 내심 잡아주길 바랐을 텐데 남자 친구가 마음을 몰라주니 섭섭했겠어요.',\n",
       " '그 말씀 그대로 정말 활기가 느껴져요. 아이들 돌볼 때 수월해진다는 기분을 저도 느껴보고 싶어지네요.',\n",
       " '그런 얘기까지 들어야 했다니 정말 속상했겠다. 네가 수학 점수가 조금 낮긴 하지만 그래도 열심히 노력하고 있는데 말이야. 네 노고를 지켜보셨다면 그런 말을 못 했을 텐데 안타깝구나.',\n",
       " '지금 시작이니 너무 1일 1식에 부담 갖지 말고. 천천히 줄여가며 길게 오래갔으면 좋겠다. 같이 운동도 하면서 건강해진다고 생각하며 해봐.',\n",
       " '충분히 당황스러울 만한 상황이네요. 혹시 제 카디건 빌려드릴까요? 감정화자씨랑 저랑 다행히도 체격이 비슷하잖아요.',\n",
       " '누구나 시행착오를 겪으면서 더 단단해지죠, 실수를 두려워하지 마세요. 대신 몇 배 더 노력하시면 되잖아요. 전 감정화자님을 믿어요, 잘 해 내실 거예요.',\n",
       " '네 마음이 편해지면 멈출 것 같지 않던 콧물도 언젠간 멈추지 않을까? 스트레스는 온 병의 근원이니까 극복하려는 마음을 갖고 긍정적으로 산다면 이겨내리라 믿어. 지금은 정말 힘들겠지만, 넌 분명 극복할 수 있을 거야.',\n",
       " '사표도 맘대로 못 내는 감정화자 심정이 어떨까 생각하니 정말 가슴이 아프다. 내가 어떻게 해줄 수 없는 일이라 더 속상해. 그런 형편이라면 마음을 굳게 먹고 잘 버텼으면 좋겠다.',\n",
       " '돈은 또 벌면 되지만 건강은 한 번 잃으면 회복하기 어렵잖아. 난 네가 아픈 게 걱정이야. 꼭 치료받았으면 좋겠어.',\n",
       " '회사가 바로 옆 건물이라서 그랬던 건데, 사이가 유난히 좋아 보였나 보네요. 감정화자씨도 늘 잘 지내시는 것 같았는데, 혹시 무슨 일이 있으신가요?',\n",
       " '부모님도 아마 그 마음 다 아시고 신경 써서 운전하실 테니 너무 걱정 마세요. 외제차니 아무래도 더 살살 몰지 않으실까요? 다른 사람 차를 빌려 타게 되면 아무래도 좀 조심하며 타게 되잖아요, 부모님도 그러실 테니 너무 염려 말아요.',\n",
       " '옆에서 지켜보는 나도 이렇게 속상하고 슬픈데 당신 마음은 오죽 무겁고 슬플까? 생활비는 나도 벌고 있으니까 너무 걱정하지 말고, 당신이 힘냈으면 좋겠어. 어떻게 매번 실적을 다 채워, 사람이 그럴 때도 있고 그런 거니까 너무 낙담하지 마.',\n",
       " '가방을 잃어버려서 화가 나신 감정보다 즐거운 감정이 더 커질 수 있을거예요. 그리고 가방을 찾으실 수도 있고요. 지금 당장은 너무 속상하겠지만 긍정적으로 생각하시다보면 분명 일이 잘 풀릴 수도 있을 겁니다.',\n",
       " '고맙긴. 자기가 현명한 엄마니까 금세 마음 가라앉히고 방법을 찾아낸 거지. 저녁에 일찍 들어갈게.',\n",
       " '나는 내 일도 아닌데도 이렇게 열받는데, 넌 오죽했겠니. 좋은데 예약해서 잘 놀다 와.',\n",
       " '며칠 전에도 이력서 썼잖아. 꾸준히 계속 지원하고 있구나.',\n",
       " '지금의 넌 예전과 완전히 다르잖아. 모든 걸 완벽하게 다 아는 사람은 있을 수 없어. 배우려고 노력하는 자세가 중요하지.',\n",
       " '그럼. 네가 얼마나 기다려온 여행인지 내가 너무 잘 알지. 그렇게 회사 일 때문에 고생하다가 여행 가려니까 기분이 더 좋겠어.',\n",
       " '여보, 당신은 어떤 모습으로 있어도 내 눈에 그 누구보다 멋지고 근사한 사람이야. 그런데도 정말 속상하고 괴롭다면 언제든 나한테 얘기해 줘.',\n",
       " '그랬구나. 너랑 강아지가 매우 아끼는 목줄이었나 보네. 보통 소중한 게 아닌 것 같은데, 어떤 큰 의미가 있는 것 같네.',\n",
       " '그건 그럴 것 같아. 매달 월급 계획적으로 소비해 온 거에서도 또 조정하려니 힘들 것 같긴 해. 한두 달로 끝나는 것도 아니어서 더 막막한 마음이 드는 걸까?',\n",
       " '왜 그래, 은행에서 무슨 일 있었어?',\n",
       " '당신 잘못이 아닌데 눈치 볼 필요 없지. 당신이 얼마나 우리 가족을 위해 최선을 다하는지 아는데.',\n",
       " '이 세상에 어떻게 수학을 잘하는 사람만 있을 수 있겠니. 나는 그렇게 힘든 상황에서도 수학을 포기하지 않고 더 열심히 공부하는 아들이 멋지기만 한데. 자신의 결점을 알고 극복하려는 끈기와 성실함은 엄마도 배우고 싶을 정도야.',\n",
       " '입양아라는 사실을 알았다고 해서 바뀌는 건 아무것도 없어요. 당신은 여전히 사랑받는 부모님의 딸이고 가족이에요. 앞으로도 당신을 사랑으로 안아주고 든든한 울타리가 되어줄 부모님이잖아요.',\n",
       " '일단 너 혼자 참고 끙끙 앓아서 해결될 문제는 아닌 거 같으니. 여자 친구와 먼저 대화를 해봐. 나는 그게 제일 먼저일 거 같아.',\n",
       " '오래 그리워했던 친구랑 만나서 하루 종일 함께 지낼 예정이니 얼마나 더 즐겁겠어. 당신 덕분에 좋은 경험 앞두고 떨려서 일이 손에 안 잡혀.',\n",
       " '고맙긴. 너는 원래 긍정적인 친구인걸. 언제든 도움이 필요하면 연락해!',\n",
       " '아파트를 못 사준다면 결혼을 안 시키겠다는 말을 들었으니 자네가 얼마나 괴롭겠어? 해줄 수 있으면야 다해주고 싶은 게 부모 마음이지 나라도 그런 말을 들었으면 상처받았을 거야.',\n",
       " '그래도 선택과 집중을 통해서 다른 걸 잘 봤을 거야. 준비할 시간이 많이 없었잖아. 너무 상심해하지 마.',\n",
       " '맞아요, 잘해야 한다는 부담감은 언제나 실수를 불러오게 마련입니다. 아주 잘 생각하셨어요, 부담감을 좀 내려두세요.',\n",
       " '잘 생각하셨어요. 지금 무슨 위로도 괜찮지 않으실 두 분이라는 걸 잘 알아요. 하지만 놀라셨을 어머니를 생각해서 대리님이라도 냉정을 찾으셔야 할 것 같아요.',\n",
       " '그래도 난 당신이 너무 자책하지 않았으면 좋겠어요. 누구나 부모님께 더 잘해드리지 못해서 죄송스러운 마음은 항상 가지고 있는 거잖아요. 그리고 이제부터라도 어머님 모시고 더 많은 시간을 함께 보내면 되죠.',\n",
       " '네 마음이 뭔지 충분히 이해해. 아이들이 사춘기라서 그런지 우리 이야기는 그냥 잔소리로 듣더라. 내 마음을 몰라주는 것만큼 속상한 게 없는 것 같아.',\n",
       " '감정화자씨는 지금도 충분히 잘하고 있으니까 지금처럼만 해! 더 잘하려고 할 필요도 없고 일하는 데 부담 가질 필요도 없어.',\n",
       " '그래 우리도 사춘기 때 그냥 늘 뭔가 만족스럽지 않고 마음에도 안 들고 그랬잖아. 분명 이 시기만 잘 이겨내면 더 크게 성장할 거야. 자립심이 강한 멋진 우리 아들이 될 거야.',\n",
       " '자기가 아프면 돈이 다 무슨 소용이야. 이게 다 같이 잘 살자고 하는 건데. 난 자기 없으면 삶의 낙이 없다니까.',\n",
       " '저런, 지금 네 심정이 어떨지 감히 상상도 못하겠어. 강아지가 많이 안 좋은 거니?',\n",
       " '출장을 가면 더 바쁘고 시간 안에 일들을 빨리 처리해야 하니 얼마나 더 힘들겠어요. 게다가 이번처럼 멀리 출장을 간다면 체력적으로 더 힘든 건 당연해요. 혼자가 아니라 동료랑 둘이라도 갔으면 덜 힘들 텐데 너무 마음이 안타깝네요.',\n",
       " '네가 무슨 마음을 가지고 있는지 충분히 이해 가. 실패했다는 이유로 기분이 안 좋아지기도 하고 우울해지기도 하겠지. 하지만 그 감정에 속지 않고 훌훌 털어버리면 되는걸.',\n",
       " '그동안 혼자의 시간을 감내해내느라 마음이 얼마나 찢어졌을까요. 정말 누구보다도 외로웠을 것 같아요.',\n",
       " '인터넷으로 엄청 따져가면서 골랐던 호텔인데 안 좋다니 당신 속상하겠네. 얼마나 안 좋으면 당신이 그렇게 화나 났을까?',\n",
       " '그렇지. 하루 동안 스마트폰을 꺼놓는다거나, 산책할 때 들고 가지 않는다거나, 밥 먹을 때 스마트폰 꺼내지 않기 등등...',\n",
       " '우리 아이도 당신도 나도 한걸음 성장하는 과정이예요. 자연스럽게 받아들이면 돼요. 너무 상심해하지 말고 응원하자고요.',\n",
       " '일 처리를 어떻게 그렇게 하죠? 감정화자씨 진짜 어이없겠다.',\n",
       " '첫 출근이라 많이 설레고 기대했을 텐데 당황하기만 한 것 같아서 속상하다. 하지만 네가 그 회사를 선택하게 된 이유가 있다고 생각해. 분명 일은 하다 보면 익숙해질 거야, 조금 더 그곳에 들어간 목적에 집중하면 어때?',\n",
       " '나도 그런 일이 있긴 한데, 자주 그런 일이 생기면 당연히 짜증 나지. 그리고 감정화자씨 오늘 야구 본다고 술자리도 마다하고 집으로 향했으니 속상함은 이루 말할 수 없지.',\n",
       " '충분히 화가 날 수 있어. 소중한 사람이었기에 더욱더 그럴 수 있다고 생각하고 전혀 이상하지 않아. 마지막까지 친구도 위로하고 당신도 애도하고 왔으면 좋겠어.',\n",
       " '그래, 잘 넘어갈 테니 너무 떨지 말고 차분하게 있어. 안개 구간 넘어가면 아버님께 고생했다고 말씀 꼭 드리고. 나한테도 연락해줘!',\n",
       " '그래, 친구야. 네가 그런 이유로 사과를 보냈다는 이야기를 듣고 아주 최고의 사과를 먹은 것처럼 기분이 좋았어. 내 말 믿고 마음 편안하게 가져!',\n",
       " '네가 기운 차린 걸 보니까 내가 다 안심이 되는걸. 다음에도 이런 일이 오면 먼저 대화해서 풀기를 바랄게!',\n",
       " '다행이네요, 당신이 상처를 너무 깊게 받은 당신이라는 생각이 들어서 염려가 되었어요. 그래서 내가 어떤 방법을 사용해서 든 지 당신에게 힘을 주고 싶었어요.',\n",
       " '왜, 무슨 이유라도 있어?',\n",
       " '그렇지? 이렇게 시트콤처럼 넘어가면 큰일도 좀 가볍게 환기가 되더라. 물론 오늘 네가 넘어진 일은 큰일 축에도 못 끼지만.',\n",
       " '당신이 늘 그래왔던 것처럼 평범하게 안부 물으면 되죠. 어머님께서도 당신이랑 시간을 자주 보내고 싶은 마음에 서운하다고 말씀하셨을 거예요. 당신도 어머님께 서운한 마음 몰라드려서 죄송하다고 솔직하게 말해봐요.',\n",
       " '내가 오늘은 정시에 퇴근해서 그릇도 찾아보고 모임 준비도 거들게. 당신이 혼자서 모임 준비하느라 정신이 없는 것 같아서 내가 정말 미안하네. 내가 도와줄 일이 뭐가 있는지 알려줘.',\n",
       " '네가 그리 큰 슬픔에 빠져 있으니 어떻게 위로를 해야 할지 모르겠어. 내 마음까지 너무 슬퍼지는구나.',\n",
       " '아이고. 너처럼 적응력도 좋고 긍정적으로 생각하는 사람이 이렇게 힘들 정도면 얼마나 힘들지 상상도 안 간다. 아침잠도 많은 네가 더 힘들어할 것 같아. 지금까지 버틴 것부터가 너무 대단해 보이는데?',\n",
       " '친구분의 여행 얘기를 들으니까 우리 추억이 떠오르면서 새삼 설레고 기분이 좋다. 그리고 기뻐하는 당신을 보니까 감사하고 고마워. 친구가 여행 떠난다고 부럽고 실투가 날 수도 있는데 진심으로 축하해 주고 기뻐하는 당신이 멋져.',\n",
       " '그거면 충분한 이유가 되지 않아? 당장 경제적인 부분이 조금 어렵긴 하겠지만 다른 부분들에서 조금만 더 아껴보자! 자긴 평소에 돈 관리도 잘하는 편이잖아?',\n",
       " '그렇다면 오늘은 더더욱 네 상처받은 마음을 한순간에 치유할 수 있는 하루였겠다. 아주 마법 같은 일인걸? 그래서 그 사람에게 번호를 알려줬어?',\n",
       " '진짜? 시험은 공정해야 하는데 그런 행동을 하다니, 정말 이해가 안 간다. 그걸 네가 발견했을 때 너무 당황스러웠을 것 같아.',\n",
       " '왜 안 그렇겠니? 얼마나 좋아했는지 내가 옆에서 지켜봐서 아는데 매일 하루도 거르지 않고 만났잖아. 얼마나 가슴이 찢어질 듯 아프겠니. 내가 다 가슴이 미어지고 슬프다.',\n",
       " '꽃을 보면서 그런 감정을 느끼다니, 정말 감동인걸. 그런 네 모습이 부럽기도 하고.',\n",
       " '그 심정 잘 알죠. 저도 예전에 차 수리 맡긴다고 대중교통으로 출근했을 때 사람들 너무 많은 것 자체가 스트레스더라고요. 저도 그때 온종일 기분이 안 좋았던 터라 감정화자씨 마음이 너무나도 이해가 가네요.',\n",
       " '요리하면서 함께 담긴 마음은 충분히 닿았을 거예요. 그러니 속상하고 아쉬웠던 마음은 접어 두고 편안하게 쉬셨으면 좋겠어요. 주말 동안 푹 자다 보면 속상했던 것도 금세 사라질 거예요.',\n",
       " '책임감이 강해서 그러니 너무 자신을 자책하지 마세요. 당신의 책임감과 리더십이 지금의 위치까지 오르게 한 증거이기도 하니까요. 당신의 그런 모습이 정말 멋지고요.',\n",
       " '친구끼리 뭘! 나중에 힘든 일 있으면 또 연락해!',\n",
       " '그래 생각보다 5퍼센트도 오래 버티더라고, 너무 크게 걱정하지 말고 차분히 편의점부터 찾아보자. 혹 전화 오면 그때 사정을 말하면 되니까. 일단 지금 급하고 불안하지만 그런 마음이면 더 초조해져서 놓칠 수도 있어.',\n",
       " '뭐라고? 아니 어쩌다가 그런 일이 다 있었어!',\n",
       " '너희 부부는 평소에 사이좋게 잘 지내잖아. 무슨 일이 있었던 거야?',\n",
       " '해외에서 여권을 분실하는 일은 흔하잖아요. 감정화자님이 이상한 게 아니에요. 매사에 철저한 감정화자님이신데 도난당하셨을지도 모르는 일이고요.',\n",
       " '결과 보고 네가 충격받아서 기겁했을 모습이 눈에 훤하네. 아무래도 우리 나이에는 슬슬 관리를 시작해야지.',\n",
       " '너의 반응 충분히 이해해. 나 같아도 오래 기다린 샌들이 1주일 만에 뚝 끊어져버리면 정말 화날 것 같아.',\n",
       " '아이고. 부장님이 요새는 누구한테 그렇게 연락을 하시나 했더니 이번엔 김 주임님이었구나. 아무래도 부장님이 퇴근 후 연락이 잦으시기는 하죠. 얼마나 짜증나겠어요.',\n",
       " '아들, 이거 하나만 물어볼까? 너는 스스로 네가 도난범이라고 생각하니?',\n",
       " '예기치 못한 일로 혼비백산해서 10년은 늙은 기분이겠어. 상상만 해도 아찔한 일이라 나였으면 어쩔 줄 몰라서 발만 동동 구르고 있었을 거야.',\n",
       " '그렇지, 하지만 외할머니 생전에 너와 쌓은 기억은 외할머니에게도 좋은 기억일 거야. 그리고 생전에 네가 외할머니를 소중하게 여긴 것을 분명히 아실 거야.',\n",
       " '가장 친한 친구들이니 비교도 제일 많이 되잖아요. 충분히 그렇게 생각할 수 있어요.',\n",
       " '이제라도 자기가 용기를 낸다니 정말 다행이라는 생각이 든다. 그리고 앞으로는 이런 일이 생기면 같이 고민할 수 있게 나에게도 바로 얘기해 줘.',\n",
       " '비교하는 마음으로 불안이 밀려올 때면, 쉽게 중심을 잃고, 마음이 흔들리게 되잖아요. 친구와 사는 모습에 격차가 생기면, 누구나 감정화자님과 비슷한 마음을 가질 거예요. 이렇게 생각하시니 다행입니다.',\n",
       " '와. 네 말을 들으니까 내가 당했던 압박면접이 생각났어. 진짜 그 순간만큼 머릿속이 복잡해지는 순간이 없지 않냐? 얘기 듣는 내가 다 당황스러울 지경이야.',\n",
       " '머리를 푸는 것보다 훨씬 단정하게 보일 것 같구나.',\n",
       " '친구가 힘들 때 도와줄 수 있는 건 당연한 거지. 그리고 당신이 나한테 일일이 말하고 허락받을 일이라고 생각하지도 않아. 그저 당신이 혼자 너무 상처받았을까 봐 너무 걱정이 될 뿐이야.',\n",
       " '아이고. 우리 딸이 그런 생각을 하고 있었구나. 마음이 정말 많이 상했겠네. 그동안 혼자 얼마나 많은 고민을 했을까, 많이 힘들었겠구나.',\n",
       " '자기를 온 마음 다해 좋아하는 사람이라면 자기의 기분을 고려해가며 말을 했을 거야. 그러니 자기를 배려해 주지 않는 사람의 말에 크게 상처받을 필요도 없어.',\n",
       " '내가 너에게 도움이 될 수 있다니 정말 다행이야. 언제든 또 도움이 필요하면 나한테 연락해.',\n",
       " '우리 같이 발이 큰 사람들은 비록 맞는 구두는 없지만 키도 크고 다리도 길잖아. 옷 입었을 때 얼마나 멋있어. 구두 대신 운동화 신어도 충분히 멋있을 것 같은데?',\n",
       " '당신 마음에 상처를 많이 받았겠어요, 그런 걸 놀리다니 어린아이도 아니고 저라도 속상했을 것 같네요. 장난이 심하다는 생각이 들어서 당신의 마음이 많이 다치진 않았을지 걱정이 돼요.',\n",
       " '친구가 우울증이라는 이야기에 당신이 혼란스러웠군요. 내가 친구가 아프다는 이야기를 들었어도 마음이 어지러웠을 것 같아요. 당신의 마음이 충분히 이해가 되네요.',\n",
       " '딸이 그런 얘기를 듣는다면 부모로서 당연히 상처가 되지요. 하지만 그건 당신 잘못이 아니잖아요. 너무 속상해하지 않았으면 좋겠어요.',\n",
       " '자기를 칭찬하면서 내가 배우는 것도 많은데. 자기가 그렇게 문자 해 주니 우리의 관계가 참 발전적이란 생각이 들어.',\n",
       " '생일이었구나. 늦었지만 생일 축하해. 나를 부르지 그랬어. 같이 쇼핑 했더라면 더 좋았을 텐데.',\n",
       " '잘 생각했어, 여보. 부모님도 연로해지시고 우리도 나이 들면 기대고 의논할 곳은 가족밖에 없을 것 같아. 누나한테 다시 연락해 오면 같이 밥이라도 먹으며 대화를 이어가 보자.',\n",
       " '그래, 나중에 또 필요한 일 있으면 연락해.',\n",
       " '앞으로도 그 마음 오래오래 응원하고 지지하고 있을게요! 회사에서 덕분에 긍정적인 에너지를 얻어 가요!',\n",
       " '이게 다 네가 이 문제를 해결하려는 의지를 가지고 있었기 때문이지. 문제를 숨기기 보다 남에게 알림으로써 같이 해결할 수 있게 하잖아. 정말 현명한 방법이라는 생각이 들어.',\n",
       " '네가 선택한 공부를 존중해주지 않는 사위의 태도에 딸이 많이 서운했나 보구나. 가사일이 너무 힘들면, 사위와 대화를 나누며, 방법을 찾아가는 게 어떠니? 혼자 너무 다 짊어지고 가려다 면, 몸과 마음 모두 탈나게 될 수 있거든.',\n",
       " '저도 우리 집 과일 먹는 사람들 다 행복하길 기원하며 장사해요. 그러면 손님 한 명 한 명 다 귀해요. 저도 중요한 일을 하는 사람인 것 같아 뿌듯하고요.',\n",
       " '저도 그렇게 되길 너무나 간절히 바라요. 그리고 분명 그렇게 될 거라고 생각해요. 지금까지의 감정화자씨라면 분명 잘 이겨낼 거라고 믿거든요.',\n",
       " '내가 자기 입장이어도 너무 배가 아프고 짜증까지 날 거 같아. 나는 열심히 준비해서 한 건데 성과가 없고 반면 친구는 대충 했는데 성과가 좋으면. 나는 진짜 배 아프고 질투감이 심하게 느껴져서 내가 못났나 스스로 상처받을 거 같아.',\n",
       " '아버지, 무슨 일이 있으셨나요? 평소보다 기운이 없는 것 같아서 제 마음이 아파요.',\n",
       " '네, 제가 바로 보고 드릴게요. 출근길에 무슨 일 생기신 건 아니죠? 감정화자씨가 이런 적은 처음이라 걱정이 되네요.',\n",
       " '무례하게 구는 사람들은 나중에 분명 돌려받게 돼 있어. 그 안에서도 배울 점을 찾고 발전하는 모습을 보이면 좋을 것 같아. 너는 충분히 그럴 수 있는 사람이니까.',\n",
       " '우리 집 고양이들 잘 봐주시는 병원 한 군데 있어. 무슨 일이야?',\n",
       " '자네만 그런 게 아니야 나도 애인한테 감정표현을 못 한다고 핀잔을 많이 들어. 사회생활이란 게 쉽지 않아. 말 한마디 잘못하면 바로 찍히니 감정표현을 안 하게 되지. 각박한 현실이 우릴 그렇게 만든 거야.',\n",
       " '참 손이 많이 가는 사람이라니까. 그동안 이런 일 말고도 계속 사람들에게 사기당하는 모습을 너도 함께 봐왔으니 당연히 걱정되지. 엄마도 네 아빠랑 산 지 얼마 안 됐을 때 그런 성향을 알고선 불안해서 잠도 안 왔단다.',\n",
       " '600일 기념일인 것 한번 더 축하해. 지금처럼 우리 딸이 이쁜 사랑을 했으면 좋겠어. 엄마도 응원할게.',\n",
       " '엄마는 네가 정말 열심히 노력하고 있는 걸 알기에 결과와는 상관없이 정말 뿌듯하고 대견하단다. 물론 네가 더 열심히 해서 멋진 결과를 얻고 싶은 마음에 조급하고 힘든 마음은 이해해. 하지만 먹고 싶은 걸 억지로 참으면서 불행해지지는 않았으면 좋겠어, 스트레스받지도 않았으면 하고 말이야.',\n",
       " '그러게요 마치 세기에 보물을 찾은 것 같은 기분일 것 같아요! 비록 제가 찾은 것은 아니지만 저도 그 현장에 있던 것같이 기뻐요!',\n",
       " '당신 마음이 좋은 일만큼 내게 중요한 일도 없는걸. 똑 부러지고 현명한 당신이랑 살면서 더 좋은 선택을 하는 쪽은 언제나 나니까. 이번에는 나도 당신 선택을 기쁘게 격려하고 존중해주고 싶어.',\n",
       " '그럴 수도 있지, 친구가 걱정해줬다고 해서 네가 다 고마워해야 하는 건 아니잖아. 친구도 나중에 너의 마음을 알게 된다면 다 이해할 거야. 그러니까 우선은 상처 받은 너의 마음이 우선이라고 생각해.',\n",
       " '그렇지요. 솔직히 잘나서 바쁜 자식보다 명절 때 집에 와서 얼굴 보여주는 자식이 최고예요. 감정화자씨의 아들딸들 감정화자씨한테 얼마나 잘하니, 정말 부러워요.',\n",
       " '엄마도 네 아빠랑 그런 작은 일로 부부싸움을 하고 후회한 나날들이 많아서 잘 알지. 네 성격이 누구를 닮았겠니.',\n",
       " '힘들겠지만 너는 이 상처를 통해 다른 사람들을 더 이해할 수 있는 마음을 갖게 됐잖니. 아마 이 아픔이 타인을 더 배려 하게 만들고 존중하게 만들 거야. 그리고 가족과 다른 사람들과 마음을 나누며 치유받을 테고 말이야.',\n",
       " '오죽하면 자기가 그런 생각까지 들었을까? 혼자 상심했을 자기를 생각하니 함께 해주지 못해서 미안한 마음이 들어. 지금이라도 일 미루고 집에 갈까?',\n",
       " '지금 당장은 아들 모습이 못나 보이고 속이 상하겠지만 성장해 나가는 과정이라고 생각해보면 어떨까요? 만남에는 헤어짐은 반드시 있으니까요. 아이도 그 과정을 견뎌내는 중 일거예요.',\n",
       " '이 옷은 우리가 같이 매장에 가서 골라 산 건데 정말 어이가 없다. 마음에 없는 말을 하고 다른 사람에게까지 거짓말을 한다니, 나 같아도 정말 화가 날 것 같아. 그 친구에게 말은 해봤어?',\n",
       " '네가 그동안 얼마나 좋은 친구일지 알고 있으니까 네 입장을 잘 이해해 줄 거야.',\n",
       " '오늘 나한테 털어놓기를 잘했구나. 어쩐지, 아빠랑 너랑 가끔 연락도 하지 않고 서먹할 때가 있더라니 이런 이유였구나.',\n",
       " '당신이 상처받지 않길 바라요. 저는 당신이 지혜롭게 살아가는 모습이 좋고 본받고 싶어요.',\n",
       " '우리는 공부한 지 오래 지났으니 당연히 기억하지 못할 수밖에 없지. 당신 아니어도 누구라도 잘 모를 수 있는 부분이니 너무 당황할 거 없어. 그리고 어른이라고 해서 모두 알아야 한다고 생각하지 않아도 돼.',\n",
       " '아버님도 괜찮다고 하셨으니 정말 괜찮을거예요. 아이들이 뛰어놀다 보면 그런 일도 있는거니까요, 다음부터 더 조심하면 되는 부분이고요. 너무 깊게 생각하고 고민 안하셔도 될 것 같은데요, 당황스러운 감정 털어내셔도 괜찮아요.',\n",
       " '와 대박. 실제로 경기 보고 온 거예요? 와 진짜 부럽다. 어제 엄청 즐거우셨겠어요 심지어 이겼잖아요!',\n",
       " '하지만 사람도 외모가 전부가 아니듯이 채소도 겉모습이 전부는 아니잖아요 너무 신경 쓰지 마요. 세상이 미울 법도 한데 이렇게 털어 놔줘서 고마워요. 세상으로 한 발자국 나오신 거예요 잘하셨어요 앞으로 제가 얼마든지 도와드릴 테니 같이 힘내 봐요.',\n",
       " '별말씀을. 오늘 좋은 하루 보내길 바라.',\n",
       " '그렇지? 그 상처 받은 마음을 잘 극복하려는 네 모습이 참 대견하다. 앞으로도 그런 마음으로 지낸다면 더 이상 상처 받을 일도 없을 거야.',\n",
       " '감정화자는 내 생각 이상으로 멋진 사람이라 내 마음이 너무 좋다. 그런 마음가짐으로 살면 어떤 고난도 감정화자를 흔들지 못할 거야. 늘 단단한 마음으로 자신을 지키며 살기 바라.',\n",
       " '우선은 축하부터 마음껏 받고! 진급시험 예상 문제는 제가 또 구해볼게요. 너무 불안해하지 말아요.',\n",
       " '정신이 없는 와중에도 당장 해야 하는 것들을 찾아서 준비하고 있구나. 역시 부지런한 내 동생다워. 그런 점은 늘 칭찬을 해주고 싶다니까.',\n",
       " '그러니까 음악이 인류의 위대한 자산 아니겠어?',\n",
       " '편할려고 배달시킨 건데 기분이 별로였겠어요. 일하면서 유일하게 편하게 쉴 수 있는 시간인데 그런 일이 있어서 얼마나 화가 났을지 느껴지네요.',\n",
       " '부부로서 힘든 일이 있으면 들어주는 건 당연한 일인걸. 앞으로는 웃는 날만 있으면 좋겠다.',\n",
       " '애인의 입대 영장을 받고 울적하고 슬픈 마음이 들어 많이 힘드셨죠? 하지만 지금껏 서로를 신뢰하고 지내온 만큼 군 생활도 잘 이겨내실 수 있을 거예요. 감정화자님이 워낙 사랑에 솔직하시고 애인을 아끼시는 분이신 만큼요.',\n",
       " '감정이 예민해지다 보면, 다른 사람의 말을 왜곡해서 듣게 되는 경우도 있어. 아마 사위는 그런 뜻이 아니었을 텐데, 네가 논문 쓰느라 신경이 예민해져 그렇게 받아들이는 건 아닐까? 어떤 관계에 있어 네가 힘들면, 다른 사람도 그만큼 힘들 수 있다는 사실을 기억하렴.',\n",
       " '왜 그렇게 까지 생각을 해. 난 당신이 그 세탁기를 아끼는 마음은 알지만, 그걸로 상처를 받진 않았으면 좋겠어. 그래야 당신도 편안해질 테니까.',\n",
       " '언니가 그곳에서 당황한 내색을 보이면서 어쩔 줄 몰라 했을 걸 생각하니까 안쓰럽고 귀엽기도 하네. 그 명품들도 분명 좋아 보이고 예뻐 보이지만 언니도 나름대로 풋풋한 매력을 뽐냈을 거라고 생각해. 언니는 그런 거 들고나오지 않아도 사람 자체가 명품이니까 너무 신경 쓸 필요 없어.',\n",
       " '그럴 만도 하지. 어쩌면 중고 거래를 하는 사람들이 흔히들 겪는 일일지도 모르겠어. 이건 분명 당신 혼자만의 당혹스러움이 아닐 거야.',\n",
       " '그런 마음 왜 안 들겠어요. 나였어도 그런 생각 들었을 거예요. 당신도 나도 우리 아이에게 마음이 더 쓰이는 게 당연한 거죠.',\n",
       " '그렇게 좋아해서 직접 따러 간 산딸기도 이제 못 먹겠다니, 정말 많이 놀랐나 보네. 이러다가 트라우마 생기는 거 아니야?',\n",
       " '그럼 그럼, 어떤 마음인지 잘 알 거 같아. 새로운 곳에 적응하는 게 쉬운 일이 아니잖아 자기가 힘들고 슬프게 느껴질 수 있어. 자기는 지금 너무 잘하고 있어, 안정된 곳에 안주할 수 있는데 도전한 당신이 너무 멋져.',\n",
       " '진심은 서로 통하게 되어있어. 가족 간에 서로 믿고 사랑하는 마음만 있다면 안 될 일이 뭐가 있겠니. 누구보다 더 행복하게 살 수 있다, 새로운 마음으로 다시 시작해 보는 거야.',\n",
       " '가려워서 긁었을 뿐인데, 염증이 생기니까 자기가 아주 당황스럽겠네. 긁을 때 심하게 긁었던 거야?',\n",
       " '당신과는 말 잘하는 편인데 많이 놀라고 속상했겠다. 그런데 당신이 이해해줘. 어쩌겠어 사춘기라 예민해서 그런 걸 다행히 큰 말썽은 없고 어차피 우리가 기다려줘야 하잖아. 우리 좋게 마음먹고 우리 아들을 잘 이해 해 보는 게 좋을 것 같아.',\n",
       " '엔진오일 교체 주기를 놓쳤구나. 마지막이 언제였는지 기억나?',\n",
       " '세상을 살다 보면 이런 경우가 많이 생길 거란다. 그럴 때는 네 뜻대로 되지 않는다고 힘들어하지 말고 털어내렴. 엄마는 네가 이런 계기를 통해서 해결하는 방법을 한 단계 더 배웠다는 생각이 드는구나.',\n",
       " '내가 언니라도 화가 났을 거야. 언니는 분명 통증에 대해서 말을 하려고 했잖아? 그래도 난 이번 일로 언니가 그곳에서 교정치료를 하지 않는 것만 해도 다행이라고 생각해. 잘 걸렀지.',\n",
       " '그렇게 생각해 줘서 고마워요. 다음에 같이 해요.',\n",
       " '그렇지, 평상시에도 혼자 있는 것을 무서워하는 너라서 많이 걱정했었어. 그런데 나의 문자로 힘을 얻었다니 고마워서 눈물이 날 것 같네. 나이 차이가 크게 나는 동생이라 항상 애틋한 마음이 있는데 잘 따라줘서 고마운 마음뿐이야.',\n",
       " '누구에게나 첫 시작은 두려운 법이지. 엄마도 많은 경험이 있지만 무언가 새롭게 시작하자면 걱정부터 앞서거든. 불안한 네 마음도 이해가 된다.',\n",
       " '그래도 너의 탁월한 대처 능력에 정말 감탄했어. 걱정하는 마음도 너무 예쁘고. 요즘 사회에 너처럼 따뜻한 마음씨를 가진 사람들이 있어서 사회가 돌아가는 게 아닐까?',\n",
       " '너도 잘 있지? 늘 긍정적인 네가 상처라니 벌써 부터 걱정이 되는구나. 그래도 천천히 편하게 얘기해 주렴.',\n",
       " '기껏 머리를 하고 나와서 기분이 좋았을 와중에 비가 와서 무척 난처하셨죠. 예기치도 못한 일로 공들인 머리가 망가지면 어쩌나 싶어 괴롭기도 했을 듯해요. 문자로 상황을 전해 듣기만 해도 대리님이 그 순간 겪었을 혼란스러움이 전해지는데 대리님 자신은 오죽했을까 싶어요.',\n",
       " '상한 게장을 받으셨다니 정말 화나고 억울하시겠어요. 값도 싸지 않을 텐데, 홈쇼핑 회사에선 뭐라고 해요?',\n",
       " '네가 이렇게 기뻐하니까 나도 기분이 좋네. 어떤 부분이 가장 흡족하게 느껴져?',\n",
       " '확실하지도 않은데 순간의 감정에 빠져서 판단하는 건 앞으로의 기회를 단절시키는 거야. 네가 그렇게 좋아했던 데에는 이유가 있었을 거야, 그러니까 너의 안목을 믿고 조금 더 기다려봤으면 좋겠어. 그래야 네 마음도 편해질 거야.',\n",
       " '그러니까 나까지 기대된다! 얼마나 설렐까? 꼭 수학여행 가기 전에 떨리는 기분이겠다. 기분이 좋다 못해 아주 활기찬 상태일 거 같아!',\n",
       " '앞으로 주의하면 되니까 너무 걱정하지 마. 소화제인 줄 알고 진통제를 계속 복용한 게 아니잖아. 앞으로 신경 써서 약을 복용하면 괜찮을 거야.',\n",
       " '네가 난임 때문에 첫째 가졌을 때도 얼마나 고생했었니. 첫째도 난임 전문 병원 다니면서 힘들게 얻었는데 아무리 뜻하지 않은 둘째라 해도 얼마나 기쁘겠어. 네가 정말 행복하겠구나!',\n",
       " '그랬군요. 제가 들어드리면 혹시 도움이 될까요? 그분만큼은 안 되겠지만 슬픈 마음에서 헤어 나올 수 있도록 조금이라도 돕고 싶어요.',\n",
       " '우리 아들 왜 그렇게 화가 났니? 아버지랑 무슨 일 있었어?',\n",
       " '그렇구나, 아빠는 우리 아들이 평소에 친구들이랑 사이좋게 지내고 한 번도 싸운 적이 없는데. 말싸움을 크게 했다고 하니까 속으로 많이 걱정이 됐단다. 그런데, 다른 친구를 도와주기 위해서 그랬다고 하니 한편으로 자랑스럽구나.',\n",
       " '형도 경제적 도움을 받을 때는 마음에 든다고 다 사지는 못했었지. 내 신세 한탄을 하기도 하고 세상 탓도 하고 그랬는데, 넌 그러지 않았으면 좋겠어.',\n",
       " '너 지금 학교 친구랑 둘이서 태국 여행 중이잖아. 근데 싸우다니 마음 상한 일이 생겼나 보구나.',\n",
       " '네, 그럼요. 앞으로 좀더 자주 찾아뵐게요. 딸도 할아버지랑 자주 보면 더 좋아할 거예요. 지금도 보고 싶어 하네요.',\n",
       " '위로된다는 말을 들으니 나도 기쁘다. 난 그저 우리 대리님이 행복하기만을 바랄 뿐이야.',\n",
       " '할아버지에게 드린 게 없다고는 했지만, 할아버지를 위해 해 드릴 걸 미리 생각하고 있었네. 그런 자기의 착한 마음이 나는 참 값지게 느껴져. 그런 자기의 마음이 하늘에 계신 할아버지께도 전해졌을 거라고, 그렇게 믿었으면 좋겠어.',\n",
       " '좋은 생각이에요. 당신과 같은 친구를 가진 당신의 친구가 너무 부럽네요.',\n",
       " '아, 술버릇 문제면 불안하고 조심스러워질 수밖에 없지. 왜 안 그러겠어. 가벼운 문제가 아니잖아. 나 같아도 망설였을 거 같다.',\n",
       " '그래. 답답한 마음을 저 멀리 훨훨 털어 내버려. 기분 전환을 위해 바다를 한번 다녀와도 좋고.',\n",
       " '치우는 사람이 따로 있는 상황이 아닌데 그러면 정말 당황스럽지. 그래도 당신은 항상 긍정적으로 생각하려 하잖아. 이 상황을 잘 이겨내고 있을 거 같단 생각이 드네.',\n",
       " '그렇겠네요. 술 담배 기름진 음식들. 모두 좋아하는 것들이지만. 헌혈을 위해선 잠시 안녕.',\n",
       " '정말? 어제 비가 와서 빗길이 덜 말랐나 보다. 괜찮아?',\n",
       " '갑자기 많이 떨어지긴 했더라. 자기가 그거 보고 많이 속상했나 보구나.',\n",
       " '마음에 드는 게 없었나 보네. 너 옷 사는 거 꽤 까다롭잖아.',\n",
       " '계획이 틀어졌다고 생각하지 말고 잠시 휴식 시간을 가져보는 시간이라고 생각하면 어때? 이제까지 너무 쉼 없이 달려온 너에게 돌아가면서 쉴 시간을 주는 거라고 생각하자. 그러면 기분이 좀 나아지지 않을까?',\n",
       " '어휴, 정말 울적하겠다. 나도 저번에 일본 갔을 때 보조배터리 없어서 사진을 많이 못 찍었거든. 그 마음 알아서 나까지 덩달아 마음이 안 좋아지네.',\n",
       " '좋은 자세예요. 지금처럼 일단 한 걸음만 더 용기를 내면 돼요. 그 다음 일은 당신이 생각하는 것보다 어렵지 않을 거예요. 해보기도 전에 겁을 먹고 피하려는 자세는 당신을 소극적으로 만들 뿐인걸요.',\n",
       " '예전과는 달리 독서가 어렵게 느껴지셔서 아버지 마음이 편치 않았겠어요. 어렵지 않았던 일인데 나이로 인해 어려워진다는 걸 체감한다는 것은 당황스러운 일이죠.',\n",
       " '그 마음 이해해요, 저도 예전에 다이어트하면서 매번 감정화자씨와 같은 상황에 부딪혔었어요. 그래도 그 순간들을 인내하다 보면 결국 원하는 길 끝에 다다르게 되더라고요. 그러니 감정화자씨도 지금의 분노를 잘 다스려서 성공의 길에 더욱 다가가셨으면 좋겠네요.',\n",
       " '왜요, 무슨 일이길래 기분이 이렇게 안 좋은 건지 신경이 쓰이네요. 많이 심각하거나 그런 건 아니죠? 지금 시간 괜찮으니까 얘기해 봐요.',\n",
       " '쉽게 나지 않는 자리고, 아무나 갈 수 있는 것도 아닌데 갑자기 기회가 오니까 걱정될 만도 하지. 네 마음 이해가 돼. 동기한테 바로 물어보고 연락을 줄게.',\n",
       " '갱년기 때는 충분히 그럴 수 있지. 평상시 화를 내는 경우가 거의 없잖아. 그런 당신이 자꾸 화가 난다는 것은 갱년기 때 나타나는 현상이라고 하니 너무 속상해하지 마.',\n",
       " '자기야! 자동차 계약이라니, 갑자기 그게 무슨 소식이야? 나한테 비밀로 할 정도로 아주 은밀한 작전이구나. 얼른 알려줘.',\n",
       " '그렇지. 악역으로 이미지가 굳어질까 하는 두려움은 배우라면 큰 걱정 요소이지. 하지만 요즘은 악역도 사랑받는 시대고 악역에도 다양한 배역이 있잖아. 너의 대단한 연기력으로 그 배역들을 표현해 준다면 관객들은 너의 다양한 매력에 다시 빠질 것이야.',\n",
       " '세상에 그렇게 대놓고 말을 했다니 자네가 정말 난감하겠네. 결혼 준비하면서 그런 얘기를 들었으니 너무 속상했겠다.',\n",
       " '맞아요. 남자 친구분도 감정화자씨의 상처받은 마음을 알면 몹시 미안해할 거예요. 불똥이라도 튄 것처럼 속상한 마음이겠지만, 시간이 지나면 자연히 잊힐 거예요. 그렇게 믿고 마음을 편히 가져 봐요.',\n",
       " '남들 의식하지 않고 셀카를 찍으려고 했었잖아. 엄마가 보기에 그것이 너 자신을 사랑할 수 있다는 증거야.',\n",
       " '그나마 다행이네. 앞으로 무서워서 산에 갈 수 있겠어? 계속 뱀 생각날 것 같은데.',\n",
       " '감정 화자님이 아무하고나 싸우는 사람이 아닌데, 뭔가 억울한 일을 겪은 거니? 기분이 안 좋다고 하니까 나도 기분이 안 좋네.',\n",
       " '네! 감정화자씨도 파이팅합시다!',\n",
       " '우리 딸이 정말 속상했겠다. 듣는 엄마도 가슴이 다 아프네.',\n",
       " '앞일을 몰라서 불안해 하는 감정화자 마음은 충분히 이해가 돼. 그런데 내 생각에는 감정화자에게 안 좋은 일이 생길 것 같지 않으니 안심해도 좋아. 좋은 일을 했으니 그에 대한 보답이 분명 있을 거라고 생각하면 마음이 편해질 거야.',\n",
       " '네가 좋아하는 수학인데도 다 못했다는 걸 보니 많이 힘들었니? 숙제가 생각보다 너무 어려웠나 보다.',\n",
       " '돌아가신 친구들을 보면 얼마나 마음이 찢어질까요. 그런데 엄마, 계속 그렇게 슬퍼하시면 더 힘드실 거예요. 이번 주말에 저와 함께 1박 2일 여행 떠날까요?',\n",
       " '그런 마음으로 커피를 만들어서 그렇게 맛있었나 보네요. 화는 이제 푸시고 이참에 드라이한 거품도 도전해 보시는 건 어때요?',\n",
       " '선생님께서 기쁘고 즐거워 보이셔서 저도 덩달아 좋은 에너지를 받는 것 같아요. 선생님 덕분에 저도 기분이 좋아졌어요.',\n",
       " '그래. 너 그동안 항상 모든 일에 최선을 다하고 열심히 해왔잖아. 그걸 누구보다도 내가 잘 아니까 너는 충분히 잘 살아왔다고 자부할 수 있어. 너에 대한 자신감을 가져.',\n",
       " '정말 속상하실 것 같아요. 막역한 친구 사이도 아니고 남편의 직장 동료를 만나는 자리였으니 얼마나 괴로우시겠어요. 첫인상이 부정적으로 낙인찍혔을까 봐 불안하신 마음도 정말 이해돼요.',\n",
       " '그래. 잘 풀리길 응원하고 있을게. 연락 줘.',\n",
       " '응, 눈물이 나면 실컷 울어. 그리고 다시 일어서면 되니까. 자기가 새로운 과외를 찾을 수 있을 때까지 내가 옆에서 힘이 되어 줄게, 알았지?',\n",
       " '왜 안 그렇겠어, 나도 그랬는데. 그래서 나는 눈높이를 낮추고 그전에 일했던 나는 잊어버리고 새로운 삶에 다시 도전해보자 하는 마음으로 다시 도전했었어.',\n",
       " '당신의 메시지를 보는데 깜짝 놀랐어요. 생각지도 못했는데 소중한 사진을 만난 기분이 얼마나 신이 났을까요. 그저 그 시절로 다시 돌아간 듯 정다운 마음이 솟아났겠죠.',\n",
       " '뭐라고? 그런 일이 있었어? 그러니 네가 더 걱정하는 거구나. 정말 중요한 부분이니만큼 오늘 딸하고 진지하게 다시 이야기해보는 건 어때?',\n",
       " '그럼. 여보는 좋지 않은 상황에 닥쳐도 시간이 조금 지나면 금세 아무 일 없었다는 듯이 돌아오잖아! 그러니 마음을 천천히 가다듬어서 화를 잠재워보자. 어때?',\n",
       " '밤늦게까지 너무 무리하는 바람에 실수를 했나보다. 더 잘하려고 그랬던 건데 일이 꼬여서 정말 속상했을 거 같아.',\n",
       " '난 네가 자존심도 있고 어디 가서 꿀리지 않고 그렇게 꿋꿋해서 좋아. 사람 사는 게 다 다른 거니까 이번에는 친구들 배려가 좀 부족했더라도 네가 넘어가 주지 그래.',\n",
       " '그게 무슨 말이야? 네가 혼나도 되지 않을 일로 꾸중을 들었다는 거야?',\n",
       " '무슨 일이 벌어졌을까? 궁금하다, 얼른 말해봐.',\n",
       " '세상에는 다양한 사람이 사는거야. 다른이들의 좋은 모습을 닮을 필요도 그렇게 보일 필요도 없어. 지금 너자체로도 얼마나 멋진데!',\n",
       " '그래? 우리 아들이 내 판박이라니 완전 감동인데.',\n",
       " '우리 딸이 그동안 버텨내려고 정말 안간힘을 썼겠구나. 지금까지 어떻게 견뎌냈을지 상상이 안 될 정도로 말이야. 하지만 분명 우리 딸의 능력이 발휘되어 언젠간 모두가 인정해줄 날이 올 거라고 확신한단다.',\n",
       " '나였어도 그런 감정이 들 수밖에 없었을 것 같아. 하지만 일단 중요한 건 친구에게 미안한 네 마음이잖아. 진심으로 사과하고 미안한 감정을 드러내면 친구도 널 용서해줄 거야.',\n",
       " '집안에 부담을 덜어드리기 위해 맡은 자리에서 최선을 다하려는 당신이 정말 기특하다. 아버지 퇴사와 별개로 당신이 열심히 해서 장학금을 받는다면 부모님도 정말 기뻐하실 거야. 퇴사를 결정하실 땐 부모님들끼리 충분히 상의 후 대책도 생각하실 테니 괜찮을 거야.',\n",
       " '드디어 내 여자 친구가 원하던 의대생이 되는구나, 정말 축하해. 그 모든 수고와 노력을 다해온 네가 진심으로 존경스럽고 멋졌어.',\n",
       " '우리 아버지도 누나에게만 관대하세요. 언제 한번 진지하게 얘기해 보는 건 어때요?',\n",
       " '그럼 같이 쓸 베개도 찾아보고 구매해야겠다. 새로운 매트에 새 베개가 있으면 더 포근하게 잠들 수 있을 것 같아. 어느 인터넷 쇼핑몰에서 샀는지 알려줘 묶음 배송으로 받을 수 있게 해볼게.',\n",
       " '자기가 오래 고민했던 거 나도 알고 있었는데, 드디어 결정했다니 나도 자기만큼 기쁘다. 고민했던 시간들이 무색할 만큼 기쁠 거라고 생각해.',\n",
       " '뭐라고? 요샌 산에 자주 가지도 못했는데 회장이라니? 말도 안 돼.',\n",
       " '저는 감정화자님 마음이 충분히 이해돼요. 불안한 마음이 들어도 가족들 때문에 표현하지 못해서 감정화자님 마음이 아주 답답했을 것 같아요.',\n",
       " '명절에 쉬지도 못하고 저런 소리 나 들어야 하면 불쾌할 만하지. 그만하시라고 한마디 하고 싶을 것 같은데.',\n",
       " '나도 당신 말에 동의해. 어차피 사야 했던 물건이 저렴할 때 구입을 더 하는 것이 현명한 소비라고 생각해. 당신은 정말 현명하게 잘 살아오고 있어.',\n",
       " '그래, 남은 하루도 잘 보내.',\n",
       " '그럼. 다른 사람이 안 좋은 평가를 한다고 하더라도 네가 즐겁고 행복했다면 그걸로 된 거 아니겠어? 그리고 너는 분명 발표를 훌륭하게 해낼 것이 분명하니 자신감을 가져보자.',\n",
       " '내가 시골만 아니었어도 달려가서 힘을 보탰을 텐데 안타깝다. 이렇게만 들어도 얼마나 난처한 상황인지 알겠어.',\n",
       " '세상에, TV는 바보들이나 보는 거라고 하셨던 아버님이신데! 자기 정말 많이 걱정되겠다. 내가 신경을 못 써서 미안해.',\n",
       " '사위 사랑은 장모라더니 맞는 말이네. 네가 노력하는 모습을 보니까 정말 멋있다. 그래도 딸을 시집 보낸다는 아쉬움이 있지는 않아?',\n",
       " '그거야. 결과적으로는 크게 다친 곳이 없다고 하니 지금처럼 과하게 걱정할 필요는 없어. 너무 불안해 말고 침착하게 차 주인 분과 이야기를 나눠보렴. 상황을 파악하면 네가 진정하는 데 도움이 될 거야.',\n",
       " '나도 소액이지만 장학금을 기부했을 때 기분이 너무 좋더라고. 금액에 상관없이 마음이 정말 중요한 거잖아. 좋은 일을 했다고 생각하니 우리 자기 기분이 너무 좋겠다.',\n",
       " '응. 너는 현명한 엄마니까 잘 이야기할 수 있을 거야!',\n",
       " '우리 손녀가 내가 할머니라고 잘 따른다니 너무 고마운 걸. 엄마가 얘기해서 우리 손녀가 네 말을 잘 들게 되면 좋겠다. 엄마는 네가 손녀하고 사이좋게 지내면 정말 행복할 거 같아.',\n",
       " '감정화자씨가 사수인데 당연히 되죠. 그런데 무슨 문제가 있는 건가요?',\n",
       " '나도 그건 정말 동의해. 결혼으로 맺어진 가족인데 딸처럼 아들처럼 하는 게 쉬운 게 아니잖아. 서로 인정하면서 맞춰야 하는 거잖아.',\n",
       " '친구들도 다 학교를 떠났으면 네가 얼마나 외로웠을지 이해가 간다. 나도 재수했기에 네 마음 알아, 어린 친구들이랑 지내는 게 어떨 땐 쓸쓸하고 외롭더라. 네가 다시 친구도 사귀고 즐겁게 지내면 좋을 텐데.',\n",
       " '그래 잘 생각했어. 혹 불안하면 문자 메시지라도 남겨서 사정을 말해놓고 얼른 일회용 보조 배터리를 구해봐. 요즘 편의점에 파니까 찾아보면 될 거야.',\n",
       " '그래도 일할 곳이 있는 넌 행복한 거야. 직장을 구하지 못해서 지금도 구인 광고만 열심히 찾아보고 있는 백수가 이곳에 얼마나 많은데. 그래도 너는 번듯한 직장이 있고 거기서 인정받고 있으니까 오랜만에 이 곳에 와도 친구들이 다들 너를 반겨주잖아.',\n",
       " '야근으로 힘든가 보네. 회사가 한창 바쁠 시기인가 봐.',\n",
       " '이미 들으면서 대리만족해서 내 기분이 다 좋아. 나도 용기 있게 내일 가서 뽑고 문자할게.',\n",
       " '에이, 사람들은 의외로 그런 건 금방 까먹어. 너는 당사자니까 오래 기억할지 몰라도 그들은 벌써 잊었을걸? 이 일 때문에 자주 가던 공원을 안 갈 필요까진 없지.',\n",
       " '네 적응력과 친화력이면 새로운 직장을 구해도 문제없이 적응하고 잘 해낼 거야. 그러니까 걱정하지 말고 어깨 펴.',\n",
       " '괜찮아. 누구나 주위에서 그런 말에 휘둘리고 흔들릴 수는 있어. 하지만 그 말이 자존감을 깎아내리고 너 자신을 꺾이게 하진 말았으면 좋겠어. 아들 넌 이제까지 너무나 잘해 왔어.',\n",
       " '그동안 혼자 얼마나 마음 졸여 왔어. 누나뿐만 아니라 우리 가족들이 이런 너의 마음을 안다면 다 같이 울음바다가 되고 말걸. 그만큼 다들 너를 많이 사랑하고 계신다는 걸 알아줘.',\n",
       " '세상 모든 사람들에게 좋은 사람으로 기억되면 좋겠지만 현실적으로는 어려워. 잠깐 스쳐간 사람들 마음까지 신경 쓰면 감정화자가 너무 힘들 것 같아. 그러니 그만 털어버리는 게 감정화자 마음 안정에도 좋을 거야.',\n",
       " '기준이라는 건, 정하는 사람에게 달려 있는 거잖아요, 시작도 끝도 우리의 기준에 맞추면 돼요! 지금 당장은 당신의 생각이 바뀌기 어려울지 몰라도, 우리가 결코 부족하거나 모자라지 않다고 생각해요. 그러니 조금은 자신감을 갖고 우리만의 행복과 속도를 찾으면 좋겠어요.',\n",
       " '아내랑 무슨 일 있어?',\n",
       " '중요한 수업이라면 그 속상함이 좀 더 크겠다. 그 수업 자기가 엄청 좋아하는 강의였잖아. 그런데 동기들이나 교수님께 연락드려보면 분명 해결방법이 있을꺼야 그러니 너무 걱정하지 마.',\n",
       " '엄마의 상처는 당연한 거예요. 내가 아는 사람들 중에 엄마가 가장 성실한 사람이에요. 회사 일을 성실히 해내는 엄마를 보면서 나는 늘 본받을 점이라고 생각했었어요.',\n",
       " '맞아! 사실 나도 네가 말하지 않았더라면 몰랐을 거야. 괜히 말했다고 생각되지?',\n",
       " '집에 식물들을 두는 건 어때? 숲만큼은 아니지만 기쁘고 편안한 마음을 다시 한번 되새길 수 있을 것 같아.',\n",
       " '응응. 여보, 내가 고마워. 얼른 여보랑 우리 아가 보러 갈게 조금만 기다려줘.',\n",
       " '사람마다 살아가는 방식은 다 다르잖아요, 지나간 시간의 감정화자님도 앞으로 다가올 시간의 감정화자님도 다 소중해요. 그동안 많이 피곤하셨으니 이제는 타인의 시선에서 벗어나 자유로운 삶을 살아보세요. 생각보다 나쁘지 않을 거예요.',\n",
       " '당신이야말로 늘 제가 가장 필요한 순간에 필요한 곳에 나타나잖아요. 저번의 서류 때도 그렇고요. 그런 고마운 당신에게 조금이라도 도움이 되고 싶은 마음이에요.',\n",
       " '네 여행이 벌써 다음 주였다니, 하필 그 소식을 접해서 네가 많이 곤란하겠는걸. 너는 더위를 무척이나 버거워하니 그 소식이 청천벽력이었겠구나.',\n",
       " '이야기 하실 때, 근육통 따위 생각도 안 났을 것 같은데요. 저였어도 별반 다르지 않았을거예요. 기쁜 마음은 어디에라도 털어놓고 싶으니까요.',\n",
       " '안 그래도 지쳤을텐데 옆자리 사람 때문에 더 힘들고 괴로웠겠다. 퇴근길에 자리에 앉은 행운을 내팽겨치고 싶어질만큼 힘들었다니 정말 엄청나네.',\n",
       " '만족스러운 회사 생활로 즐겁다고 하더니 갑자기 왜 이렇게 마음이 안 좋은 거야. 무슨 일인지 모르겠지만. 잠시 화난 마음에 섣부르게 결정하면 후회가 될 수 있으니 우선 진정하고 잘 생각해 봐.',\n",
       " '편안해졌다면 됐다. 계속 슬퍼하는 것도 할머니께서 싫어하실 거야. 할머니께서도 네가 다시 기운 차리고 씩씩하게 잘 살아가는 모습을 원하실 거야.',\n",
       " '그러니까 내 가슴이 다 시원해. 거기다 바닐라라테까지. 기분까지 달콤해지는 느낌이겠다.',\n",
       " '삶의 질이 더 중요해서 바로 자취 시작했어, 당장에 돈보다는 행복이 더 중요하잖아? 자기도 마찬가지고.',\n",
       " '일단 아빠가 괜찮으실지 지켜봐야겠네. 너도 많이 놀라고 속상하겠구나.',\n",
       " '당신이 나의 진심을 느꼈다니 정말 다행이네요. 내가 표현이 서툴러서 당신에게 잘 못 말하는 것 같아서 많이 속상했는데. 역시 당신은 내가 말을 안 해도 나의 마음을 알아주는 현명한 여성이네요.',\n",
       " '음, 평소에 하고 싶었던 것들 없어? 내가 같이 해줄게. 가서 편안하게 쉬고 힐링하고 오자.',\n",
       " '그럼. 새 차가 출고되면 기분도 몹시 좋아질 거야. 새로 나올 차도 첫 차만큼 아끼면서 사용하면 10년 넘게 너와 함께할 수 있을 거야.',\n",
       " '오히려 네 마음이 편해졌다니 정말 다행이고 내 기분이 다 좋아진다. 너는 강한 아이니까 분명히 잘 이겨낼 수 있을 거야, 힘내!',\n",
       " '나도 예전에 그런 적이 있었는데, 나중에 알고 나서 깜짝 놀랐어. 약 겉봉지와 내용물을 확인 안 하고 복용했던 거야.',\n",
       " '싫어하는 게 많아지는 요즘, 좋아하는 거에 집중하며 긍정적으로 생각하는 네가 참 멋있고 대견하다. 덕분에 행복과 기쁨이 먼 곳에만 있는 게 아니라 의외로 가까운 곳에 있단 걸 배우네.',\n",
       " '당연하지! 내가 아는 너는 사려 깊고 다정한 사람이라서, 상견례도 잘할 수 있을 거야. 너도 시댁 식구들도 좋은 사람이니까 분명 화기애애하게 잘 마치고 올 거야. 그리고 벌써부터 사위를 예뻐하는 모습을 보면, 네가 얼마나 좋은 사람인지 잘 느껴져.',\n",
       " '다행입니다, 감정화자님께서 이렇게 생각을 바꾸셨으니 말입니다. 남은 며칠 동안 푹 주무시면, 하루 정도 잠을 설친다고 해도 일정에 큰 무리는 없을 거예요. 이렇게 생각하시면, 마음이 훨씬 편안해질 수 있을 거예요.',\n",
       " '양보를 강요받는 것 같아서 화가 많이 났구나. 동생이라고 무조건 양보해야 하는 법이 있는 것도 안데 나였어도 너무 짜증 났을 것 같아.',\n",
       " '그게 무슨 말이야? 그 사람이랑 뭔 일 있었어 ?',\n",
       " '모두에게 각자의 사정이 있는 거니까, 당신이 너무 자책하지 않았으면 좋겠어. 힘들어하는 동료들을 보며 마음이 아픈 것도 당연하지만, 당신 마음도 돌보길 바라. 잠도 못 자고 힘들어하는 거 보니까 너무 안타깝고 나도 눈물이 나.',\n",
       " '내가 아는 너는 배려심이 깊고 스쳐 가는 인연도 소중하게 생각할 줄 아는 따뜻한 사람인걸. 분명히 너와 잘 맞는 사람들을 언젠간 만날 수 있을 거야. 네 오랜 친구로서 난 그렇다고 확신해.',\n",
       " '스스로 한 약속을 꾸준히 지키는 것만큼 어려운 일은 없어. 넌 그 어려운 일을 오랫동안 해오고 있는 거야. 그런 모습을 자식에게 보여주는 것만큼 값진 건 없어.',\n",
       " '불안하다는 게 어떤 부분이 그렇다는 거예요?',\n",
       " '아무래도 그렇죠. 고의가 아닌데 계속 주의를 주기 조심스럽잖아요. 대리님 마음이 조금이라도 나아졌다니 저도 기분이 좋네요.',\n",
       " '엄마도 한때는 만화와 소설을 사랑하는 문학소녀였단다. 그리고 엄마 시대엔 선생님들이 더 엄격해서 아예 만화책을 가져오는 게 금지였어. 그래도 몰래 보는 그 재미에 꼬박꼬박 가져갔었지.',\n",
       " '많이 힘들었을 텐데, 그런 의미에서 오늘은 선배가 점심 살게. 수업 끝나고 연락해!',\n",
       " '제가 조금이라도 도움이 될 수 있어서 다행이에요. 한동안 고생 많으셨으니까 그만큼 푹 쉬면서 마음을 편안하게 비워 보세요. 또 언제든 하고 싶은 이야기가 생기면 저에게 연락해주시고요.',\n",
       " '예상했던 이미지와 다른 모습을 보이면 당황스러울 수 있지. 나도 일하면서 생각했던 이미지를 갖고 있지 않은 사람들을 볼 때 당신처럼 당황스러움을 느껴. 당신이 어떤 마음이었을지 알 것 같다.',\n",
       " '사람에 대한 믿음, 기대가 한순간에 무너지는 일만큼 기운이 빠지고 슬픈 일은 없지. 혼란스러운 마음 이해가. 하지만 내가 보기에도 그럴 사람으로는 안 보이니까, 네가 사람을 잘못 보지는 않았을 거야.',\n",
       " '나는 관절 통증은 없었는데 대신 우울증이 심하게 왔었어. 시간이 약이라고 이제는 좀 벗어나긴 했는데, 너는 관절 통증으로 왔으니 더 힘들지.',\n",
       " '그러게 정말 다행이다. 앞 유리 중앙에 여러 갈래로 금이 갔으면 당신이 운전하는데도 지장이 있었을 텐데.',\n",
       " '그러게 말이야. 자기 친구들과의 버킷리스트였는데 이렇게 이루게 되었네! 예쁜 사진 남기면 평생의 추억이 되고 참 기분이 좋은 것 같아.',\n",
       " '이제 과장님의 페이스를 찾은 것 같아 다행이에요. 사실 상황이 이러니 어쩔 수 없지만, 부장님도 본인 나름의 사정이 있었을 거예요. 저희가 이해해 준다면 본인도 많이 고마워하시겠죠.',\n",
       " '뭘요. 소중한 동기인데 이 정도는 당연히 할 수 있죠. 마음이 너무 힘들면 차라리 그분이랑 대화라도 해보는 건 어때요? 어쩌면 본인이 한 말에 미안함을 느끼실지도 몰라요.',\n",
       " '동생도 시댁에서 힘든 일 이 있으면 엄마한테 하소연하기도 하는 걸요. 충분히 당신 마음을 이해해 줄 거예요.',\n",
       " '무심하다니 절대 그렇지 않아. 네가 얼마나 아빠에게 자랑스러운 딸이었는데 그런 생각을 가지다니 아직도 아빠 때문에 많이 힘든가 보구나.',\n",
       " '맙소사. 형이 깜짝 놀라고 허둥지둥하며 당황할만했네. 인명사고가 날 뻔했으니 형 심장이 남아나지를 않겠는데?',\n",
       " '지금은 의료진을 믿고, 친구가 어서 일어나길 바랄 수밖엔 없겠네요.',\n",
       " '딱 상황이 마음을 쉬라고 만들어줬구나. 그동안 너무 바쁘게 살아왔잖아. 한 템포 쉬어가면서 마음을 챙겨보자.',\n",
       " '너는 단순히 시원한 자리가 있는지 물어보았을 뿐인데 되레 직원이 화를 내니까 많이 당황스러웠겠다. 날도 더운데 화가 배가 되었겠네.',\n",
       " '세상에, 진짜 큰일이 났네요? 이를 어쩌면 좋아요. 너무 당황스러우시겠다.',\n",
       " '그렇다면 다행이야. 차분하고 솔직하게 자초지종을 말씀드리고 반성해 보자.',\n",
       " '감정화자씨가 싫은 소리 한마디 안 하면서 오죽 정성을 들여 키웠니. 게다가 권위적이지도 않으면서 다정하게 키웠잖아.',\n",
       " '우선 마음을 진정시키고 방법을 찾아 보자. 안경집에 가서 안경알을 살릴 수 있는지 물어봐. 다 방법이 있을 테니 우선 침착해.',\n",
       " '너는 예전부터 독서하는 게 가장 편하고 즐겁다더니 직장 다니는데도 꾸준히 읽는구나. 일 다니면서 책 읽기 정말 쉽지 않은데 진짜 대단해. 네가 책을 많이 읽어서 이렇게 금방 침착해지는 건가 봐!',\n",
       " '많은 사람들이 하고 싶은 말을 다 꺼내놓지 못해. 때로는 배려를 위해서 때로는 사랑 때문에 삼켜내는 말들이 많아. 그런데 그 사람들이 소심하다고 그 누구도 생각하지 않아, 그건 신중한 거야. 너처럼.',\n",
       " '아. 나도 맨날 비 온다고 해서 우산 들고 나가면 꼭 비가 안 오더라. 그럴 때 우산 들고 다니기 너무 귀찮고 성가시긴 하지. 너의 짜증나는 기분 알 거 같아.',\n",
       " '그랬다면 네가 그 친구와 진지하게 이야기를 해보면 어떨까? 네가 아파서 그랬다고.',\n",
       " '진짜라니까? 나 완전히 진심이야. 내가 친구라고 무조건 좋은 말만 해주는 줄 알아?',\n",
       " '당신 마음이 지금 어떨지 이해할 수 있어. 하지만 별일 아니니까 너무 마음을 쓰지 않았으면 좋겠어. 아직 시간 여유가 있으니 그릇을 다시 사면 되잖아.',\n",
       " '왜? 무슨 일 있었던 거야?',\n",
       " '맞아. 귀여운 걸 보면 자꾸 생각나고 괜히 기분 좋아서 흐뭇해지게 되더라. 나도 그 시간에 목동에 가봐야겠는걸.',\n",
       " '그러겠죠. 대표와 친한 그 동기 이야기를 누구에게 말하겠어요. 대표 귀에 들어가면 당신이 곤란해질 텐데요.',\n",
       " '네가 밀려 썼다는 사실을 알고 나서 마음이 많이 놀랐겠어. 그동안의 노력이 수포로 돌아가는 것 같아 얼마나 허무하고 황당했겠니. 엄마는 성적보다도 네 마음이 더 걱정이 되는구나.',\n",
       " '마음이 풀렸다니 다행이다. 이제 조금만 참고 노력하면 원하는 결과를 얻을 테니 더 힘을 내 보자, 감정 화자님.',\n",
       " '다이어트 중이라 아아에만 마신다더니 오늘은 웬일로 바닐라라테야?',\n",
       " '엄마가 본 너는 네 딸에게 친아빠보다 더 훌륭한 부모의 역할을 하고 있다고 생각해. 딸을 아끼고 사랑하는 네 모습을 어느 누가 의심할 수 있겠니. 너는 충분히 잘하고 있으니 그런 걱정은 하지 않아도 돼.',\n",
       " '하루도 쉬지 않고 장사를 계속했으니 얼마나 힘들었겠니. 너무 잘 생각했어.',\n",
       " '내가 고맙지. 네가 늘 나를 생각하고 챙겨주니까. 이렇게 마음 예쁜 친구를 둔 내가 복이 많지.',\n",
       " '너무 다행이야. 당신이 이렇게 많이 상처받은 모습을 처음 봐서 나도 걱정했는데 기분이 나아져서 나도 기뻐. 이제 긍정적으로 생각하며 당신 스스로를 응원해 줘!',\n",
       " '그렇게 생각하고 계시다니 정말 다행이에요. 아주 당당하셔도 되니까 약해지지 마시고 힘을 내세요.',\n",
       " '넣는 곳마다 안된다니 네가 얼마나 조급한 마음일지 알 것 같아. 정말 속상하겠다.',\n",
       " '과거를 떠올리면서 나에게 고마웠던 것을 생각하는 네가 내 동생이라서 정말 고마워. 그리고 그렇게 과거를 회상하면서 오면 금방 집에 올 수 있겠네. 역시 현명한 내 동생 외로움을 극복하는 방법을 스스로 찾았네.',\n",
       " '어쨌든 주어진 일이니 잘 해내고 싶었을 텐데 속 많이 끓였겠다. 그래서 아직도 그 일에 매달리고 있는 거야?',\n",
       " '울다니, 무슨 일 있었던 거야?',\n",
       " '우리 막내가 싹싹하고 다정다감한 성격이라서, 친구도 비슷한 성향인 사람과 친하구나. 똑소리 나네, 우리 막내. 역시, 우리 집 복덩이라니까.',\n",
       " '고집불통인 엄마에게 시달리느라 네가 많이 피곤하고 지쳤겠구나. 아빠도 네 엄마의 성화를 못 이겨서 결국 10년째 금연 중 아니냐. 네가 지금 얼마나 압박을 받고 있을지 이해한단다.',\n",
       " '나이 들수록 근육 운동을 하는 게 맞긴 하지. 그런데 갑자기 팔 근육은 왜 만들려고 하는 거야? 언니.',\n",
       " '응. 나도 일주일에 두 번 이상은 힘들더라고. 매일 운동하는 너는 정말 부지런해.',\n",
       " '네가 평소에 수학이 다른 과목에 비해 점수가 낮은 건 사실이었지. 하지만 이번 시험을 통해서 증명된 게 하나 있잖아. 다음 시험엔 수학을 우선적으로 공부를 하는 거야.',\n",
       " '그렇구나. 다음엔 저도 같이 가요. 용기를 내서 실천해 볼래요.',\n",
       " '그렇게 인간적으로 무시당하는 느낌을 받으면 누구라도 정말 억울하죠. 오늘만 바빠서 그런 게 아니고 다음에도 또 그런다면 지적하는 것도 괜찮은 생각인 것 같아요. 그렇게 말해줄 용기가 있는 사람도 흔치 않잖아요.',\n",
       " '당신이 문학소녀 같은 감성의 소유자라서 더 그럴 거야. 그럴수록 힘을 내야지 자칫하면 감정의 골에서 빠져나오지 못할 수도 있어. 그러니 다른 좋은 일을 생각하면서 마음을 잘 다스렸으면 좋겠어.',\n",
       " '왜 안 그렇겠어요. 저도 제 단짝이랑 몇 시간만 연락이 안 돼도 허전한걸요. 엄마가 얼마나 행복하고 기쁠지 상상이 안 되네요.',\n",
       " '요즘처럼 취업이 어려운 시대에 바로 직장 잡았으니 저라면 고마워서 업고 다니고 싶을 것 같아요.',\n",
       " '심각한 상황이네요. 사하라 사막에 눈이 내린 적은 있어도, 이렇게 쌓였던 적은 없었는데요. 걱정이 많이 됩니다.',\n",
       " '차선 변경할 때 뒤에 달려오는 차 때문에 무섭지. 그러다가 한순간에 사고가 나곤 하니까. 너가 차 안에서 지켜보는 입장에서 너무 힘들었겠다.',\n",
       " '네 마음 충분히 이해해. 나라도 부모님이 원망스럽고, 아무것도 하기 싫을 거야. 마음이 많이 안 좋겠다.',\n",
       " '얼마나 슬프겠니. 오직 한 사람만 바라보고 만났는데 얼마나 상실감이 클지 말로는 표현을 못 하겠어.',\n",
       " '엄마도 크루즈 여행은 티비로만 봤네. 갑자기 그런 제안을 들어서 네가 많이 당혹스러웠겠다.',\n",
       " '엄마, 무슨 말씀이세요. 요즘은 다들 장수하셔서 칠순이면 젊은이에요.',\n",
       " '자기 스스로 병원에 간 것만으로도 지금의 마음을 충분히 극복할 수 있다 생각해요. 당신은 누구보다 강인한 사람이고, 책임감이 있으니 이제는 스스로를 믿어주면 어떨까요? 제가 언제 어디서나 말동무가 되어드릴게요.',\n",
       " '이런 얘기라면 언제든 어울려 줄게요. 회사라고 계속 일 얘기만 하면 그것도 너무 숨 막히잖아요.',\n",
       " '당연하죠, 이 세상 누구보다 당신이 나에게 가장 소중한 존재예요. 당신이 건강을 지켜야 하는데 너무 무리하는 것 같아서 너무 걱정됐어요.',\n",
       " '왜 안 그러겠어. 하지만 남자 친구가 일부러 널 아프게 하려고 그랬던 건 아니었을 거야. 너무 나쁘게만 생각하지 마.',\n",
       " '다른 집안일에도 조금 소극적인 편이세요? 음식물 쓰레기 버리는 건 누구든 꺼려 하는 일이긴 하잖아요? 너무 서운해하지 마세요.',\n",
       " '지금 너한테 소식 전해 듣는 나도 이렇게 심장이 두근거리고 기쁜데 너는 오죽하겠어? 정말 내가 다 감사하고 기분이 좋아진다.',\n",
       " '왜? 너 어제 술 마시고 어디 안 좋아?',\n",
       " '아이구. 지하철 안이 사람으로 꽉 차서 흔들리다가 뭐에 스쳤는데 네가 만졌다고 오해했나보네. 너 진짜 당황했겠다.',\n",
       " '지금 당장에 네가 할 수 있는 최선은 버스회사에 전화하는 거야. 지금 당장 해볼 수 있는 일은 모두 해야 해. 하지만, 그보다 침착해지는 게 우선이야.',\n",
       " '그래, 아무런 노력도 하지 않았는데 행운이 저절로 찾아온 거잖아. 생각만 해도 정말 설렘 폭발이야.',\n",
       " '곧 졸업인데도 자퇴 생각을 할 만큼 네 마음이 슬픔과 후회로 가득 찬 것 같아. 하지만, 지금 너 자신을 탓하며 꿈을 포기하려 한다면 네 마음도 무너지겠지만 부모님 또한 무너지실 거야. 그러니 자기와 부모님이 모두 상처받지 않기 위해 진지하게 이야기를 나눠보면 어떨까?',\n",
       " '나도 그런 생각이 문득문득 들 때가 있어. 내가 그 상황이었어도 슬프고 비참했을 거야. 뭐 대단한 일이라고 그 문제 하나에 내가 이런 기분을 느껴야 하나 싶은 생각도 들고 말이야.',\n",
       " '대리님이 그렇게 말해주니 제가 더 고맙네요. 언제든 지금처럼 연락해요.',\n",
       " '우리 아들은 열성적인 당신을 닮아서 자기 할 일을 뚝심 있게 해내잖아. 아이 건강을 염려하는 당신 마음에 하늘도 감동할 정도인데 아들이라고 모르겠어? 잘 조절할 거야.',\n",
       " '상상만 해도 짜릿하네요! 너무 현실감이 느껴져서 방금 제 팔에도 소름이 돋았어요. 나도 이런데 찾을 당시에는 지금 표현하는 것보다 더 좋았겠어요!',\n",
       " '제일 소중한 아이가 아픈데 마음이 편한 부모는 아무도 없을 거야. 나도 아이가 아파 본 경험이 있어서 부모가 아무것도 해줄 수 없을 때 너무 속상하더라고. 그래서 네 마음이 아주 이해돼.',\n",
       " '여보의 취향에 잘 맞아서 다행이다. 여보가 누워있는 걸 좋아하니까 그걸로 바꾼 것도 있어. 여보의 행복은 내 행복이니까.',\n",
       " '성별이 다르면 친절하셔도 대하기가 어렵게 느껴질 수도 있을 거 같아요. 어색하기도 할 테고 말이에요.',\n",
       " '에고. 오늘같이 더운 날 회사 가는 것도 힘든데 만원 지하철 타는 것도 모자라 가방끈까지 떨어지고. 여보 인내심이 바닥날 만도 해. 나 같아도 그랬을 거야.',\n",
       " '맞아. 내가 아는 너는 밝고 따뜻한 사람이야. 이런 고민하는 것도 네가 배려심이 많아서 그런 거 같아. 친구한테도 밝은 기운 마구 전파해 봐!',\n",
       " '아유, 그런 일이 어쩌다 한 번도 아니고 또 생겨서 엄청 당혹스러웠겠다.',\n",
       " '당신이 아들을 끝까지 믿고 격려해 준 덕분이야. 맘속으로 아무리 속상해도 아들 앞에서 내색도 안 하고 지켜봐 줄 때 진짜 대단하다고 생각했어.',\n",
       " '비행기 그만 태우고 얼른 업무에 집중하세요. 그리고 내 차에 새 셔츠가 있으니까 혹시 필요하면 나한테 언제든 메신저로 보내. 내가 주차장에서 서둘러서 가져다줄 테니까.',\n",
       " '괜찮아. 우리 딸 노트북 사고 싶다는데 엄마가 도와줘야지.',\n",
       " '훌륭한 다짐이야. 형 외롭지 않게 내가 자주 찾아가고 할 테니까 귀찮아하지 마.',\n",
       " '그런 생각 들 만하지. 네가 화를 좀 가라앉히고 이성적으로 여자 친구랑 진지하게 대화 한번 해볼 필요가 있는 거 같아. 여자 친구는 본인이 sns 중독이라는 사실을 전혀 모르고 있을 수도 있어.',\n",
       " '혼자서 공부하다 보면 많이 외로울 거라고 생각해. 그럴 때마다 주저하지 말고 언제든 내게 연락해 줬으면 좋겠어.',\n",
       " '앞으로 살아가다 보면 힘들고 어려운 일도 생기겠지만, 오늘의 기쁨을 잊지 말고 기억했으면 좋겠다. 네가 다시 일어날 용기를 받을 수 있을 거야.',\n",
       " '네가 있었으니 더 장사가 잘되고 직원들도 널 신뢰하니 쉴 생각을 못 했었을 거야.',\n",
       " '이제야 안심이 되네요. 감정화자씨의 결정을 응원하고 싶네요. 정말 많이 달라지셨어요.',\n",
       " '남편이랑 무슨 일 있었어? 무슨 일인데 그래 나한테 얘기해 봐.',\n",
       " '그럼 일하다 너무 힘들다 싶으면 연락하고. 주말에 한의원으로 보약 지으러 가자. 돈 걱정은 하지 말고 자기만 생각해.',\n",
       " '너도 제부가 저녁 준비하면서 힘들었을 생각을 하니 더 속이 상하는구나? 여전히 신혼부부 같은 애정이 느껴지는데?',\n",
       " '남들보다 시간이 오래 걸려서 그렇지, 배운 건 확실하게 실수 없이 하시잖아요. 급하게 많이 하려고 하지 마시고 천천히 한 걸음씩 간다고 생각하세요.',\n",
       " '네. 엄마 혼자서 너무 힘들어하지 마세요. 절 못난 딸로 만드시는 거예요. 꼭 저와 상의해 주세요.',\n",
       " '요새 많이 의기소침해진 것 같았는데 무슨 일 생겼니?',\n",
       " '머리도 예쁘게 하셨으니 남은 하루는 기분 좋게 보내세요. 언제라도 하고 싶은 이야기가 생기면 저한테 메시지 보내 주시고요. 확인하는 대로 곧장 답장할게요.',\n",
       " '당연하지, 내가 도와줄게. 처음부터 완전히 끊는 건 힘드니까 어느 정도만 보고 자려고 노력해보자. 내가 그 시간에 전화해서 재워줄 테니까, 너무 걱정하지 않았으면 좋겠어.',\n",
       " '저도 같이 일을 하면서 감정화자씨의 씩씩함에 덩달아 힘을 얻을 때가 얼마나 많았는데요. 이렇게 약해진 모습을 보니 제 마음도 찢어질 것 같지만, 곧 회복하시리라 의심치 않아요. 저도 힘을 보탤게요, 벌레가 정 무서운 날에는 저를 부르셔도 좋아요.',\n",
       " '마음 한 구석이 뚫린 것만 같은 기분이겠다. 자기가 이렇게 우울해하는 거 처음 봐. 내 가슴이 찢어질 것 같네.',\n",
       " '가족이니까 이런 사소한 문제로 갈등이 있는 거란다. 나이 들면 이런 일도 다 추억이 될 테니 편하게 생각하렴.',\n",
       " '정말 하루하루 고통의 연속이겠다. 밥 먹는 즐거움이 얼마나 큰데 그걸 송두리째 뺏긴 거나 다름없는 거잖아. 얼마나 상처가 크겠니.',\n",
       " '다른 사람들이 보기엔 별일 아닐 수 있지만, 매번 참아온 자기는 얼마나 속에 울분이 쌓였겠어. 아무도 자기 편을 들어주지 않는 것 같아서 듣는 내가 다 속상하다.',\n",
       " '여보, 회사에서 안 좋은 일이 있었던 거야? 차장님이 뭐라고 하셨는데?',\n",
       " '알겠어. 언니가 고기 구우니까 오이고추는 내가 사가지고 가서 씻을게.',\n",
       " '인생에는 누구나 굴곡이 있다고 했어. 하지만 내가 보는 너에게는 이런 슬픔을 꿋꿋이 이겨낼 힘이 있어. 그리고 내 생각에 너는 이번을 잘 이겨낸다면 앞으로는 정말 행복한 일들이 벌어질 거야. 슬퍼하지 말아.',\n",
       " '당신이 책임감이 강해서 어떻게든 아이들을 이끌어주려는 마음에 욕심내다 보니 더 그럴 수 있겠다. 늘 맡은 일에 책임을 다하려고 힘쓰는 당신을 보면서 정말 존경스럽다고 느낄 때가 많아. 하지만 마음의 짐을 좀 내려두고 가볍게 생각할 필요도 있을 것 같아.',\n",
       " '응. 정말 좋은 친구가 생겼네. 기분이 날아갈 듯이 기쁘겠네. 네가 좋아하는 모습을 보니 나도 기분이 좋아진다.',\n",
       " '그동안 감정화자님이 고생 많이 하셨죠. 드디어 마스크 실외 착용이 해제되어 감정화자님이 그 누구보다 기분 좋으시겠네요. 이제는 좀 편하게 수업하실 수 있으실 것 같아요. 고생 많으셨어요.',\n",
       " '항상 시간을 계획적으로 쓰려는 너라서 이 상황이 더 이해하기 힘들 수 있겠다는 생각 드네. 항상 시간 활용을 잘하는 너를 보면서 엄마도 너에게 배울 점이 많다고 생각해.',\n",
       " '아... 온갖 걸로 다 잔소리하신다고 하셨지. 그걸 또 어떻게 참냐. 너 진짜 답답하겠다.',\n",
       " '벌써 폐가 깨끗해지고 있는 것 같아. 너무 기대된다. 연락 기다리고 있을게.',\n",
       " '왜 화가 안 나시겠어요. 저 같아도 화가 잔뜩 날 것 같습니다. 너무 고생하시고 계시네요.',\n",
       " '그러면 네가 불편해서 렌즈도 빼고 잤을 확률이 높지 않을까?',\n",
       " '잘 알지. 나였어도 나부터가 힘든 상황이면 나를 방해하는 무언가에 대해 좋게 생각하기 힘들 것 같아. 그 와중에 친구한테 그런 반응이 돌아와서 자기가 얼마나 당황했겠어. 괜히 죄책감이 커졌을 것 같아서 내 마음도 좋지 않네.',\n",
       " '내가 만약 너 같은 상황이었으면 당황해서 정말 아무것도 못했을 거 같은데 대단하다. 그래도 침착하게 위기를 잘 극복했는걸?',\n",
       " '동생아, 더운데 화내면 더 더워. 엄마 말씀대로 찬물 샤워라도 자주 하면 잠시나마 시원해지지 않을까? 더위를 무조건 견디는 것보단 낫잖아.',\n",
       " '너 비 오는 거 좋아하잖아. 난 비가 계속 와서 네가 기뻐할 줄 알았는데. 비가 그치기를 기다리는 거니?',\n",
       " '그래. 날이 많이 더운데 금방 다녀오렴. 연락 기다리고 있을게, 아들.',\n",
       " '처제는 지금 당신한테 하소연하면서 실연의 상처를 치유하는 중인 것 같아. 자꾸 얘기함으로 나중에는 아무것도 아닌 것으로 만들고 싶은 건지도 몰라. 당신도 그렇게 이해하고 너그러운 마음으로 들어줌으로 당신 마음이 편해졌으면 좋겠다.',\n",
       " '머릿속이 맑아졌으니 이제 다른 방법도 생각났나보네. 다행이야. 네 말대로 다른 방법도 이제 있으니까 이제 마음을 차분하게 달래보자.',\n",
       " '그랬구나. 당신 아끼던 건데 마음 많이 아팠겠다. 돌아가신 장모님이 사 주신 거라고 오래 쓰고 싶어 했잖아. 너무 힘들어하지 않았으면 좋겠다. 괜찮아?',\n",
       " '왜 그러세요 무슨 일인데 그런 말씀을 하시는 거예요?',\n",
       " '무례한 행동으로 자기가 상처받은 것 이해해, 듣는 것만으로 나도 속상한걸. 그래도 친구가 벌인 무례한 행동에 진심으로 상처받고 혼란스러워하지는 않았으면 좋겠어. 자기를 깎아내리기 위한 말에 일일이 반응해 주면 결국 지치고 상처받는 건 자기잖아.',\n",
       " '내가 예전에 당신은 너무 일만 열심히 하는 게 아니냐고 툴툴거렸던 적 있었죠? 그래서 우리 처음으로 부부싸움 할 뻔했었잖아요.',\n",
       " '정말 다행이네요, 사실 문자를 받고 당신이 많이 실망하는 것 같아서 걱정이 되었어요. 친구를 위하는 당신의 마음이 무시 되었다고 생각하는 것 같았기 때문이에요.',\n",
       " '오늘 그것 때문에 연차까지 내지 않았어요?',\n",
       " '왜 무슨 일 있었던 거야?',\n",
       " '우리 딸이 기분이 좋다니 엄마도 덩달아 행복한걸. 오랜 시간 고민 끝에 낸 결론이라 더 기분이 좋겠다.',\n",
       " '당연히 그럴 수 있었다고 생각해. 그래서 못한 일을 해결했어?',\n",
       " '그래 맞아. 힘들고 불편해도 세상을 암담하게 살 필요까진 없어. 병을 안 좋게 생각하는 것보단, 그 불편을 딛고도 일상을 잘 헤쳐 나가고 있다고 생각하면 어떨까?',\n",
       " '너는 지금 가족들을 위해서 겨우 버티고 있는 거잖아. 최선을 다해서 힘을 내고 있는데 이런 상황이 되었으니 정말 많이 괴로울 것 같아.',\n",
       " '네, 맞아요. 이제 불안한 마음이 조금 가라앉으신 것 같아서 저도 마음이 놓이네요. 약 발라주시고 따뜻하게 해주시고 물 먹이면 기운 차리는 데 많은 도움이 될 거예요.',\n",
       " '그렇지, 우리 감정화자는 밥을 먹으면 기분이 좋아지고 표정도 밝아지는데. 오늘 시작이 조금 우울하겠다. 출근하는 길에 간단한 샌드위치나 간식 사먹지. 사먹었어?',\n",
       " '그런 상황에 섣불리 행동하기도 힘들지 당황한 네 맘 이해해. 하지만 이건 네 문제가 아니니 너무 자책하지 말았으면 좋겠어. 상황이 원하는대로 흘러가지 않는 것이 어떻게 너의 잘못이겠니.',\n",
       " '입사한 지 몇 년 됐는데 업무 능력이 부족한 거 같다는 사람? 이번에 무슨 잘못을 했는데 자기가 이렇게 기분이 상해있을까.',\n",
       " '걱정스러워하는 건 마음 아프지만, 나는 자기가 이렇게 생각해 주는 게 오히려 고마운걸? 그만큼 나랑 함께하는 시간을 소중히 여긴다는 거잖아.',\n",
       " '그렇구나. 그러면 집 도착하면 시간이 너무 늦잖아요.',\n",
       " '응, 잠깐잠깐 문자로 연락은 괜찮아. 무슨 일이야? 나도 없는데 혼자서 많이 놀란 거 같아 마음이 쓰이네. 자기 괜찮은 거 맞지?',\n",
       " '왜 안 그러겠어. 감정 화자님의 기분이 어떨지 눈에 선하다. 누구나 다 이런 일을 겪는다면 행복하다고 느낄 거 같아.',\n",
       " '엄마도 한때 고민이 정말 많았단다. 하지만 그건 네 잘못이 아니야 누가 빠르고 누가 느리고는 중요하지 않아. 절대 조급해할 필요가 없는 부분이야 도와줄 테니 천천히 생각해 보자 기운 내 우리 딸.',\n",
       " '항상 엄마가 최고라고 말해주던 딸에게 그런 말을 들었다니 정말 속상할 만했네. 당신은 흰머리 나도 매력 있고 예쁘기만 한데.',\n",
       " '감정화자님이 많이 속상했겠다. 교수님이 직접 가리키면서 그렇게까지 말씀하셨다니. 얼마나 상처 입었을지가 느껴져서 내가 다 속상하다.',\n",
       " '당신은 연로하신 부모님을 모시고픈 마음이 크잖아요. 그걸 생각하며 마음을 다스려봐요. 잘 해내고자 하는 욕심이 있다면 무엇이든 금방 익히고 익숙해져 마음이 편할 수 있을 거예요.',\n",
       " '당신이 무척 바빴으니까 어쩔 수 없다고 생각해요. 아이와 함께 있을 때 행복감은 정말 말로 표현할 수 없죠.',\n",
       " '정말 좋은 자세다. 그래, 그 정도의 의지라면 빠르게 성장할 수 있을 거야. 위기를 발전의 기회로 삼는 내 친구가 대견하다.',\n",
       " '아니야. 우리가 친구가 된 세월만 해도 몇 년이야? 네가 부르는 건데 당연히 나와야지. 뜸 들이지 말고, 갑자기 무슨 일이길래 이렇게 급하게 불렀는지 얘기나 해봐.',\n",
       " '생각했던 스타일대로 안 되는 것만큼 당황스러운 일도 없잖아요. 그런 마음이 드는 건 당연해요. 게다가 파마나 염색도 아니고 커트만 했는데 그런 결과가 나오다니, 정말 놀라고 정신이 없겠어요.',\n",
       " '나에게 없는 걸 남이 가지고 있으면 당연히 질투 날 수밖에 없지. 오늘 그것 때문에 온종일 기분이 좋지 않았겠구나. 아무래도 너도 탐이 나서 그런 기분이 다 들었던 거지?',\n",
       " '저런, 말 실수를 한 모양이네. 특히나 함께 간 곳을 헷갈리는 건 상대에게 큰 실례고 상처가 되지. 그것 때문에 많이 힘들어 보이네. 괜찮아?',\n",
       " '앞으로 닥쳐올 액을 가방을 잃어버림으로써 미리 겪으셨다고 생각합니다. 앞으로의 일정은 무사히, 그리고 즐겁게 넘기실 수 있을 거예요. 그렇게 되길 제가 기도하겠습니다.',\n",
       " '그 후배와 남자 친구분이 서로의 일상을 공유하는 것처럼 느껴져서 많이 서운하고 상처받았구나. 게다가 언니 남자 친구가 무심하고 눈치 없게 행동하는 것 같이 느껴져서 속이 많이 상했겠어.',\n",
       " '응, 결혼 다시 한번 축하해. 이렇게 네 결혼을 축하할 수 있어 나도 기뻐.',\n",
       " '네가 그 이야기 꺼낸 게 벌써 몇 주나 지났는데 아직도 증상이 나아지지 않았어? 요리할 때 악영향이 있을 것 같은데 괜찮아?',\n",
       " '어디 아프신 거예요? 멀리 나가서 사는데 부모님 아프다는 소식 들으면 너무 죄송하고 걱정이 많이 되죠.',\n",
       " '당연하지. 오히려 네가 단호하게 마음먹는 것이 네 전 여자 친구한테도 좋은 일일 거야. 네가 겨우 마음 추슬렀는데 다시 힘들까 봐 너무 걱정된다.',\n",
       " '응, 자기도 지금 너무 속상하겠지만, 감정 추스르고 기다리다 보면 연락이 분명히 올 거라고 생각해. 일단 조금 기다리고 추후에 연락이 오면 다시 대화해보는 건 어때?',\n",
       " '그게 정말이야? 너무 불편할 텐데 걱정이다.',\n",
       " '너랑 친한 직원분이 너 몰래 말도 없이 가버려서 큰 상처를 받았구나. 왜 안 그러겠어. 누구나 상처받을만한 상황이야.',\n",
       " '많은 사람들이 같은 기분을 느꼈다면 정말 화가 나는 결말 내용이었나 보구나. 맞아, 어떤 내용을 보여주겠다는 기획의도도 약속이라면 약속인데 농락당한 기분이 드는 것도 당연해. 아무리 어려워도, 돌고 돌아서 위로하는 마음들이 만난게 드라마란 걸 잊지 말았으면 좋았을 텐데.',\n",
       " '갑자기 무슨 일이에요, 이 시간에. 왜 그렇게 화가 난 거예요?',\n",
       " '네, 자기 자신을 믿는 일만큼 중요한 일이 없다고 생각해요. 제 얘기를 괜한 참견이라 여기지 않고 좋게 생각해줘서 저야 말로 고마워요. 언제든 고민이 있으면 편하게 얘기해줘요.',\n",
       " '네가 기분이 좋아졌다니 너무 다행이야, 나도 안도의 미소가 절로 나온다. 네가 아이를 잘 돌봐준 덕분에 가정은 다시 웃게 될 거야, 걱정하지 마.',\n",
       " '괜찮아요, 일단 차분하게 생각하면 좋은 방법이 나올 거예요. 급할수록 돌아가라고 하잖아요. 무리하다가 다치면 더욱 상황이 어려워질 뿐이니, 항상 안전과 건강을 최우선 하세요.',\n",
       " '원래 모든 일은 깊게 생각할수록 크게 느껴지는 법이야. 서로 사랑하는 진심을 생각하고 걱정은 잠시 내려놔. 언니 마음이 괜찮아지면 자연히 해결될 일이라고 믿어.',\n",
       " '엄마도 가끔 동창회나 동호회 모임이 있을 때면 평소보다 옷차림에 신경을 쓰게 되더라고. 그게 얼마나 사람을 예민하게 만드는지 잘 알고 있어서 그런지 그 마음이 충분히 이해가 가. 하지만 이미 지난 일이니 더는 마음에 담아두지 않는 게 어떨까.',\n",
       " '그래도 한 번 물어보는 게 어떨까? 그 친구의 생각이라도 들어봐야 네가 받은 상처가 나아질 수 있을지 알 것 같은데. 그러면 네 마음이 조금이라도 나아질 수 있지 않을까?',\n",
       " '정말 좋은 생각이야! 언제든 그런 의지와 마음가짐만 가지고 지낸다면 어떤 일이든 잘 이겨낼 거야. 엄마도 늘 우리 딸을 응원하고 있으니까 꼭 힘내서 늘 즐겁게 지낼 수 있기를 바란단다.',\n",
       " '응? 무슨 일이라도 있어? 왜 그래.',\n",
       " '안 그래도 엄마는 명예퇴직으로 인해 마음에 충격을 받았잖아요. 저도 엄마 명예퇴직 소식을 들었을 때 마음이 찢어지는 것 같았어요. 엄마는 그 누구보다 열심히 일했잖아요.',\n",
       " '당신에게 도움이 될 수 있어서 정말 다행이야. 잘 만나고 와서 어땠는지 꼭 알려줘.',\n",
       " '당연하죠! 당신이 얼마나 사랑하고 아껴주는지 알고 있을 거예요. 그러니까 더더욱 아빠와의 시간을 기대했던 거고요.',\n",
       " '네가 너무 슬퍼하면 시어머니도 마음이 편치 않으실 거야. 그러니 네가 더욱 기운을 내야지.',\n",
       " '네 말대로 그렇게 되면 정말 야구장 분위기 한껏 달아올라서 재밌긴 하겠다. 집에서 보는 걸로도 신날 텐데 현장에 있으면 얼마나 더 신나겠어.',\n",
       " '왜 무슨 일인데 그래?',\n",
       " '도움이 되었다니 저 또한 기쁘게 보낼 수 있을 것 같아요. 언제든 또 하고 싶은 얘기가 생기면 연락해 주세요!',\n",
       " '그래, 우리 대리님 설 연휴 끝나고 보자.',\n",
       " '칭찬을 해주니까 기분이 좋네. 내 동생 얘기인데 내가 누구보다 잘 들어줘야지. 힘든 일 있으면 언제든지 연락해.',\n",
       " '네 친구들이 만나면 명품 얘기만 한다니 나는 좀 놀랍구나. 세상에 얼마나 많은 이야기가 있는데 그런 걸로 시간을 보내는 게 과연 맞는지 모르겠다. 네가 그 모임에서 남의 얘기를 듣기만 한다 생각하니 너무 가슴이 아프다.',\n",
       " '야속하지만 감정화자씨 잘못이 아닌 만큼 더 깊이 생각하지 않았음 좋겠어요. 살아보니 억울한 일도, 기쁜 일도 부지불식간에 찾아오더라고요. 내 힘으로는 막을 수 없는 흐름이라고 생각해보면 마음이 편해질지 몰라요.',\n",
       " '자신감 있는 태도는 더욱 신뢰가 간다고 하잖아. 안 그래도 넌 언제나 밝고 빛나는 사람이었는데, 더욱 즐거운 대학 생활이 되겠다.',\n",
       " '그렇다면 다행이다. 주말에는 부모님과 드라이브라도 다녀오는 건 어때?',\n",
       " '아침부터 멀리 이동하느라 고생 많았어요. 다른 친구들도 다 도착한 거예요?',\n",
       " '내가 도와주러 갔어야 했는데 못 가서 미안하구나. 안 그래도 네가 괜찮을지 걱정 중이었단다. 잠도 못 자서 피곤할 텐데 걱정거리가 하나 더 늘었구나.',\n",
       " '그렇게 생각 하지 마. 당신의 통증이 얼마나 큰지 그분은 모르니까 하는 말인 거잖아. 그런 말에 너무 신경 쓰지 않았으면 좋겠어.',\n",
       " '네가 상처를 크게 받은 것 같아 걱정됐는데 다행이구나. 너무 상처받지만 말고 남편이 돌아오면 진지한 대화를 나눠보렴.',\n",
       " '여보가 늘 이용하는 호선 말하는 거지? 사람들 사이에 껴서 타기도 힘들잖아. 참을 인을 몇 번이나 그렸을 텐데.',\n",
       " '응 우리 아들, 아빠는 맨 앞자리에 잘 앉아있어. 우리 아들 나오는 것만 기다리는 중이야. 돌발 상황이라니 무슨 일 있니?',\n",
       " '무슨 일이야? 눈물까지 흘릴 정도면 보통 일이 아닌 것 같은데.',\n",
       " '저도 이해돼요, 과장님. 유독 피부가 거칠거나 트러블이 생기면 저는 집 밖에 나가기도 싫더라고요.',\n",
       " '저희 아이는 견과류 알레르기가 있어서 식품알레르기에 대해서 좀 찾아봤거든요. 그러다가 알게 됐는데 많이 드시더라고요.',\n",
       " '무슨 일 있었어? 고민이 있다면 형한테 다 털어놔 봐.',\n",
       " '그렇다면 엄마도 이제 마음이 놓인다. 한결 가벼워진 것 같아 다행이야.',\n",
       " '그래도 혹시 모르니까 가지고 있어 봐. 예보대로 진짜 갑자기 비가 내릴 수도 있잖아. 요즘 맑다가도 갑자기 어두워지면서 소나기 내리더라!',\n",
       " '우리가 안 될 거라고 단정 짓지 말고 긍정적으로 생각하자. 우리가 기운 내고 믿어드려야 할머니도 힘내실 거 아니야. 형도 우울한 생각 떨쳐내고 이겨내자고.',\n",
       " '멋지다. 슬픈 상황에서도 착한 마음을 가지고 살아가려는 모습에 할머니께서도 분명 기뻐하실 거야.',\n",
       " '왜 안 그러셨겠어요. 이런 상황이 계속 반복되면 너무 힘드실 것 같아요. 이번 기회에, 아버지께 솔직하게 말씀을 드려보는 건 어떨까요?',\n",
       " '감정화자님, 그렇게 말씀하시면 저 섭섭해요. 전 감정화자님의 고민을 언제든 들어드릴 수 있답니다. 어서 제게 털어놓아 보세요. 다 들어드릴게요.',\n",
       " '사람 마음이 쉽게 변하기도 참 어려운데 정말 대견스럽네. 엄마의 말에 이렇게 금방 기운 내는 모습을 보여줘서 너무 다행이고 뿌듯해. 지금처럼만 열심히 살아간다면 아무 문제 없을 테니 다 잘하려고 너무 부담은 갖지 않았으면 좋겠어.',\n",
       " '나도 네가 좋은 친구라고 생각해. 그래서 네가 궂은일 겪지 않고, 일이 잘 풀리길 바라. 내가 뒤에서 있는 힘껏 응원해 줄게.',\n",
       " '자기가 행복해 보여서 요즘 나까지 덩달아 행복한 거 알아? 자기는 늘 나에게 좋은 에너지만 주는 사람이라니까.',\n",
       " '우리, 내년에는 가족끼리 다 같이 계획을 세워서 지켜보는 게 어때?',\n",
       " '그래. 저녁 맛있는 거 먹고 기운 냈으면 해.',\n",
       " '그렇다니 다행이야. 앞으로도 고민 있으면 언제든지 형한테 얘기하고. 형은 언제나 네 편이니까.',\n",
       " '일이 많아서 그래?',\n",
       " '누구라도 쫓겨나듯이 해고가 되면 너처럼 괴롭고 상처를 받을 거야. 그렇지만 세상이 너를 힘들게 하더라도 쉽게 무너지지 말자. 우리는 그저 주어진 상황 속에서 좌절하지 말고 최선을 다하면 되는 거야.',\n",
       " '평소에는 커피를 마시면 효과가 있었는데 지금은 두 세잔 먹어도 계속 졸릴 줄은 몰랐어. 지금 이 이야기를 듣는 동안에도 너무 당황스럽다. 그렇다면 잠이 오려고 하면 몸을 움직이는 활동을 하면 어떨까?',\n",
       " '그렇겠네. 너는 이미 아이 둘 잘 낳아서 잘 키우고 있으니깐 상대적으로도 더 힘들겠다.',\n",
       " '네가 아프지 않았으면 좋겠다. 빨리 나아서 건강한 모습으로 보자.',\n",
       " '아들, 네가 그 친구를 위한 마음이 커서 그래. 그래서 더 잘하려고 하니 스트레스를 받는 거겠지. 평소대로 하면 무사히 잘 끝낼 수 있을 거야.',\n",
       " '자기가 이렇게 힘들어하는 모습을 보니 마음이 너무 아프네. 유독 힘든 날이 있는 것 같아. 더 힘들지 않으려고 자기가 잘 이겨내고 있는 것 같아.',\n",
       " '힘겨웠을 텐데도 씩씩하게 웃으며 살아온 그 학생이 대견하네요. 그리고 학생의 고민을 자기 일처럼 여기며 함께 슬퍼할 줄 아는 선생님도 참 멋져요. 자신의 이야기에 진심으로 귀 기울여주는 선생님이 있어서 그 학생은 이제 덜 슬플 거예요.',\n",
       " '우리 사이에 뭘 이런 걸 가지고 그래. 이번 주말에 너네 집으로 갈게. 그때는 도와줄 테니 샤워도 맘껏 하고, 깁스 때문에 못하는 거 다해!',\n",
       " '응. 사람들은 원래 화가 나면 하고 싶지 않았던 말도 자동으로 하게 될 때가 있잖아. 진심이 아니었다는 말을 전하면서 진심을 털어놓으면 모두가 이해해줄 거야. 그리고 친구들이 불만을 얘기한 건 너와 관계를 개선하고 싶어서 그랬다고 생각할 수 있지 않을까?',\n",
       " '자기가 그런 마음이라니 내가 다 속상하다. 자기가 화가 나는 부분이 어떤 건지 알아서 나도 더 화가 나기도 하고. 그리고 너무 자주 고장이 난다고 하니까 위험할까 봐 걱정이 되기도 하네.',\n",
       " '헤어지자고 했던 여자 친구 이야기구나. 형이 도움을 줄 수는 없어도 이야기는 들어 줄 수 있어. 자세히 말해 볼래?',\n",
       " '당연하지. 대화는 관계 회복의 시작이니까. 지금이라도 네가 먼저 손을 내밀어서 대화하자고 해봐.',\n",
       " '왜 갑자기 그런 말씀을 하세요? 무슨 일 있으신가요?',\n",
       " '동생아, 사람은 누구나 생각하는 것보다는 강하더라. 선배도 자기 몸 상태를 누구보다 잘 알 테니까, 너무 불안해하지 않아도 돼. 선배를 위하는 따뜻한 마음이 불안을 키운 것도 있을 거야.',\n",
       " '난 초보운전일 때는 너무 떨려서 식은땀 나고 장난 아니었는데. 심장이 밖으로 튀어나오는 줄 알았다니까. 아직도 가끔 운전할 때 긴장될 때가 있는데 너는 대단한 편이다.',\n",
       " '갑자기 무슨 일이야? 남자 친구랑 다투기라도 한 거야?',\n",
       " '손수 제작한다는 게 절대 쉽지 않은 일이었을 텐데 결심하고 실행에 옮긴 것도 정말 너답고 멋있는데? 이번 일로 네가 활기차고 생기있어진 거 같아서 정말 보기도 좋고 말이야.',\n",
       " '우리 딸 마음이 편안하다니 엄마는 이보다 기쁠 수가 없다. 부모란 역시 자식의 행복이 가장 큰 기쁨인가 봐.',\n",
       " '내 동생 참 속도 깊다. 엄마랑 이야기해봐 분명 사과하실 거야.',\n",
       " '자기를 닮아서 좋은 어른으로 클 거니, 전혀 걱정할 필요 없어. 성장에는 항상 고통이 따르는 법이지만 성장 후의 성숙은 무엇과도 바꿀 수 없지.',\n",
       " '피부가 까맣든 하얗든, 혼혈이든 아니든, 그게 뭐가 중요하겠어. 형에 대해 사람들이 뭐라고 떠들든 형은 누가 뭐래도 형이잖아. 그런 소리에 속상해하지 말고, 단단하고 담대하게 이겨내고, 자기 자신을 더 많이 사랑해줬으면 좋겠어.',\n",
       " '물론 처음부터 쉽지는 않을 거란 생각이 들어요. 하지만 포기하지 않고 꿋꿋하게 노력해 나가다 보면 많이 괜찮아질 거예요. 당신이 언제 그랬냐는 듯 떨쳐버리고 홀가분한 마음으로 지낼 수 있기를 바랄 뿐이에요.',\n",
       " '네가 얼마나 지극정성으로 대했는데 왜 그 마음도 몰라주고 그러는지 이해가 안 간다. 이건 내가 생각해도 있을 수 없는 일이야. 나도 이런 마음이 드는데 너는 오죽하겠니.',\n",
       " '아니에요. 오늘 병원 잘 다녀오고 무슨 일 있으면 또 연락해줘요.',\n",
       " '너는 책임감이 크니까 그만큼 부담감도 많이 느꼈을 거야. 하지만 그만큼 오래도록 신경을 많이 쓰고 노력을 해왔잖아. 분명 그 노력은 너를 배신하지 않고 잘 해결될 테니 너무 걱정하지 마.',\n",
       " '언제나 자부심을 가지고 일하시는 매니저님이 얼마나 자존심이 상했을까요.',\n",
       " '그럼 정말이고 말고 너무 걱정할 필요 없을 것 같아. 너의 진심은 분명 친구에게 닿을 거야.',\n",
       " '네가 얼마나 슬플지 이해해. 나도 작년에 할아버지께서 갑작스럽게 돌아가셨는데, 그동안 잘 해드리지 못한 게 후회로 남더라. 마음 잘 추스르고 장례식장에 잘 다녀와.',\n",
       " '그렇군요, 답답해하는 아이와 그걸 지켜보는 감정화자님 입장에서는 그동안 얼마나 속이 상했을까요. 이제 마스크를 벗어서 아이와 함께 더 기쁘실 것 같네요.',\n",
       " '죽을 쑤는 것도 보통 일이 아닌데, 정성스러운 포장까지. 나는 이야기만 들어도 감동이 밀려오네.',\n",
       " '아버지께서 고생하신 거야 당연히 잘 알고 있죠. 하지만 아버지께 그런 인내심을 심어주고 응원을 해주신 건 항상 엄마였잖아요.',\n",
       " '무슨 일이길래 그래? 동생에게 게임을 가르쳐줘도 제대로 배우지 못해서 그런 거야?',\n",
       " '아침에 눈 뜨자마자 얼마나 신나서 달려갔을지 눈에 선하고 나라도 그랬을 것 같아. 오늘을 특별한 날로 만든 건 너니까 너한테는 그에 따른 기쁨과 성취감을 누릴 자격이 충분해.',\n",
       " '무슨 일인데 그래? 자주 보던 친한 친구가 그러는 거야? 아니면 가끔 보는 친구야?',\n",
       " '어린 시절의 향수는 누구에게도 아련하고 동화 같은 그림으로 남아있는 것 같아요. 그리워하지만 막상 잊고 살아가는데 이렇게 당신처럼 반가운 사람을 보게 된다면 다시금 떠오르죠. 언제 한번 그 친구 우리 집에 초대해 봐요, 당신 어린 시절이 나도 궁금하네요.',\n",
       " '덥다고 너무 안 좋은 생각만 하지 마시고 차가운 거 먹고 좋은 생각만 하시면 좋겠어요. 주말에 시원한 곳 가서 더위 싹 가시고 오자고요.',\n",
       " '그래요. 식사도 단단히 하시고 무엇보다 잘 먹어야 이 힘든 상황을 잘 극복할 힘이 나죠! 가보시고 오래 계시게 될 것 같으면 연락 주세요. 나머지는 제가 대리님 일까지 차질 없게 하겠습니다.',\n",
       " '출발했다니 어쩔 수 없지. 내가 집 가는 길에 들렀다가 갈게! 해결할 수 없는 일도 아니니까 너무 자책하지 마.',\n",
       " '고양이가 그 무거운 창문까지 열 거라고 어떻게 짐작할 수 있겠어. 자기가 큰 잘못을 한 게 아니니까 너무 자책하지 마. 우선은 고양이를 찾는 게 중요하니까 침착하게 마음 먹고 생각을 정리해 보는 게 좋겠어.',\n",
       " '그렇지. 그런데 운동을 해도 체력이 한순간에 갑자기 늘지는 않잖아. 어느 순간 계단식으로 한 번씩 고통의 단계가 낮아지지 않을까? 그럼 그 시간만큼 네가 즐길 수 있는 여가 시간도 생기고 지금 느끼는 슬픔도 줄어들 수 있지 않을까?',\n",
       " '전 감정화자님 행동이 옳고 그르고를 떠나서 바람직한 행동이라고 생각해요. 정말 요즘 보기 드물게 남을 배려하는 너무 귀한 마음이고요. 정말 멋지세요.',\n",
       " '다행이구나. 가서 휴일에는 친구들하고 여행도 다닐 테니 가고 싶은 여행지를 적어보는 것도 좋을 것 같아. 불안한 마음이 드는 생각은 깊게 하지 말고 설레고 좋은 생각을 더 많이 하렴.',\n",
       " '넌 정말 현명하고 알뜰한 소비 습관을 가지고 있구나. 너의 꼼꼼하고 부지런한 성격이 여기에서 빛을 발하는걸.',\n",
       " '감정화자님께서 너무 힘든 일을 겪으셨었기 때문에 마음이 아직 극복을 못 해서 그런 거라고 저는 생각해요. 마음속에 여물어지지 않은 상처가 꿈으로 나온다고 하잖아요.',\n",
       " '이미 지난 간 일을 계속 생각하면 자기가 더 속상할 것 같아 걱정이네. 많이 안 다쳤으니 다행이야. 너무 신경 쓰지 말고 마음 편하게 가지면 좋겠어.',\n",
       " '그래 그것참 너무 다행이네. 그러고 보면 넌 어떤 신발이건 좋아하는 건 아닐까? 항상 가장 마지막에 나를 완벽하게 맞춰주는 게 신발이어서 좋아한다고 했었잖아.',\n",
       " '누군가와의 결실만을 좇기보다는 네 마음 그 자체를 소중히 여기는 네 성숙함이 참 예쁘다. 어두운 밤길에 가로등의 한 줄기 빛은 유난히 밝게 다가오잖니. 그 빛의 가치를 알기 쉽지 않은데, 넌 이미 마음을 나눌 준비가 된 것 같구나. 정말 대견해.',\n",
       " '우리 딸의 결정은 믿어 의심치 않지. 그보다 점점 네 남자 친구가 어떤 사람일지 더 기대가 되는걸? 한시라도 빨리 만나보고 싶구나.',\n",
       " '그래도 잘 견뎌내고 마무리 잘했다니 다행이야. 역시 네 의지력과 책임감은 알아줘야 해. 학창 시절 때부터 너는 한다면 하는 애였잖아.',\n",
       " '다행이에요. 너무 불안해하시거나 자책하지 않으셨으면 좋겠어요. 살다 보면 누구나 자신의 힘으로 통제할 수 없는 일들이 생기기 마련이잖아요. 그러니 훌훌 털어버리시고 편안하게 마음먹으세요.',\n",
       " '평상시 네 모습과 야구장은 왠지 동떨어진 분위기인데, 의외의 면이 있네.',\n",
       " '맞아요. 지금 너무 배가 고파서 뭐 좀 먹으려고요. 감정화자씨는 회사에 남아 계세요?',\n",
       " '나도 그 기분 뭔지 알 것 같아. 마냥 불안하고 조급한 마음으로 지내다가 느긋한 시간을 가지게 되니 왜 안 그렇겠어.',\n",
       " '자기는 자격이 충분한걸. 우리 학과에서 가장 열심히 노력하고, 성적도 우수하고 똑똑하잖아. 자기는 좋은 인재이기도 하고, 실력적으로도 뛰어나기에 난 평소에도 자기가 참 멋지다고 생각해왔어.',\n",
       " '그렇죠, 당연히 당신의 마음이 상하고 당황하고 했을 거예요. 그런데 나의 말을 들으면 기분이 풀려서 아들을 혼내지 않고 잘 타이르는 전략으로 바꿨다니. 내가 다 뿌듯할 지경이네요.',\n",
       " '나라도 너무 힘들고 마음이 섭섭할 거 같아. 그런데 자기가 상처받고 힘들어서 안 좋은 마음이 생겼을 텐데. 나라면 그렇게 못할 거 같은데, 자기는 엄마의 입장을 배려하고 생각하는 자기가 자랑스럽다.',\n",
       " '친구들과 내가 다르다는 지점을 알게 되면서 아주 당황스럽고 곤란해졌구나. 여권 말고도 다른 많은 경험에 대해 나누는 걸 들으면서 남들과 다르다는 생각에 놀라기도 했고. 당황스러워지는 바람에 어찌할 줄 모르고 막막해졌을 마음을 이해해.',\n",
       " '엄마가 알뜰해서 그런 거예요. 엄마가 그렇게 내핍하지 않았다면 경제적으로 그렇게 어려운 시기를 어떻게 넘겼겠어요.',\n",
       " '최저시급을 받으면서 힘들게 일을 하는데 상사가 시키는 게 많다니 나 같아도 짜증날 것 같아. 나도 손님 응대를 해본 적이 있는데 감정적으로 정말 지치더라고.',\n",
       " '우리 딸이 아주 사랑에 푹 빠진 모양인걸. 네게 잘해주니?',\n",
       " '네가 오늘 정말 그 샌들 때문에 분노가 일었을 것 같아. 그동안 기다린 시간까지 더해져서 말이야. 네 기분이 정말 나빴겠구나.',\n",
       " '잘했네. 시어른들 모두 만족스러운 식사가 되었나 보다!',\n",
       " '역시 화끈한데, 나도 동참할게. 배우는 거야 큰 비용 안 드니까 시작은 할 수 있을 것 같아.',\n",
       " '식용유 가격 때문이라고 이해는 가지만 안타깝네요. 그 사장님이 좋은 단골을 잃으셨어요. 대리님도 편하게 다니던 단골집을 잃은 거 같아 쓸쓸한 기분이 들겠어요?',\n",
       " '엎친 데 덮친 격이라고 요새 네 상황이 그랬겠구나. 힘들어하는 네 모습을 보니 엄마도 마음이 좋지 않구나.',\n",
       " '자기는 어떤 모습이어도 내게는 가장 예쁘고 아름다워 보여. 자기 눈에 지금 모습이 창피할 수도 있겠지만, 난 이것도 추억의 한 장면으로 기억해 놓을래. 단지, 자기 마음이 너무 속상하지만 않길 바랄 뿐이야.',\n",
       " '맞아, 회사를 그만둔 지 오래되면 자신감도 많이 떨어지지 과연 내가 무얼 할 수 있을까? 하는 상실감과 슬픔이 크지.',\n",
       " '갑자기 그건 왜? 너무 오래된 일이라 기억도 잘 안 난다. ',\n",
       " '괜찮아질 필요 없어, 당신의 이 슬픈 마음이 풀리고 나아질 때까지 마음껏 아이를 추억하고 그리워해. 당신과 같은 슬픔을 가진 내가 있잖아, 서로 끌어안고 마음을 달래다 보면 자연스럽게 괜찮아지는 날이 올 거야. 아이를 위해서라도 우리는 괜찮아질 거니까, 그런 생각 하면서 당신 마음을 더 괴롭게 만들지 마.',\n",
       " '고맙기는. 앞으로 서로 더 다양한 모습 보여주면서 잘 만나라. 보기 좋다.',\n",
       " '기분이 좀 풀렸다니 다행이다. 언제든지 짜증 나거나 화나는 일 있으면 나한테 얘기해 줘. 내가 항상 옆에서 들어줄게.',\n",
       " '그렇게 생각해 주는 주면 내가 더 감사하지. 네가 나의 메시지를 읽고 힘을 내서 너무 고맙고. 엄마의 마음도 진정으로 이해해주는 것 같아서 내가 되려 행복해진다.',\n",
       " '분명 좋은 결과가 있을 거라고 생각해. 형이 뒤에서 늘 응원하고 있는 거 알지? 혹시라도 도움이 필요하면 언제든 편히 말해.',\n",
       " '충분히 불안한 마음을 느낄 수 있다고 생각해. 하지만 너랑 네 친구와의 관계는 오래 전부터 함께 해 온 견고한 사이잖아. 이러한 일로 우정이 무너지지 않을 테니까 너무 걱정하지 마.',\n",
       " '정말? 너 전시회 가는 것 너무 좋아하는데 간만에 시간 내서 다녀왔던 거 아냐? 정말 많이 신났겠다.',\n",
       " '일 못하는 사람한테 중요한 일을 시키진 않잖아. 모두 감정화자씨가 일을 잘하기 때문이라고 생각해.',\n",
       " '게임 좋아하는 거랑 매번 pc방에서만 만나는 거랑은 다르지요.',\n",
       " '그 얘기 듣는데 나도 속상하다. 세상일 쉬운 게 정말 하나도 없지. 잘하고 싶은데 마음만큼 쉽지 않고 말이야.',\n",
       " '그동안 내가 본 너는 정말 꼼꼼하고, 성실한 친구야. 오히려 일기를 완벽하게 써야 한다는 생각만 줄이면 더 오래 즐기면서 쓸 수 있을 것 같아.',\n",
       " '맞아. 네가 실패했다고 해서 네 잘못도 아니고 네 탓도 아니야. 그저 아직 준비가 되지 않은 거라고 생각해. 넘어지면 언제든 다시 일어서면 되니까 내가 옆에서 도와줄게.',\n",
       " '우리 딸, 많이 화가 난 것 같아 연락받고 엄마도 가슴이 철렁한다. 대체 무슨 일인데 그래?',\n",
       " '그럴 수 있죠. 우선은 아이가 주는 기쁨에 좀더 집중해봐요. 그 기쁜 마음으로 불안함을 조금 해소시켜 보면 스트레스도 풀리고 좋지 않을까 싶어요.',\n",
       " '너는 주어진 상황에 최선을 다하기 위해 온 힘을 다한 건데 내가 다 마음이 아프다. 정말 허탈한 기분이 들겠지만, 그동안 네가 노력한 것은 절대 헛된 일이 아닐 거야. 그러니까 너의 노력을 깎아내릴 필요는 없어.',\n",
       " '정말 난감하시겠네요. 갑자기 새끼 고양이를 돌보게 되셨으니 얼마나 당혹스러우시겠어요. 게다가 아픈 아이니 더 신경이 쓰이시겠죠.',\n",
       " '사실 엄마가 용돈을 깎은 것은 돈도 돈이지만 혹시나 네가 돈을 헤프게 쓰는 버릇이 들까봐도 있었어.',\n",
       " '나중에 꼭 사진으로라도 자랑해줘. 다시 한번 축하해 우리 자기. 목숨만큼 아끼는 반려견이 새끼를 낳았을 때 얼마나 뿌듯하고 감동적일지, 내 상상 이상일 것 같아.',\n",
       " '너 혼자만의 시간이 늘어났으니 커피 한잔하면서 여유를 즐겨보는 건 어때? 재미있는 드라마를 보거나, 그래도 심심하면 나랑 계속 연락하자. 내가 너 외롭지 않도록 계속 연락할게!',\n",
       " '잘 자라줘서 고맙고, 한 분 한 분 뵙지는 못해도 꼭 감사 인사 드려야 한다.',\n",
       " '왜 아니겠어요. 그럼 당분간은 만회할 기회가 아예 없는 거예요? 감정화자씨 능력이 뛰어난 걸 아니까 더욱 안타까워요.',\n",
       " '순서만 바꿨을 뿐인데 삶의 질이 달라졌네요! 꽉 막힌 도로에서 스트레스 받을 일도 없고요!',\n",
       " '많이 당황하셨을 텐데 상대방이 무안하지 않게 대처해주시니 정말 고마운 분이네. 그런데 여보가 장모님으로 착각할 정도면 굉장히 닮으셨나봐.',\n",
       " '제가 링크 보내드릴게요! 메뉴가 깔끔해서 좋더라고요. 제 여자 친구도 최근에 갔던 식당 중에 제일 괜찮았다고 했어요.',\n",
       " '날도 덥고 기분까지 나빴을 텐데, 고생 정말 많았어. 혹시나 오늘과 같은 상황이 있다면 언제든지 연락해줘. 언제든 들어주고 조언을 줄게!',\n",
       " '살면서 그만한 짜릿함과 기쁨을 주는 직업을 만나기가 하늘의 별 따기라고 하잖아. 그런 직업을 발견해 내고 온 마음을 다해 즐기고 해내는 자기가 너무 대단해. 앞으로도 축제가 더 활성화되어서 베테랑 사회자로 성장하기를 진심으로 응원할게.',\n",
       " '그런 생각이 드는 것도 어쩌면 당연한 일인 것 같아. 처음 나가본 온라인 동호회가 실망스러웠으니 다른 동호회도 선뜻 나가기 쉽지 않을 거야. 하지만 아직 동호회 모임에 한 번 나간 것뿐이니까 너무 미리 슬퍼하지 않았으면 해.',\n",
       " '자꾸만 감정화자씨의 의도와 다르게 대화가 흘러가니까 난감하겠어요. 아내에게 이런 마음을 이야기해 봤어요?',\n",
       " '에이 그건 아니야 시누이는 분명히 너를 힘들게 하긴 했어. 다만 네 생각처럼 너를 무시하거나 그런 건 아닌 것 같으니 한번 날 잡아서 힘들다고 말 해봐. 어린아기가 있는 집에 초등학생 두 명 부탁하는 건 좀 지나치다고 말이야 그럼 이해해 줄지도 몰라.',\n",
       " '어쩌면 지금 너무 바쁜 와중에 차까지 말썽이라 더 화가 났을 수도 있어. 차분하게 생각해보면 분명히 자기 기분도 괜찮아질 거야. 가만히 조금만 자기 화를 다스려 봐.',\n",
       " '앞으로도 서울 생활하면서 도움이 필요하면 언제든 연락하세요. 제가 도와드릴 수 있는 건 모두 도와드릴게요. 그럼 즐거운 시간 보내시길 바라요.',\n",
       " '그럼. 좋은 말로 좋게 타이르면 특별히 심성이 나쁘지 않은 사람치고 알아듣게 되어 있거든. 한번 시도해 봐.',\n",
       " '엄마가 연세 드시면서 우울한 마음이 많이 들었나 봐요. 제가 좀더 잘해드리지 못한 것 같아 죄송해요.',\n",
       " '오빠를 보면 너무 존경스러워. 난 가끔 알람 소리도 못 듣고 지각한 적도 많았었잖아. 근데 오빠 만난 이후로 오빠가 항상 알람이 돼주니 얼마나 맘이 편안한지 몰라.',\n",
       " '왜? 너 학원 간다고 하지 않았어?',\n",
       " '네 사정이 그런 줄 몰랐는데 얘기를 들으니 마음이 안 좋구나. 요즘 경제가 좋지 않다 보니 파트타임 일자리를 구하기도 어렵다고들 하더라. 너는 항상 성실한 사람이었으니 곧 좋은 소식을 들을 수 있을 거야.',\n",
       " '당신이 피아노를 그만둘 때 얼마나 마음에 상처를 많이 받았는지 아직도 생생히 기억이 나. 여보, 당신은 그때 어쩔 수 없었잖아. 되돌릴 수 없는 과거 때문에 스스로에게 상처 주지 마.',\n",
       " '왜 그래? 무슨 일 있었어?',\n",
       " '아직 두 번째인데 뭐. 우리가 20년을 넘게 한국어를 사용했는데 방학 두 달 동안 영어를 한다고 어떻게 완벽해지겠어. 너무 초조하게 생각하지 말고 좀 마음을 편하게 가지는 것도 너에게 도움이 될 것 같아.',\n",
       " '나도 묵묵히 자기 길을 가면서 최선을 다하다가 성과를 내는 사람들 보면 참 좋지요.',\n",
       " '사랑하는 사람으로부터 받는 격려가 얼마나 큰 힘을 가졌는지 알기에 자기한테 더 힘을 주고 싶었어. 논문 쓰면서 할 수 없다고 느낄 때면, 자기가 보내 준 격려의 메시지에 힘을 얻었거든. 자기도 같은 마음으로 어려운 일을 해냈다고 하니 고맙고, 서로 아끼는 우리가 너무 예쁘게 느껴진다.',\n",
       " '오랫동안 준비했기 때문에 상심이 더 크겠다. 자존감이 상했을 널 생각하니 나도 마음이 찢어지듯 슬프네.',\n",
       " '엄마는 언제나 우리 딸 편이지! 사회인으로 한 발짝 내디딘 걸 축하해!',\n",
       " '무슨 일이 있었는지 정확히는 모르지만 나라도 그런 상황이라면 혼자 이겨내지 못 했을거야. 매일 같이 얼굴을 마주 봐야 하는 동료들과 불편한 사이로 지낸다니 상상만 해도 힘들 것 같아. 사람들이 자기 말에 조금이라도 귀를 기울여주었더라면 좋았을 텐데 마음이 아프다.',\n",
       " '저였어도 혼자 마음 편하게 일하고 있다가 갑자기 상사가 들이닥친다면 너무 신경 쓰이고 불안할 것 같아요. 잘못한 것도 없는 괜히 눈치 보게 되고, 쭈뼛거리게 되고 말이에요. 야근하는 내내 업무에 집중도 제대로 안 되고 마음만 불편했겠어요.',\n",
       " '처음에는 어떤 일이든 누구나 미숙하고 어려운 법이죠. 너무 걱정할 필요는 없어요. 운전도 찬찬히 배워가면 늘 수 있고, 익숙해질수록 점점 마음이 편안해질 거예요.',\n",
       " '얼마나 당황스러웠으면 물어볼수도 없었을지 이해가 돼. 사람이 너무 놀라면 뭘 할수가 없다잖아. 그래도 이유는 물어봐야 하지 않을까?',\n",
       " '자기의 마음이 안정되었다니 내 마음도 함께 좋아지는 것 같아. 분명 그렇게 될 거니, 너무 괴로워하지 말고 우리 함께 이겨내 보자.',\n",
       " '힘들면 포기하고 싶단 생각이 드는 건 당연한 거란다. 우리 아들이 그런 생각까지 했어도 맡은 바에 최선을 다하는 모습이 정말 대견하구나. 책임감 있는 모습 덕에 다른 팀원들 사기 진작에도 도움이 됐겠는걸?',\n",
       " '네가 차곡차곡 쌓아온 지식과 기술이 살아가는 평생 너에게 안전한 부와 명예를 줄 거야. 누군가 와 비교할 필요도 없이 너만의 성공 비법과 능력을 갖추고 있잖아.',\n",
       " '어디로? 그런데 무슨 일 있어? 너 계획 없이 여행 떠나는 거 싫어하잖아.',\n",
       " '안 그래도 이야기하려고 했어. 자기가 좋아하는 야구선수 다른 팀으로 이적했던데?',\n",
       " '형이 많이 충격을 받은 거 같네, 고객으로서 좋은 서비스를 받고 싶은 마음은 당연한걸. 하지만 그 마음이 충족되지 못해서 화가 나는 마음 이해해. 하지만 제작사에서 곧 대응할 테니 너무 걱정하지 않았으면 좋겠어.',\n",
       " '그거 좋은 생각이구나. 아빠도 이 소식을 들으면 분명 기뻐하고 축하해주실 거야.',\n",
       " '당신이 얼마나 아이를 바라고 있는지 알기 때문에 그 비통함이 너무나 이해돼요. 이번에는 임신 같다고 좋아하던 모습이 눈에 선해요. 지금 당신 마음이 얼마나 상처 입었을지 생각하니 정말 마음이 아파요.',\n",
       " '다른 사람들과 커리어에 대한 이야기를 나누는 것도 좋지만 중요한 것은 내가 무엇을 원하는가 야. 이번 기회에 자기 자신에 대한 충분한 성찰을 할 수 있는 계기가 될 수 있을 거야. 그런 시간을 보내고 나면 한결 성장한 나 자신을 발견할 거야.',\n",
       " '왜? 안 좋은 거라도 봤어?',\n",
       " '당신이 처음에는 건강 유지 목적으로 헬스에 다녔는데, 이렇게 보람까지 느끼게 되어서 보기 좋다. 사실 직장인이 일 끝나고 헬스장에 간다는 게 마음처럼 쉬운 일이 아니잖아. 의지를 갖고 끝까지 노력한 점이 너무 자랑스러워.',\n",
       " '상황이 안 좋았지. 우리 아기 말이 늦어서 작년부터 언어 치료도 시작했잖아. 일주일에 두 번씩 수업하는 데만 적잖은 돈이 들어갔지.',\n",
       " '앞으로도 언니로서 좋은 본보기가 될 수 있도록 노력하면 동생도 당연히 그 부분을 알아줄 거야. 나도 그래서 늘 동생한테 좋은 영향만 주려고 노력하는데 그게 잘 안되기는 하더라고.',\n",
       " '너의 상처를 엄마가 너무 늦게 알게 된 거 같아서 속상하다. 시간이 걸리겠지만 분명히 너는 상처를 치유하고 다시금 좋은 사람을 만나게 될 거야. 아니, 더 좋은 사람을 만나서 상처가 생각나지도 않을거 라고 엄마는 확신해.',\n",
       " '네가 참 힘들었겠다, 어떤 마음이었을지 나도 다 겪어봐서 너무 공감하고 충분히 이해해. 가족관계라도 좀 떨어져 있을 필요는 있는 것 같아, 그래야 더 소중해지고 심리적으로 독립도 되고 그렇더라. 내가 예전에 너무 힘들어했던 부분이어서 잘 알아, 네가 그동안 참 마음고생 많았겠다 싶다.',\n",
       " '잘했네요. 세상의 어딘가에 늘 내 편이 되어 지켜주는 사람이 있다고 생각하는 것도 좋은 것 같아요.',\n",
       " '엄마 억지로 안 하셔도 괜찮아요. 그래도 헌것을 버려야 새것이 온다는 말이 있잖아요. 엄마도 예쁜 옷 입으셨으면 좋겠어요.',\n",
       " '나는 당신이 친구를 정말 아끼고 사랑한다는 걸 알아. 그렇기에 월급을 통째로 빌려줄 수도 있었던 거잖아. 그러니 우리 너무 조급해 말고 친구를 조금만 더 믿어보자.',\n",
       " '정말 앞뒤가 다른 사람이다. 하필 그런 사람이 사수였다니, 자기가 지금 배신감을 느끼는 건 당연한 거야. 자기가 그런 사람 때문에 상처받았다고 생각하니까 나까지 너무 속상해.',\n",
       " '술버릇이 어떻길래 네가 그런 고민까지 하는 거야?',\n",
       " '정말 훌륭하다. 보통 상처받거나 억울한 감정이 들면, 사람들 원망부터 하게 되잖아. 감정화자는 네 상처를 다 끌어안고, 사람들까지 배려하니 정말 속이 꽉 찬 친구다.',\n",
       " '1년 넘게 좋은 대학 진학이라는 목표를 함께 품고 달려왔는데 참 허무하겠다. 과외가 끊겨서 생계가 막막해진 것도 안타깝지만 인간적인 대우를 받지 못했다는 게 더 슬프네. 자기가 이 밤에 혼자 착잡해 하고 있는데 같이 있어 주질 못하니 너무 미안해.',\n",
       " '어우야, 나도 갑자기 밥 먹다가 네 말 듣고 숟가락 내려놨잖아. 네가 정말 오랜만에 관심 있어 하는 사람이 나타난 거잖아. 나라도 혹시나 여자 친구 있으면 어쩌나 괜히 불안해서 일이 손에 안 잡힐 것 같아.',\n",
       " '나도 이렇게 속상한데 당사자인 자기 마음은 얼마나 미어지고 슬플지 상상도 안 가. 일을 너무 잘하는 사원이라 이런 시련도 겪게 되는 것 같네. 이번에 열심히 한 보람은 어떻게든 자기에게 돌아갈 거라 믿어.',\n",
       " '현명하지 못하다는 말을 들으면 나라도 기분이 나쁘고 상처가 됐겠다. 당신이 그런 소리를 들을 이유가 없으니까 너무 속상해하지 마.',\n",
       " '그럼, 내가 기분 좋아지는 계획을 좀 세워볼까? 너 평소에 바다 보고 싶어 했지? 일출도 보고 회도 먹고 돌아올래?',\n",
       " '감정화자씨가 기뻐하는 모습을 보니 저까지 기분이 좋아지는 거 같아요. 포기하고 있던 건데 가지게 되셨으니 그 기쁨과 행복이 훨씬 클 수밖에 없죠. 세상이 다 아름다워 보일 거 같아요.',\n",
       " '좋지, 우리 딸이랑 데이트할 생각을 하니 벌써 신나는구나.',\n",
       " '아냐, 나였더라도 이게 뭘까 싶어서 불안했을 거야. 그래도 대화로 잘 풀 수 있는 문제인 것 같으니까 너무 걱정하지 말기를!',\n",
       " '네가 건강 때문에도 많이 속상하겠지만, 그래도 스스로 한심하다고 여기진 마. 나는 오히려 네가 지금 좀더 건강해졌다고 생각하는데. 몸도 그렇고, 마음도 그렇고 지금의 너는 네 몸을 돌아볼 마음의 여유가 생겼잖아.',\n",
       " '혹시 두통이나 어지럼증 같은 게 느껴지니? 어디 다른 아픈 구석은 없고?',\n",
       " '다행이다. 동생과 대화를 잘 나눠봐. 큰일은 없을 거야.',\n",
       " '감정화자님 오늘 중요한 협상이 있다고 외근 나가셨잖아요. 긴장되지 않으세요?',\n",
       " '당연하지, 주위 모든 사람이 너와 아버지를 응원하잖아. 너무 슬퍼하지 말고 다시 힘을 내서 일어났으면 좋겠어. 나는 진심으로 너와 아버님을 믿고 지지해.',\n",
       " '아무리 예뻐서 아까워도 건강을 해치면서까지 구두를 고집하면 결국 더 후회되는 결과가 오는 건 당연해. 아쉽겠지만 잘 생각했어.',\n",
       " '왜 너한테 직접 생활비를 늘려달라고 말하지 않고 지갑에서 돈을 꺼내갔대? 아내의 행동에 많이 실망스럽고 슬프겠다.',\n",
       " '새 옷 입는 건 언제나 기분이 좋지. 기분도 전환이 딱 되잖아.',\n",
       " '과부하에 걸리면 극도로 불안해진다고 해요. 그럴 때는 행복한 생각을 하면서 부정적인 마음을 빨리 떨치도록 노력하는 게 중요할 거예요.',\n",
       " '그렇다면 회사 근처에 친절한 정비소가 한 군데 있는데 앞으로 거기서 해 보는 건 어때? 그곳은 고객 데이터 관리를 하고 있으니 매월 1일 언제 엔진오일을 교체했는지 물어보자! 넌 실행력이 매우 뛰어나니 생각난 김에 내일 가 보는 건 어때?',\n",
       " '아이고, 너무 속상하겠어. 동료에게 얼마나 힘이 되고 싶었으면 술도 잘 못 먹는 네가 그런 제안도 하고. 동료도 너의 마음을 충분히 공감하고 있었을 거니 너무 속상해하지 마.',\n",
       " '요즘에는 절을 하는 문화가 사라지다 보니까 자연스럽게 하는 방법을 잊어버린 것이 아닐까. 예전에는 정말 중요했지만 이제 시대가 변하면서 세배 대신에 조용히 묵도를 하는 사람들도 많아졌잖아. 친구 아버지를 존중하지 않아서가 아니라 방법이 달랐다고 생각하는 건 어때.',\n",
       " '그런 사람을 만나게 되어 너무 행복하겠다. 네 문자에서도 행복이 묻어나네.',\n",
       " '설마 친구가 악의적으로 널 속이려고 했겠니. 그냥 쓰다 보니까 체감이 안 돼서 그런 거겠지.',\n",
       " '뭐라고? 어제 나랑 다른 친구들이랑 같이 술 마시고서 집에 잘 들어간 거 아니었어?',\n",
       " '그런 일들에서 그동안의 방식이 틀렸다는 걸 인정하고 받아들이는 게 쉽지 않은 일인데. 말씀을 들으니 저 또한 삶의 방식을 배울 수 있었던 것 같아요. 사실 나이를 먹을수록 입맛도 그렇고 삶의 방식도 그렇고 바꾸기 쉽지 않잖아요.',\n",
       " '하지만 나는 네가 많은 배우들 중에서 가장 빛난다고 믿어. 내가 네 연기 본 게 하루 이틀이 아니잖아. 네가 작은 호흡 하나까지 전부 그 캐릭터로 바꿔내는 모습을 보면서 내가 얼마나 많이 감탄을 했었는데.',\n",
       " '어, 와줘서 고마워. 안 그래도 고맙다고 연락하려고 했어. 참 그때 같이 온 분은 누구셔?',\n",
       " '올케가 생가면 잘해주고 싶고 자주 만나서 이야기하고 싶고 그런 마음 생긴다고 하더라. 너도 그런 마음인 거 같아. 이제 가족이 되어 가는 중이잖아.',\n",
       " '평소에 이성적인 감정화자씨가 이리 말씀하시는 걸 보니, 얼마나 마음이 슬픔에 잠겼는지 알 것만 같아요. 감정화자씨의 이런 모습을 처음 본 터라 더욱 제 마음이 아프네요.',\n",
       " '나도 지난달 전시회에 갔을 때, 어린아이가 너무 귀여워서 한참을 넋을 놓고 쳐다봤거든. 그래서 오늘 네가 얼마나 기뻤을지, 네 마음을 이해할 것 같아.',\n",
       " '그래요, 잘 용기를 내셨어요. 분명 잘 풀릴 테니까 염려하지 마시고 제게도 후기를 들려주세요.',\n",
       " '우와, 그러시군요. 저도 운동해야지 생각은 있는데 실행이 잘 안되네요.',\n",
       " '우리 아직 20대인데, 벌써부터 흰머리가 나다니. 네가 걱정스러울 만하네. 한 가닥도 아니고 두 가닥이나 발견하다니, 정말 우울할 거 같아.',\n",
       " '넌 잘할 수 있을 거야. 책임감도 있고, 문제 해결 능력도 뛰어나고! 게다가 부모님을 생각하는 마음이 이렇게 넓은데, 무슨 일이 생겨도 잘 헤쳐 나갈 수 있어.',\n",
       " '이제 직원 새로 들어오면 분위기도 새로워지고 너희 부서 웃음꽃이 피겠어.',\n",
       " '와. 진짜 너무 값진 일이다. 나도 예전에 심어봤는데, 그게 엄청 즐겁고 뿌듯하더라고. 힘들지는 않았어?',\n",
       " '네 얘기를 듣는 내가 이렇게 어이없고 기가 막히는데 너는 말해 뭐하겠니. 계획대로 일이 안 돼서 네가 얼마나 애를 태웠을지 짐작하니까 정말 속상하다.',\n",
       " '감정화자야 일단 심호흡을 해보자. 엄마도 이전에 강아지 키웠을 적에 강아지 목줄이 풀려서 도망간 적이 있었어. 나도 너처럼 너무 혼란스러웠어서 그 마음 이해하지만 일단 마음을 진정시키는 게 중요할 것 같구나.',\n",
       " '너무 화내지는 말렴, 알다시피 아빠가 퇴직 이후로 아주 우울하고 불안해 보이셨어. 다들 사느라 바빠 그런 아빠한테 신경 써주지 못해서 쌓인 게 많았을 거야.',\n",
       " '그랬구나, 그건 네 잘못이 아니야. 너는 최선을 다해서 달려왔잖아. 아버지도 이해하실 거야.',\n",
       " '물론이지! 감정 화자님은 꼭 이겨낼 수 있을 거야. 나도 옆에서 응원해 주고 감정 화자님 편이 되어줄게!',\n",
       " '자기랑 오래도록 친하게 지내온 친구잖아요. 여행에 대한 기대감에 잠깐 잊었을 뿐이지, 아예 모를 거 같진 않아요.',\n",
       " '많이 기분이 안 좋으시겠어요. 하지만 앞으로의 여행은 분명 좋은 일만 일어나실 겁니다. 비 온 뒤 맑음이라고 하잖아요.',\n",
       " '와, 진짜요? 뭐 시켜주실 거예요? 난 피자랑 스파게티 먹고 싶은데.',\n",
       " '아마 할머니도 당신 마음 다 알고 있을 거야. 당신이 너무 슬퍼하면 할머니도 마음이 편치 않으실 거라고 생각해. 당신이 할머니 때문에 슬퍼하다가 병이라도 날까 봐, 난 그게 더 걱정돼.',\n",
       " '당신이 우는 모습을 보고 나 역시 너무나 슬펐어. 여전히 생각하면 힘들고 고통스럽겠지? 하지만 언젠가 지금의 괴로움도 무뎌지는 날이 올 거야. 그렇게 믿자.',\n",
       " '평소와 다른 증상이 느껴지니 마음이 아주 힘드셨겠어요. 엄마가 혼자 걱정하셨을 걸 생각하니 저도 마음이 너무 아파요. 잠까지 깊게 못 주무신다니 불안함을 많이 느끼시는 것 같아요.',\n",
       " '저런, 네가 그런 상황을 겪고 심각하게 고민하고 있는 줄 전혀 몰랐어. 동생아, 사투리를 쓴다는 건 절대로 웃음거리가 될 일이 아니니 주눅 들지 않아도 돼. 다른 지방에서 살았기 때문에 당연한 거야.',\n",
       " '이런 일도 있고 저런 일도 있는 거지. 여보가 마음이 한결 나아진 것 같아서 나도 안심이 된다.',\n",
       " '네가 그만큼 친구를 믿었기에 지금 느끼는 실망도 큰 법이겠지. 하지만 이럴 때일수록 의연해져야 해. 누구에게도 너를 함부로 험담할 권리는 없단다.',\n",
       " '그래도 치료 잘 받았다고 하니까 정말 다행이다. 큰일은 아니었던 거지?',\n",
       " '그렇게 생각해 주면 내가 더 고맙지, 난 너에게 힘이 되어 주고 싶은 게 진심이지. 나의 진심이 너에게 통해서 내가 되려 기분이 좋아지고 행복해 지려 해. 난 네가 항상 행복했으면 좋겠다는 마음이야.',\n",
       " '어머! 정말요? 스타일 바꾸는 것만큼 스트레스 풀리는 게 또 없으니까요. 그런데 어떤 점에서 후회가 되었어요?',\n",
       " '그렇게 말해주니 저도 고맙고 힘이 나네요. 언제든 감정화자씨가 털어놓고 싶은 게 있으면 얘기해요. 해결해주진 못해도 들어주고 마음을 알아줄 수는 있으니까요.',\n",
       " '둘 다 컨디션이 안 좋아서 다툼이 일어났나 보네요. 자기는 생리통이 많이 심하잖아요. 친구는 괜찮은가 보네요?',\n",
       " '네 마음이 진정됐다면 일단 다행이야. 혼자서 버티느라 힘들었다면 이제는 자매인 내게 기댔으면 좋겠어. 내가 많은 걸 해결해 줄 순 없겠지만, 백지장도 맞들면 낫다는 말처럼 도움이 되고 싶어.',\n",
       " '이왕 맡은 일이니 어쩌겠어. 우리 남편의 카리스마와 친화력이 거기서도 꼭 필요하려니 생각하며 자랑스러워해야지 뭐. 너무 당황하지 말고 결정된 일은 흔쾌히 받아들이도록 노력해, 여보.',\n",
       " '그래? 전에도 같이 식사를 했을 텐데 이제야 그런 생각이 드는 건 뭘까? 정말 지금껏 몰랐던 거야?',\n",
       " '다행이네. 엄마는 우리 딸이 상처받는 걸 무서워해서 사람을 멀리하고 그러지 않았으면 좋겠어요. 관계와 사람은 다양하니까.',\n",
       " '좋은 생각 이구나. 제가 좋은 사람이니 분명히 좋은 사람이 네게 찾아 올 거야. 걱정하지 말고 기다려 보 렴.',\n",
       " '많이 다치진 않았어? 나도 심하게 넘어지면 아픈 것보다 부끄러운 게 크게 느껴질 때가 있더라. 그것도 통화 중이었다니 정말 놀랐겠다.',\n",
       " '그거 티켓 예매하기 힘들다고 하던데 그 어려운 걸 해냈다고요?',\n",
       " '사람이 워낙 많았던 지하철이니까 많은 사람들이 오해였을 수 있다고 생각할 거야. 게다가 네 주변에 있던 사람들은 네가 핸드폰하는 것도 봤을 테니 더욱 진실을 알 거야. 너무 걱정하지 마.',\n",
       " '어머, 나도 누가 사소한 말이나 행동 기억해놨다가 선물해 주면 그게 참 행복하더라. 출장 가서 바쁜 와중에도 네 생각해서 사 왔다고 하니 얼마나 기쁘니. 내 마음이 다 간질거린다.',\n",
       " '아마 그럴 거예요. 그리고 여자 친구분과 나이 차이가 좀 있다고 하지 않으셨어요? 그래서 더 긴장하고 계신 것 같기도 해요!',\n",
       " '제가 조금이나마 도움이 되었다니 기뻐요. 워낙 슬기로우신 분이라 다른 사람의 말에 흔들릴 필요 없으실 것 같아요.',\n",
       " '그렇지 않아도 몸이 아주 피곤해서 마음의 여유도 부족해지는 와중에 날이 선 말을 들었구나. 평소처럼 담담하게 반응하려고 해도 자기 마음에는 이미 상처로 남았으니 아주 괴롭고 속상했겠어. 문자로 상황을 전해 듣기만 해도 착잡해지는데 자기는 오죽했을까 싶다.',\n",
       " '가족들의 거절로 과장님께서 혼자 일과 육아 전부 해결해야 하는 상황이니 가슴이 막막하고 속상하셨을 것 같아요. 제가 과장님의 상황이었다면 가족들에게 거절당한 서러움에 울어버렸을 것 같아요.',\n",
       " '상처를 받았음에도 끝까지 아이들을 위해서 용기를 낸 여보가 정말 대단하고 자랑스러워. 누가 뭐래도 그런 게 정말 멋진 엄마의 모습일 거야. 많이 상처를 받았지만 그래도 결국 여보가 해낸 거잖아, 정말 멋져.',\n",
       " '그렇게도 생각할 수 있을 것 같긴 해, 자연스러워야 마음에서 진짜 우러나오는 거라 생각할 수 있으니까. 뭐든 자기 마음 편한 게 가장 좋지만, 사랑하지만 사랑한다고 표현하지 못해서 나중에 후회하는 경우도 많잖아. 그런 경우를 생각하면, 미리 진심을 표현하는 걸 연습하는 것도 나쁘지 않은 것 같아.',\n",
       " '아빠도 아르바이트했을 때 힘들었기에 우리 아들 힘든 거 정말 잘 알아. 자고 일어나도 허리가 아픈 거면 한의원 가서 침이라도 맞아볼래? 그럼 조금 괜찮아질 거야.',\n",
       " '아, 그랬구나. 다른 사람한테까지 피해를 끼쳤으니 정말 얼굴이 화끈거렸겠다. 네가 왜 그렇게 당황했는지 알겠다. 정말 놀랐을 것 같아.',\n",
       " '그런 일이 있었다니 과장님 지금까지 얼마나 힘드셨어요. 주변에 말도 못 하고 혼자 끙끙 앓으셨을 생각을 하니까 너무 마음이 안 좋네요. 분명 방법이 있을 테니까 너무 걱정하지 마세요.',\n",
       " '잘 생각하셨어요. 열심히 살아왔던 만큼 분명히 보상받는 날이 올 거라고 믿어요. 그동안은 힘든 오르막길을 걷고 있던 거라고 생각하면 어때요? 앞으로는 분명 편히 내려갈 일만 남았을 거예요 기운 내요.',\n",
       " '구취의 원인은 다양해서 양치를 자주 해도 냄새가 날 수 있어. 혹시 충치나 치석이 있는 건 아닌지 내일 치과에 가보자. 그래도 원인을 못 찾으면, 위에 문제가 있는 것일 수도 있으니까 내과에 가서 검사를 받아보면 괜찮을 거야.',\n",
       " '목표를 바라보고 달려온 세월인데, 아무것도 잡히는 게 없다고 느껴지면 서글픔에 낙담스러운 것도 당연하지. 비싼 옷을 사는 것이 네게 위로가 된다면 눈치 보지 말고 당당하게 너만을 생각해도 된단다. 다만, 힘들고 괴로워도 너를 해치는 방법으로 문제를 다루지는 말았으면 좋겠어.',\n",
       " '연인과 잘 싸우지 않던 네가 무슨 일이니?',\n",
       " '우리 딸은 뭐든 잘하니까 춤도 잘 출 텐데 무슨 걱정이 있을까?',\n",
       " '그 말이 아무런 가치가 없다는 것 알고 있지? 동생도 그 순간을 분명 후회하고 있을 거야. 자기를 사랑하는 사람들은 아무도 그런 생각을 하지 않아.',\n",
       " '나를 응원하는 걸 보니 정말 마음이 많이 풀린 것 같아 안심이다. 그동안 감정화자가 나하고만 왕래하며 다른 동료들을 등한시했잖아? 앞으로 다른 동료들도 신경 쓰면 또 새로운 친구가 생길 테니 마음을 넉넉하게 가졌으면 좋겠어.',\n",
       " '당신에게 오늘 무척 혼란스러운 일이 있었구나. 당신 이야기 들으니, 나도 당황스럽고 어쩔 줄 모르겠네.',\n",
       " '그렇지, 너는 여자 친구의 새로운 모습을 보고 이전보다 더 가까워진 거야. 그건 관계에 있어서 환영할 일이지. 내 여자 친구도 사람이구나 하고 편히 생각해.',\n",
       " '위로되었다면 다행이다. 다음 시험은 잘 볼 수 있길 응원할게!',\n",
       " '자기가 상처를 많이 받은 것 같아서 너무 걱정되고 나까지 가슴이 아프다. 우리 자기는 누구에게나 사랑받아 마땅할 사람인데 말이지. 대신 내가 그 직원 몫까지 자기한테 애정과 관심을 잔뜩 쏟아줄 테니까 너무 속상해하지 마.',\n",
       " '아냐, 자기는 내가 없어도 분명 잘 해냈을 거야! 항상 응원할게. 힘내!',\n",
       " '모든 걸 혼자 이겨내려 하지 말고 언제든 나한테 다 얘기해요. 마음이 힘든 일을 혼자 이겨내려 한다면 더 힘들고 이겨내기도 어려울 거 같아요. 힘들 때 서로 힘을 주고 의지하라고 부부잖아요, 그러니 항상 말을 해요.',\n",
       " '요즘 어디가 많이 아픈 거야?',\n",
       " '처음 나가는 콩쿠르인데 떨리지는 않아? 오랫동안 열심히 준비하더니 이제 드디어 콩쿠르도 나가고 너무 잘 됐다.',\n",
       " '왜, 아침부터 무슨 일 있어? 기분이 많이 안 좋게 느껴지는데, 아버지랑 또 싸우기라도 한 거야? 무슨 일인지 너무 걱정된다.',\n",
       " '아이고 꽤 크게 넘어졌나 보다... 아프지? 반창고 같은 거라도 붙이는 게 어떨까?',\n",
       " '정말요? 좋은 일을 하셨네요. 저는 해야지, 하고 생각하는데 정말 대단하세요.',\n",
       " '이렇게 좋은 친구가 곁에 있다는 건 이대리도 좋은 사람이라는 뜻이겠죠. 친구 칭찬만 하지만 이대리도 그 친구를 잘 챙겨줬으니 오랫동안 이런 관계를 유지하고 있을 거예요. 그런 친구가 있다는 게 너무 부럽네요.',\n",
       " '힘들다니, 그렇지 않아. 당신이 영업 실적을 못 채워서 매우 속상하고 슬픈가 보네. 당신이 우울해하니까 내 가슴이 슬픔으로 미어지는 것 같아.',\n",
       " '친구는 너를 도와주려고 했던 선한 마음이였을 거야. 일부러 그런게 아니라는건 너도 알고 있을것 같아. 그러니 네가 화를 풀고 친구랑 화해를 하는건 어떨까?',\n",
       " '정말 걱정스럽겠어요. 저도 예전에 다시 만난 연인에게서 어색하고 이전과 달리 여겨지는 모습들을 발견했었거든요. 그때 저도 되게 걱정스럽고 불안하고 그랬어요.',\n",
       " '와, 그거 대단한걸? 너 정말 공부를 열심히 했나 보구나.',\n",
       " '정말 기분 나쁜 경험이었겠어. 새 물건이 들어 있을 것이라 생각하며 기분 좋게 택배 상자를 열었을 텐데 말이야. 깨진 화장품을 본 순간 얼마나 허무하고 화가 났겠어.',\n",
       " '결혼식 하고 보니 우리 딸이 친구들한테도 그렇고 회사 생활도 너무 잘하고 있는 것 같아 대견스럽다.',\n",
       " '그런 일 역시 네게 잊지 못할 추억이라고 생각하면 돼. 이미 벌어진 일이고, 어쩌면 다른 친구들도 네게 좋은 느낌을 가질 수도 있어. 얼마나 멋진 친구이기에 저런 공개 고백을 받았을까 하고.',\n",
       " '아무리 철없는 애들이라고 해도 남을 배려하지 못한 행동이라는 것을 알려줄 필요는 있을 것 같은데. 그렇게까지 하고 싶지 않다는 자기 마음은 너무 잘 알겠어. 내가 너무 속이 상하다.',\n",
       " '당신은 정말 회복이 빠르다니까. 진정된 것 같아 나도 이제 마음이 놓인다. 그럼 오늘 업무도 파이팅이야.',\n",
       " '충분히 그럴 수 있을 거 같아요. 많이 슬펐을 거 같아요. 지금 옆에 있으면 꼭 껴안고 괜찮다고 토닥여주고 싶네요.',\n",
       " '타인의 평가보다 작업을 하면서 즐겁고 의미를 고심해 봤다는 행위 자체에 중심을 놓는 건 어떨까? 게다가 너는 설명도 잘하니 사람들이 너의 예술 세계를 쉽게 이해하고 집중해서 들어줄 거야. 섣부른 걱정으로 스스로 불안감을 키우지 않았으면 좋겠어.',\n",
       " '이렇게 금방 기운 차리는 모습을 보니 너무 보람차고 내 기분이 다 좋아진다. 아무쪼록 이번 일도 잘 이겨낼 수 있기를 바랄게!',\n",
       " '본인에게 일어난 일이라 크게 보일 뿐이니 계속 의식하고 부끄러워하지 않았으면 좋겠어. 오늘 맛있는 음식도 먹으면서 즐거운 시간 보냈을 텐데 그 일로 하루를 망칠 필요는 없잖아. 다들 이미 잊어버렸을 테니까 자기도 그만 생각하고 남은 하루 잘 마무리했으면 좋겠어!',\n",
       " '남편도 예상치 못한 주부습진에 미안해하고 있을 수 있으니 평소보다 밝고 다정한 모습으로 대해보면 어때요. 워낙 둘 다 배려감이 깊으니 서로 상대방 걱정에 마음만 썩고 있을까 걱정되네요.',\n",
       " '물론이지. 걷는 과정 자체가 데이트잖아. 서로의 새로운 부분을 발견하고 자연을 즐기는 좋은 시간이 될 수 있을 거야. 완주하지 못해서 만약 실망한다면 그런 즐거움을 함께해서 좋았다고 말하면 괜찮지 않을까?',\n",
       " '욕을 어느 정도 하길래? 그게 고민이 될 정도로 많이 해?',\n",
       " '정말로 멋지고 존경스러워. 사실 내가 피해 받고 내가 다치면 눈앞에 다른 사람이 안 보이는데. 자기는 침착하게 생각하고 이성적으로 대응한 거잖아, 자기의 차분함과 배려심이 너무 대단해.',\n",
       " '와르르, 무너져도 이제는 함께 쌓아 올라가면 돼. 언제든 울어도 괜찮아. 내가 안아줄 테니까.',\n",
       " '난 초보 시절에 엔진 오일을 교체해야 한다는 사실도 몰랐는걸? 익숙해지면 괜찮으니 너무 걱정하지 마!',\n",
       " '감정화자님 마음이 그렇다면 그건 확실한 걸 거야. 이제 마음 푹 놓고 차근차근 뒤져 봐. 어디 어두운 주머니 속에서 기다리고 있을 거야.',\n",
       " '어린 시절부터 너는 도전정신이 뛰어나서 한번 시작하면 끝까지 해내고야 마는 집중력이 정말 뛰어났지. 옆 사람이 도전하는 모습에 너 역시 도발되어서 최선을 다해버렸을 모습이 눈에 선하다. 나라도 갑자기 다들 열중에서 뭔가를 하고 있으면 덩달아 승부욕이 생겼을 거 같아.',\n",
       " '그래, 자기는 금방 찾을 수 있을 거야. 고양이가 얼른 돌아오길 바랄게. 기운 내서 잘 찾아 봐.',\n",
       " '너무도 간절한 순간에 절실한 도움들이 밀려왔다니, 자기가 정말 마음에 안도감이 들면서 정말 기뻤겠다. 그 도움이 아니었다면, 지금 이렇게 웃고 있지 못했을 텐데 도움의 손길들이 정말 감사하고 소중하겠네. 많은 사람들의 따뜻한 마음에 자기가 정말 감동받고 기분이 좋았을 것 같아.',\n",
       " '아이를 위해 노력하는 네 마음이 너무 예쁘다. 정말 반짝거리는 거 같아.',\n",
       " '그렇게 불편해도 참았었는데 신지 못하겠다 생각하고 정리를 했으니 얼마나 속상했을까? 집에서 나오면서 마지막으로 오늘 어떤 구두를 신을까 고를 때 가장 행복하다고 말했었잖아.',\n",
       " '시야가 안 보인다니 나라도 정말 당황했을 것 같아. 산에서는 넘어지거나 사고가 나면 정말 큰 일이잖아. 자기가 맘졸이며 내려왔을 생각 하니 마음이 안 좋네.',\n",
       " '그러게. 안전벨트가 괜히 생명 벨트라고 이야기하는 게 아닐 텐데. 딸의 안전하고 관련 있는 문제인 만큼 네가 지금 얼마나 걱정될지 충분히 이해가 가.',\n",
       " '그렇군요, 그런데 그 친구도 분명 당신과 똑같이 생각할 것이라고 믿어 의심치 않아요. 제가 아는 사람 중에 당신처럼 좋은 사람을 못 봤거든요.',\n",
       " '사랑하는 사람에게 안 좋은 말을 들었으니, 그 충격이 오죽 크겠니? 다른 사람이 다 뭐라 해도, 그 사람만은 네 맘을 이해해주어야 하는데. 그러질 못하고 오히려 상처를 주었구나.',\n",
       " '물론 세상 일이 그렇게 순리대로만 가지 않는 건 사실이야. 그런데 배가 사고를 일으키는 것도 그렇게 흔한 일은 아니니까 너무 걱정하지 마. 설혹 무슨 문제가 생겨도 구조가 신속하게 이루어질 테니까 마음 놓고 있었으면 좋겠다.',\n",
       " '감정화자씨와 똑같은 입장이라 그렇게 속상함을 표현한 거라 생각해요. 서로 너무 사랑해서 마음을 크게 다친 거라고요. 늦지 않게 수습한다면 두 분 다 마음을 잘 회복할 수 있을 거예요.',\n",
       " '저런 새벽까지 불안감으로 잠 못 이룬 감정화자님을 생각하니 마음이 아픕니다. 그런데 회사 사정으로 불안감이 드는 건 충분히 이해는 됩니다만, 아직 아무 일도 일어나지는 않았잖아요. 만약 무슨 일이 생기더라도, 현실적인 대안은 많으니, 괜한 상상으로 불필요한 불안감을 만들지는 마세요.',\n",
       " '말만 들어도 내 가슴이 다 답답하다. 언니 마음은 오죽했을까 싶어. 다툼도 많이 없던 친한 친구였는데 언니가 많이 상처받았을 수도 있을 것 같아.',\n",
       " '정말? 오래 기다린 연주회인 만큼 네가 기대를 많이 했을 텐데 옆자리에서 코를 골다니. 화가 잔뜩 났겠구나.',\n",
       " '그래, 우리 요즘 못 모였네. 겸사겸사 회포를 풀자고. 좋은 소식 기다릴게!',\n",
       " '대리님은 항상 피곤한 상황에도 화내지 않고 웃어넘기시잖아요. 한결같이 여유 있는 모습에 많은 사람이 대리님을 좋아하는 것 같아요.',\n",
       " '어머, 정말? 너 꽃가루 알레르기 있잖아. 네가 많이 당황할 수밖에 없었겠네. 코도 많이 간지러워서 힘들었겠다.',\n",
       " '올케에게 숨기는 게 그렇게 불편하면 털어놓는 것도 네 마음 안정에 도움이 될 것 같다. 솔직하게 말하면 올케도 이해해줄 거라 믿어. 혼자 속 끓이지 말고 그냥 얘기하고 마음이라도 편해졌으면 좋겠다.',\n",
       " '응. 잘 생각했어. 모쪼록 대화가 잘 되기를 바랄게. 너희 둘 다 이해심이 깊으니 서로의 입장을 잘 받아들일 수 있을 거야.',\n",
       " '그런 사람이라면 나 같아도 고백을 받아도 설레거나 기쁘지 않을 것 같아. 이제껏 나를 괴롭혀 놓고서는 하루아침에 손바닥 뒤집듯이 뒤집다니.',\n",
       " '당연히 그러실 거야. 모쪼록 시어머님 얼른 쾌차하셨으면 좋겠다. 병간호 끝내면 우리도 얼굴 보고 대화 나누자!',\n",
       " '제가 힘이 되었다니 정말 다행입니다. 너무 노여워 마시고, 지금처럼 강아지에게 조금만 더 사랑을 주세요. 분명 이 시기도 금방 지나갈 겁니다.',\n",
       " '사람들 다 똑같은 생각인가 보네. 귀여운 것을 싫어하는 사람은 없나 봐.',\n",
       " '너는 어쩌면 그렇게 정의롭고 마음이 따뜻하니? 겁도 많으면서 이런 상황에서는 언제나 약자의 편에 서서 용기를 내잖아. 너의 그런 모습을 본받고 싶어.',\n",
       " '사장님이 쓴소리의 소중함을 몰라서 그런 거예요. 그런 의심을 받은 걸 너무 마음에 두지 않았으면 좋겠어요. 그 사장님도 나중에 자신의 실수를 깨달으실 거예요.',\n",
       " '아기가 조금만 울어도 신경이 바짝 쓰일 시기인데 이런 일까지 생겨서 네 마음이 정말 불편하겠다. 어떻게 대처하는 게 좋을지 모르니 가시방석에 앉은 기분이겠네.',\n",
       " '그래도 굶으면 안 되지. 내일은 공감화자가 아침에 먹을 수 있게 미리 샌드위치나 식사를 준비해 둘게. 조금만 더 힘내.',\n",
       " '갑작스러운 상황이 생기면 뭘 해야 할지 난감하고 눈앞이 깜깜할 거야. 그렇지만 그럴 때일수록 최악의 상황을 상상하지 말고 열심히 연습해 온 너를 믿으렴. 아빠는 우리 아들이 말은 그렇게 하지만 실전에 들어가면 멋지게 해낼 거라는 생각이 드는걸.',\n",
       " '이별할 준비가 돼 있지 않은 상태에서 떠나셨군요. 그러니 상실감이 얼마나 클까요.',\n",
       " '부모님께 쉽게 말을 하지 못한 마음도 이해가 된다. 무작정 나무라시기만 하면 나보다 회사가 더 중요하다는 느낌이 들 것 같긴 해. 그런 말을 들으면 감정 화자님이 부모님께 실망스러운 존재인 것처럼 느껴져서 망설인 거 아니야?',\n",
       " '그럴 수 있겠다. 내가 너의 상황이었어도 충분히 초조하고 불안했을 것 같아. 네가 그것 때문에 계속 고민했을 생각하니까 나도 마음이 아프네.',\n",
       " '누구나 신입일 때는 모르는 게 많고 다른 사람의 도움이 필요한 법이야. 나도 일을 배울 때는 선배들이 많이 도와줬고 지금은 내가 후배들을 도와주고 있어. 너무 혼자서 끙끙 앓지 말고 주변에 도움을 요청해보는 게 어때?',\n",
       " '언제든 도움이 필요하면 말만 해. 나도 많이 아는 건 아니지만 육아에 대한 정보를 공유해 줄게.',\n",
       " '너하고 나하고 세상에서 둘도 없는 친구 사이잖아. 엄마는 너랑 우리 손녀도 그랬으면 하는 바람을 얘기한 거야.',\n",
       " '그러면 계획을 세부적으로 조금 다르게 바꿔봐. 예를 들어 여행 대신에 친구 집에서 파자마 파티를 한다거나 학원 대신에 독서실에서 인터넷 강의를 듣는다거나 해봐도 좋을 거 같아.',\n",
       " '회원님의 이 아픔에 굴하거나 포기하지 않는 태도가 너무 멋지십니다. 제가 처음 운동했을 때보다 끈기 있고 열정적이신데요.',\n",
       " '그런 일이 있었구나. 원하지 않는 사람이 갑자기 내게 호감을 보인다면 어떻게 해야 할지 난처하지. 게다가 너는 지금 연애도 하고 있어서 더욱 상황이 난감할 것 같아.',\n",
       " '무슨 마음인지 알겠어요. 내가 힘든데도 비난이 무서워서 이러지도 저러지도 못하고 숨이 막혀 괴로울 때가 있죠. 감정화자씨도 꼭 그럴 것 같네요.',\n",
       " '기분이 나아지고 있다니 정말 다행이다. 조심히 가고 도착하면 다시 연락 줘. 주눅 들지 말고.',\n",
       " '남편분도 선배님의 마음을 아실 거예요. 어쩌면 바쁜 일이 끝나면 여행이라도 다녀와야겠다 다짐하고 계실지도 모를 일이고요. 선배님은 마음이 너그러우시고 상대방의 입장을 잘 헤아리시니까 지금의 힘든 시기도 잘 버텨내실 거예요.',\n",
       " '아우 그건 좀 심하네. 정확히 거절해야 할 거 같아. 사회초년생들이 잘 모를 수 있으니 이유를 정확하게 친절히 설명해주면서 말이야.',\n",
       " '그런 고민이 있었구나. 보통 자기 몸이 아플까 봐 도전하기를 망설이잖아. 그런데 우리 딸은 본인 몸보다 남 걱정을 더 먼저 할 줄 아는 멋지고 착한 사람이었네.',\n",
       " '정말 잘 생각한 거죠, 혼자 앓고 있을 생각을 하면 내 마음이 찢어져요. 연락하면서 소통하는 것이 훨씬 더 내가 덜 불안해요. 난 지금 연락해 준 것만 해도 고마운 마음이에요.',\n",
       " '가장 편해야 할 공간이 집인데, 그런 기분이 들면 너무 힘들지요.',\n",
       " '와, 정말 대단한 일을 해냈는 걸? 나 몰래 이런 좋은 일을 언제 계획한 거야? 너무 대단해. 기분 정말 좋겠다.',\n",
       " '비교는 정말 아니지! 나도 저번에 엄마가 옆집 딸이랑 비교할 때 충격적이었거든, 한동안 엄마랑 대화를 안 했어.',\n",
       " '다음번 동호회 모임에서도 혹시 어색한 분위기가 지속되면 당신이 주도적으로 대화를 꺼내 보는 게 어때?',\n",
       " '네가 그렇게 생각해 주니까 형이 더 기운이 나는 것 같아. 널 위로해 주려다가 내가 위로 받네.',\n",
       " '갑자기 그게 무슨 소리야? 무슨 일이라도 생겼어?',\n",
       " '주말만을 손꼽아 기다리던 네가 주말이 싫은 정도라니, 너무 놀라운걸. 사랑은 정말 위대한 것이고, 그 마음을 소중히 여길 줄 아는 너는 정말 멋진 거야. 누군가를 품지 못할 만큼 각박하지 않고 열린 마음으로 호의를 진심으로 받아들일 수 있는 거잖아. 얼마나 예쁘니.',\n",
       " '그 친구 어렵게 살았다고 하더니 결혼을 잘했나 보네. 신랑 잘 만나서 호강하네. 너도 부러웠어?',\n",
       " '누구나 처음에는 그런 생각을 해. 내가 보기에 네 친구가 쓴 글은 정말 재미있고 공감되는 부분이 많아.',\n",
       " '자기 말대로 사람이 모두 다 같을 수는 없잖아. 자기가 화를 내기보다는 후임이 행동을 고칠 수 있도록 이끌어주려고 하면 나아지지 않을까? 자기 마음도 조금 풀리겠지만, 이번 기회에 오히려 다른 팀원들과의 관계도 어쩌면 달라질지 몰라.',\n",
       " '당연하지, 사람은 배움의 동물이라고 하잖아? 매 순간 배우는 점이 있으니 지금의 순간도 곧 지나갈 거라고 생각하고 극복하면 좋겠어. 내가 생각하는 너는 얼마든지 그럴 수 있어!',\n",
       " '누구라도 그런 말을 들으면 상처받았을 거야. 그래도 너무 자책하지 말고 털어버리자.',\n",
       " '네 꼼꼼한 성격과 섬세함이라면 분명 앞으로의 문제를 더욱 잘 예방할 수 있을 거야. 이번엔 비록 방심해버렸지만 두 번은 없을 거라고 생각해보자!',\n",
       " '감정화자씨가 아내를 정말 많이 사랑하나 봐. 순간의 화를 못 이겨서 부부싸움으로 이어지는 경우도 많은데, 이렇게 상담하면서 마음을 풀고 있네. 정말 다정하고 훌륭한 남편상이야.',\n",
       " '에고 그동안 간절히 바랐던 회사였는데 면접도 못 보고 나와서 정말 속상하겠다. 원래 내 잘못으로 이렇게 됐다고 생각되면 괜히 더 자책하게 되잖아. 네가 아니라 누구라도 이런 상황이 되면 정말 마음이 무너져 내릴 거야.',\n",
       " '대단하시네요. 에너지 넘치는 남자아이들 키우면서 운동까지 마음먹기 쉽진 않으셨을 텐데요. 게다가 효과를 볼 정도로 열심히 다니셨다니 놀랍네요.',\n",
       " '정말 많은 것을 얻으셨네요. 선생님께서 이야기해주신 덕분에 저도 다시 제 인생을 생각해보는 기회를 가질 수 있었어요. 덕분에 제 안에도 기쁨이 가득 찼습니다.',\n",
       " '맞아요 정말 다행이라고 생각해요. 그동안 얼마나 고생 많이 했어요. 저거 하나 찾으려고 밤새도록 집을 뒤졌잖아요.',\n",
       " '밤새 책을 읽는 기쁨이 어떤 건지 알 거 같아. 너무 만족스러워서 피곤한 줄도 모르겠지. 너도 살림하느라 요즘 책 읽을 시간이 없어서 더 마음이 흡족한 거 같다.',\n",
       " '누구 동생인지 아주 잘 컸는데? 정말 대견해! 기분 풀고 나머지 일 해. 오늘 언니가 저녁 맛있는 거 사줄게.',\n",
       " '이야기를 들어주는 건 어려운 일이 아니니 얼마든지 연락해도 좋아. 네가 어서 기운을 차리길 바랄게.',\n",
       " '지금껏 열심히 해 온 만큼 상심이 크겠다. 하지만 자기 스스로를 생각해서라도 마음을 편히 가져보는 게 어때? 과도한 자책은 시험에 더한 손해일 거야.',\n",
       " '아침에 얼마나 놀라고 조급한 마음이 들었으면 그랬겠어. 누구나 그 정도의 실수는 할 수 있으니까 너무 자책하지 마. 네가 너무 속상해하는 것 같아서 내 마음이 안 좋네.',\n",
       " '그래. 당신의 음식에선 항상 진심이 느껴져. 그건 우리 아이들도 똑같이 느낄 거야. 그러니 이번 사건에 너무 마음 쓰지 말고 조금 쉬면서 잊으려고 해봐.',\n",
       " '난 너무 좋지, 벌써부터 기대가 된다. 우리 딸이 고른 남자라면 분명 훌륭한 사람이겠지.',\n",
       " '감정화자씨 야구를 좋아하는 건 우리 부서 사람들도 다 알잖아. 감정화자씨 아내도 이해 못하는 건 아니지만 오늘 같은 날은 좀 양보했더라면 좋았을걸. 결승전 진출 게임이었는데 채널을 돌리면 나라도 화가 났을 거야.',\n",
       " '그래. 아직은 검사 결과도 나오지 않았고, 우리가 최대한 어머니를 도울 수 있는 만큼 도와드리자. 찾아봤더니 증상을 조금 완화하는 방법들이 몇 가지 있나 봐. 너무 혼자 힘들어하지 말고 내가 옆에 있다는 걸 잊지 말아 줘.',\n",
       " '누가 그런 못된 짓으로 자기를 화나게 하는걸까. 누가봐도 정말 불쾌한 일이잖아. 문자를 보내는 사람이 누군지 몰라도 잡아서 벌을 줘야할 것 같아.',\n",
       " '나도 아버지가 나한테 주신 만년필을 아직도 가지고 있어. 너무 오래 써서 촉이 부러졌는데도 버리질 못했지. 그래서 당신 마음 충분히 이해해. 많이 힘들었겠다.',\n",
       " '그럴 만하지. 나 같았으면 회사 일이 힘든 순간부터 가족들한테 기댔을 것 같은데, 감정 화자님 정말 고생했네. 결정하기까지는 부모님께 말을 안 했지만, 언젠가는 말해야 하는 문제라서 걱정스러운 거야?',\n",
       " '하늘은 사람에게 감당할 수 있을 만큼만 고난을 준다고 하잖아. 어릴 때 어머니를 잃고도 이렇게 바르게 큰 걸 보면 감정화자는 정말 그릇이 큰 사람이야. 그만큼 자신의 마음도 잘 돌봐서 늘 즐겁게 지내길 바랄게.',\n",
       " '나도 수강 신청에 실패해서 하루 종일 컴퓨터를 붙잡고 있었던 적이 있어서 너의 마음에 너무 공감돼. 네가 학기를 앞두고 걱정이 정말 많이 되겠다.',\n",
       " '자기의 기분을 고려하지 않고 뱉은 무례한 말에 그렇게까지 영향받지 않았으면 좋겠어. 진정 자기를 위하는 마음이었다면 그렇게 심하게 말하지는 않았을 거야. 게다가 자기 얼굴에 뭐가 나든 자기는 나에게 있어서 변함없이 사랑스럽고 소중한 사람인걸.',\n",
       " '직장인한테 연차가 얼마나 소중한데 당연히 짜증나죠. 속상해서 어떡해요.',\n",
       " '아직 시기가 오지 않았을 뿐인 거야. 기회는 준비하는 자에게 찾아온다고 하잖아.',\n",
       " '그래도 그 상황을 급하게 무마하려다가 더 큰일로 이어지진 않은 것 같아서 다행이다. 때로는 실수가 더 큰 실수를 불러오기도 하잖아.',\n",
       " '나라도 그 함성에 힘이 생겨서 더 열심히 뛸 것 같아. 절대 실수하면 안 될 것 같고.',\n",
       " '네 남자 친구도 잊고 싶어서 잊어버린 게 아닐 거야. 남자 친구는 네게 미안해하고 있을 것 같아. 너무 상심하지 마.',\n",
       " '왜 아니겠어. 나 같아도 상당히 화가 났을 거야. 하지만 직접적으로 가서 뭐라 하는 것보다는 사감님이나 학교 측에 얘기하는 게 낫지 않을까?',\n",
       " '나도 옆에서 많이 도와줄게요. 필요한 게 있으면 언제든 말만 하세요.',\n",
       " '나이 많고 자기보다 어린데 후배인 직원 얘기하는 거지?',\n",
       " '네가 업무가 바빠 야근할 때도 많은데 정말 힘들었겠다. 엄마는 다른 것보다 네가 너무 힘이 들까 걱정이 되네.',\n",
       " '저는 필터를 따로 더 구입했던 것 같아요. 조금 더 공기청정기의 효과가 있었고 그러면 감정화자님도 당황스러운 마음이 조금은 사라지지 않을까 싶어요. 아무래도 걸리는 게 눈에 보이니까 비교적 안심이 되실 것 같아요.',\n",
       " '그래, 무슨 일 있으면 언제든지 연락 남겨 줘.',\n",
       " '허스키에 유치원이라니 뭔가 안 어울리면서도 오히려 귀여울 것 같은 느낌이네. 나도 한번 보고 싶다!',\n",
       " '일단은 의사 선생님하고 좀 전에 통화했고 눈 상태 설명 잘했으니까 얼른 병원으로 넘어와.',\n",
       " '왜 그래, 무슨 일인데?',\n",
       " '저번 달에 여행도 다녀오고, 배달도 꽤 시키다 보니 지출이 많았나 보네. 잔고 없는 거 보고, 여보 놀랐겠다.',\n",
       " '시간이 흘러도 떠나신 분에 대한 그리움은 쉽게 옅어지지 않잖아. 듣는 나도 이렇게 울컥하는데 당사자인 너는 얼마나 슬펐겠니. 아무리 해도 사랑하는 상대가 죽었다는 사실은 정말 큰 슬픔을 가져오잖아.',\n",
       " '그래. 엄마도 좋은 일인데 많은 분들 초대하지 못할까 걱정했어.',\n",
       " '그렇게 행복한 시간들이 쌓이다 보면 어느 순간 네 딸도 자연스럽게 아빠라는 호칭이 입에 붙을 거야. 너희 가족에게 그런 날이 곧 오기를 엄마가 기도할게.',\n",
       " '그 정도로 놀랐구나. 네가 워낙 새치 걱정 없이 살아와서 그런가 보다. 그러다 보니 더 놀랐나 봐.',\n",
       " '우리 애들? 보통은 나가서 친구들이랑 놀면서 시간 보내는 것 같아. 갑자기 그건 왜?',\n",
       " '그럼, 그리고 요즘 시대가 어느 때인데, 만나지 못하더라도 영상 통화도 있고 메신저도 있고! 정말 그리우면 돈 모아서 미국으로 날아가면 돼.',\n",
       " '감정화자님이 그동안 기름을 꽉 채워서 낭비하셨다는 생각에 무척 후회스러우셨을 것 같아요. 하지만 살면서 이런 일 저런 일 겪는 게 인생 아닐까요? 연비에 대한 지식을 앎으로써 감정화자님이 이미 한 계단 위에 올라서신 게 느껴지는데요.',\n",
       " '지금도 충분하답니다. 내년 생일에는 저도 꼭 좋은 선물해드리고 싶어요.',\n",
       " '짧은 대화를 나누며 그런 생각을 하셨다니 대단하세요, 감정화자님. 저 또한 오늘 이 시간을 통해 느낄 수 있었습니다. 감사드려요.',\n",
       " '어휴 어쩌니? 허리도 원래 안 좋은 애가 아이를 업고 있었으면 많이 아프겠네. 아이가 많이 보챘나 보구나.',\n",
       " '왜? 어떤 일이 있었는지 너무 궁금하다!',\n",
       " '동생아, 너는 이미 올케에게 네가 할 수 있는 최선을 다하고 있어. 너만큼 헌신적인 남편은 누나는 모르니 자책하지 말아줘. 다만 올케가 진정 원하는 것이 네 사랑과 헌신이 아닐 수 있는 거야.',\n",
       " '네 마음도 순수해서 그런 생각이 들 거야. 언니도 행복한 네 모습을 보니 마음이 따뜻해지네.',\n",
       " '그러면 내가 너무 고맙지. 또 얘기하고 싶은 일 있으면 언제든지 편히 연락줘.',\n",
       " '천만에. 나도 감정 화자님 얘기를 듣는 게 좋은걸. 감정 화자님은 내가 소중하게 생각하는 사람이니까 내가 존중하고 이야기를 듣는 건 당연한 일이야.',\n",
       " '무슨 일 났어? 화장실 간 애가 갑자기 왜?',\n",
       " '선생님께서 얼마나 가슴 아픈 사랑을 하셨고 정말 많이 상처받으셨단 걸 알아요. 하지만 저는 언젠가 선생님께서 선생님의 넘치는 사랑의 가치를 알아볼 사람을 만날 수 있다고 믿어요. 선생님은 사랑이 넘치고 반짝반짝 빛나는 사람이니까요.',\n",
       " '엄마에게 오랫동안 시달려서 얼굴 보는 것도 용기가 필요할 텐데 큰 결심을 했구나. 언제든 다른 사람을 먼저 배려하는 넌 내 자랑이란다.',\n",
       " '놀라거나 걱정하는 마음을 남성성이나 여성성으로 구분하는 건 합리적이지 않아. 그리고 위험한 상황에서 주의해야 피해를 줄일 수 있잖아.',\n",
       " '아직 젊으신데 퇴직을 권고받아 당신만큼이나 아버지도 혼란스럽고 당황하셨을 것 같아. 자기도 시험을 앞두고 청천벽력 같은 소리를 들어서 많이 심란하겠다. 아직 퇴사 결정이 내려진 건 아니니 마음을 차분히 하고 시험에 집중해 보는 건 어떨까.',\n",
       " '그때 사람들이 얼마나 놀랐니? 요리를 배운 지 얼마 되지 않은 네가 합격해서 모두가 천부적 재능이라고 느꼈어.',\n",
       " '약하다니, 전혀 아니야. 난 오히려 상처받았다고 말하는 우리 아들이 그 누구보다 강하다고 생각하는 걸. 그렇게 자신의 아픔과 상처를 당당하게 얘기하고 발전하려는 사람이 진정으로 강한 사람이란다.',\n",
       " '털이 빠지는 건 뾰족한 수도 없고 말이죠. 특히 검정 옷을 입는 날에는 정말 전쟁이지요. 저도 강아지 털 때문에 세탁소에 쓴 비용만 해도 어마어마한걸요.',\n",
       " '너도. 좋은 소식 있으면 꼭 말해주기다.',\n",
       " '너의 응원이 문제를 해결하는 데 도움이 될진 못하더라도 친구에게 큰 위로가 될 거야. 지금 친구에겐 잘하고 있다는 격려와 응원이 제일 필요할 거 같아. 슬픈 감정은 내려놓고 친구에게 힘이 되고 더 웃을 수 있게 좋은 생각을 해보자.',\n",
       " '그렇구나. 윗집에 아기들이 있나? 요즘 일 때문에 많이 피곤할 텐데 제대로 잠도 자지 못해서 어떡해. 피곤하면 더 예민해질 텐데 걱정이 되네.',\n",
       " '감정화자씨는 혜성처럼 나타난 스타보다는 서서히 빛을 발하는 사람을 좋아하는 것 같더라고요.',\n",
       " '알지요. 감정화자씨 남자친구가 감정화자씨랑 사귀기 전에 소꿉친구라고 둘이 엄청 붙어다녔다면서요.',\n",
       " '아내가 잘못한 게 맞는데도 네가 원인 제공을 한 것 같아서 슬픈 네 마음이 이해돼. 하지만 그럼에도 불구하고 아내가 네 돈을 가져간 건 명백히 잘못된 행동이잖아. 너무 자책하지 말고 더 이상 이런 일이 없도록 아내와 진지하게 이야기를 나누어보는 건 어때?',\n",
       " '이런 사소한 걸 챙기는 게 생각보다 정말 힘들더라. 매일 습관처럼 만지고 있는 거라 더 까먹기 쉬운 것 같아.',\n",
       " '나는 지금 당신 이름도 충분히 예쁘다고 생각하는데. 당신이 원하는 일이라면 당연히 존중하지.',\n",
       " '아무래도 자기가 워낙 훌륭한 딸이다 보니까 부모님들도 정말 좋은 분이실 것 같아. 가족들과 긍정적인 영향을 주고받는 것을 보니 내가 다 뿌듯하다.',\n",
       " '열심히 일한 결과가 내 아이 속상하게 한다고 하면 마음이 너무 아프지. 나였어도 눈물이 펑펑 났을 거야. 언니 마음도 너무 아프다. 동생아.',\n",
       " '아무리 친한 사이라고 해도 기분 나쁠만한 말을 하다니 너무하네. 자기가 그 자리에서 얼마나 불쾌하고 상처받았겠어.',\n",
       " '네가 회의 시작 전에 미리 준비를 해서 다행이다. 네가 가진 준비성이 너를 위기 상황으로부터 도운 거야. 그렇게 생각하면 안 좋은 생각에서 벗어날 수 있지 않을까?',\n",
       " '요즘 세상이 많이 흉흉해서 그런 생각 하는 거 나도 이해해요. 하지만 이럴 때 더 잔소리하고 강요하면 더 안 좋을 수 있잖아요? 너무 불안해하지 말고 한번 믿어봐요.',\n",
       " '여행 가기 전 가장 설레는 순간이 환전하는 순간이라고 하잖아. 너가 그토록 다시 가고 싶어 하던 미국 여행을 곧 간다니 정말 기쁘겠다. 여행을 정말 좋아하는 네가 얼마나 오랜만에 가는 여행인지 알아서 나도 덩달아 설레.',\n",
       " '네 남편 출장 다녀왔구나! 어묵이 유명한 곳으로 다녀온 거래?',\n",
       " '그럼요. 당장 저도 선생님의 사연에 깊이 공감하다 못해 눈물이 나올 것 같은걸요. 그러니 다른 사람들도 선생님의 동행에 함께하고 싶은 분이 분명히 있을 테니 용기를 내보세요.',\n",
       " '감정화자님이 언니와 비교되는 기분을 느껴 많이 울적하고 슬프셨겠어요. 가장 가까이서 보는 가족이다보니 안 그러려고 해도 더 부정적인 마음이 생기셨을 것 같아요.',\n",
       " '너는 말도 조리 있게 잘하고 동물에 관심이 많아 전문적인 지식도 풍부하잖아. 그러니 분명 네가 원하는 대로 대화를 이끌 수 있을 거야. 진심으로 응원할게.',\n",
       " '우리가 장모님과 떨어져서 생활하다 보니까 어쩔 수 없이 발견하기 어려웠던 거지. 너무 자신의 탓이라고 자책하지 않았으면 좋겠어. 그래도 예전부터 어머니랑 통화도 많이 하면서 잘 살폈잖아.',\n",
       " '갑자기 물 폭탄처럼 쏟아 붓는구나! 출근을 못하게 돼서 얼마나 당황스럽니. 회사에 연락은 한거야?',\n",
       " '지금의 무력감은 일시적인 것이라고 생각해요. 시간이 약이라잖아요. 엄마는 무력감을 이겨낼 수 있는 힘이 충분히 있는 사람이에요.',\n",
       " '더운 날 고생해서 장 보러 다녀왔는데 이런 일이 생겨서 스트레스 받았겠네. 물어보고 사 온 건데 아니라니 나였어도 분한 마음이 생길 것 같아.',\n",
       " '사회를 위해 신경쓰는 만큼 한편으로는 지금처럼 속에 화가 쌓일 일도 많이 생기니까. 이렇게 한 번씩 나한테라도 말하면서 털어내.',\n",
       " '지금은 몸이 고단해서 잊었던 일들이 다 떠오르고 만 것 같아. 나도 비슷한 경험에 울적했던 날이 있어서 무슨 마음인지 알아. 다만 나는 당신이 이미 지난 일들을 모두 꺼내어 보면서 거듭 상처받지는 않았음 좋겠어.',\n",
       " '당연히 돈이 걸려있으니까 속상한 마음이 너무 이해가 돼. 그래도 그것 때문에 낭비하는 자기 감정과 시간이 더 귀한 거 아니겠어? 그걸로 너무 스트레스받으면 더 손해잖아.',\n",
       " '어머, 넥타이 매주시면서 정말 뿌듯하셨겠어요.',\n",
       " '왜 그렇게 자책을 하는 거니. 네가 이번 대회를 위해서 누구보다 열심히 연습했다는 것을 모르는 사람이 없을 정도야. 우리 모두 너의 아픔에 안타까울 뿐이지 1등을 못했다고 너를 원망하는 일은 없을 거야.',\n",
       " '중요한 물건이 아니더라도 충분히 화가 날 상황이죠. 정말 기분 안 좋으실 것 같아요. 누구보다 행복하게 여행을 떠나셨을 텐데 말이에요.',\n",
       " '자기가 그때는 자기에게 가장 적합하고 자기의 도전정신과 자기의 열정을 쏟을 회사로 옮긴 거잖아. 처음에는 비교되고 후회스럽고 슬픈 마음이 들 수도 있지만. 자기는 올바른 방향으로 나아가고 있어, 당신의 용감한 결정을 항상 지지해.',\n",
       " '형의 그동안의 아픔과 어려움 다 알 수는 없지만 형의 생각이 형을 위하는 일이기만을 바라. 형이 더는 고통받지 않는다는 것이 제일 중요한 일이야. 형의 시간은 너무나도 소중하고 그 소중함을 알아줘서 고마워.',\n",
       " '고맙기는. 힘이 난다니 너무 다행이다. 밥 든든히 먹고 무너지지 않고 해오던 대로 열심히 해보자.',\n",
       " '아, 진급시험이 정말 이제 3주 남았네요. 지금 입덧이나 다른 증상이 있어요?',\n",
       " '사랑하는 가족이랑 잠시라도 이별해서 멀리 떨어지는 것이니 얼마나 마음이 아프겠어. 아쉽고 보고 싶은 만큼 하루에도 영상통화 몇 번씩 하면서 버티고 힘내보자.',\n",
       " '딸을 달래주기 위해 평소에 좋아하는 걸 할 수 있게 해주셨다니 너무 사려 깊고 마음씨가 좋으세요.',\n",
       " '요즘에도 그런 못된 상사가 있어? 어디 말도 못하고 혼자 속 끓이느라 얼마나 고생했니.',\n",
       " '그럼에도 엄마가 오랫동안 지켜본 너에게는 매사에 성실하게 임하면서 무엇이든지 최선을 다한다는 장점이 있어. 그러니 다른 사람이 너를 보면서 하는 말은 너무 괘념치 않았으면 해. 이런 날일수록 고생하고 노력한 너 자신을 잘 다독여 주면 괴로웠던 마음도 차츰 나아질 거야.',\n",
       " '마음을 편하게 먹고 푹 잘 쉬면 그만큼 좋은 아이디어도 떠오를 거야. 내가 항상 옆에 있으니까 너무 걱정하지 말고 오늘처럼 힘들 때는 언제든지 나에게 얘기해.',\n",
       " '아버지는 그래도 정정하신 편이죠. 유치원에도 멋쟁이 할아버지라고 소문났어요. 운동도 열심히 하시고 소일거리도 하시는 노인들이 얼마나 된다고요.',\n",
       " '알아. 너처럼 마음씨 고운 아이가 그럴 생각은 꿈에도 없었겠지. 그냥 답답하니까 엄마한테 하소연한 거 다 알아. 네 마음을 내가 모르면 누가 알겠니?',\n",
       " '예상치 못한 일에 화가 많이 낫나 보네. 너무 짜증 내지 말고 그럴 수 있는 일이라고 생각해 봐. 이미 일어난 일이니 너무 화내지 말고, 안 다친 걸 다행이라고 생각하고 기분 풀어.',\n",
       " '그랬겠구나. 아빠였다면 도망치고 싶었을 것 같다. 원래 넌 노래를 잘하는 아이였는데 무슨 이유가 있었니?',\n",
       " '당신은 충분히 그 가방을 누릴 자격이 있고 그 기쁨을 만끽해야 해. 내가 확신하고 장담하니 걱정 없이 기뻐하기만 하자.',\n",
       " '자기가 진짜 실망 많이 했겠네. 그래도 혹시 본인이 한 걸 진짜 몰라서 그럴 수도 있으니까 이야기해보는 건 어떨까? 원래 둘이 사이가 좋았으니까 이야기해 보면 풀릴 수 있을 것 같아.',\n",
       " '차장님이 좋은 의도로 말한 거였다고 하더라도, 다른 사람이 있는 자리에서 하면 안 되는 거지. 너무 예의가 없는 행동이네. 그런 말에 당신이 상처받지 말고, 훌훌 털어버렸으면 좋겠다.',\n",
       " '어렸을 적 느꼈던 기쁨과 안도는 삶을 지탱하는 힘이 될 때가 있으니까요. 당신이 은퇴하기까지 많은 고통을 겪고 인생을 살아왔기에 그때의 기쁨을 되찾고 싶은 순간이 왔나 봐요. 한 사람이 기운을 차릴 수 있다면 그 기쁨은 무척 소중하고 성취해야 하는 거라고 생각해요.',\n",
       " '그러게, 그래도 운전에 능숙하신 아버님이 운전하셔서 나도 마음이 조금이라도 놓인다. 너무 긴장되고 떨리겠지만, 안개 구간 만나면 어떻게 해야 할지 아버님 보면서 눈으로 꼭 익혀놔. 물론 자기가 운전할 때는 그런 일 절대 없었으면 좋겠지만.',\n",
       " '잘 해결될 거야. 너무 걱정하지 말고, 어서 자기 집에서 편안함과 진정한 휴식을 찾았으면 좋겠다.',\n",
       " '감정화자님, 아무도 없다니요. 감정화자님을 정말 끝까지 지지하고 응원할 사람 여기 있는걸요. 감정화자님이 너무 속상하고 상처받으셨겠지만, 다른 사람들의 사고의 틀에 감정화자님을 맞추지 않으셨으면 해요.',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./empathy.csv', encoding='UTF-8')\n",
    "\n",
    "sampled_df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "\n",
    "user0 = list(sampled_df['user0'])\n",
    "user1 = list(sampled_df['user1'])\n",
    "\n",
    "user1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py:1129: RuntimeWarning: Detected duplicate leading \"<|begin_of_text|>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    15 runs   (    0.06 ms per token, 16198.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.57 ms /    78 tokens (    8.19 ms per token,   122.15 tokens per second)\n",
      "llama_print_timings:        eval time =     230.27 ms /    14 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     876.25 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.05 ms /    66 tokens (    0.73 ms per token,  1373.57 tokens per second)\n",
      "llama_print_timings:        eval time =     731.84 ms /    44 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     798.49 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18485.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.89 ms /    50 tokens (    0.84 ms per token,  1193.49 tokens per second)\n",
      "llama_print_timings:        eval time =     493.09 ms /    30 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =     546.72 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /    26 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.71 ms /    51 tokens (    0.82 ms per token,  1222.73 tokens per second)\n",
      "llama_print_timings:        eval time =     411.34 ms /    25 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =     463.26 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18545.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.81 ms /    48 tokens (    0.77 ms per token,  1303.99 tokens per second)\n",
      "llama_print_timings:        eval time =     810.70 ms /    49 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     865.83 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.79 ms /    68 tokens (    0.72 ms per token,  1393.76 tokens per second)\n",
      "llama_print_timings:        eval time =     816.60 ms /    49 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     885.10 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    32 runs   (    0.06 ms per token, 18150.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.61 ms /    65 tokens (    0.75 ms per token,  1337.26 tokens per second)\n",
      "llama_print_timings:        eval time =     514.26 ms /    31 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     575.00 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18526.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.16 ms /    26 tokens (    1.16 ms per token,   861.95 tokens per second)\n",
      "llama_print_timings:        eval time =     689.02 ms /    42 runs   (   16.41 ms per token,    60.96 tokens per second)\n",
      "llama_print_timings:       total time =     735.67 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /    67 runs   (    0.05 ms per token, 18513.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.19 ms /    48 tokens (    0.75 ms per token,  1326.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.62 ms /    66 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =    1155.59 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    56 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.27 ms /    49 tokens (    0.84 ms per token,  1187.30 tokens per second)\n",
      "llama_print_timings:        eval time =     910.14 ms /    55 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     972.37 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18540.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.19 ms /    75 tokens (    0.66 ms per token,  1524.73 tokens per second)\n",
      "llama_print_timings:        eval time =     751.03 ms /    45 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     818.12 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /    66 runs   (    0.05 ms per token, 18638.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    77 tokens (    0.64 ms per token,  1556.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.69 ms /    65 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =    1162.30 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    77 runs   (    0.05 ms per token, 18456.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.02 ms /    66 tokens (    0.73 ms per token,  1374.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1268.22 ms /    76 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =    1348.14 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.05 ms per token, 18367.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.18 ms /    18 tokens (    1.45 ms per token,   687.52 tokens per second)\n",
      "llama_print_timings:        eval time =     131.26 ms /     8 runs   (   16.41 ms per token,    60.95 tokens per second)\n",
      "llama_print_timings:       total time =     161.00 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    77 runs   (    0.05 ms per token, 18333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.31 ms /    91 tokens (    0.63 ms per token,  1587.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.58 ms /    76 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1364.21 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    46 runs   (    0.05 ms per token, 18459.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.90 ms /    72 tokens (    0.68 ms per token,  1472.45 tokens per second)\n",
      "llama_print_timings:        eval time =     750.20 ms /    45 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     816.39 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    64 runs   (    0.05 ms per token, 18834.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.90 ms /    91 tokens (    0.63 ms per token,  1599.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1055.88 ms /    63 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1137.20 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18422.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      35.87 ms /    45 tokens (    0.80 ms per token,  1254.46 tokens per second)\n",
      "llama_print_timings:        eval time =     394.17 ms /    24 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =     439.43 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /    32 runs   (    0.05 ms per token, 18285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.81 ms /    59 tokens (    0.73 ms per token,  1378.02 tokens per second)\n",
      "llama_print_timings:        eval time =     511.87 ms /    31 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     566.62 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.66 ms /    39 tokens (    0.86 ms per token,  1158.58 tokens per second)\n",
      "llama_print_timings:        eval time =     525.53 ms /    32 runs   (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:       total time =     571.62 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18541.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.03 ms /    71 tokens (    0.69 ms per token,  1448.00 tokens per second)\n",
      "llama_print_timings:        eval time =     733.86 ms /    44 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     799.75 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18674.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.65 ms /    86 tokens (    0.66 ms per token,  1518.01 tokens per second)\n",
      "llama_print_timings:        eval time =     838.65 ms /    50 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     914.51 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.96 ms /    50 tokens (    0.84 ms per token,  1191.70 tokens per second)\n",
      "llama_print_timings:        eval time =     878.24 ms /    53 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     941.35 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    55 runs   (    0.05 ms per token, 18631.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.20 ms /    45 tokens (    0.80 ms per token,  1242.92 tokens per second)\n",
      "llama_print_timings:        eval time =     893.27 ms /    54 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     950.68 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18546.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.05 ms /    70 tokens (    0.70 ms per token,  1426.97 tokens per second)\n",
      "llama_print_timings:        eval time =     800.99 ms /    48 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     868.03 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    42 runs   (    0.05 ms per token, 18380.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.62 ms /    56 tokens (    0.76 ms per token,  1314.00 tokens per second)\n",
      "llama_print_timings:        eval time =     679.85 ms /    41 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     739.96 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    55 runs   (    0.06 ms per token, 18133.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    64 tokens (    0.68 ms per token,  1474.11 tokens per second)\n",
      "llama_print_timings:        eval time =     900.51 ms /    54 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     967.62 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    36 runs   (    0.05 ms per token, 18414.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    28 tokens (    1.08 ms per token,   924.12 tokens per second)\n",
      "llama_print_timings:        eval time =     575.58 ms /    35 runs   (   16.45 ms per token,    60.81 tokens per second)\n",
      "llama_print_timings:       total time =     621.30 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /    33 runs   (    0.05 ms per token, 18211.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    56 tokens (    0.76 ms per token,  1311.63 tokens per second)\n",
      "llama_print_timings:        eval time =     528.67 ms /    32 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     584.54 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    53 runs   (    0.05 ms per token, 18492.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      41.89 ms /    52 tokens (    0.81 ms per token,  1241.29 tokens per second)\n",
      "llama_print_timings:        eval time =     863.22 ms /    52 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     927.85 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /    18 runs   (    0.05 ms per token, 18367.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    30 tokens (    1.02 ms per token,   982.25 tokens per second)\n",
      "llama_print_timings:        eval time =     279.16 ms /    17 runs   (   16.42 ms per token,    60.90 tokens per second)\n",
      "llama_print_timings:       total time =     316.66 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    64 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.48 ms /    65 tokens (    0.75 ms per token,  1340.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1051.27 ms /    63 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =    1123.92 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    65 runs   (    0.05 ms per token, 18492.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    79 tokens (    0.64 ms per token,  1571.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1072.82 ms /    64 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1148.10 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18418.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.76 ms /    38 tokens (    0.89 ms per token,  1125.69 tokens per second)\n",
      "llama_print_timings:        eval time =     263.01 ms /    16 runs   (   16.44 ms per token,    60.84 tokens per second)\n",
      "llama_print_timings:       total time =     303.12 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18554.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.14 ms /    27 tokens (    1.12 ms per token,   895.70 tokens per second)\n",
      "llama_print_timings:        eval time =     772.68 ms /    47 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =     820.96 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18562.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.71 ms /    64 tokens (    0.68 ms per token,  1464.10 tokens per second)\n",
      "llama_print_timings:        eval time =     899.86 ms /    54 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     964.58 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    54 runs   (    0.05 ms per token, 18486.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.40 ms /    34 tokens (    0.98 ms per token,  1017.96 tokens per second)\n",
      "llama_print_timings:        eval time =     873.29 ms /    53 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     926.73 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18455.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    62 tokens (    0.70 ms per token,  1428.18 tokens per second)\n",
      "llama_print_timings:        eval time =     614.27 ms /    37 runs   (   16.60 ms per token,    60.23 tokens per second)\n",
      "llama_print_timings:       total time =     672.17 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.56 ms /    55 tokens (    0.77 ms per token,  1292.23 tokens per second)\n",
      "llama_print_timings:        eval time =     679.23 ms /    41 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     738.05 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /    26 runs   (    0.05 ms per token, 18374.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.08 ms /    51 tokens (    0.83 ms per token,  1211.98 tokens per second)\n",
      "llama_print_timings:        eval time =     411.49 ms /    25 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     463.07 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      48.99 ms /    68 tokens (    0.72 ms per token,  1388.10 tokens per second)\n",
      "llama_print_timings:        eval time =     784.01 ms /    47 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     850.62 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    24 runs   (    0.05 ms per token, 18677.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    20 tokens (    1.34 ms per token,   748.53 tokens per second)\n",
      "llama_print_timings:        eval time =     377.91 ms /    23 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =     413.26 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.23 ms /    43 tokens (    0.84 ms per token,  1186.70 tokens per second)\n",
      "llama_print_timings:        eval time =     559.48 ms /    34 runs   (   16.46 ms per token,    60.77 tokens per second)\n",
      "llama_print_timings:       total time =     608.66 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    67 runs   (    0.05 ms per token, 18559.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.34 ms /    46 tokens (    0.79 ms per token,  1265.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.11 ms /    66 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =    1158.61 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18677.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.46 ms /    46 tokens (    0.79 ms per token,  1261.73 tokens per second)\n",
      "llama_print_timings:        eval time =     810.76 ms /    49 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     865.86 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18598.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    61 tokens (    0.72 ms per token,  1393.49 tokens per second)\n",
      "llama_print_timings:        eval time =     916.72 ms /    55 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     981.46 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18650.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    64 tokens (    0.69 ms per token,  1454.58 tokens per second)\n",
      "llama_print_timings:        eval time =     984.90 ms /    59 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =    1051.29 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18636.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.36 ms /    53 tokens (    0.80 ms per token,  1251.15 tokens per second)\n",
      "llama_print_timings:        eval time =     712.83 ms /    43 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     771.99 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18574.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.58 ms /    35 tokens (    0.96 ms per token,  1042.32 tokens per second)\n",
      "llama_print_timings:        eval time =     691.43 ms /    42 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     741.62 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /    69 runs   (    0.05 ms per token, 18643.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.67 ms /    72 tokens (    0.69 ms per token,  1449.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.17 ms /    68 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =    1215.02 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18537.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    62 tokens (    0.70 ms per token,  1423.65 tokens per second)\n",
      "llama_print_timings:        eval time =     581.51 ms /    35 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     639.38 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18498.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.84 ms /    31 tokens (    0.99 ms per token,  1005.35 tokens per second)\n",
      "llama_print_timings:        eval time =     263.17 ms /    16 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     300.08 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    39 tokens (    0.88 ms per token,  1140.58 tokens per second)\n",
      "llama_print_timings:        eval time =     526.82 ms /    32 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     572.56 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18281.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.68 ms /    19 tokens (    1.40 ms per token,   712.06 tokens per second)\n",
      "llama_print_timings:        eval time =     312.53 ms /    19 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =     346.25 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    55 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    74 tokens (    0.68 ms per token,  1475.72 tokens per second)\n",
      "llama_print_timings:        eval time =     904.57 ms /    54 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =     975.47 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    60 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.23 ms /    58 tokens (    0.75 ms per token,  1341.57 tokens per second)\n",
      "llama_print_timings:        eval time =     983.14 ms /    59 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =    1049.15 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    78 runs   (    0.05 ms per token, 18522.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      55.70 ms /    82 tokens (    0.68 ms per token,  1472.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.69 ms /    77 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =    1381.18 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18537.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    73 tokens (    0.68 ms per token,  1467.75 tokens per second)\n",
      "llama_print_timings:        eval time =     601.84 ms /    36 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =     665.81 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18625.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    56 tokens (    0.77 ms per token,  1305.06 tokens per second)\n",
      "llama_print_timings:        eval time =     462.01 ms /    28 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     516.00 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18511.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.41 ms /    60 tokens (    0.72 ms per token,  1382.30 tokens per second)\n",
      "llama_print_timings:        eval time =     832.82 ms /    50 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     896.06 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18398.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.29 ms /    25 tokens (    1.21 ms per token,   825.25 tokens per second)\n",
      "llama_print_timings:        eval time =     263.22 ms /    16 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =     299.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    54 runs   (    0.05 ms per token, 18672.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    70 tokens (    0.71 ms per token,  1416.20 tokens per second)\n",
      "llama_print_timings:        eval time =     886.65 ms /    53 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =     956.22 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.19 ms /    25 tokens (    1.21 ms per token,   828.03 tokens per second)\n",
      "llama_print_timings:        eval time =     411.24 ms /    25 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =     451.22 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18646.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    31 tokens (    1.00 ms per token,  1000.23 tokens per second)\n",
      "llama_print_timings:        eval time =     428.15 ms /    26 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     469.03 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /    26 runs   (    0.05 ms per token, 18245.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    20 tokens (    1.34 ms per token,   745.43 tokens per second)\n",
      "llama_print_timings:        eval time =     411.22 ms /    25 runs   (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:       total time =     447.80 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    57 runs   (    0.05 ms per token, 18597.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    54 tokens (    0.79 ms per token,  1258.42 tokens per second)\n",
      "llama_print_timings:        eval time =     931.76 ms /    56 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     996.98 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18240.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.40 ms /    45 tokens (    0.81 ms per token,  1236.43 tokens per second)\n",
      "llama_print_timings:        eval time =     263.52 ms /    16 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     306.08 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18467.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.25 ms /    40 tokens (    0.86 ms per token,  1167.99 tokens per second)\n",
      "llama_print_timings:        eval time =     428.09 ms /    26 runs   (   16.46 ms per token,    60.74 tokens per second)\n",
      "llama_print_timings:       total time =     471.90 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18471.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.29 ms /    50 tokens (    0.85 ms per token,  1182.40 tokens per second)\n",
      "llama_print_timings:        eval time =     577.85 ms /    35 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     633.46 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /    13 runs   (    0.06 ms per token, 18030.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.70 ms /    19 tokens (    1.41 ms per token,   711.61 tokens per second)\n",
      "llama_print_timings:        eval time =     197.38 ms /    12 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     228.66 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    56 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    56 tokens (    0.77 ms per token,  1301.72 tokens per second)\n",
      "llama_print_timings:        eval time =     915.69 ms /    55 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     979.67 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    56 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.87 ms /    56 tokens (    0.77 ms per token,  1306.37 tokens per second)\n",
      "llama_print_timings:        eval time =     915.91 ms /    55 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     980.34 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    41 runs   (    0.05 ms per token, 18653.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.88 ms /    56 tokens (    0.77 ms per token,  1305.85 tokens per second)\n",
      "llama_print_timings:        eval time =     663.63 ms /    40 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     721.35 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    19 runs   (    0.05 ms per token, 18591.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.81 ms /    36 tokens (    0.94 ms per token,  1064.62 tokens per second)\n",
      "llama_print_timings:        eval time =     296.44 ms /    18 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     337.23 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    85 runs   (    0.05 ms per token, 18490.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.69 ms /    96 tokens (    0.61 ms per token,  1635.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1414.34 ms /    84 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =    1507.52 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /    25 runs   (    0.05 ms per token, 18628.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.69 ms /    36 tokens (    0.94 ms per token,  1068.66 tokens per second)\n",
      "llama_print_timings:        eval time =     395.33 ms /    24 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     438.01 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /    26 runs   (    0.05 ms per token, 18558.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    30 tokens (    1.03 ms per token,   972.23 tokens per second)\n",
      "llama_print_timings:        eval time =     411.51 ms /    25 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     452.43 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18591.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.86 ms /    62 tokens (    0.71 ms per token,  1413.46 tokens per second)\n",
      "llama_print_timings:        eval time =     615.11 ms /    37 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     673.03 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18465.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.28 ms /    39 tokens (    0.88 ms per token,  1137.62 tokens per second)\n",
      "llama_print_timings:        eval time =     725.28 ms /    44 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     776.78 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18410.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    39 tokens (    0.87 ms per token,  1143.49 tokens per second)\n",
      "llama_print_timings:        eval time =     345.91 ms /    21 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     388.30 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    55 tokens (    0.78 ms per token,  1281.19 tokens per second)\n",
      "llama_print_timings:        eval time =     713.75 ms /    43 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     773.72 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    59 runs   (    0.05 ms per token, 18460.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    75 tokens (    0.67 ms per token,  1496.86 tokens per second)\n",
      "llama_print_timings:        eval time =     972.69 ms /    58 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1045.00 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /    34 runs   (    0.05 ms per token, 18732.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.77 ms /    36 tokens (    0.94 ms per token,  1065.94 tokens per second)\n",
      "llama_print_timings:        eval time =     543.71 ms /    33 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     590.33 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    68 runs   (    0.05 ms per token, 18614.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    64 tokens (    0.69 ms per token,  1456.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1120.29 ms /    67 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =    1190.05 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18411.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    54 tokens (    0.79 ms per token,  1264.02 tokens per second)\n",
      "llama_print_timings:        eval time =     562.57 ms /    34 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     618.30 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18667.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.08 ms /    90 tokens (    0.65 ms per token,  1549.67 tokens per second)\n",
      "llama_print_timings:        eval time =     840.96 ms /    50 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     919.13 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.94 ms /    36 tokens (    0.94 ms per token,  1060.79 tokens per second)\n",
      "llama_print_timings:        eval time =     411.68 ms /    25 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     454.73 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18427.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    31 tokens (    1.00 ms per token,   997.52 tokens per second)\n",
      "llama_print_timings:        eval time =     230.33 ms /    14 runs   (   16.45 ms per token,    60.78 tokens per second)\n",
      "llama_print_timings:       total time =     266.35 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18596.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.87 ms /    48 tokens (    0.77 ms per token,  1301.77 tokens per second)\n",
      "llama_print_timings:        eval time =     644.47 ms /    39 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     696.13 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18572.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    61 tokens (    0.72 ms per token,  1397.67 tokens per second)\n",
      "llama_print_timings:        eval time =     514.31 ms /    31 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     569.60 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18500.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.17 ms /    49 tokens (    0.86 ms per token,  1161.94 tokens per second)\n",
      "llama_print_timings:        eval time =     930.51 ms /    56 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     994.28 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /    37 runs   (    0.05 ms per token, 18753.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.54 ms /    46 tokens (    0.79 ms per token,  1258.83 tokens per second)\n",
      "llama_print_timings:        eval time =     593.61 ms /    36 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     643.57 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    59 runs   (    0.05 ms per token, 18535.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.00 ms /    55 tokens (    0.78 ms per token,  1279.01 tokens per second)\n",
      "llama_print_timings:        eval time =     966.00 ms /    58 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =    1031.26 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18541.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.73 ms /    47 tokens (    0.78 ms per token,  1279.75 tokens per second)\n",
      "llama_print_timings:        eval time =     711.34 ms /    43 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     764.36 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /    26 runs   (    0.05 ms per token, 18772.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.82 ms /    35 tokens (    0.97 ms per token,  1035.01 tokens per second)\n",
      "llama_print_timings:        eval time =     411.80 ms /    25 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     455.34 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18376.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    30 tokens (    1.03 ms per token,   967.12 tokens per second)\n",
      "llama_print_timings:        eval time =     378.61 ms /    23 runs   (   16.46 ms per token,    60.75 tokens per second)\n",
      "llama_print_timings:       total time =     418.07 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    42 runs   (    0.05 ms per token, 18364.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    45 tokens (    0.82 ms per token,  1224.06 tokens per second)\n",
      "llama_print_timings:        eval time =     677.31 ms /    41 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     729.28 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18586.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.70 ms /   102 tokens (    0.63 ms per token,  1576.63 tokens per second)\n",
      "llama_print_timings:        eval time =     926.43 ms /    55 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =    1012.93 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    64 runs   (    0.05 ms per token, 18497.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.24 ms /    92 tokens (    0.63 ms per token,  1579.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.79 ms /    63 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =    1143.93 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /    29 runs   (    0.05 ms per token, 18412.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.56 ms /    33 tokens (    1.02 ms per token,   983.43 tokens per second)\n",
      "llama_print_timings:        eval time =     461.91 ms /    28 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     506.58 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    89 runs   (    0.05 ms per token, 18380.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    70 tokens (    0.71 ms per token,  1405.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1489.03 ms /    88 runs   (   16.92 ms per token,    59.10 tokens per second)\n",
      "llama_print_timings:       total time =    1576.64 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18582.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      45.86 ms /    60 tokens (    0.76 ms per token,  1308.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1072.17 ms /    64 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =    1143.63 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18463.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.09 ms /    65 tokens (    0.76 ms per token,  1324.23 tokens per second)\n",
      "llama_print_timings:        eval time =     398.25 ms /    24 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     456.12 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18542.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.41 ms /    50 tokens (    0.85 ms per token,  1179.00 tokens per second)\n",
      "llama_print_timings:        eval time =     695.99 ms /    42 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     754.32 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    53 tokens (    0.81 ms per token,  1241.01 tokens per second)\n",
      "llama_print_timings:        eval time =     764.38 ms /    46 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     824.70 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /    68 runs   (    0.05 ms per token, 18579.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.40 ms /   106 tokens (    0.62 ms per token,  1620.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.21 ms /    67 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =    1220.82 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /    15 runs   (    0.05 ms per token, 18315.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.67 ms /    18 tokens (    1.48 ms per token,   674.84 tokens per second)\n",
      "llama_print_timings:        eval time =     230.64 ms /    14 runs   (   16.47 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     263.06 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    64 runs   (    0.05 ms per token, 18669.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.17 ms /    66 tokens (    0.75 ms per token,  1342.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.84 ms /    63 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =    1128.79 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    56 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.32 ms /    49 tokens (    0.86 ms per token,  1157.82 tokens per second)\n",
      "llama_print_timings:        eval time =     914.49 ms /    55 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     977.97 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18536.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    64 tokens (    0.69 ms per token,  1449.21 tokens per second)\n",
      "llama_print_timings:        eval time =     633.40 ms /    38 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     692.62 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /    26 runs   (    0.05 ms per token, 18705.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    76 tokens (    0.66 ms per token,  1508.30 tokens per second)\n",
      "llama_print_timings:        eval time =     418.63 ms /    25 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     478.75 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    71 runs   (    0.05 ms per token, 18689.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    70 tokens (    0.71 ms per token,  1410.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.21 ms /    70 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =    1250.68 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /    15 runs   (    0.06 ms per token, 17772.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    28 tokens (    1.09 ms per token,   914.97 tokens per second)\n",
      "llama_print_timings:        eval time =     230.68 ms /    14 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     267.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /    29 runs   (    0.05 ms per token, 18709.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.27 ms /    48 tokens (    0.78 ms per token,  1288.07 tokens per second)\n",
      "llama_print_timings:        eval time =     461.84 ms /    28 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     509.77 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /    25 runs   (    0.05 ms per token, 18698.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.07 ms /    37 tokens (    0.92 ms per token,  1086.10 tokens per second)\n",
      "llama_print_timings:        eval time =     395.80 ms /    24 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     438.89 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18606.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    55 tokens (    0.78 ms per token,  1277.91 tokens per second)\n",
      "llama_print_timings:        eval time =     765.01 ms /    46 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     825.53 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    61 runs   (    0.05 ms per token, 18395.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.09 ms /    78 tokens (    0.66 ms per token,  1526.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1008.45 ms /    60 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1082.62 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    41 runs   (    0.05 ms per token, 18254.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.67 ms /    52 tokens (    0.82 ms per token,  1218.65 tokens per second)\n",
      "llama_print_timings:        eval time =     663.01 ms /    40 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     721.02 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    60 runs   (    0.05 ms per token, 18581.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.39 ms /    50 tokens (    0.85 ms per token,  1179.41 tokens per second)\n",
      "llama_print_timings:        eval time =     982.02 ms /    59 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =    1047.49 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18566.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    70 tokens (    0.71 ms per token,  1406.19 tokens per second)\n",
      "llama_print_timings:        eval time =     702.59 ms /    42 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =     768.39 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    40 runs   (    0.05 ms per token, 18535.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    73 tokens (    0.69 ms per token,  1459.71 tokens per second)\n",
      "llama_print_timings:        eval time =     652.97 ms /    39 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     718.43 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    66 runs   (    0.05 ms per token, 18586.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.29 ms /    75 tokens (    0.67 ms per token,  1491.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.72 ms /    65 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1166.94 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.49 ms /    44 tokens (    0.83 ms per token,  1205.68 tokens per second)\n",
      "llama_print_timings:        eval time =     577.39 ms /    35 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     627.36 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    54 runs   (    0.05 ms per token, 18665.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.92 ms /    35 tokens (    0.97 ms per token,  1031.87 tokens per second)\n",
      "llama_print_timings:        eval time =     876.19 ms /    53 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     930.67 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /    34 runs   (    0.05 ms per token, 18732.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.93 ms /    71 tokens (    0.70 ms per token,  1422.05 tokens per second)\n",
      "llama_print_timings:        eval time =     551.51 ms /    33 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     614.45 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    69 runs   (    0.05 ms per token, 18593.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.15 ms /    64 tokens (    0.69 ms per token,  1449.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.41 ms /    68 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =    1209.08 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    19 runs   (    0.06 ms per token, 17740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.28 ms /    26 tokens (    1.16 ms per token,   858.71 tokens per second)\n",
      "llama_print_timings:        eval time =     296.56 ms /    18 runs   (   16.48 ms per token,    60.70 tokens per second)\n",
      "llama_print_timings:       total time =     334.76 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18557.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.57 ms /    60 tokens (    0.73 ms per token,  1377.19 tokens per second)\n",
      "llama_print_timings:        eval time =     565.10 ms /    34 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     621.92 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.68 ms /    45 tokens (    0.82 ms per token,  1226.83 tokens per second)\n",
      "llama_print_timings:        eval time =     627.30 ms /    38 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     678.66 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18489.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.92 ms /    34 tokens (    1.00 ms per token,  1002.39 tokens per second)\n",
      "llama_print_timings:        eval time =     560.58 ms /    34 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     607.81 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    56 tokens (    0.77 ms per token,  1293.30 tokens per second)\n",
      "llama_print_timings:        eval time =     765.58 ms /    46 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =     826.07 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18600.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.38 ms /    43 tokens (    0.85 ms per token,  1182.03 tokens per second)\n",
      "llama_print_timings:        eval time =     744.46 ms /    45 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     798.15 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.11 ms /    83 tokens (    0.69 ms per token,  1453.28 tokens per second)\n",
      "llama_print_timings:        eval time =     942.69 ms /    56 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =    1021.37 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18707.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    60 tokens (    0.73 ms per token,  1373.37 tokens per second)\n",
      "llama_print_timings:        eval time =     716.09 ms /    43 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     775.64 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    56 runs   (    0.05 ms per token, 18842.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.84 ms /    46 tokens (    0.80 ms per token,  1248.47 tokens per second)\n",
      "llama_print_timings:        eval time =     913.66 ms /    55 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     971.31 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /    10 runs   (    0.05 ms per token, 18552.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.67 ms /    34 tokens (    0.99 ms per token,  1009.71 tokens per second)\n",
      "llama_print_timings:        eval time =     148.19 ms /     9 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     185.28 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    43 runs   (    0.05 ms per token, 18785.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    38 tokens (    0.90 ms per token,  1108.13 tokens per second)\n",
      "llama_print_timings:        eval time =     692.79 ms /    42 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     742.72 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18560.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    61 tokens (    0.72 ms per token,  1389.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1070.46 ms /    64 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =    1139.26 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    75 runs   (    0.05 ms per token, 18684.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    61 tokens (    0.72 ms per token,  1395.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1238.89 ms /    74 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =    1312.61 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18447.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    23 tokens (    1.19 ms per token,   843.39 tokens per second)\n",
      "llama_print_timings:        eval time =     378.98 ms /    23 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     415.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18619.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.79 ms /    33 tokens (    1.02 ms per token,   976.62 tokens per second)\n",
      "llama_print_timings:        eval time =     379.31 ms /    23 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     421.70 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    83 runs   (    0.05 ms per token, 18411.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.18 ms /    65 tokens (    0.76 ms per token,  1321.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.13 ms /    82 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1457.71 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    73 runs   (    0.05 ms per token, 18560.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.36 ms /    50 tokens (    0.85 ms per token,  1180.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.34 ms /    72 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =    1272.77 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    58 runs   (    0.05 ms per token, 18313.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.77 ms /    52 tokens (    0.82 ms per token,  1215.95 tokens per second)\n",
      "llama_print_timings:        eval time =     949.75 ms /    57 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =    1015.02 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.12 ms /    65 tokens (    0.76 ms per token,  1323.34 tokens per second)\n",
      "llama_print_timings:        eval time =     785.14 ms /    47 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     852.98 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    37 runs   (    0.05 ms per token, 18353.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.69 ms /    51 tokens (    0.84 ms per token,  1194.66 tokens per second)\n",
      "llama_print_timings:        eval time =     595.67 ms /    36 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     652.03 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18498.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    64 tokens (    0.69 ms per token,  1450.03 tokens per second)\n",
      "llama_print_timings:        eval time =     852.20 ms /    51 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     916.42 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18528.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.61 ms /    51 tokens (    0.84 ms per token,  1196.99 tokens per second)\n",
      "llama_print_timings:        eval time =     562.30 ms /    34 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     617.75 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    20 runs   (    0.05 ms per token, 18639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.09 ms /    31 tokens (    1.00 ms per token,   997.11 tokens per second)\n",
      "llama_print_timings:        eval time =     313.09 ms /    19 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     351.49 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /    38 runs   (    0.05 ms per token, 18269.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.30 ms /    66 tokens (    0.75 ms per token,  1338.61 tokens per second)\n",
      "llama_print_timings:        eval time =     617.41 ms /    37 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     680.75 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /    50 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.52 ms /    51 tokens (    0.83 ms per token,  1199.55 tokens per second)\n",
      "llama_print_timings:        eval time =     814.41 ms /    49 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     876.20 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18546.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    35 tokens (    0.97 ms per token,  1030.38 tokens per second)\n",
      "llama_print_timings:        eval time =     593.62 ms /    36 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     641.87 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.01 ms /    47 tokens (    0.79 ms per token,  1269.86 tokens per second)\n",
      "llama_print_timings:        eval time =     561.10 ms /    34 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     610.82 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18640.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.69 ms /    44 tokens (    0.83 ms per token,  1199.20 tokens per second)\n",
      "llama_print_timings:        eval time =     778.40 ms /    47 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     833.50 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    47 tokens (    0.79 ms per token,  1271.85 tokens per second)\n",
      "llama_print_timings:        eval time =     577.71 ms /    35 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     627.85 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18479.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.62 ms /    33 tokens (    1.02 ms per token,   981.44 tokens per second)\n",
      "llama_print_timings:        eval time =     412.17 ms /    25 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     455.52 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    13 runs   (    0.05 ms per token, 18544.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.42 ms /    26 tokens (    1.17 ms per token,   854.76 tokens per second)\n",
      "llama_print_timings:        eval time =     197.67 ms /    12 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     233.02 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18492.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.55 ms /    40 tokens (    0.86 ms per token,  1157.68 tokens per second)\n",
      "llama_print_timings:        eval time =     844.46 ms /    51 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     899.24 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    32 runs   (    0.05 ms per token, 18212.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.04 ms /    35 tokens (    0.97 ms per token,  1028.14 tokens per second)\n",
      "llama_print_timings:        eval time =     511.12 ms /    31 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     557.12 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    54 runs   (    0.05 ms per token, 18723.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.32 ms /    84 tokens (    0.68 ms per token,  1465.35 tokens per second)\n",
      "llama_print_timings:        eval time =     892.31 ms /    53 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     969.78 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    30 tokens (    1.04 ms per token,   964.01 tokens per second)\n",
      "llama_print_timings:        eval time =     346.11 ms /    21 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     385.36 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18446.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    54 tokens (    0.80 ms per token,  1253.71 tokens per second)\n",
      "llama_print_timings:        eval time =     529.56 ms /    32 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     584.78 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /    26 runs   (    0.05 ms per token, 18651.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    40 tokens (    0.86 ms per token,  1166.62 tokens per second)\n",
      "llama_print_timings:        eval time =     412.32 ms /    25 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     456.44 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    59 runs   (    0.05 ms per token, 18617.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.49 ms /    68 tokens (    0.73 ms per token,  1374.01 tokens per second)\n",
      "llama_print_timings:        eval time =     971.65 ms /    58 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =    1044.12 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    46 runs   (    0.05 ms per token, 18319.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.92 ms /    53 tokens (    0.81 ms per token,  1234.74 tokens per second)\n",
      "llama_print_timings:        eval time =     747.78 ms /    45 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     808.12 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18650.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    59 tokens (    0.74 ms per token,  1352.78 tokens per second)\n",
      "llama_print_timings:        eval time =     766.60 ms /    46 runs   (   16.67 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     827.87 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18509.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    36 tokens (    0.94 ms per token,  1059.07 tokens per second)\n",
      "llama_print_timings:        eval time =     626.85 ms /    38 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     675.66 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /    27 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    37 tokens (    0.93 ms per token,  1078.94 tokens per second)\n",
      "llama_print_timings:        eval time =     428.74 ms /    26 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     472.89 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18457.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    52 tokens (    0.82 ms per token,  1215.98 tokens per second)\n",
      "llama_print_timings:        eval time =     730.73 ms /    44 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     789.58 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /    18 runs   (    0.05 ms per token, 18274.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.39 ms /    43 tokens (    0.85 ms per token,  1181.61 tokens per second)\n",
      "llama_print_timings:        eval time =     280.39 ms /    17 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     323.16 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18623.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.77 ms /    33 tokens (    1.02 ms per token,   977.20 tokens per second)\n",
      "llama_print_timings:        eval time =     577.40 ms /    35 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     624.67 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    80 runs   (    0.05 ms per token, 18462.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    71 tokens (    0.70 ms per token,  1418.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.81 ms /    79 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1407.91 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /    58 runs   (    0.05 ms per token, 18625.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.25 ms /    85 tokens (    0.67 ms per token,  1484.77 tokens per second)\n",
      "llama_print_timings:        eval time =     959.75 ms /    57 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =    1039.05 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18545.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.29 ms /    49 tokens (    0.86 ms per token,  1158.58 tokens per second)\n",
      "llama_print_timings:        eval time =     396.21 ms /    24 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     447.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18615.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    55 tokens (    0.79 ms per token,  1273.06 tokens per second)\n",
      "llama_print_timings:        eval time =     748.67 ms /    45 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     808.99 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18607.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.23 ms /    39 tokens (    0.88 ms per token,  1139.25 tokens per second)\n",
      "llama_print_timings:        eval time =     428.92 ms /    26 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     473.57 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18579.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.13 ms /    31 tokens (    1.00 ms per token,   995.73 tokens per second)\n",
      "llama_print_timings:        eval time =     445.21 ms /    27 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     486.18 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18566.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.14 ms /    47 tokens (    0.79 ms per token,  1265.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1065.52 ms /    64 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =    1127.27 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18453.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    60 tokens (    0.73 ms per token,  1374.89 tokens per second)\n",
      "llama_print_timings:        eval time =     767.18 ms /    46 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     828.42 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.25 ms /    81 tokens (    0.69 ms per token,  1439.95 tokens per second)\n",
      "llama_print_timings:        eval time =     689.79 ms /    41 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     762.20 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18538.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.64 ms /    68 tokens (    0.73 ms per token,  1369.75 tokens per second)\n",
      "llama_print_timings:        eval time =     853.80 ms /    51 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     922.84 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18569.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.21 ms /    37 tokens (    0.92 ms per token,  1081.62 tokens per second)\n",
      "llama_print_timings:        eval time =     759.16 ms /    46 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     810.62 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18394.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    51 tokens (    0.84 ms per token,  1193.76 tokens per second)\n",
      "llama_print_timings:        eval time =     528.64 ms /    32 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     583.43 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18355.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.93 ms /    35 tokens (    0.97 ms per token,  1031.44 tokens per second)\n",
      "llama_print_timings:        eval time =     362.75 ms /    22 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     404.66 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18453.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.07 ms /    20 tokens (    1.35 ms per token,   738.83 tokens per second)\n",
      "llama_print_timings:        eval time =     329.63 ms /    20 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     364.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.89 ms /    53 tokens (    0.81 ms per token,  1235.83 tokens per second)\n",
      "llama_print_timings:        eval time =     781.53 ms /    47 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     842.99 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18485.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.73 ms /    53 tokens (    0.81 ms per token,  1240.26 tokens per second)\n",
      "llama_print_timings:        eval time =     663.84 ms /    40 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     721.99 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    73 tokens (    0.69 ms per token,  1455.17 tokens per second)\n",
      "llama_print_timings:        eval time =     939.57 ms /    56 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =    1011.81 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    56 runs   (    0.05 ms per token, 18439.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.79 ms /    53 tokens (    0.81 ms per token,  1238.61 tokens per second)\n",
      "llama_print_timings:        eval time =     916.15 ms /    55 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     980.99 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18707.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    64 tokens (    0.69 ms per token,  1451.35 tokens per second)\n",
      "llama_print_timings:        eval time =     717.87 ms /    43 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     778.78 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    55 runs   (    0.05 ms per token, 18631.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    67 tokens (    0.74 ms per token,  1357.02 tokens per second)\n",
      "llama_print_timings:        eval time =     904.19 ms /    54 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     974.88 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    41 runs   (    0.05 ms per token, 18730.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.74 ms /    45 tokens (    0.82 ms per token,  1224.76 tokens per second)\n",
      "llama_print_timings:        eval time =     661.27 ms /    40 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     713.03 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18393.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.78 ms /    53 tokens (    0.81 ms per token,  1238.78 tokens per second)\n",
      "llama_print_timings:        eval time =     798.62 ms /    48 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     860.18 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /    30 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.43 ms /    43 tokens (    0.85 ms per token,  1180.28 tokens per second)\n",
      "llama_print_timings:        eval time =     478.39 ms /    29 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     525.55 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    40 runs   (    0.05 ms per token, 18492.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.54 ms /    50 tokens (    0.85 ms per token,  1175.50 tokens per second)\n",
      "llama_print_timings:        eval time =     646.01 ms /    39 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     703.40 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.68 ms /    69 tokens (    0.72 ms per token,  1389.03 tokens per second)\n",
      "llama_print_timings:        eval time =     719.38 ms /    43 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =     785.62 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /    20 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.80 ms /    20 tokens (    1.34 ms per token,   746.16 tokens per second)\n",
      "llama_print_timings:        eval time =     313.13 ms /    19 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     346.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    68 runs   (    0.05 ms per token, 18528.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.21 ms /    80 tokens (    0.64 ms per token,  1562.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.65 ms /    67 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1205.50 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    34 runs   (    0.05 ms per token, 18388.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.74 ms /    46 tokens (    0.80 ms per token,  1251.91 tokens per second)\n",
      "llama_print_timings:        eval time =     544.90 ms /    33 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     594.91 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18763.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.51 ms /    49 tokens (    0.87 ms per token,  1152.59 tokens per second)\n",
      "llama_print_timings:        eval time =     712.96 ms /    43 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     771.88 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18550.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    76 tokens (    0.67 ms per token,  1500.55 tokens per second)\n",
      "llama_print_timings:        eval time =     873.54 ms /    52 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     944.65 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18639.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.62 ms /    44 tokens (    0.83 ms per token,  1201.53 tokens per second)\n",
      "llama_print_timings:        eval time =     879.69 ms /    53 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     937.12 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    72 runs   (    0.05 ms per token, 18759.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.16 ms /    81 tokens (    0.69 ms per token,  1442.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1195.28 ms /    71 runs   (   16.83 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =    1278.78 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.05 ms /    48 tokens (    0.77 ms per token,  1295.41 tokens per second)\n",
      "llama_print_timings:        eval time =     214.65 ms /    13 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     257.31 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /    64 runs   (    0.05 ms per token, 18427.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    59 tokens (    0.74 ms per token,  1350.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.01 ms /    63 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1122.04 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18731.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.36 ms /    43 tokens (    0.85 ms per token,  1182.55 tokens per second)\n",
      "llama_print_timings:        eval time =     711.02 ms /    43 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     763.70 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /    18 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.79 ms /    33 tokens (    1.02 ms per token,   976.68 tokens per second)\n",
      "llama_print_timings:        eval time =     280.13 ms /    17 runs   (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:       total time =     320.66 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18563.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.28 ms /    64 tokens (    0.69 ms per token,  1445.45 tokens per second)\n",
      "llama_print_timings:        eval time =     869.43 ms /    52 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     933.99 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /    12 runs   (    0.06 ms per token, 18126.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    29 tokens (    1.07 ms per token,   934.91 tokens per second)\n",
      "llama_print_timings:        eval time =     181.15 ms /    11 runs   (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_print_timings:       total time =     215.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18527.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    52 tokens (    0.83 ms per token,  1211.10 tokens per second)\n",
      "llama_print_timings:        eval time =     596.32 ms /    36 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     653.34 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    59 runs   (    0.05 ms per token, 18736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    71 tokens (    0.71 ms per token,  1417.79 tokens per second)\n",
      "llama_print_timings:        eval time =     972.83 ms /    58 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =    1045.13 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    56 runs   (    0.05 ms per token, 18306.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.19 ms /    72 tokens (    0.70 ms per token,  1434.55 tokens per second)\n",
      "llama_print_timings:        eval time =     922.92 ms /    55 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     995.22 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18295.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.84 ms /    45 tokens (    0.82 ms per token,  1221.56 tokens per second)\n",
      "llama_print_timings:        eval time =     561.09 ms /    34 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     610.76 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    39 runs   (    0.05 ms per token, 18344.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.65 ms /    45 tokens (    0.81 ms per token,  1227.70 tokens per second)\n",
      "llama_print_timings:        eval time =     627.80 ms /    38 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     678.16 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    57 tokens (    0.76 ms per token,  1311.28 tokens per second)\n",
      "llama_print_timings:        eval time =     716.13 ms /    43 runs   (   16.65 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     775.31 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18464.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.38 ms /    26 tokens (    1.17 ms per token,   855.77 tokens per second)\n",
      "llama_print_timings:        eval time =     824.78 ms /    50 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     873.30 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    43 runs   (    0.05 ms per token, 18695.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    51 tokens (    0.84 ms per token,  1192.73 tokens per second)\n",
      "llama_print_timings:        eval time =     697.08 ms /    42 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     755.19 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /    27 runs   (    0.05 ms per token, 18698.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.32 ms /    41 tokens (    0.89 ms per token,  1128.85 tokens per second)\n",
      "llama_print_timings:        eval time =     429.38 ms /    26 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     475.48 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.53 ms /    25 tokens (    1.22 ms per token,   818.97 tokens per second)\n",
      "llama_print_timings:        eval time =     511.38 ms /    31 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     553.01 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    92 runs   (    0.05 ms per token, 18407.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.45 ms /    91 tokens (    0.64 ms per token,  1556.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1534.92 ms /    91 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1629.07 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    58 runs   (    0.05 ms per token, 18494.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.20 ms /    82 tokens (    0.69 ms per token,  1458.97 tokens per second)\n",
      "llama_print_timings:        eval time =     959.95 ms /    57 runs   (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:       total time =    1037.38 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    58 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    27 tokens (    1.13 ms per token,   886.44 tokens per second)\n",
      "llama_print_timings:        eval time =     941.71 ms /    57 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     993.67 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    64 runs   (    0.05 ms per token, 18550.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.24 ms /    73 tokens (    0.69 ms per token,  1453.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1058.01 ms /    63 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =    1132.04 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.54 ms /    43 tokens (    0.85 ms per token,  1176.76 tokens per second)\n",
      "llama_print_timings:        eval time =     627.60 ms /    38 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     678.61 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    19 runs   (    0.05 ms per token, 18627.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.56 ms /    42 tokens (    0.87 ms per token,  1148.77 tokens per second)\n",
      "llama_print_timings:        eval time =     297.23 ms /    18 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     340.37 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    70 runs   (    0.05 ms per token, 18661.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.14 ms /    81 tokens (    0.69 ms per token,  1442.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.43 ms /    69 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =    1245.37 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.37 ms /    32 tokens (    0.98 ms per token,  1020.08 tokens per second)\n",
      "llama_print_timings:        eval time =     577.62 ms /    35 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     622.11 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    44 tokens (    0.84 ms per token,  1196.92 tokens per second)\n",
      "llama_print_timings:        eval time =     578.00 ms /    35 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     627.54 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    51 runs   (    0.05 ms per token, 18586.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.48 ms /    43 tokens (    0.85 ms per token,  1178.73 tokens per second)\n",
      "llama_print_timings:        eval time =     829.09 ms /    50 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     883.61 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    53 runs   (    0.05 ms per token, 18454.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    69 tokens (    0.72 ms per token,  1379.34 tokens per second)\n",
      "llama_print_timings:        eval time =     871.25 ms /    52 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     941.08 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    34 runs   (    0.05 ms per token, 18408.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    62 tokens (    0.71 ms per token,  1409.22 tokens per second)\n",
      "llama_print_timings:        eval time =     549.05 ms /    33 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     604.95 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    82 runs   (    0.05 ms per token, 18505.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.79 ms /    88 tokens (    0.66 ms per token,  1522.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1365.63 ms /    81 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =    1454.32 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18385.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.54 ms /    17 tokens (    1.56 ms per token,   640.52 tokens per second)\n",
      "llama_print_timings:        eval time =     362.61 ms /    22 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     397.36 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.16 ms /    48 tokens (    0.77 ms per token,  1291.64 tokens per second)\n",
      "llama_print_timings:        eval time =     898.20 ms /    54 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     955.75 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /    21 runs   (    0.05 ms per token, 18600.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.98 ms /    30 tokens (    1.03 ms per token,   968.27 tokens per second)\n",
      "llama_print_timings:        eval time =     329.73 ms /    20 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     367.84 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.21 ms /    55 tokens (    0.79 ms per token,  1272.88 tokens per second)\n",
      "llama_print_timings:        eval time =     631.37 ms /    38 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     688.51 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18488.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.92 ms /    54 tokens (    0.79 ms per token,  1258.18 tokens per second)\n",
      "llama_print_timings:        eval time =     731.92 ms /    44 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     790.71 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.55 ms /    43 tokens (    0.85 ms per token,  1176.47 tokens per second)\n",
      "llama_print_timings:        eval time =     728.78 ms /    44 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     781.27 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    90 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.00 ms /    71 tokens (    0.70 ms per token,  1419.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1496.92 ms /    89 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =    1581.34 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    19 runs   (    0.05 ms per token, 18536.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    22 tokens (    1.23 ms per token,   812.53 tokens per second)\n",
      "llama_print_timings:        eval time =     296.73 ms /    18 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     330.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18458.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.37 ms /    81 tokens (    0.70 ms per token,  1436.88 tokens per second)\n",
      "llama_print_timings:        eval time =     555.29 ms /    33 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =     623.72 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    54 runs   (    0.05 ms per token, 18711.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.90 ms /    78 tokens (    0.65 ms per token,  1532.48 tokens per second)\n",
      "llama_print_timings:        eval time =     891.47 ms /    53 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     962.31 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.79 ms /    35 tokens (    0.97 ms per token,  1035.96 tokens per second)\n",
      "llama_print_timings:        eval time =     577.60 ms /    35 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     624.86 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    47 runs   (    0.05 ms per token, 18822.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    68 tokens (    0.73 ms per token,  1364.28 tokens per second)\n",
      "llama_print_timings:        eval time =     770.00 ms /    46 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     836.77 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /    26 runs   (    0.05 ms per token, 18207.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.54 ms /    26 tokens (    1.17 ms per token,   851.34 tokens per second)\n",
      "llama_print_timings:        eval time =     412.22 ms /    25 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     451.57 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /    31 runs   (    0.05 ms per token, 18663.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.74 ms /    52 tokens (    0.82 ms per token,  1216.52 tokens per second)\n",
      "llama_print_timings:        eval time =     495.66 ms /    30 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     549.18 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /    36 runs   (    0.05 ms per token, 18209.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    31 tokens (    1.01 ms per token,   991.78 tokens per second)\n",
      "llama_print_timings:        eval time =     577.20 ms /    35 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     621.41 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    55 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.24 ms /    41 tokens (    0.88 ms per token,  1131.19 tokens per second)\n",
      "llama_print_timings:        eval time =     895.94 ms /    54 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     952.61 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18352.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.11 ms /    63 tokens (    0.70 ms per token,  1428.12 tokens per second)\n",
      "llama_print_timings:        eval time =     701.19 ms /    42 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     761.73 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18464.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    63 tokens (    0.70 ms per token,  1427.79 tokens per second)\n",
      "llama_print_timings:        eval time =     835.88 ms /    50 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =     898.82 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18548.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.39 ms /    85 tokens (    0.68 ms per token,  1481.09 tokens per second)\n",
      "llama_print_timings:        eval time =     758.02 ms /    45 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     831.80 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18630.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.42 ms /    40 tokens (    0.86 ms per token,  1162.25 tokens per second)\n",
      "llama_print_timings:        eval time =     544.85 ms /    33 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     591.65 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.64 ms /    43 tokens (    0.85 ms per token,  1173.71 tokens per second)\n",
      "llama_print_timings:        eval time =     879.83 ms /    53 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     935.79 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    40 runs   (    0.05 ms per token, 18700.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.59 ms /    42 tokens (    0.87 ms per token,  1147.89 tokens per second)\n",
      "llama_print_timings:        eval time =     643.97 ms /    39 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     695.31 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.71 ms /    43 tokens (    0.85 ms per token,  1171.47 tokens per second)\n",
      "llama_print_timings:        eval time =     778.78 ms /    47 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     832.99 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.35 ms /    49 tokens (    0.86 ms per token,  1157.08 tokens per second)\n",
      "llama_print_timings:        eval time =     713.62 ms /    43 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     772.82 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18714.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    57 tokens (    0.76 ms per token,  1310.44 tokens per second)\n",
      "llama_print_timings:        eval time =     480.26 ms /    29 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     534.04 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18557.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    63 tokens (    0.70 ms per token,  1427.86 tokens per second)\n",
      "llama_print_timings:        eval time =     869.72 ms /    52 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =     933.14 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    52 runs   (    0.05 ms per token, 18738.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    51 tokens (    0.84 ms per token,  1194.27 tokens per second)\n",
      "llama_print_timings:        eval time =     848.88 ms /    51 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     910.60 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18538.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.87 ms /    53 tokens (    0.81 ms per token,  1236.24 tokens per second)\n",
      "llama_print_timings:        eval time =     832.30 ms /    50 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     893.81 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18639.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.64 ms /    75 tokens (    0.68 ms per token,  1481.13 tokens per second)\n",
      "llama_print_timings:        eval time =     890.37 ms /    53 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     960.55 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    14 runs   (    0.06 ms per token, 18158.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.59 ms /    27 tokens (    1.13 ms per token,   882.64 tokens per second)\n",
      "llama_print_timings:        eval time =     214.25 ms /    13 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     250.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    92 runs   (    0.05 ms per token, 18638.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    75 tokens (    0.67 ms per token,  1484.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1531.44 ms /    91 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1618.82 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18437.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.48 tokens per second)\n",
      "llama_print_timings:        eval time =     676.36 ms /    41 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     722.87 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    62 runs   (    0.05 ms per token, 18652.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    69 tokens (    0.72 ms per token,  1386.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1023.24 ms /    61 runs   (   16.77 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =    1097.38 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /    10 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.20 ms /    23 tokens (    1.18 ms per token,   845.53 tokens per second)\n",
      "llama_print_timings:        eval time =     148.31 ms /     9 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     179.18 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18618.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.57 ms /    85 tokens (    0.68 ms per token,  1476.44 tokens per second)\n",
      "llama_print_timings:        eval time =     622.79 ms /    37 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     694.88 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18548.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.91 ms /    46 tokens (    0.80 ms per token,  1246.14 tokens per second)\n",
      "llama_print_timings:        eval time =     545.02 ms /    33 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     594.97 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    30 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    58 tokens (    0.75 ms per token,  1330.67 tokens per second)\n",
      "llama_print_timings:        eval time =     480.37 ms /    29 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     535.08 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.44 ms /    57 tokens (    0.76 ms per token,  1312.12 tokens per second)\n",
      "llama_print_timings:        eval time =     766.28 ms /    46 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     827.57 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /    38 runs   (    0.05 ms per token, 18710.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.88 ms /    46 tokens (    0.80 ms per token,  1247.46 tokens per second)\n",
      "llama_print_timings:        eval time =     611.05 ms /    37 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     661.58 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18557.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.39 ms /    41 tokens (    0.89 ms per token,  1126.62 tokens per second)\n",
      "llama_print_timings:        eval time =     561.21 ms /    34 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     610.41 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18579.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    73 tokens (    0.69 ms per token,  1450.86 tokens per second)\n",
      "llama_print_timings:        eval time =     838.95 ms /    50 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     908.23 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.63 ms /    44 tokens (    0.83 ms per token,  1201.20 tokens per second)\n",
      "llama_print_timings:        eval time =     379.64 ms /    23 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     424.64 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18628.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    32 tokens (    0.98 ms per token,  1023.15 tokens per second)\n",
      "llama_print_timings:        eval time =     709.62 ms /    43 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     757.18 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    72 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    64 tokens (    0.69 ms per token,  1447.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.88 ms /    71 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1261.59 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /    30 runs   (    0.05 ms per token, 18326.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.09 ms /    30 tokens (    1.04 ms per token,   965.03 tokens per second)\n",
      "llama_print_timings:        eval time =     478.17 ms /    29 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     520.57 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    13 runs   (    0.05 ms per token, 18544.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.55 ms /    25 tokens (    1.22 ms per token,   818.30 tokens per second)\n",
      "llama_print_timings:        eval time =     197.75 ms /    12 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     232.80 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    74 runs   (    0.05 ms per token, 18796.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.35 ms /    56 tokens (    0.77 ms per token,  1291.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.87 ms /    73 runs   (   16.72 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =    1292.70 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18478.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.82 ms /    53 tokens (    0.81 ms per token,  1237.80 tokens per second)\n",
      "llama_print_timings:        eval time =     697.70 ms /    42 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     757.18 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /    61 runs   (    0.05 ms per token, 18694.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.55 ms /    86 tokens (    0.67 ms per token,  1494.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1010.80 ms /    60 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =    1091.84 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    39 tokens (    0.88 ms per token,  1134.51 tokens per second)\n",
      "llama_print_timings:        eval time =     544.60 ms /    33 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     592.00 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /    17 runs   (    0.05 ms per token, 18743.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.15 ms /    47 tokens (    0.79 ms per token,  1265.21 tokens per second)\n",
      "llama_print_timings:        eval time =     264.14 ms /    16 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     306.92 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18534.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.48 ms /    49 tokens (    0.87 ms per token,  1153.51 tokens per second)\n",
      "llama_print_timings:        eval time =     713.19 ms /    43 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     772.21 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.58 ms /    50 tokens (    0.85 ms per token,  1174.21 tokens per second)\n",
      "llama_print_timings:        eval time =     595.78 ms /    36 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     651.81 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    52 tokens (    0.83 ms per token,  1210.94 tokens per second)\n",
      "llama_print_timings:        eval time =     630.14 ms /    38 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =     687.25 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /    18 runs   (    0.05 ms per token, 18672.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.52 tokens per second)\n",
      "llama_print_timings:        eval time =     280.38 ms /    17 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     317.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    55 tokens (    0.79 ms per token,  1273.62 tokens per second)\n",
      "llama_print_timings:        eval time =     530.07 ms /    32 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     585.64 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /    18 runs   (    0.05 ms per token, 18769.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.78 ms /    33 tokens (    1.02 ms per token,   976.94 tokens per second)\n",
      "llama_print_timings:        eval time =     280.22 ms /    17 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     320.71 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    50 tokens (    0.86 ms per token,  1165.37 tokens per second)\n",
      "llama_print_timings:        eval time =     982.82 ms /    59 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =    1048.11 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18589.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.03 ms /    55 tokens (    0.78 ms per token,  1278.18 tokens per second)\n",
      "llama_print_timings:        eval time =     950.71 ms /    57 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =    1016.27 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18417.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.50 ms /    50 tokens (    0.85 ms per token,  1176.36 tokens per second)\n",
      "llama_print_timings:        eval time =     595.67 ms /    36 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     651.89 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /    62 runs   (    0.05 ms per token, 18529.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.56 ms /    49 tokens (    0.87 ms per token,  1151.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1016.24 ms /    61 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =    1082.56 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18609.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    52 tokens (    0.82 ms per token,  1216.03 tokens per second)\n",
      "llama_print_timings:        eval time =     798.28 ms /    48 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     859.61 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18258.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.09 ms /    47 tokens (    0.79 ms per token,  1267.36 tokens per second)\n",
      "llama_print_timings:        eval time =     198.14 ms /    12 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     239.96 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    69 runs   (    0.05 ms per token, 18553.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    56 tokens (    0.77 ms per token,  1293.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.44 ms /    68 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =    1205.84 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18559.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    52 tokens (    0.82 ms per token,  1215.98 tokens per second)\n",
      "llama_print_timings:        eval time =     396.53 ms /    24 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     449.09 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    13 runs   (    0.05 ms per token, 18705.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    23 tokens (    1.18 ms per token,   843.91 tokens per second)\n",
      "llama_print_timings:        eval time =     197.84 ms /    12 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     230.07 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    77 runs   (    0.05 ms per token, 18554.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.38 ms /    82 tokens (    0.69 ms per token,  1454.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1280.84 ms /    76 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1367.95 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18462.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    57 tokens (    0.76 ms per token,  1317.34 tokens per second)\n",
      "llama_print_timings:        eval time =     699.15 ms /    42 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     759.19 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /    29 runs   (    0.05 ms per token, 18204.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.80 ms /    44 tokens (    0.84 ms per token,  1195.49 tokens per second)\n",
      "llama_print_timings:        eval time =     462.05 ms /    28 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     509.18 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18493.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.17 ms /    37 tokens (    0.92 ms per token,  1082.69 tokens per second)\n",
      "llama_print_timings:        eval time =     660.18 ms /    40 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     709.21 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /    46 runs   (    0.05 ms per token, 18752.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.21 ms /    37 tokens (    0.92 ms per token,  1081.46 tokens per second)\n",
      "llama_print_timings:        eval time =     742.75 ms /    45 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     794.28 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18586.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    55 tokens (    0.79 ms per token,  1268.45 tokens per second)\n",
      "llama_print_timings:        eval time =     917.06 ms /    55 runs   (   16.67 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     981.90 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /    27 runs   (    0.05 ms per token, 18417.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.30 ms /    37 tokens (    0.93 ms per token,  1078.81 tokens per second)\n",
      "llama_print_timings:        eval time =     428.97 ms /    26 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     473.02 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18595.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.61 ms /    42 tokens (    0.87 ms per token,  1147.20 tokens per second)\n",
      "llama_print_timings:        eval time =     794.93 ms /    48 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     849.45 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    60 tokens (    0.73 ms per token,  1370.86 tokens per second)\n",
      "llama_print_timings:        eval time =     396.89 ms /    24 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     449.23 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /    46 runs   (    0.05 ms per token, 18744.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.03 ms /    30 tokens (    1.03 ms per token,   966.71 tokens per second)\n",
      "llama_print_timings:        eval time =     742.57 ms /    45 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     790.28 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18478.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    53 tokens (    0.81 ms per token,  1234.42 tokens per second)\n",
      "llama_print_timings:        eval time =     697.79 ms /    42 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     756.37 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18640.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.59 ms /    51 tokens (    0.83 ms per token,  1197.60 tokens per second)\n",
      "llama_print_timings:        eval time =     545.72 ms /    33 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     601.34 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.37 ms /    41 tokens (    0.89 ms per token,  1127.46 tokens per second)\n",
      "llama_print_timings:        eval time =     561.16 ms /    34 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     610.85 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18341.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    29 tokens (    1.06 ms per token,   940.67 tokens per second)\n",
      "llama_print_timings:        eval time =     395.88 ms /    24 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     436.18 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18524.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.88 ms /    52 tokens (    0.82 ms per token,  1212.69 tokens per second)\n",
      "llama_print_timings:        eval time =     966.65 ms /    58 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =    1032.00 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18532.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.80 ms /    45 tokens (    0.82 ms per token,  1222.93 tokens per second)\n",
      "llama_print_timings:        eval time =     396.16 ms /    24 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     441.75 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    61 tokens (    0.72 ms per token,  1387.75 tokens per second)\n",
      "llama_print_timings:        eval time =     650.36 ms /    39 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     709.58 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18464.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.82 ms /    69 tokens (    0.72 ms per token,  1384.93 tokens per second)\n",
      "llama_print_timings:        eval time =     837.43 ms /    50 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     906.85 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18452.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.30 ms /    65 tokens (    0.76 ms per token,  1318.40 tokens per second)\n",
      "llama_print_timings:        eval time =     499.49 ms /    30 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     559.91 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    63 tokens (    0.70 ms per token,  1429.35 tokens per second)\n",
      "llama_print_timings:        eval time =     431.56 ms /    26 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     485.39 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /    23 runs   (    0.05 ms per token, 18608.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.50 ms /    42 tokens (    0.87 ms per token,  1150.56 tokens per second)\n",
      "llama_print_timings:        eval time =     362.96 ms /    22 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     407.64 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    56 tokens (    0.77 ms per token,  1292.38 tokens per second)\n",
      "llama_print_timings:        eval time =     346.71 ms /    21 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     397.58 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18716.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    37 tokens (    0.92 ms per token,  1083.01 tokens per second)\n",
      "llama_print_timings:        eval time =     445.45 ms /    27 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     490.31 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /    30 runs   (    0.05 ms per token, 18610.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.30 ms /    37 tokens (    0.93 ms per token,  1078.72 tokens per second)\n",
      "llama_print_timings:        eval time =     478.42 ms /    29 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     524.10 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     7 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    23 tokens (    1.19 ms per token,   840.37 tokens per second)\n",
      "llama_print_timings:        eval time =      98.80 ms /     6 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     128.16 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18315.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    30 tokens (    1.04 ms per token,   965.44 tokens per second)\n",
      "llama_print_timings:        eval time =     395.95 ms /    24 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     436.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    24 runs   (    0.05 ms per token, 18677.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    29 tokens (    1.07 ms per token,   934.88 tokens per second)\n",
      "llama_print_timings:        eval time =     379.19 ms /    23 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     419.17 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    40 runs   (    0.05 ms per token, 18535.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.29 ms /    31 tokens (    1.01 ms per token,   990.67 tokens per second)\n",
      "llama_print_timings:        eval time =     643.38 ms /    39 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     689.13 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    50 runs   (    0.05 ms per token, 18573.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.77 ms /    46 tokens (    0.80 ms per token,  1250.85 tokens per second)\n",
      "llama_print_timings:        eval time =     813.36 ms /    49 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     869.13 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    63 runs   (    0.05 ms per token, 18677.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.49 ms /    74 tokens (    0.68 ms per token,  1465.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.51 ms /    62 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =    1115.69 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /    18 runs   (    0.05 ms per token, 18442.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.04 ms /    30 tokens (    1.03 ms per token,   966.46 tokens per second)\n",
      "llama_print_timings:        eval time =     280.31 ms /    17 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     317.64 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.46 ms /    32 tokens (    0.98 ms per token,  1017.16 tokens per second)\n",
      "llama_print_timings:        eval time =     527.85 ms /    32 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     571.19 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    54 runs   (    0.05 ms per token, 18730.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.90 ms /    67 tokens (    0.74 ms per token,  1342.63 tokens per second)\n",
      "llama_print_timings:        eval time =     887.47 ms /    53 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     958.33 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18646.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.33 ms /    63 tokens (    0.70 ms per token,  1421.13 tokens per second)\n",
      "llama_print_timings:        eval time =     751.57 ms /    45 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     814.04 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /    14 runs   (    0.05 ms per token, 18817.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.25 ms /    39 tokens (    0.88 ms per token,  1138.69 tokens per second)\n",
      "llama_print_timings:        eval time =     214.47 ms /    13 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     254.05 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    52 tokens (    0.82 ms per token,  1217.20 tokens per second)\n",
      "llama_print_timings:        eval time =     579.51 ms /    35 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     635.07 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18508.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.47 ms /    40 tokens (    0.86 ms per token,  1160.60 tokens per second)\n",
      "llama_print_timings:        eval time =     544.76 ms /    33 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     591.37 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18460.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    53 tokens (    0.81 ms per token,  1233.19 tokens per second)\n",
      "llama_print_timings:        eval time =     764.89 ms /    46 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     825.37 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     8 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    31 tokens (    1.01 ms per token,   994.04 tokens per second)\n",
      "llama_print_timings:        eval time =     115.40 ms /     7 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     149.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18320.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.33 ms /    82 tokens (    0.69 ms per token,  1455.63 tokens per second)\n",
      "llama_print_timings:        eval time =     387.06 ms /    23 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     452.11 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    71 runs   (    0.05 ms per token, 18586.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    57 tokens (    0.76 ms per token,  1310.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.70 ms /    70 runs   (   16.72 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =    1241.48 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    37 tokens (    0.92 ms per token,  1082.09 tokens per second)\n",
      "llama_print_timings:        eval time =     709.83 ms /    43 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     760.57 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18532.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    70 tokens (    0.71 ms per token,  1402.33 tokens per second)\n",
      "llama_print_timings:        eval time =     804.23 ms /    48 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     872.36 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    33 runs   (    0.05 ms per token, 18718.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.92 ms /    45 tokens (    0.82 ms per token,  1218.72 tokens per second)\n",
      "llama_print_timings:        eval time =     528.24 ms /    32 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     577.48 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    69 tokens (    0.72 ms per token,  1383.51 tokens per second)\n",
      "llama_print_timings:        eval time =     501.03 ms /    30 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     562.54 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    53 runs   (    0.05 ms per token, 18454.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    28 tokens (    1.10 ms per token,   911.64 tokens per second)\n",
      "llama_print_timings:        eval time =     858.19 ms /    52 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     908.84 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    34 runs   (    0.05 ms per token, 18408.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.41 ms /    46 tokens (    0.81 ms per token,  1229.49 tokens per second)\n",
      "llama_print_timings:        eval time =     544.81 ms /    33 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     595.12 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    16 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    23 tokens (    1.18 ms per token,   844.16 tokens per second)\n",
      "llama_print_timings:        eval time =     247.28 ms /    15 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     279.97 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18460.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.05 ms /    44 tokens (    0.84 ms per token,  1187.46 tokens per second)\n",
      "llama_print_timings:        eval time =     761.94 ms /    46 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     816.31 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /    62 runs   (    0.05 ms per token, 18629.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    74 tokens (    0.68 ms per token,  1467.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1024.77 ms /    61 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =    1099.15 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /    26 runs   (    0.05 ms per token, 18258.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.24 ms /    31 tokens (    1.01 ms per token,   992.32 tokens per second)\n",
      "llama_print_timings:        eval time =     412.41 ms /    25 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     453.01 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    60 tokens (    0.73 ms per token,  1370.02 tokens per second)\n",
      "llama_print_timings:        eval time =     901.98 ms /    54 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     966.40 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18328.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    27 tokens (    1.13 ms per token,   881.60 tokens per second)\n",
      "llama_print_timings:        eval time =     395.62 ms /    24 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     435.49 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18493.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    35 tokens (    0.97 ms per token,  1028.84 tokens per second)\n",
      "llama_print_timings:        eval time =     428.97 ms /    26 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     472.77 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    43 tokens (    0.86 ms per token,  1165.47 tokens per second)\n",
      "llama_print_timings:        eval time =     627.14 ms /    38 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     678.45 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18583.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.97 ms /    52 tokens (    0.83 ms per token,  1210.17 tokens per second)\n",
      "llama_print_timings:        eval time =     781.46 ms /    47 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     842.80 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18543.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.30 ms /    80 tokens (    0.64 ms per token,  1559.61 tokens per second)\n",
      "llama_print_timings:        eval time =     689.68 ms /    41 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     756.00 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18595.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    74 tokens (    0.68 ms per token,  1465.84 tokens per second)\n",
      "llama_print_timings:        eval time =     957.29 ms /    57 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1030.12 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /    69 runs   (    0.05 ms per token, 18454.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.71 ms /    69 tokens (    0.72 ms per token,  1387.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.00 ms /    68 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =    1216.88 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18400.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    54 tokens (    0.80 ms per token,  1255.11 tokens per second)\n",
      "llama_print_timings:        eval time =     799.08 ms /    48 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     861.30 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     8 runs   (    0.05 ms per token, 18306.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.14 ms /    20 tokens (    1.36 ms per token,   736.81 tokens per second)\n",
      "llama_print_timings:        eval time =     115.26 ms /     7 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     145.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    41 runs   (    0.05 ms per token, 18594.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.63 ms /    75 tokens (    0.68 ms per token,  1481.22 tokens per second)\n",
      "llama_print_timings:        eval time =     671.13 ms /    40 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     736.87 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    62 runs   (    0.05 ms per token, 18652.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    73 tokens (    0.69 ms per token,  1447.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1024.53 ms /    61 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1098.38 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /    22 runs   (    0.05 ms per token, 18211.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    27 tokens (    1.13 ms per token,   883.59 tokens per second)\n",
      "llama_print_timings:        eval time =     346.17 ms /    21 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     385.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    71 runs   (    0.05 ms per token, 18679.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    59 tokens (    0.74 ms per token,  1351.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.58 ms /    70 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =    1242.84 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    24 tokens (    1.14 ms per token,   874.48 tokens per second)\n",
      "llama_print_timings:        eval time =     379.26 ms /    23 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     415.90 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    97 runs   (    0.05 ms per token, 18553.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.75 ms /   100 tokens (    0.65 ms per token,  1544.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1620.34 ms /    96 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =    1724.78 ms /   196 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    41 runs   (    0.05 ms per token, 18585.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.52 ms /    40 tokens (    0.86 ms per token,  1158.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.43 ms /    40 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     710.07 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.12 ms /    21 runs   (    0.05 ms per token, 18783.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    59 tokens (    0.74 ms per token,  1345.71 tokens per second)\n",
      "llama_print_timings:        eval time =     330.32 ms /    20 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     381.87 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    74 runs   (    0.05 ms per token, 18527.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    68 tokens (    0.73 ms per token,  1367.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.05 ms /    73 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1303.77 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    55 runs   (    0.05 ms per token, 18625.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.40 ms /    84 tokens (    0.68 ms per token,  1463.52 tokens per second)\n",
      "llama_print_timings:        eval time =     909.51 ms /    54 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     988.54 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18482.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.46 ms /    49 tokens (    0.87 ms per token,  1154.14 tokens per second)\n",
      "llama_print_timings:        eval time =     612.27 ms /    37 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     669.13 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /    32 runs   (    0.05 ms per token, 18724.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    28 tokens (    1.09 ms per token,   913.99 tokens per second)\n",
      "llama_print_timings:        eval time =     511.26 ms /    31 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     553.89 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.72 ms /    44 tokens (    0.83 ms per token,  1198.29 tokens per second)\n",
      "llama_print_timings:        eval time =     627.32 ms /    38 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     678.73 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18504.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.92 ms /    19 tokens (    1.42 ms per token,   705.87 tokens per second)\n",
      "llama_print_timings:        eval time =     395.57 ms /    24 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     431.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    43 runs   (    0.05 ms per token, 18736.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.57 ms /    50 tokens (    0.85 ms per token,  1174.59 tokens per second)\n",
      "llama_print_timings:        eval time =     696.76 ms /    42 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     755.07 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18533.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.89 ms /    46 tokens (    0.80 ms per token,  1247.05 tokens per second)\n",
      "llama_print_timings:        eval time =     762.74 ms /    46 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     817.36 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18441.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.45 ms /    42 tokens (    0.87 ms per token,  1152.17 tokens per second)\n",
      "llama_print_timings:        eval time =     795.29 ms /    48 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     850.76 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18451.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    37 tokens (    0.92 ms per token,  1087.47 tokens per second)\n",
      "llama_print_timings:        eval time =     826.98 ms /    50 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     880.66 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    53 runs   (    0.05 ms per token, 18701.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.63 ms /    57 tokens (    0.77 ms per token,  1306.29 tokens per second)\n",
      "llama_print_timings:        eval time =     867.36 ms /    52 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     930.67 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18645.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.11 ms /    48 tokens (    0.77 ms per token,  1293.45 tokens per second)\n",
      "llama_print_timings:        eval time =     612.01 ms /    37 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     663.25 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18602.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.74 ms /    93 tokens (    0.63 ms per token,  1583.22 tokens per second)\n",
      "llama_print_timings:        eval time =     808.67 ms /    48 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     885.45 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /    58 runs   (    0.05 ms per token, 18709.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.88 ms /    45 tokens (    0.82 ms per token,  1220.01 tokens per second)\n",
      "llama_print_timings:        eval time =     947.59 ms /    57 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =    1006.34 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    57 runs   (    0.05 ms per token, 18762.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.81 ms /    70 tokens (    0.71 ms per token,  1405.26 tokens per second)\n",
      "llama_print_timings:        eval time =     939.07 ms /    56 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1010.13 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18703.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.89 ms /    53 tokens (    0.81 ms per token,  1235.72 tokens per second)\n",
      "llama_print_timings:        eval time =     478.84 ms /    29 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     533.16 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.11 ms /    21 tokens (    1.29 ms per token,   774.62 tokens per second)\n",
      "llama_print_timings:        eval time =     346.15 ms /    21 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     381.24 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18463.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.37 ms /    65 tokens (    0.76 ms per token,  1316.64 tokens per second)\n",
      "llama_print_timings:        eval time =     600.39 ms /    36 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     663.53 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    76 runs   (    0.05 ms per token, 18609.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.90 ms /    54 tokens (    0.79 ms per token,  1258.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.08 ms /    75 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =    1326.39 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.56 ms /    43 tokens (    0.85 ms per token,  1176.18 tokens per second)\n",
      "llama_print_timings:        eval time =     727.96 ms /    44 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     781.47 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18654.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.30 ms /    41 tokens (    0.89 ms per token,  1129.63 tokens per second)\n",
      "llama_print_timings:        eval time =     445.60 ms /    27 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     491.95 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18652.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.12 ms /    48 tokens (    0.77 ms per token,  1293.17 tokens per second)\n",
      "llama_print_timings:        eval time =     578.35 ms /    35 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     628.51 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    75 runs   (    0.05 ms per token, 18513.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.39 ms /    50 tokens (    0.85 ms per token,  1179.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1235.61 ms /    74 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =    1307.15 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /    15 runs   (    0.05 ms per token, 18270.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.66 ms /    27 tokens (    1.14 ms per token,   880.74 tokens per second)\n",
      "llama_print_timings:        eval time =     230.83 ms /    14 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     267.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    64 runs   (    0.05 ms per token, 18588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    76 tokens (    0.67 ms per token,  1500.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1059.04 ms /    63 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =    1134.07 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18474.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    77 tokens (    0.66 ms per token,  1518.35 tokens per second)\n",
      "llama_print_timings:        eval time =     503.61 ms /    30 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     566.28 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18532.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    54 tokens (    0.80 ms per token,  1250.46 tokens per second)\n",
      "llama_print_timings:        eval time =     799.12 ms /    48 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     860.68 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /    64 runs   (    0.05 ms per token, 18702.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.66 ms /    44 tokens (    0.83 ms per token,  1200.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1048.14 ms /    63 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =    1109.37 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18652.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.50 ms /    44 tokens (    0.83 ms per token,  1205.35 tokens per second)\n",
      "llama_print_timings:        eval time =     795.66 ms /    48 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     850.03 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18619.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.15 ms /    48 tokens (    0.77 ms per token,  1292.20 tokens per second)\n",
      "llama_print_timings:        eval time =     379.75 ms /    23 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     425.27 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18304.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    36 tokens (    0.95 ms per token,  1055.38 tokens per second)\n",
      "llama_print_timings:        eval time =     296.82 ms /    18 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     338.21 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18555.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.12 ms /    36 tokens (    0.95 ms per token,  1054.95 tokens per second)\n",
      "llama_print_timings:        eval time =     594.31 ms /    36 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     643.31 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.93 ms /    45 tokens (    0.82 ms per token,  1218.59 tokens per second)\n",
      "llama_print_timings:        eval time =     544.91 ms /    33 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     594.02 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18620.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.65 ms /    40 tokens (    0.87 ms per token,  1154.57 tokens per second)\n",
      "llama_print_timings:        eval time =     710.11 ms /    43 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     761.39 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    51 runs   (    0.05 ms per token, 18729.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.47 ms /    49 tokens (    0.87 ms per token,  1153.84 tokens per second)\n",
      "llama_print_timings:        eval time =     831.15 ms /    50 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     892.83 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /    37 runs   (    0.05 ms per token, 18668.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.59 ms /    42 tokens (    0.87 ms per token,  1148.01 tokens per second)\n",
      "llama_print_timings:        eval time =     594.30 ms /    36 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     644.50 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18588.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    38 tokens (    0.90 ms per token,  1105.20 tokens per second)\n",
      "llama_print_timings:        eval time =     709.68 ms /    43 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     760.56 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18387.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    38 tokens (    0.90 ms per token,  1109.23 tokens per second)\n",
      "llama_print_timings:        eval time =     412.57 ms /    25 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     456.53 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    52 runs   (    0.05 ms per token, 18738.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.59 ms /    67 tokens (    0.74 ms per token,  1351.16 tokens per second)\n",
      "llama_print_timings:        eval time =     853.97 ms /    51 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     922.96 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    46 runs   (    0.05 ms per token, 18684.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    57 tokens (    0.76 ms per token,  1312.82 tokens per second)\n",
      "llama_print_timings:        eval time =     749.31 ms /    45 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     810.48 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18590.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.43 ms /    49 tokens (    0.87 ms per token,  1154.73 tokens per second)\n",
      "llama_print_timings:        eval time =     696.49 ms /    42 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =     754.79 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    56 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.46 ms /    57 tokens (    0.76 ms per token,  1311.58 tokens per second)\n",
      "llama_print_timings:        eval time =     917.74 ms /    55 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     982.55 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    68 runs   (    0.05 ms per token, 18650.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    62 tokens (    0.71 ms per token,  1410.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.57 ms /    67 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =    1191.87 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18446.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    56 tokens (    0.77 ms per token,  1294.17 tokens per second)\n",
      "llama_print_timings:        eval time =     530.62 ms /    32 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     586.27 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    71 runs   (    0.05 ms per token, 18669.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    62 tokens (    0.71 ms per token,  1411.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.45 ms /    70 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =    1244.32 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18484.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.60 ms /    40 tokens (    0.86 ms per token,  1156.07 tokens per second)\n",
      "llama_print_timings:        eval time =     313.67 ms /    19 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     356.04 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /    18 runs   (    0.05 ms per token, 18499.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    21 tokens (    1.29 ms per token,   772.43 tokens per second)\n",
      "llama_print_timings:        eval time =     280.26 ms /    17 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     314.06 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /    66 runs   (    0.05 ms per token, 18681.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.25 ms /    72 tokens (    0.70 ms per token,  1432.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.51 ms /    65 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =    1167.64 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /    10 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      29.61 ms /    14 tokens (    2.11 ms per token,   472.81 tokens per second)\n",
      "llama_print_timings:        eval time =     148.04 ms /     9 runs   (   16.45 ms per token,    60.80 tokens per second)\n",
      "llama_print_timings:       total time =     181.07 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.67 ms /    44 tokens (    0.83 ms per token,  1199.96 tokens per second)\n",
      "llama_print_timings:        eval time =     379.64 ms /    23 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     424.54 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18557.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.85 ms /    34 tokens (    1.00 ms per token,  1004.31 tokens per second)\n",
      "llama_print_timings:        eval time =     709.64 ms /    43 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     760.25 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18479.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    68 tokens (    0.73 ms per token,  1365.41 tokens per second)\n",
      "llama_print_timings:        eval time =     416.51 ms /    25 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     475.65 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.04 ms /    47 tokens (    0.79 ms per token,  1268.97 tokens per second)\n",
      "llama_print_timings:        eval time =     611.63 ms /    37 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     662.38 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18592.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    29 tokens (    1.07 ms per token,   937.66 tokens per second)\n",
      "llama_print_timings:        eval time =     593.83 ms /    36 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     638.25 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    67 runs   (    0.05 ms per token, 18678.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    61 tokens (    0.72 ms per token,  1383.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.28 ms /    66 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1174.17 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18343.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.84 ms /    33 tokens (    1.03 ms per token,   975.32 tokens per second)\n",
      "llama_print_timings:        eval time =     561.12 ms /    34 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     608.83 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18379.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    51 tokens (    0.84 ms per token,  1188.40 tokens per second)\n",
      "llama_print_timings:        eval time =     346.87 ms /    21 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     397.35 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18547.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    67 tokens (    0.74 ms per token,  1352.66 tokens per second)\n",
      "llama_print_timings:        eval time =     567.69 ms /    34 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     630.18 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18651.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    56 tokens (    0.77 ms per token,  1294.56 tokens per second)\n",
      "llama_print_timings:        eval time =     715.49 ms /    43 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     775.63 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.14 ms /    55 tokens (    0.78 ms per token,  1274.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1068.91 ms /    64 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =    1137.83 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18407.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    61 tokens (    0.72 ms per token,  1390.63 tokens per second)\n",
      "llama_print_timings:        eval time =     700.40 ms /    42 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     760.69 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    54 tokens (    0.80 ms per token,  1254.53 tokens per second)\n",
      "llama_print_timings:        eval time =     782.27 ms /    47 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     843.72 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    19 tokens (    1.41 ms per token,   706.79 tokens per second)\n",
      "llama_print_timings:        eval time =     445.09 ms /    27 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     481.89 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.18 tokens per second)\n",
      "llama_print_timings:        eval time =     683.71 ms /    41 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     743.30 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    63 runs   (    0.05 ms per token, 18534.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    56 tokens (    0.77 ms per token,  1293.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1035.59 ms /    62 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =    1103.38 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /    29 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.89 ms /    29 tokens (    1.07 ms per token,   938.82 tokens per second)\n",
      "llama_print_timings:        eval time =     461.76 ms /    28 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     503.14 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    46 runs   (    0.05 ms per token, 18488.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.45 ms /    42 tokens (    0.87 ms per token,  1152.42 tokens per second)\n",
      "llama_print_timings:        eval time =     744.46 ms /    45 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     798.44 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18539.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    37 tokens (    0.92 ms per token,  1085.27 tokens per second)\n",
      "llama_print_timings:        eval time =     511.66 ms /    31 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     557.86 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.66 ms /    51 tokens (    0.84 ms per token,  1195.61 tokens per second)\n",
      "llama_print_timings:        eval time =     579.29 ms /    35 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     635.04 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    60 runs   (    0.05 ms per token, 18709.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.26 ms /    84 tokens (    0.68 ms per token,  1466.89 tokens per second)\n",
      "llama_print_timings:        eval time =     993.77 ms /    59 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =    1073.45 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18441.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    68 tokens (    0.73 ms per token,  1372.05 tokens per second)\n",
      "llama_print_timings:        eval time =     803.79 ms /    48 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     872.45 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /    42 runs   (    0.05 ms per token, 18733.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    61 tokens (    0.72 ms per token,  1382.72 tokens per second)\n",
      "llama_print_timings:        eval time =     683.34 ms /    41 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     742.96 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18532.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.84 ms /    19 tokens (    1.41 ms per token,   707.95 tokens per second)\n",
      "llama_print_timings:        eval time =     395.81 ms /    24 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     431.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    28 tokens (    1.10 ms per token,   910.48 tokens per second)\n",
      "llama_print_timings:        eval time =     428.77 ms /    26 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     469.46 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    83 runs   (    0.05 ms per token, 18664.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    55 tokens (    0.79 ms per token,  1273.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1372.42 ms /    82 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =    1447.89 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    71 runs   (    0.05 ms per token, 18610.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    51 tokens (    0.84 ms per token,  1194.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.92 ms /    70 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =    1240.04 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18547.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.50 ms /    40 tokens (    0.86 ms per token,  1159.55 tokens per second)\n",
      "llama_print_timings:        eval time =     561.65 ms /    34 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     609.95 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    41 runs   (    0.05 ms per token, 18670.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.46 ms /    56 tokens (    0.78 ms per token,  1288.66 tokens per second)\n",
      "llama_print_timings:        eval time =     665.21 ms /    40 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     723.76 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.03 ms /    36 tokens (    0.95 ms per token,  1057.98 tokens per second)\n",
      "llama_print_timings:        eval time =     429.08 ms /    26 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     473.26 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.60 ms /    42 tokens (    0.87 ms per token,  1147.64 tokens per second)\n",
      "llama_print_timings:        eval time =     778.36 ms /    47 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     833.84 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    77 runs   (    0.05 ms per token, 18666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    53 tokens (    0.81 ms per token,  1234.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1271.48 ms /    76 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1344.09 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    64 runs   (    0.05 ms per token, 18523.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    87 tokens (    0.66 ms per token,  1506.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.96 ms /    63 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =    1144.23 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18618.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.99 ms /    48 tokens (    0.77 ms per token,  1297.79 tokens per second)\n",
      "llama_print_timings:        eval time =     729.94 ms /    44 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.94 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /    24 runs   (    0.06 ms per token, 18113.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.10 ms /    47 tokens (    0.79 ms per token,  1266.71 tokens per second)\n",
      "llama_print_timings:        eval time =     379.91 ms /    23 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     426.49 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18626.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    60 tokens (    0.73 ms per token,  1366.31 tokens per second)\n",
      "llama_print_timings:        eval time =     515.06 ms /    31 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     570.49 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    14 runs   (    0.05 ms per token, 18229.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.72 ms /    18 tokens (    1.48 ms per token,   673.58 tokens per second)\n",
      "llama_print_timings:        eval time =     214.24 ms /    13 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     245.67 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18482.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.33 ms /    73 tokens (    0.69 ms per token,  1450.48 tokens per second)\n",
      "llama_print_timings:        eval time =     788.45 ms /    47 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     856.59 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18435.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    31 tokens (    1.00 ms per token,   996.08 tokens per second)\n",
      "llama_print_timings:        eval time =     594.07 ms /    36 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     639.26 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /    23 runs   (    0.05 ms per token, 18837.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.47 ms /    40 tokens (    0.86 ms per token,  1160.60 tokens per second)\n",
      "llama_print_timings:        eval time =     363.07 ms /    22 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     405.76 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.93 ms /    45 tokens (    0.82 ms per token,  1218.55 tokens per second)\n",
      "llama_print_timings:        eval time =     644.52 ms /    39 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     696.36 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    62 runs   (    0.05 ms per token, 18419.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    55 tokens (    0.79 ms per token,  1272.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1018.66 ms /    61 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =    1086.68 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /    21 runs   (    0.05 ms per token, 18584.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.68 ms /    33 tokens (    1.02 ms per token,   979.72 tokens per second)\n",
      "llama_print_timings:        eval time =     329.90 ms /    20 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     370.93 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    43 runs   (    0.05 ms per token, 18313.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.43 ms /    38 tokens (    0.91 ms per token,  1103.72 tokens per second)\n",
      "llama_print_timings:        eval time =     693.33 ms /    42 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     744.45 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /    27 runs   (    0.06 ms per token, 18157.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.07 ms /    60 tokens (    0.73 ms per token,  1361.35 tokens per second)\n",
      "llama_print_timings:        eval time =     430.87 ms /    26 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     484.83 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    82 runs   (    0.05 ms per token, 18547.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    68 tokens (    0.73 ms per token,  1370.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1360.29 ms /    81 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =    1441.93 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18489.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    61 tokens (    0.72 ms per token,  1387.66 tokens per second)\n",
      "llama_print_timings:        eval time =     767.62 ms /    46 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     829.38 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    62 runs   (    0.05 ms per token, 18680.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.11 ms /    88 tokens (    0.66 ms per token,  1514.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1028.03 ms /    61 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1109.97 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18637.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.77 ms /    33 tokens (    1.02 ms per token,   977.31 tokens per second)\n",
      "llama_print_timings:        eval time =     511.85 ms /    31 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     557.78 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /    21 runs   (    0.05 ms per token, 18340.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.48 ms /    42 tokens (    0.87 ms per token,  1151.16 tokens per second)\n",
      "llama_print_timings:        eval time =     330.30 ms /    20 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     373.95 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /    19 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.56 ms /    26 tokens (    1.18 ms per token,   850.73 tokens per second)\n",
      "llama_print_timings:        eval time =     296.70 ms /    18 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     334.49 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18376.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.61 ms /    40 tokens (    0.87 ms per token,  1155.87 tokens per second)\n",
      "llama_print_timings:        eval time =     693.52 ms /    42 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     744.17 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18593.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.94 ms /    61 tokens (    0.72 ms per token,  1388.38 tokens per second)\n",
      "llama_print_timings:        eval time =     751.22 ms /    45 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     812.04 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.01 ms /    19 tokens (    1.42 ms per token,   703.50 tokens per second)\n",
      "llama_print_timings:        eval time =     379.35 ms /    23 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     414.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /    27 runs   (    0.05 ms per token, 18417.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.82 ms /    51 tokens (    0.84 ms per token,  1191.00 tokens per second)\n",
      "llama_print_timings:        eval time =     429.88 ms /    26 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     483.19 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    50 tokens (    0.85 ms per token,  1170.93 tokens per second)\n",
      "llama_print_timings:        eval time =     730.83 ms /    44 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     789.82 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18428.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.48 ms /    39 tokens (    0.88 ms per token,  1131.25 tokens per second)\n",
      "llama_print_timings:        eval time =     544.84 ms /    33 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     591.50 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /    30 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    55 tokens (    0.78 ms per token,  1276.04 tokens per second)\n",
      "llama_print_timings:        eval time =     479.94 ms /    29 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     533.58 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18636.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.80 ms /    33 tokens (    1.02 ms per token,   976.22 tokens per second)\n",
      "llama_print_timings:        eval time =     561.25 ms /    34 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     607.64 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18369.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    60 tokens (    0.73 ms per token,  1360.58 tokens per second)\n",
      "llama_print_timings:        eval time =     666.80 ms /    40 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     725.45 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.05 ms per token, 18218.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.71 ms /    18 tokens (    1.48 ms per token,   673.96 tokens per second)\n",
      "llama_print_timings:        eval time =     131.84 ms /     8 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     161.52 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18402.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.55 ms /    49 tokens (    0.87 ms per token,  1151.56 tokens per second)\n",
      "llama_print_timings:        eval time =     713.79 ms /    43 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     772.74 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18555.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.67 ms /    33 tokens (    1.02 ms per token,   980.10 tokens per second)\n",
      "llama_print_timings:        eval time =     594.45 ms /    36 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     641.60 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    69 runs   (    0.05 ms per token, 18613.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    60 tokens (    0.73 ms per token,  1375.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.74 ms /    68 runs   (   16.75 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =    1208.67 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    56 runs   (    0.05 ms per token, 18318.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    71 tokens (    0.71 ms per token,  1412.26 tokens per second)\n",
      "llama_print_timings:        eval time =     923.11 ms /    55 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     995.35 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /    10 runs   (    0.06 ms per token, 17513.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.48 ms /    40 tokens (    0.86 ms per token,  1160.09 tokens per second)\n",
      "llama_print_timings:        eval time =     148.36 ms /     9 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     186.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18309.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    67 tokens (    0.74 ms per token,  1351.35 tokens per second)\n",
      "llama_print_timings:        eval time =     198.11 ms /    12 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     252.70 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    62 tokens (    0.71 ms per token,  1404.49 tokens per second)\n",
      "llama_print_timings:        eval time =     717.69 ms /    43 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =     778.18 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    56 tokens (    0.77 ms per token,  1294.35 tokens per second)\n",
      "llama_print_timings:        eval time =     648.38 ms /    39 runs   (   16.63 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     706.57 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.38 ms /    32 tokens (    0.98 ms per token,  1019.73 tokens per second)\n",
      "llama_print_timings:        eval time =     313.28 ms /    19 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     351.52 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    35 runs   (    0.05 ms per token, 18786.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.42 ms /    42 tokens (    0.87 ms per token,  1153.09 tokens per second)\n",
      "llama_print_timings:        eval time =     561.27 ms /    34 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     610.39 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.54 ms /    42 tokens (    0.87 ms per token,  1149.52 tokens per second)\n",
      "llama_print_timings:        eval time =     379.53 ms /    23 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     424.57 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /    58 runs   (    0.05 ms per token, 18506.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    79 tokens (    0.65 ms per token,  1546.78 tokens per second)\n",
      "llama_print_timings:        eval time =     959.37 ms /    57 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1033.48 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     8 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.26 ms /    21 tokens (    1.30 ms per token,   770.47 tokens per second)\n",
      "llama_print_timings:        eval time =     115.27 ms /     7 runs   (   16.47 ms per token,    60.73 tokens per second)\n",
      "llama_print_timings:       total time =     145.59 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18592.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.14 ms /    37 tokens (    0.92 ms per token,  1083.84 tokens per second)\n",
      "llama_print_timings:        eval time =     445.56 ms /    27 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     489.89 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    56 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.32 ms /    38 tokens (    0.90 ms per token,  1107.36 tokens per second)\n",
      "llama_print_timings:        eval time =     911.57 ms /    55 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     967.31 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18606.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.13 ms /    48 tokens (    0.77 ms per token,  1292.82 tokens per second)\n",
      "llama_print_timings:        eval time =     696.26 ms /    42 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     749.61 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /    30 runs   (    0.05 ms per token, 18438.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.32 ms /    41 tokens (    0.89 ms per token,  1128.92 tokens per second)\n",
      "llama_print_timings:        eval time =     478.86 ms /    29 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     525.74 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /    73 runs   (    0.05 ms per token, 18717.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.81 ms /   100 tokens (    0.65 ms per token,  1543.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.53 ms /    72 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =    1308.02 ms /   172 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /    58 runs   (    0.05 ms per token, 18673.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.00 ms /    54 tokens (    0.80 ms per token,  1255.87 tokens per second)\n",
      "llama_print_timings:        eval time =     950.67 ms /    57 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =    1016.24 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    76 runs   (    0.05 ms per token, 18858.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.33 ms /    42 tokens (    0.87 ms per token,  1155.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.77 ms /    75 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =    1315.72 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    37 runs   (    0.05 ms per token, 18289.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.75 ms /    45 tokens (    0.82 ms per token,  1224.59 tokens per second)\n",
      "llama_print_timings:        eval time =     594.59 ms /    36 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     644.84 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.61 ms /    50 tokens (    0.85 ms per token,  1173.35 tokens per second)\n",
      "llama_print_timings:        eval time =     429.49 ms /    26 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     481.74 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18380.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.16 ms /    46 tokens (    0.81 ms per token,  1237.96 tokens per second)\n",
      "llama_print_timings:        eval time =     594.68 ms /    36 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     646.53 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    77 runs   (    0.05 ms per token, 18675.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    77 tokens (    0.66 ms per token,  1514.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.31 ms /    76 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1359.95 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18673.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.66 ms /    69 tokens (    0.72 ms per token,  1389.53 tokens per second)\n",
      "llama_print_timings:        eval time =     770.26 ms /    46 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     837.63 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18630.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.34 ms /    41 tokens (    0.89 ms per token,  1128.39 tokens per second)\n",
      "llama_print_timings:        eval time =     643.89 ms /    39 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     695.18 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    42 runs   (    0.05 ms per token, 18800.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    23 tokens (    1.18 ms per token,   844.72 tokens per second)\n",
      "llama_print_timings:        eval time =     676.53 ms /    41 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     719.73 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     7 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    28 tokens (    1.09 ms per token,   913.45 tokens per second)\n",
      "llama_print_timings:        eval time =      98.90 ms /     6 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     131.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    47 runs   (    0.05 ms per token, 18710.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    69 tokens (    0.72 ms per token,  1383.24 tokens per second)\n",
      "llama_print_timings:        eval time =     770.26 ms /    46 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     837.78 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18636.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.04 ms /    47 tokens (    0.79 ms per token,  1268.97 tokens per second)\n",
      "llama_print_timings:        eval time =     561.45 ms /    34 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     611.47 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18512.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.66 ms /    50 tokens (    0.85 ms per token,  1172.06 tokens per second)\n",
      "llama_print_timings:        eval time =     932.85 ms /    56 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     998.69 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    21 tokens (    1.29 ms per token,   775.54 tokens per second)\n",
      "llama_print_timings:        eval time =     313.28 ms /    19 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     347.89 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18623.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    54 tokens (    0.80 ms per token,  1254.41 tokens per second)\n",
      "llama_print_timings:        eval time =     580.50 ms /    35 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     636.88 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    41 runs   (    0.05 ms per token, 18560.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.01 ms /    48 tokens (    0.77 ms per token,  1296.88 tokens per second)\n",
      "llama_print_timings:        eval time =     662.71 ms /    40 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     715.59 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    66 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    58 tokens (    0.75 ms per token,  1333.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.94 ms /    65 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =    1156.10 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.56 ms /    17 tokens (    1.56 ms per token,   639.99 tokens per second)\n",
      "llama_print_timings:        eval time =     329.84 ms /    20 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     364.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18452.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.29 ms /    32 tokens (    0.98 ms per token,  1022.59 tokens per second)\n",
      "llama_print_timings:        eval time =     495.23 ms /    30 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     537.78 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18531.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.61 ms /    64 tokens (    0.70 ms per token,  1434.53 tokens per second)\n",
      "llama_print_timings:        eval time =     835.87 ms /    50 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =     899.45 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18527.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.61 ms /    32 tokens (    0.99 ms per token,  1012.27 tokens per second)\n",
      "llama_print_timings:        eval time =     594.00 ms /    36 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     639.34 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    50 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    58 tokens (    0.75 ms per token,  1325.35 tokens per second)\n",
      "llama_print_timings:        eval time =     817.35 ms /    49 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     879.78 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    70 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    60 tokens (    0.73 ms per token,  1362.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.30 ms /    69 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =    1226.27 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18511.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    36 tokens (    0.94 ms per token,  1059.17 tokens per second)\n",
      "llama_print_timings:        eval time =     843.94 ms /    51 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     897.66 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    27 tokens (    1.13 ms per token,   882.44 tokens per second)\n",
      "llama_print_timings:        eval time =     379.23 ms /    23 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     418.98 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18456.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    62 tokens (    0.71 ms per token,  1408.71 tokens per second)\n",
      "llama_print_timings:        eval time =     717.65 ms /    43 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     778.48 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    41 runs   (    0.06 ms per token, 18125.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.20 ms /    41 tokens (    0.88 ms per token,  1132.66 tokens per second)\n",
      "llama_print_timings:        eval time =     660.44 ms /    40 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     711.80 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /    35 runs   (    0.06 ms per token, 17694.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    38 tokens (    0.90 ms per token,  1111.37 tokens per second)\n",
      "llama_print_timings:        eval time =     561.44 ms /    34 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     608.69 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18436.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.50 ms /    42 tokens (    0.87 ms per token,  1150.68 tokens per second)\n",
      "llama_print_timings:        eval time =     396.13 ms /    24 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     441.62 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18355.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    73 tokens (    0.69 ms per token,  1446.23 tokens per second)\n",
      "llama_print_timings:        eval time =     367.67 ms /    22 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     426.38 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    56 runs   (    0.05 ms per token, 18729.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    50 tokens (    0.86 ms per token,  1169.40 tokens per second)\n",
      "llama_print_timings:        eval time =     915.92 ms /    55 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     980.20 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    46 runs   (    0.05 ms per token, 18444.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.61 ms /    50 tokens (    0.85 ms per token,  1173.38 tokens per second)\n",
      "llama_print_timings:        eval time =     747.70 ms /    45 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     808.40 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18610.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.46 ms /    42 tokens (    0.87 ms per token,  1152.01 tokens per second)\n",
      "llama_print_timings:        eval time =     913.18 ms /    55 runs   (   16.60 ms per token,    60.23 tokens per second)\n",
      "llama_print_timings:       total time =     971.00 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    43 runs   (    0.05 ms per token, 18679.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.83 ms /    87 tokens (    0.66 ms per token,  1504.41 tokens per second)\n",
      "llama_print_timings:        eval time =     707.53 ms /    42 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     781.40 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    64 runs   (    0.05 ms per token, 18534.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.48 ms /    43 tokens (    0.85 ms per token,  1178.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1048.21 ms /    63 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =    1109.70 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    64 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.14 ms /    62 tokens (    0.71 ms per token,  1404.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.55 ms /    63 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =    1123.04 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18685.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.58 ms /    58 tokens (    0.75 ms per token,  1330.92 tokens per second)\n",
      "llama_print_timings:        eval time =     430.11 ms /    26 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     483.32 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18508.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.20 ms /    48 tokens (    0.78 ms per token,  1290.32 tokens per second)\n",
      "llama_print_timings:        eval time =     545.18 ms /    33 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     595.35 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18601.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    58 tokens (    0.75 ms per token,  1328.84 tokens per second)\n",
      "llama_print_timings:        eval time =     884.90 ms /    53 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     948.55 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18602.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.57 ms /    74 tokens (    0.68 ms per token,  1463.23 tokens per second)\n",
      "llama_print_timings:        eval time =     603.48 ms /    36 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     668.16 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18557.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    75 tokens (    0.67 ms per token,  1483.62 tokens per second)\n",
      "llama_print_timings:        eval time =     570.11 ms /    34 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     633.95 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.18 ms /    38 tokens (    0.90 ms per token,  1111.92 tokens per second)\n",
      "llama_print_timings:        eval time =     594.42 ms /    36 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     641.95 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    70 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    68 tokens (    0.73 ms per token,  1369.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.66 ms /    69 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =    1234.20 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    32 runs   (    0.05 ms per token, 18401.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.85 ms /    33 tokens (    1.03 ms per token,   974.98 tokens per second)\n",
      "llama_print_timings:        eval time =     511.79 ms /    31 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     558.45 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.86 ms /    34 tokens (    1.00 ms per token,  1004.28 tokens per second)\n",
      "llama_print_timings:        eval time =     776.00 ms /    47 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     828.02 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.42 ms /    41 tokens (    0.89 ms per token,  1125.85 tokens per second)\n",
      "llama_print_timings:        eval time =     761.12 ms /    46 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     815.67 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /    31 runs   (    0.05 ms per token, 18364.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.81 ms /    33 tokens (    1.02 ms per token,   976.01 tokens per second)\n",
      "llama_print_timings:        eval time =     495.05 ms /    30 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     540.15 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /    45 runs   (    0.05 ms per token, 18672.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    50 tokens (    0.86 ms per token,  1169.45 tokens per second)\n",
      "llama_print_timings:        eval time =     730.97 ms /    44 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     790.20 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    38 tokens (    0.90 ms per token,  1108.29 tokens per second)\n",
      "llama_print_timings:        eval time =     379.49 ms /    23 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     422.36 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    70 tokens (    0.71 ms per token,  1398.71 tokens per second)\n",
      "llama_print_timings:        eval time =     737.17 ms /    44 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     804.46 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    80 runs   (    0.05 ms per token, 18480.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.64 ms /    99 tokens (    0.65 ms per token,  1531.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.02 ms /    79 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1429.86 ms /   178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /    12 runs   (    0.05 ms per token, 18264.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    29 tokens (    1.07 ms per token,   935.63 tokens per second)\n",
      "llama_print_timings:        eval time =     181.35 ms /    11 runs   (   16.49 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =     216.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18468.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.60 ms /    66 tokens (    0.75 ms per token,  1330.62 tokens per second)\n",
      "llama_print_timings:        eval time =     668.57 ms /    40 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     733.69 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    41 runs   (    0.05 ms per token, 18653.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    56 tokens (    0.78 ms per token,  1287.27 tokens per second)\n",
      "llama_print_timings:        eval time =     665.01 ms /    40 runs   (   16.63 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     723.78 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    71 runs   (    0.05 ms per token, 18679.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.61 ms /    75 tokens (    0.67 ms per token,  1481.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.08 ms /    70 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =    1255.46 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    46 runs   (    0.05 ms per token, 18481.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.38 ms /    39 tokens (    0.88 ms per token,  1134.25 tokens per second)\n",
      "llama_print_timings:        eval time =     743.96 ms /    45 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     796.61 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    66 runs   (    0.05 ms per token, 18513.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.37 ms /    83 tokens (    0.69 ms per token,  1446.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.15 ms /    65 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =    1177.97 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    60 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.87 ms /    52 tokens (    0.82 ms per token,  1212.88 tokens per second)\n",
      "llama_print_timings:        eval time =     984.02 ms /    59 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =    1050.59 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    71 runs   (    0.05 ms per token, 18576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.54 ms /    75 tokens (    0.67 ms per token,  1484.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.97 ms /    70 runs   (   16.81 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =    1255.12 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     9 runs   (    0.06 ms per token, 18145.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.30 ms /    25 tokens (    1.21 ms per token,   824.97 tokens per second)\n",
      "llama_print_timings:        eval time =     131.95 ms /     8 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     165.85 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /    45 runs   (    0.05 ms per token, 18679.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.41 ms /    72 tokens (    0.70 ms per token,  1428.34 tokens per second)\n",
      "llama_print_timings:        eval time =     737.69 ms /    44 runs   (   16.77 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     804.88 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18259.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.48 ms /    26 tokens (    1.17 ms per token,   852.88 tokens per second)\n",
      "llama_print_timings:        eval time =     263.95 ms /    16 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     300.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    40 runs   (    0.05 ms per token, 18700.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.48 ms /    40 tokens (    0.86 ms per token,  1160.06 tokens per second)\n",
      "llama_print_timings:        eval time =     644.13 ms /    39 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     694.09 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    77 runs   (    0.05 ms per token, 18567.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    72 tokens (    0.70 ms per token,  1429.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1277.38 ms /    76 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1357.86 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    53 tokens (    0.81 ms per token,  1237.19 tokens per second)\n",
      "llama_print_timings:        eval time =     647.43 ms /    39 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     705.36 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     6 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    15 tokens (    1.82 ms per token,   547.99 tokens per second)\n",
      "llama_print_timings:        eval time =      82.15 ms /     5 runs   (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:       total time =     111.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /    10 runs   (    0.05 ms per token, 18315.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.84 ms /    29 tokens (    1.06 ms per token,   940.22 tokens per second)\n",
      "llama_print_timings:        eval time =     148.35 ms /     9 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     182.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18654.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.20 ms /    37 tokens (    0.92 ms per token,  1081.84 tokens per second)\n",
      "llama_print_timings:        eval time =     445.47 ms /    27 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     490.29 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /    27 runs   (    0.05 ms per token, 18230.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.80 ms /    51 tokens (    0.84 ms per token,  1191.62 tokens per second)\n",
      "llama_print_timings:        eval time =     429.73 ms /    26 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     483.11 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /    38 runs   (    0.05 ms per token, 18384.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    67 tokens (    0.74 ms per token,  1352.42 tokens per second)\n",
      "llama_print_timings:        eval time =     618.37 ms /    37 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     682.44 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    51 runs   (    0.05 ms per token, 18729.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    65 tokens (    0.76 ms per token,  1314.96 tokens per second)\n",
      "llama_print_timings:        eval time =     836.59 ms /    50 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =     904.81 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    41 runs   (    0.05 ms per token, 18730.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    50 tokens (    0.85 ms per token,  1172.28 tokens per second)\n",
      "llama_print_timings:        eval time =     663.33 ms /    40 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =     721.16 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18643.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.24 ms /    32 tokens (    0.98 ms per token,  1024.23 tokens per second)\n",
      "llama_print_timings:        eval time =     577.60 ms /    35 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     622.49 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18639.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.31 ms /    31 tokens (    1.01 ms per token,   990.13 tokens per second)\n",
      "llama_print_timings:        eval time =     875.75 ms /    53 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     927.95 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    88 runs   (    0.05 ms per token, 18632.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    72 tokens (    0.70 ms per token,  1432.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1463.56 ms /    87 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =    1549.80 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18527.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.28 tokens per second)\n",
      "llama_print_timings:        eval time =     633.39 ms /    38 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     692.01 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    36 runs   (    0.05 ms per token, 18414.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    32 tokens (    0.97 ms per token,  1025.74 tokens per second)\n",
      "llama_print_timings:        eval time =     577.65 ms /    35 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     622.59 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18651.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    54 tokens (    0.80 ms per token,  1247.23 tokens per second)\n",
      "llama_print_timings:        eval time =     631.00 ms /    38 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     688.68 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.86 ms /    46 tokens (    0.80 ms per token,  1247.97 tokens per second)\n",
      "llama_print_timings:        eval time =     396.40 ms /    24 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     442.58 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18447.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.20 ms /    31 tokens (    1.01 ms per token,   993.72 tokens per second)\n",
      "llama_print_timings:        eval time =     379.44 ms /    23 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     418.96 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /    69 runs   (    0.05 ms per token, 18459.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    66 tokens (    0.75 ms per token,  1331.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.31 ms /    68 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1216.38 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    63 runs   (    0.05 ms per token, 18761.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.52 ms /    44 tokens (    0.83 ms per token,  1204.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1031.82 ms /    62 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =    1092.64 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18540.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    28 tokens (    1.09 ms per token,   914.29 tokens per second)\n",
      "llama_print_timings:        eval time =     494.97 ms /    30 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     537.15 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    54 tokens (    0.80 ms per token,  1253.74 tokens per second)\n",
      "llama_print_timings:        eval time =     832.89 ms /    50 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     895.23 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18453.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.36 ms /    38 tokens (    0.90 ms per token,  1106.10 tokens per second)\n",
      "llama_print_timings:        eval time =     330.06 ms /    20 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     371.99 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18615.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.11 ms /    46 tokens (    0.81 ms per token,  1239.73 tokens per second)\n",
      "llama_print_timings:        eval time =     512.11 ms /    31 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     561.70 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /    23 runs   (    0.05 ms per token, 18608.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.64 ms /    40 tokens (    0.87 ms per token,  1154.70 tokens per second)\n",
      "llama_print_timings:        eval time =     363.16 ms /    22 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     406.40 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18553.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.84 tokens per second)\n",
      "llama_print_timings:        eval time =     803.41 ms /    48 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =     871.63 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    48 runs   (    0.05 ms per token, 18742.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.11 ms /    47 tokens (    0.79 ms per token,  1266.64 tokens per second)\n",
      "llama_print_timings:        eval time =     780.12 ms /    47 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     834.99 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18427.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.00 ms /    71 tokens (    0.70 ms per token,  1419.89 tokens per second)\n",
      "llama_print_timings:        eval time =     805.01 ms /    48 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     873.37 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    36 tokens (    0.95 ms per token,  1053.03 tokens per second)\n",
      "llama_print_timings:        eval time =     412.46 ms /    25 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     456.21 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    32 runs   (    0.05 ms per token, 18390.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    62 tokens (    0.71 ms per token,  1407.24 tokens per second)\n",
      "llama_print_timings:        eval time =     515.64 ms /    31 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     571.56 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18269.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    29 tokens (    1.07 ms per token,   933.11 tokens per second)\n",
      "llama_print_timings:        eval time =     296.98 ms /    18 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     335.76 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /    17 runs   (    0.06 ms per token, 17970.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    26 tokens (    1.18 ms per token,   850.42 tokens per second)\n",
      "llama_print_timings:        eval time =     263.74 ms /    16 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     300.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    30 runs   (    0.05 ms per token, 18541.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.59 ms /    49 tokens (    0.87 ms per token,  1150.53 tokens per second)\n",
      "llama_print_timings:        eval time =     478.95 ms /    29 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     532.99 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18637.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.92 ms /    29 tokens (    1.07 ms per token,   937.81 tokens per second)\n",
      "llama_print_timings:        eval time =     511.36 ms /    31 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     554.14 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    66 runs   (    0.05 ms per token, 18560.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.99 ms /    87 tokens (    0.67 ms per token,  1500.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.32 ms /    65 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1178.64 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    51 runs   (    0.05 ms per token, 18756.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    61 tokens (    0.72 ms per token,  1389.62 tokens per second)\n",
      "llama_print_timings:        eval time =     835.13 ms /    50 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     898.68 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.44 ms /    42 tokens (    0.87 ms per token,  1152.48 tokens per second)\n",
      "llama_print_timings:        eval time =     610.93 ms /    37 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     661.05 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18335.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.46 ms /    39 tokens (    0.88 ms per token,  1131.85 tokens per second)\n",
      "llama_print_timings:        eval time =     197.92 ms /    12 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     237.13 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /    13 runs   (    0.06 ms per token, 17310.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.08 ms /    35 tokens (    0.97 ms per token,  1027.15 tokens per second)\n",
      "llama_print_timings:        eval time =     197.79 ms /    12 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     236.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    61 runs   (    0.05 ms per token, 18395.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.51 ms /    40 tokens (    0.86 ms per token,  1159.22 tokens per second)\n",
      "llama_print_timings:        eval time =     996.72 ms /    60 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =    1054.57 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    68 runs   (    0.05 ms per token, 18619.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.08 ms /    83 tokens (    0.69 ms per token,  1454.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.17 ms /    67 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1212.49 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.39 ms /    49 tokens (    0.87 ms per token,  1156.01 tokens per second)\n",
      "llama_print_timings:        eval time =     578.82 ms /    35 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     634.71 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18583.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.71 ms /    27 tokens (    1.14 ms per token,   879.31 tokens per second)\n",
      "llama_print_timings:        eval time =     941.45 ms /    57 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     994.44 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    34 runs   (    0.06 ms per token, 18162.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.75 ms /    44 tokens (    0.84 ms per token,  1197.34 tokens per second)\n",
      "llama_print_timings:        eval time =     545.09 ms /    33 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     594.72 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18474.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.96 ms /    52 tokens (    0.83 ms per token,  1210.46 tokens per second)\n",
      "llama_print_timings:        eval time =     630.16 ms /    38 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =     687.19 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18540.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    57 tokens (    0.76 ms per token,  1309.62 tokens per second)\n",
      "llama_print_timings:        eval time =     749.88 ms /    45 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     811.05 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    19 runs   (    0.06 ms per token, 17707.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.43 ms /    26 tokens (    1.17 ms per token,   854.36 tokens per second)\n",
      "llama_print_timings:        eval time =     296.83 ms /    18 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     333.86 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    59 runs   (    0.05 ms per token, 18670.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    52 tokens (    0.83 ms per token,  1207.98 tokens per second)\n",
      "llama_print_timings:        eval time =     967.22 ms /    58 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =    1032.32 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.83 ms /    35 tokens (    0.97 ms per token,  1034.49 tokens per second)\n",
      "llama_print_timings:        eval time =     676.86 ms /    41 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     726.25 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    52 tokens (    0.83 ms per token,  1205.66 tokens per second)\n",
      "llama_print_timings:        eval time =     346.98 ms /    21 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     398.21 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    73 tokens (    0.69 ms per token,  1447.12 tokens per second)\n",
      "llama_print_timings:        eval time =     872.94 ms /    52 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     943.54 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /    55 runs   (    0.05 ms per token, 18701.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    56 tokens (    0.77 ms per token,  1291.60 tokens per second)\n",
      "llama_print_timings:        eval time =     901.12 ms /    54 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     965.68 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18399.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.81 ms /    52 tokens (    0.82 ms per token,  1214.58 tokens per second)\n",
      "llama_print_timings:        eval time =     647.09 ms /    39 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     704.95 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /    38 runs   (    0.05 ms per token, 18700.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.28 ms /    63 tokens (    0.70 ms per token,  1422.67 tokens per second)\n",
      "llama_print_timings:        eval time =     616.91 ms /    37 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     675.52 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18670.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.45 ms /    49 tokens (    0.87 ms per token,  1154.38 tokens per second)\n",
      "llama_print_timings:        eval time =     814.56 ms /    49 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     876.01 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    59 runs   (    0.05 ms per token, 18629.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    71 tokens (    0.70 ms per token,  1419.55 tokens per second)\n",
      "llama_print_timings:        eval time =     973.60 ms /    58 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =    1045.81 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    59 runs   (    0.05 ms per token, 18249.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.81 ms /    52 tokens (    0.82 ms per token,  1214.73 tokens per second)\n",
      "llama_print_timings:        eval time =     968.16 ms /    58 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =    1037.38 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    31 runs   (    0.06 ms per token, 18054.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    29 tokens (    1.07 ms per token,   938.57 tokens per second)\n",
      "llama_print_timings:        eval time =     495.34 ms /    30 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     538.92 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18468.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.93 ms /    61 tokens (    0.72 ms per token,  1388.54 tokens per second)\n",
      "llama_print_timings:        eval time =     784.62 ms /    47 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     846.41 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /    20 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.73 ms /    59 tokens (    0.74 ms per token,  1349.31 tokens per second)\n",
      "llama_print_timings:        eval time =     313.73 ms /    19 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     364.37 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /    37 runs   (    0.05 ms per token, 18658.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    35 tokens (    0.97 ms per token,  1028.93 tokens per second)\n",
      "llama_print_timings:        eval time =     594.40 ms /    36 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     642.19 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    43 runs   (    0.05 ms per token, 18711.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    56 tokens (    0.77 ms per token,  1292.50 tokens per second)\n",
      "llama_print_timings:        eval time =     698.84 ms /    42 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     758.51 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18599.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.09 ms /    62 tokens (    0.71 ms per token,  1406.09 tokens per second)\n",
      "llama_print_timings:        eval time =     902.91 ms /    54 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     967.75 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18557.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.01 ms /    54 tokens (    0.80 ms per token,  1255.46 tokens per second)\n",
      "llama_print_timings:        eval time =     715.00 ms /    43 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     774.19 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    59 runs   (    0.05 ms per token, 18641.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.54 ms /    50 tokens (    0.85 ms per token,  1175.45 tokens per second)\n",
      "llama_print_timings:        eval time =     966.46 ms /    58 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =    1031.36 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18338.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.57 ms /    25 tokens (    1.22 ms per token,   817.66 tokens per second)\n",
      "llama_print_timings:        eval time =     263.87 ms /    16 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     300.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18555.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    68 tokens (    0.73 ms per token,  1365.76 tokens per second)\n",
      "llama_print_timings:        eval time =     753.46 ms /    45 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =     820.28 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18414.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.92 ms /    35 tokens (    0.97 ms per token,  1031.72 tokens per second)\n",
      "llama_print_timings:        eval time =     362.99 ms /    22 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     405.37 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    86 runs   (    0.05 ms per token, 18586.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.15 ms /    89 tokens (    0.65 ms per token,  1530.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.19 ms /    85 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =    1526.63 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    47 runs   (    0.05 ms per token, 18702.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.43 ms /    49 tokens (    0.87 ms per token,  1154.79 tokens per second)\n",
      "llama_print_timings:        eval time =     763.82 ms /    46 runs   (   16.60 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     823.62 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /    61 runs   (    0.05 ms per token, 18597.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    71 tokens (    0.71 ms per token,  1417.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.42 ms /    60 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1081.16 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /    30 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    28 tokens (    1.10 ms per token,   912.62 tokens per second)\n",
      "llama_print_timings:        eval time =     478.52 ms /    29 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     521.16 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /    67 runs   (    0.05 ms per token, 18631.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    74 tokens (    0.68 ms per token,  1466.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.22 ms /    66 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1185.97 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    34 runs   (    0.05 ms per token, 18269.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    58 tokens (    0.75 ms per token,  1330.73 tokens per second)\n",
      "llama_print_timings:        eval time =     548.17 ms /    33 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     604.97 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18550.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    55 tokens (    0.78 ms per token,  1276.58 tokens per second)\n",
      "llama_print_timings:        eval time =     513.38 ms /    31 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     568.02 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18695.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    58 tokens (    0.75 ms per token,  1330.55 tokens per second)\n",
      "llama_print_timings:        eval time =     834.20 ms /    50 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     897.09 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /    36 runs   (    0.05 ms per token, 18789.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.74 ms /    58 tokens (    0.75 ms per token,  1325.90 tokens per second)\n",
      "llama_print_timings:        eval time =     581.78 ms /    35 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     639.30 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18574.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.32 ms /    66 tokens (    0.75 ms per token,  1338.28 tokens per second)\n",
      "llama_print_timings:        eval time =     904.64 ms /    54 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     974.74 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    75 runs   (    0.05 ms per token, 18582.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    66 tokens (    0.75 ms per token,  1335.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1241.81 ms /    74 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1320.98 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    38 runs   (    0.06 ms per token, 18155.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.98 ms /    47 tokens (    0.79 ms per token,  1270.85 tokens per second)\n",
      "llama_print_timings:        eval time =     611.86 ms /    37 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     663.47 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.38 ms /    91 tokens (    0.64 ms per token,  1558.89 tokens per second)\n",
      "llama_print_timings:        eval time =     707.60 ms /    42 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =     782.23 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18429.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.30 ms /    38 tokens (    0.90 ms per token,  1107.87 tokens per second)\n",
      "llama_print_timings:        eval time =     677.11 ms /    41 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     727.56 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    64 runs   (    0.05 ms per token, 18675.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.78 ms /    51 tokens (    0.84 ms per token,  1192.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1051.05 ms /    63 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =    1117.93 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    72 runs   (    0.05 ms per token, 18537.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    52 tokens (    0.82 ms per token,  1213.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.50 ms /    71 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =    1258.15 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18563.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.60 ms /    27 tokens (    1.13 ms per token,   882.32 tokens per second)\n",
      "llama_print_timings:        eval time =     858.65 ms /    52 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     909.67 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18506.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    24 tokens (    1.15 ms per token,   871.30 tokens per second)\n",
      "llama_print_timings:        eval time =     445.06 ms /    27 runs   (   16.48 ms per token,    60.67 tokens per second)\n",
      "llama_print_timings:       total time =     482.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18646.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.68 ms /    44 tokens (    0.83 ms per token,  1199.56 tokens per second)\n",
      "llama_print_timings:        eval time =     561.46 ms /    34 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     610.52 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    93 runs   (    0.05 ms per token, 18626.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.93 ms /    87 tokens (    0.67 ms per token,  1501.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1551.93 ms /    92 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =    1647.19 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    63 runs   (    0.05 ms per token, 18589.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    61 tokens (    0.72 ms per token,  1391.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1037.57 ms /    62 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =    1105.61 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    81 runs   (    0.05 ms per token, 18493.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.86 ms /    52 tokens (    0.82 ms per token,  1213.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1338.48 ms /    80 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1413.56 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    59 runs   (    0.05 ms per token, 18576.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    79 tokens (    0.65 ms per token,  1539.18 tokens per second)\n",
      "llama_print_timings:        eval time =     976.48 ms /    58 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =    1050.35 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18550.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.46 ms /    42 tokens (    0.87 ms per token,  1152.04 tokens per second)\n",
      "llama_print_timings:        eval time =     512.05 ms /    31 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     560.40 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18474.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    53 tokens (    0.81 ms per token,  1231.30 tokens per second)\n",
      "llama_print_timings:        eval time =     765.37 ms /    46 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     826.30 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.42 ms /    41 tokens (    0.89 ms per token,  1125.79 tokens per second)\n",
      "llama_print_timings:        eval time =     561.53 ms /    34 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     610.91 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    28 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.52 ms /    57 tokens (    0.76 ms per token,  1309.59 tokens per second)\n",
      "llama_print_timings:        eval time =     446.65 ms /    27 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     500.64 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18572.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.39 ms /    38 tokens (    0.90 ms per token,  1105.04 tokens per second)\n",
      "llama_print_timings:        eval time =     511.84 ms /    31 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     558.02 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18355.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.19 ms /    47 tokens (    0.79 ms per token,  1263.88 tokens per second)\n",
      "llama_print_timings:        eval time =     396.64 ms /    24 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     443.51 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    61 tokens (    0.72 ms per token,  1384.92 tokens per second)\n",
      "llama_print_timings:        eval time =     650.06 ms /    39 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     708.55 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18617.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    68 tokens (    0.73 ms per token,  1367.66 tokens per second)\n",
      "llama_print_timings:        eval time =     803.83 ms /    48 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     872.18 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    44 runs   (    0.05 ms per token, 18787.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.37 ms /   103 tokens (    0.63 ms per token,  1575.57 tokens per second)\n",
      "llama_print_timings:        eval time =     724.96 ms /    43 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     806.75 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18462.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.74 tokens per second)\n",
      "llama_print_timings:        eval time =     693.11 ms /    42 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     736.69 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    53 runs   (    0.05 ms per token, 18794.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.64 ms /    40 tokens (    0.87 ms per token,  1154.60 tokens per second)\n",
      "llama_print_timings:        eval time =     862.15 ms /    52 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     916.63 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18531.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.22 ms /    46 tokens (    0.81 ms per token,  1235.93 tokens per second)\n",
      "llama_print_timings:        eval time =     830.32 ms /    50 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     887.18 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.84 ms /    28 tokens (    1.10 ms per token,   907.79 tokens per second)\n",
      "llama_print_timings:        eval time =     379.31 ms /    23 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     418.77 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18441.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.59 ms /    50 tokens (    0.85 ms per token,  1174.09 tokens per second)\n",
      "llama_print_timings:        eval time =     495.70 ms /    30 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     549.60 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    71 runs   (    0.05 ms per token, 18649.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.40 ms /    72 tokens (    0.70 ms per token,  1428.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.41 ms /    70 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1254.36 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    48 runs   (    0.05 ms per token, 18369.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    63 tokens (    0.70 ms per token,  1425.02 tokens per second)\n",
      "llama_print_timings:        eval time =     785.78 ms /    47 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     849.82 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    85 runs   (    0.05 ms per token, 18738.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.95 ms /    70 tokens (    0.71 ms per token,  1401.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1412.18 ms /    84 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =    1496.09 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18678.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.91 ms /    36 tokens (    0.94 ms per token,  1061.57 tokens per second)\n",
      "llama_print_timings:        eval time =     627.34 ms /    38 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     675.63 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /    29 runs   (    0.05 ms per token, 18296.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    24 tokens (    1.14 ms per token,   877.55 tokens per second)\n",
      "llama_print_timings:        eval time =     461.73 ms /    28 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     499.52 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    26 tokens (    1.17 ms per token,   853.47 tokens per second)\n",
      "llama_print_timings:        eval time =     412.35 ms /    25 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     452.37 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18526.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.15 ms /    47 tokens (    0.79 ms per token,  1265.14 tokens per second)\n",
      "llama_print_timings:        eval time =     696.29 ms /    42 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     749.74 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    65 runs   (    0.05 ms per token, 18507.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    53 tokens (    0.81 ms per token,  1230.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1068.61 ms /    64 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =    1137.17 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18489.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.42 ms /    39 tokens (    0.88 ms per token,  1133.19 tokens per second)\n",
      "llama_print_timings:        eval time =     761.69 ms /    46 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     815.01 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /    21 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.43 ms /    47 tokens (    0.80 ms per token,  1255.68 tokens per second)\n",
      "llama_print_timings:        eval time =     330.48 ms /    20 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     376.11 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18572.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.14 ms /    35 tokens (    0.98 ms per token,  1025.31 tokens per second)\n",
      "llama_print_timings:        eval time =     512.20 ms /    31 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     558.18 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /    38 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    49 tokens (    0.88 ms per token,  1141.13 tokens per second)\n",
      "llama_print_timings:        eval time =     613.04 ms /    37 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     670.58 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18572.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.48 ms /    64 tokens (    0.69 ms per token,  1438.98 tokens per second)\n",
      "llama_print_timings:        eval time =     516.83 ms /    31 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     572.79 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18551.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.63 ms /    25 tokens (    1.23 ms per token,   816.30 tokens per second)\n",
      "llama_print_timings:        eval time =     677.21 ms /    41 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     724.11 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18628.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    54 tokens (    0.80 ms per token,  1247.63 tokens per second)\n",
      "llama_print_timings:        eval time =     715.66 ms /    43 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     775.93 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18498.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.86 ms /    44 tokens (    0.84 ms per token,  1193.87 tokens per second)\n",
      "llama_print_timings:        eval time =     562.00 ms /    34 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     612.17 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18619.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.69 ms /    32 tokens (    0.99 ms per token,  1009.81 tokens per second)\n",
      "llama_print_timings:        eval time =     379.82 ms /    23 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     420.89 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18683.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.47 ms /    48 tokens (    0.78 ms per token,  1280.99 tokens per second)\n",
      "llama_print_timings:        eval time =     713.85 ms /    43 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     767.62 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /    65 runs   (    0.05 ms per token, 18721.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.88 ms /    85 tokens (    0.68 ms per token,  1468.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.94 ms /    64 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1163.12 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18543.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    53 tokens (    0.82 ms per token,  1225.09 tokens per second)\n",
      "llama_print_timings:        eval time =     681.64 ms /    41 runs   (   16.63 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     740.15 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /    23 runs   (    0.05 ms per token, 18239.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.64 ms /    39 tokens (    0.89 ms per token,  1125.74 tokens per second)\n",
      "llama_print_timings:        eval time =     363.84 ms /    22 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     408.22 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18567.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.18 ms /    60 tokens (    0.74 ms per token,  1358.05 tokens per second)\n",
      "llama_print_timings:        eval time =     802.25 ms /    48 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     865.03 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.15 ms /    77 tokens (    0.66 ms per token,  1505.44 tokens per second)\n",
      "llama_print_timings:        eval time =     571.48 ms /    34 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     636.25 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18369.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    51 tokens (    0.84 ms per token,  1186.21 tokens per second)\n",
      "llama_print_timings:        eval time =     664.38 ms /    40 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     722.34 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /    67 runs   (    0.05 ms per token, 18467.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.71 ms /    74 tokens (    0.69 ms per token,  1459.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.52 ms /    66 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =    1187.25 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    57 runs   (    0.05 ms per token, 18572.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.55 ms /    63 tokens (    0.71 ms per token,  1413.98 tokens per second)\n",
      "llama_print_timings:        eval time =     938.25 ms /    56 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =    1004.92 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18583.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.14 ms /    47 tokens (    0.79 ms per token,  1265.38 tokens per second)\n",
      "llama_print_timings:        eval time =     595.66 ms /    36 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     647.13 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18510.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    57 tokens (    0.77 ms per token,  1304.68 tokens per second)\n",
      "llama_print_timings:        eval time =     699.95 ms /    42 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     760.02 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18389.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.51 ms /    48 tokens (    0.78 ms per token,  1279.80 tokens per second)\n",
      "llama_print_timings:        eval time =     596.02 ms /    36 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     647.75 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /    22 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    43 tokens (    0.85 ms per token,  1169.85 tokens per second)\n",
      "llama_print_timings:        eval time =     347.10 ms /    21 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     391.98 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    52 runs   (    0.05 ms per token, 18826.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.40 ms /    36 tokens (    0.96 ms per token,  1046.66 tokens per second)\n",
      "llama_print_timings:        eval time =     844.61 ms /    51 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     898.90 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /    10 runs   (    0.05 ms per token, 19011.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    15 tokens (    1.83 ms per token,   545.59 tokens per second)\n",
      "llama_print_timings:        eval time =     148.31 ms /     9 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     179.82 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /    31 runs   (    0.06 ms per token, 18128.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    37 tokens (    0.93 ms per token,  1074.18 tokens per second)\n",
      "llama_print_timings:        eval time =     495.76 ms /    30 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     542.41 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.55 ms /    64 tokens (    0.70 ms per token,  1436.49 tokens per second)\n",
      "llama_print_timings:        eval time =     634.85 ms /    38 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     693.74 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18495.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    26 tokens (    1.18 ms per token,   846.93 tokens per second)\n",
      "llama_print_timings:        eval time =     231.16 ms /    14 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     267.29 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    75 runs   (    0.05 ms per token, 18541.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.47 ms /    80 tokens (    0.64 ms per token,  1554.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.73 ms /    74 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1329.43 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    44 runs   (    0.05 ms per token, 18620.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    34 tokens (    1.00 ms per token,  1002.98 tokens per second)\n",
      "llama_print_timings:        eval time =     710.79 ms /    43 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     761.73 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    66 runs   (    0.05 ms per token, 18591.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.63 ms /    73 tokens (    0.69 ms per token,  1441.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.46 ms /    65 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =    1169.87 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18525.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.91 ms /    45 tokens (    0.82 ms per token,  1219.05 tokens per second)\n",
      "llama_print_timings:        eval time =     797.00 ms /    48 runs   (   16.60 ms per token,    60.23 tokens per second)\n",
      "llama_print_timings:       total time =     851.97 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18498.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.27 ms /    34 tokens (    1.01 ms per token,   992.06 tokens per second)\n",
      "llama_print_timings:        eval time =     545.17 ms /    33 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     592.28 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18555.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.76 ms /    74 tokens (    0.69 ms per token,  1457.84 tokens per second)\n",
      "llama_print_timings:        eval time =     756.00 ms /    45 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     823.75 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    56 runs   (    0.05 ms per token, 18306.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.11 ms /   115 tokens (    0.64 ms per token,  1572.86 tokens per second)\n",
      "llama_print_timings:        eval time =     929.57 ms /    55 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =    1024.32 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18629.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    57 tokens (    0.76 ms per token,  1309.14 tokens per second)\n",
      "llama_print_timings:        eval time =     919.16 ms /    55 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     984.30 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    35 runs   (    0.05 ms per token, 18676.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.03 ms /    46 tokens (    0.80 ms per token,  1242.37 tokens per second)\n",
      "llama_print_timings:        eval time =     562.07 ms /    34 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     612.64 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /    22 runs   (    0.05 ms per token, 18723.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.24 ms /    46 tokens (    0.81 ms per token,  1235.33 tokens per second)\n",
      "llama_print_timings:        eval time =     347.16 ms /    21 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     392.12 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    70 runs   (    0.05 ms per token, 18557.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    56 tokens (    0.78 ms per token,  1280.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.03 ms /    69 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =    1225.42 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18564.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.26 ms /    54 tokens (    0.80 ms per token,  1248.38 tokens per second)\n",
      "llama_print_timings:        eval time =     732.81 ms /    44 runs   (   16.65 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     793.28 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    51 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.00 ms /    45 tokens (    0.82 ms per token,  1216.15 tokens per second)\n",
      "llama_print_timings:        eval time =     830.72 ms /    50 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     887.35 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /    11 runs   (    0.05 ms per token, 18425.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.94 ms /    17 tokens (    1.58 ms per token,   631.13 tokens per second)\n",
      "llama_print_timings:        eval time =     164.97 ms /    10 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     195.87 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.39 ms /    70 tokens (    0.72 ms per token,  1389.22 tokens per second)\n",
      "llama_print_timings:        eval time =     838.89 ms /    50 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     908.67 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18482.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    54 tokens (    0.81 ms per token,  1235.10 tokens per second)\n",
      "llama_print_timings:        eval time =     614.79 ms /    37 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     672.73 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /    37 runs   (    0.05 ms per token, 18715.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.13 ms /    45 tokens (    0.83 ms per token,  1211.83 tokens per second)\n",
      "llama_print_timings:        eval time =     595.24 ms /    36 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     646.55 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    77 runs   (    0.05 ms per token, 18412.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.43 ms /    72 tokens (    0.70 ms per token,  1427.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1278.86 ms /    76 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =    1359.18 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     5 runs   (    0.05 ms per token, 18726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    17 tokens (    1.58 ms per token,   632.06 tokens per second)\n",
      "llama_print_timings:        eval time =      65.94 ms /     4 runs   (   16.48 ms per token,    60.66 tokens per second)\n",
      "llama_print_timings:       total time =      94.22 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.48 ms /    80 tokens (    0.64 ms per token,  1554.00 tokens per second)\n",
      "llama_print_timings:        eval time =     808.85 ms /    48 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     879.20 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    36 runs   (    0.05 ms per token, 18329.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    51 tokens (    0.85 ms per token,  1183.24 tokens per second)\n",
      "llama_print_timings:        eval time =     580.03 ms /    35 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     636.96 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.82 ms /    40 tokens (    0.87 ms per token,  1148.67 tokens per second)\n",
      "llama_print_timings:        eval time =     380.36 ms /    23 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     424.87 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    70 runs   (    0.05 ms per token, 18392.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.31 ms /    54 tokens (    0.80 ms per token,  1246.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.22 ms /    69 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1224.91 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18574.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.33 ms /    65 tokens (    0.76 ms per token,  1317.74 tokens per second)\n",
      "llama_print_timings:        eval time =     905.13 ms /    54 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =     976.24 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    30 runs   (    0.05 ms per token, 18495.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.84 ms /    34 tokens (    1.00 ms per token,  1004.76 tokens per second)\n",
      "llama_print_timings:        eval time =     479.19 ms /    29 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     524.97 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /    55 runs   (    0.05 ms per token, 18675.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.20 ms /    46 tokens (    0.81 ms per token,  1236.49 tokens per second)\n",
      "llama_print_timings:        eval time =     898.55 ms /    54 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     957.14 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    52 runs   (    0.05 ms per token, 18598.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    59 tokens (    0.75 ms per token,  1340.60 tokens per second)\n",
      "llama_print_timings:        eval time =     852.32 ms /    51 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     916.22 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /    72 runs   (    0.05 ms per token, 18480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.46 ms /    69 tokens (    0.73 ms per token,  1367.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1193.88 ms /    71 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =    1271.98 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18418.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.01 ms /    60 tokens (    0.73 ms per token,  1363.23 tokens per second)\n",
      "llama_print_timings:        eval time =     667.53 ms /    40 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     728.11 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /    30 runs   (    0.05 ms per token, 18427.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.19 ms /    47 tokens (    0.79 ms per token,  1263.88 tokens per second)\n",
      "llama_print_timings:        eval time =     479.42 ms /    29 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     527.74 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    52 tokens (    0.83 ms per token,  1203.09 tokens per second)\n",
      "llama_print_timings:        eval time =     715.26 ms /    43 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     775.45 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    43 runs   (    0.06 ms per token, 17615.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.14 ms /    87 tokens (    0.67 ms per token,  1496.31 tokens per second)\n",
      "llama_print_timings:        eval time =     708.48 ms /    42 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.10 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18511.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.39 ms /    48 tokens (    0.78 ms per token,  1283.90 tokens per second)\n",
      "llama_print_timings:        eval time =     747.63 ms /    45 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     802.35 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18618.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    65 tokens (    0.76 ms per token,  1311.41 tokens per second)\n",
      "llama_print_timings:        eval time =     500.21 ms /    30 runs   (   16.67 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     560.80 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /    18 runs   (    0.05 ms per token, 18750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.17 ms /    30 tokens (    1.04 ms per token,   962.43 tokens per second)\n",
      "llama_print_timings:        eval time =     280.58 ms /    17 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     318.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /    25 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.70 ms /    65 tokens (    0.76 ms per token,  1307.93 tokens per second)\n",
      "llama_print_timings:        eval time =     399.25 ms /    24 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     457.84 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18436.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.39 ms /    32 tokens (    0.98 ms per token,  1019.60 tokens per second)\n",
      "llama_print_timings:        eval time =     396.50 ms /    24 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     437.48 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.31 ms /    52 tokens (    0.83 ms per token,  1200.70 tokens per second)\n",
      "llama_print_timings:        eval time =     563.75 ms /    34 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     620.04 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18601.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.38 ms /    71 tokens (    0.71 ms per token,  1409.26 tokens per second)\n",
      "llama_print_timings:        eval time =     957.81 ms /    57 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =    1030.16 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    71 runs   (    0.05 ms per token, 18758.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.60 ms /    42 tokens (    0.87 ms per token,  1147.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.79 ms /    70 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =    1231.18 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /    33 runs   (    0.05 ms per token, 18323.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.95 ms /    33 tokens (    1.03 ms per token,   971.90 tokens per second)\n",
      "llama_print_timings:        eval time =     528.82 ms /    32 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     575.70 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18382.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.52 ms /    47 tokens (    0.80 ms per token,  1252.60 tokens per second)\n",
      "llama_print_timings:        eval time =     645.91 ms /    39 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     698.51 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18579.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.30 ms /    70 tokens (    0.72 ms per token,  1391.79 tokens per second)\n",
      "llama_print_timings:        eval time =     737.78 ms /    44 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     805.24 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    79 runs   (    0.05 ms per token, 18570.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.22 ms /    48 tokens (    0.78 ms per token,  1289.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.55 ms /    78 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =    1372.72 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18615.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.43 ms /    81 tokens (    0.70 ms per token,  1435.51 tokens per second)\n",
      "llama_print_timings:        eval time =     522.43 ms /    31 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     591.23 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18531.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.90 ms /    27 tokens (    1.14 ms per token,   873.67 tokens per second)\n",
      "llama_print_timings:        eval time =     429.37 ms /    26 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     470.19 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18576.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.61 ms /    42 tokens (    0.87 ms per token,  1147.38 tokens per second)\n",
      "llama_print_timings:        eval time =     863.70 ms /    52 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     920.44 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18592.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.86 ms /    27 tokens (    1.14 ms per token,   874.98 tokens per second)\n",
      "llama_print_timings:        eval time =     677.20 ms /    41 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     723.67 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    75 runs   (    0.05 ms per token, 18523.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.00 ms /    85 tokens (    0.68 ms per token,  1465.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.43 ms /    74 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =    1337.07 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    35 runs   (    0.06 ms per token, 17884.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    56 tokens (    0.78 ms per token,  1287.03 tokens per second)\n",
      "llama_print_timings:        eval time =     564.93 ms /    34 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     621.98 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.32 ms /    36 tokens (    0.95 ms per token,  1049.04 tokens per second)\n",
      "llama_print_timings:        eval time =     412.99 ms /    25 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     456.51 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18341.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.59 ms /    39 tokens (    0.89 ms per token,  1127.33 tokens per second)\n",
      "llama_print_timings:        eval time =     396.45 ms /    24 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     440.09 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    40 runs   (    0.05 ms per token, 18770.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.47 ms /    31 tokens (    1.02 ms per token,   984.97 tokens per second)\n",
      "llama_print_timings:        eval time =     644.44 ms /    39 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     690.71 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    34 runs   (    0.05 ms per token, 18318.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.59 ms /    81 tokens (    0.70 ms per token,  1431.35 tokens per second)\n",
      "llama_print_timings:        eval time =     556.32 ms /    33 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     626.64 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18577.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.98 ms /    34 tokens (    1.00 ms per token,  1000.50 tokens per second)\n",
      "llama_print_timings:        eval time =     760.29 ms /    46 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     812.24 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18448.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    24 tokens (    1.15 ms per token,   870.99 tokens per second)\n",
      "llama_print_timings:        eval time =     710.29 ms /    43 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     753.88 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    83 runs   (    0.05 ms per token, 18543.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    51 tokens (    0.85 ms per token,  1178.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1373.35 ms /    82 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =    1448.77 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    65 runs   (    0.05 ms per token, 18529.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.12 ms /    75 tokens (    0.68 ms per token,  1467.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1077.32 ms /    64 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1153.93 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18650.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.58 ms /    49 tokens (    0.87 ms per token,  1150.75 tokens per second)\n",
      "llama_print_timings:        eval time =     545.79 ms /    33 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     601.36 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18437.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.87 ms /    42 tokens (    0.88 ms per token,  1139.26 tokens per second)\n",
      "llama_print_timings:        eval time =     330.52 ms /    20 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     374.95 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /    42 runs   (    0.05 ms per token, 18716.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.65 ms /    41 tokens (    0.89 ms per token,  1118.69 tokens per second)\n",
      "llama_print_timings:        eval time =     677.86 ms /    41 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     730.50 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /    30 runs   (    0.05 ms per token, 18645.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.23 ms /    53 tokens (    0.82 ms per token,  1226.14 tokens per second)\n",
      "llama_print_timings:        eval time =     479.71 ms /    29 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     534.80 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18574.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    53 tokens (    0.82 ms per token,  1224.33 tokens per second)\n",
      "llama_print_timings:        eval time =     698.88 ms /    42 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     758.68 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    20 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.05 ms /    45 tokens (    0.82 ms per token,  1214.74 tokens per second)\n",
      "llama_print_timings:        eval time =     313.99 ms /    19 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     358.03 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18363.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.22 ms /    46 tokens (    0.81 ms per token,  1235.76 tokens per second)\n",
      "llama_print_timings:        eval time =     347.26 ms /    21 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     392.38 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18542.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.61 ms /    63 tokens (    0.71 ms per token,  1412.30 tokens per second)\n",
      "llama_print_timings:        eval time =     465.84 ms /    28 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     521.57 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /    30 runs   (    0.05 ms per token, 18326.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.36 ms /    54 tokens (    0.80 ms per token,  1245.27 tokens per second)\n",
      "llama_print_timings:        eval time =     479.96 ms /    29 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     535.10 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    81 runs   (    0.05 ms per token, 18446.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    65 tokens (    0.76 ms per token,  1311.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1344.21 ms /    80 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =    1426.75 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    57 runs   (    0.05 ms per token, 18737.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.75 ms /    59 tokens (    0.74 ms per token,  1348.54 tokens per second)\n",
      "llama_print_timings:        eval time =     936.74 ms /    56 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1002.67 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /    57 runs   (    0.05 ms per token, 18676.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.83 ms /    50 tokens (    0.86 ms per token,  1167.41 tokens per second)\n",
      "llama_print_timings:        eval time =     933.88 ms /    56 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     998.47 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /    28 runs   (    0.05 ms per token, 18217.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.06 ms /    19 tokens (    1.42 ms per token,   702.14 tokens per second)\n",
      "llama_print_timings:        eval time =     445.67 ms /    27 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     483.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18402.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    28 tokens (    1.11 ms per token,   901.71 tokens per second)\n",
      "llama_print_timings:        eval time =     660.99 ms /    40 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     707.75 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /    29 runs   (    0.05 ms per token, 18721.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    33 tokens (    1.04 ms per token,   962.44 tokens per second)\n",
      "llama_print_timings:        eval time =     462.70 ms /    28 runs   (   16.52 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     507.82 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    51 tokens (    0.84 ms per token,  1184.06 tokens per second)\n",
      "llama_print_timings:        eval time =     446.58 ms /    27 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     499.97 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18462.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.31 ms /    63 tokens (    0.70 ms per token,  1421.64 tokens per second)\n",
      "llama_print_timings:        eval time =     701.97 ms /    42 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     762.68 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18636.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.62 ms /    56 tokens (    0.78 ms per token,  1283.79 tokens per second)\n",
      "llama_print_timings:        eval time =     564.92 ms /    34 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     621.59 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    79 runs   (    0.05 ms per token, 18579.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.50 ms /    72 tokens (    0.70 ms per token,  1425.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1313.43 ms /    78 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =    1395.49 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    56 runs   (    0.05 ms per token, 18555.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.77 ms /    50 tokens (    0.86 ms per token,  1169.02 tokens per second)\n",
      "llama_print_timings:        eval time =     917.02 ms /    55 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     981.45 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18640.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.20 ms /    36 tokens (    0.95 ms per token,  1052.48 tokens per second)\n",
      "llama_print_timings:        eval time =     545.26 ms /    33 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     591.80 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.25 ms /    45 tokens (    0.83 ms per token,  1208.15 tokens per second)\n",
      "llama_print_timings:        eval time =     429.74 ms /    26 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     477.12 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18588.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.68 ms /    80 tokens (    0.65 ms per token,  1548.11 tokens per second)\n",
      "llama_print_timings:        eval time =     724.30 ms /    43 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =     792.89 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    47 runs   (    0.05 ms per token, 18695.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.57 ms /    65 tokens (    0.76 ms per token,  1311.17 tokens per second)\n",
      "llama_print_timings:        eval time =     769.96 ms /    46 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     837.03 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /    25 runs   (    0.05 ms per token, 18726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    53 tokens (    0.81 ms per token,  1228.84 tokens per second)\n",
      "llama_print_timings:        eval time =     396.90 ms /    24 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     449.10 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    49 runs   (    0.05 ms per token, 18688.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.35 ms /    71 tokens (    0.71 ms per token,  1410.10 tokens per second)\n",
      "llama_print_timings:        eval time =     805.54 ms /    48 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =     874.49 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18560.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.76 ms /    90 tokens (    0.65 ms per token,  1531.73 tokens per second)\n",
      "llama_print_timings:        eval time =     809.59 ms /    48 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     886.58 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    68 runs   (    0.05 ms per token, 18483.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.98 ms /    75 tokens (    0.68 ms per token,  1471.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.83 ms /    67 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1204.53 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18738.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.84 ms /    27 tokens (    1.14 ms per token,   875.57 tokens per second)\n",
      "llama_print_timings:        eval time =     478.82 ms /    29 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     520.30 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    41 runs   (    0.05 ms per token, 18815.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.67 ms /    39 tokens (    0.89 ms per token,  1125.02 tokens per second)\n",
      "llama_print_timings:        eval time =     661.22 ms /    40 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     711.10 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.98 ms /    44 tokens (    0.84 ms per token,  1189.96 tokens per second)\n",
      "llama_print_timings:        eval time =     446.34 ms /    27 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     493.53 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18398.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.90 ms /    49 tokens (    0.88 ms per token,  1142.22 tokens per second)\n",
      "llama_print_timings:        eval time =     264.63 ms /    16 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     313.59 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18569.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.22 ms /    30 tokens (    1.04 ms per token,   960.95 tokens per second)\n",
      "llama_print_timings:        eval time =     429.31 ms /    26 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     470.50 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18384.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    44 tokens (    0.84 ms per token,  1192.35 tokens per second)\n",
      "llama_print_timings:        eval time =     529.00 ms /    32 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     577.73 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18615.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.87 ms /    67 tokens (    0.74 ms per token,  1343.47 tokens per second)\n",
      "llama_print_timings:        eval time =     635.61 ms /    38 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =     699.68 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    40 runs   (    0.05 ms per token, 18552.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.51 ms /    49 tokens (    0.87 ms per token,  1152.81 tokens per second)\n",
      "llama_print_timings:        eval time =     647.15 ms /    39 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     703.86 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    47 runs   (    0.06 ms per token, 18160.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    50 tokens (    0.85 ms per token,  1170.93 tokens per second)\n",
      "llama_print_timings:        eval time =     765.65 ms /    46 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     825.19 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    56 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.75 ms /    84 tokens (    0.69 ms per token,  1454.62 tokens per second)\n",
      "llama_print_timings:        eval time =     928.17 ms /    55 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1007.01 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18469.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.46 ms /    82 tokens (    0.69 ms per token,  1452.33 tokens per second)\n",
      "llama_print_timings:        eval time =     573.49 ms /    34 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     642.78 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    54 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.80 ms /    57 tokens (    0.77 ms per token,  1301.25 tokens per second)\n",
      "llama_print_timings:        eval time =     885.83 ms /    53 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     949.52 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /    62 runs   (    0.05 ms per token, 18501.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    37 tokens (    0.93 ms per token,  1080.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1013.87 ms /    61 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =    1071.46 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18399.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.44 ms /    64 tokens (    0.69 ms per token,  1440.31 tokens per second)\n",
      "llama_print_timings:        eval time =     651.85 ms /    39 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     710.78 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.70 ms /    32 tokens (    0.99 ms per token,  1009.59 tokens per second)\n",
      "llama_print_timings:        eval time =     346.95 ms /    21 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     386.58 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18460.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.66 ms /    64 tokens (    0.70 ms per token,  1433.05 tokens per second)\n",
      "llama_print_timings:        eval time =     770.13 ms /    46 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     831.91 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18472.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    65 tokens (    0.76 ms per token,  1308.19 tokens per second)\n",
      "llama_print_timings:        eval time =     736.36 ms /    44 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =     803.00 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    53 runs   (    0.05 ms per token, 18714.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    57 tokens (    0.77 ms per token,  1305.60 tokens per second)\n",
      "llama_print_timings:        eval time =     868.99 ms /    52 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     931.98 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    99 runs   (    0.05 ms per token, 18425.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.86 ms /    98 tokens (    0.66 ms per token,  1510.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1657.15 ms /    98 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =    1761.25 ms /   196 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /    25 runs   (    0.05 ms per token, 18615.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.75 ms /    43 tokens (    0.85 ms per token,  1170.10 tokens per second)\n",
      "llama_print_timings:        eval time =     397.03 ms /    24 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     443.16 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    35 runs   (    0.05 ms per token, 18676.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.89 ms /    44 tokens (    0.84 ms per token,  1192.83 tokens per second)\n",
      "llama_print_timings:        eval time =     562.61 ms /    34 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     613.12 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    55 runs   (    0.05 ms per token, 18419.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    55 tokens (    0.79 ms per token,  1263.09 tokens per second)\n",
      "llama_print_timings:        eval time =     902.02 ms /    54 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     966.05 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18527.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.18 ms /    61 tokens (    0.72 ms per token,  1380.68 tokens per second)\n",
      "llama_print_timings:        eval time =     634.16 ms /    38 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     692.74 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18507.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    70 tokens (    0.72 ms per token,  1398.13 tokens per second)\n",
      "llama_print_timings:        eval time =     502.29 ms /    30 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     563.68 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18538.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.15 ms /    45 tokens (    0.83 ms per token,  1211.40 tokens per second)\n",
      "llama_print_timings:        eval time =     545.64 ms /    33 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     594.86 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18488.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    37 tokens (    0.93 ms per token,  1074.11 tokens per second)\n",
      "llama_print_timings:        eval time =     727.51 ms /    44 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     778.43 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18447.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    50 tokens (    0.86 ms per token,  1163.22 tokens per second)\n",
      "llama_print_timings:        eval time =     782.46 ms /    47 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     842.61 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18580.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.37 ms /    48 tokens (    0.78 ms per token,  1284.62 tokens per second)\n",
      "llama_print_timings:        eval time =     630.60 ms /    38 runs   (   16.59 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     683.24 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    85 runs   (    0.05 ms per token, 18514.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.00 ms /    93 tokens (    0.63 ms per token,  1576.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1419.52 ms /    84 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =    1511.80 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /    21 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.60 ms /    24 tokens (    1.15 ms per token,   869.66 tokens per second)\n",
      "llama_print_timings:        eval time =     330.30 ms /    20 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     364.92 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18595.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.09 ms /    45 tokens (    0.82 ms per token,  1213.40 tokens per second)\n",
      "llama_print_timings:        eval time =     797.60 ms /    48 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     852.24 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /    20 runs   (    0.05 ms per token, 18248.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.60 ms /    71 tokens (    0.71 ms per token,  1403.19 tokens per second)\n",
      "llama_print_timings:        eval time =     316.90 ms /    19 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     374.97 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /    29 runs   (    0.05 ms per token, 18673.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.31 ms /    36 tokens (    0.95 ms per token,  1049.10 tokens per second)\n",
      "llama_print_timings:        eval time =     462.89 ms /    28 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     507.54 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    54 runs   (    0.05 ms per token, 18887.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.59 ms /    63 tokens (    0.71 ms per token,  1412.94 tokens per second)\n",
      "llama_print_timings:        eval time =     887.62 ms /    53 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     951.76 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18607.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.26 ms /    62 tokens (    0.71 ms per token,  1400.97 tokens per second)\n",
      "llama_print_timings:        eval time =     887.67 ms /    53 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     952.25 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18305.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.64 ms /    42 tokens (    0.87 ms per token,  1146.26 tokens per second)\n",
      "llama_print_timings:        eval time =     562.29 ms /    34 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     611.82 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    54 runs   (    0.05 ms per token, 18430.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.14 ms /    68 tokens (    0.74 ms per token,  1356.15 tokens per second)\n",
      "llama_print_timings:        eval time =     889.64 ms /    53 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     959.66 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    49 tokens (    0.87 ms per token,  1147.57 tokens per second)\n",
      "llama_print_timings:        eval time =     479.92 ms /    29 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     533.65 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18426.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    21 tokens (    1.30 ms per token,   770.19 tokens per second)\n",
      "llama_print_timings:        eval time =     413.03 ms /    25 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     449.99 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18476.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.94 ms /    76 tokens (    0.67 ms per token,  1491.83 tokens per second)\n",
      "llama_print_timings:        eval time =     672.44 ms /    40 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     739.18 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18471.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    29 tokens (    1.07 ms per token,   937.03 tokens per second)\n",
      "llama_print_timings:        eval time =     346.84 ms /    21 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     385.99 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.23 ms /    45 tokens (    0.83 ms per token,  1208.83 tokens per second)\n",
      "llama_print_timings:        eval time =     797.12 ms /    48 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     852.87 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18334.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.46 ms /    25 tokens (    1.22 ms per token,   820.64 tokens per second)\n",
      "llama_print_timings:        eval time =     379.69 ms /    23 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     419.23 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /    21 runs   (    0.05 ms per token, 18245.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    44 tokens (    0.84 ms per token,  1192.41 tokens per second)\n",
      "llama_print_timings:        eval time =     330.58 ms /    20 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     374.86 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18532.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.60 ms /    39 tokens (    0.89 ms per token,  1127.04 tokens per second)\n",
      "llama_print_timings:        eval time =     778.28 ms /    47 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     830.55 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /   101 runs   (    0.05 ms per token, 18420.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    71 tokens (    0.71 ms per token,  1406.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1684.61 ms /   100 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =    1776.08 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18508.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.70 ms /    49 tokens (    0.87 ms per token,  1147.51 tokens per second)\n",
      "llama_print_timings:        eval time =     562.68 ms /    34 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     618.40 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18495.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.86 ms /    43 tokens (    0.86 ms per token,  1166.54 tokens per second)\n",
      "llama_print_timings:        eval time =     712.44 ms /    43 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     766.61 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    93 runs   (    0.05 ms per token, 18633.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.50 ms /    56 tokens (    0.78 ms per token,  1287.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1543.88 ms /    92 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1624.44 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18451.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.08 ms /    34 tokens (    1.00 ms per token,   997.74 tokens per second)\n",
      "llama_print_timings:        eval time =     661.02 ms /    40 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     711.11 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /    28 runs   (    0.05 ms per token, 18217.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.25 ms /    29 tokens (    1.08 ms per token,   927.91 tokens per second)\n",
      "llama_print_timings:        eval time =     446.07 ms /    27 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     488.18 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.17 ms /    77 tokens (    0.66 ms per token,  1504.85 tokens per second)\n",
      "llama_print_timings:        eval time =     740.21 ms /    44 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     808.15 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /    65 runs   (    0.05 ms per token, 18683.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    52 tokens (    0.83 ms per token,  1206.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1069.39 ms /    64 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =    1138.13 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18512.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.66 ms /    41 tokens (    0.89 ms per token,  1118.42 tokens per second)\n",
      "llama_print_timings:        eval time =     964.51 ms /    58 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =    1024.08 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    52 runs   (    0.05 ms per token, 18591.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    53 tokens (    0.81 ms per token,  1229.24 tokens per second)\n",
      "llama_print_timings:        eval time =     850.50 ms /    51 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     912.97 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.84 ms /    82 tokens (    0.69 ms per token,  1442.65 tokens per second)\n",
      "llama_print_timings:        eval time =     640.57 ms /    38 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     712.17 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18614.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    55 tokens (    0.79 ms per token,  1264.05 tokens per second)\n",
      "llama_print_timings:        eval time =     581.20 ms /    35 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     638.84 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    72 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      73.53 ms /   118 tokens (    0.62 ms per token,  1604.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.43 ms /    71 runs   (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:       total time =    1302.82 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    33 runs   (    0.06 ms per token, 18102.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.40 ms /    52 tokens (    0.83 ms per token,  1198.18 tokens per second)\n",
      "llama_print_timings:        eval time =     529.86 ms /    32 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     586.60 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18534.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.93 ms /    45 tokens (    0.82 ms per token,  1218.46 tokens per second)\n",
      "llama_print_timings:        eval time =     712.99 ms /    43 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.43 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18593.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.70 ms /    64 tokens (    0.70 ms per token,  1431.93 tokens per second)\n",
      "llama_print_timings:        eval time =     752.68 ms /    45 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =     814.49 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    51 runs   (    0.05 ms per token, 18606.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    56 tokens (    0.78 ms per token,  1284.70 tokens per second)\n",
      "llama_print_timings:        eval time =     834.68 ms /    50 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     897.21 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18395.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    53 tokens (    0.82 ms per token,  1218.90 tokens per second)\n",
      "llama_print_timings:        eval time =     396.88 ms /    24 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     450.09 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /    18 runs   (    0.05 ms per token, 18730.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.76 ms /    50 tokens (    0.86 ms per token,  1169.45 tokens per second)\n",
      "llama_print_timings:        eval time =     281.04 ms /    17 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     329.77 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.72 ms /    66 tokens (    0.75 ms per token,  1327.38 tokens per second)\n",
      "llama_print_timings:        eval time =     854.75 ms /    51 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     924.25 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /    57 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.30 ms /    48 tokens (    0.78 ms per token,  1287.00 tokens per second)\n",
      "llama_print_timings:        eval time =     933.33 ms /    56 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     992.72 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    49 runs   (    0.05 ms per token, 18673.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    73 tokens (    0.69 ms per token,  1444.00 tokens per second)\n",
      "llama_print_timings:        eval time =     806.44 ms /    48 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     875.66 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /    28 runs   (    0.05 ms per token, 18445.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.39 ms /    35 tokens (    0.98 ms per token,  1017.80 tokens per second)\n",
      "llama_print_timings:        eval time =     445.98 ms /    27 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     490.84 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /    10 runs   (    0.05 ms per token, 18248.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.85 ms /    40 tokens (    0.87 ms per token,  1147.81 tokens per second)\n",
      "llama_print_timings:        eval time =     148.50 ms /     9 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     186.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18579.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.69 ms /    26 tokens (    1.18 ms per token,   847.21 tokens per second)\n",
      "llama_print_timings:        eval time =     445.85 ms /    27 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     486.66 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18579.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    58 tokens (    0.76 ms per token,  1315.73 tokens per second)\n",
      "llama_print_timings:        eval time =     734.00 ms /    44 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     795.50 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    63 runs   (    0.05 ms per token, 18545.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.60 ms /    81 tokens (    0.70 ms per token,  1430.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.67 ms /    62 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1126.01 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18479.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    78 tokens (    0.66 ms per token,  1519.46 tokens per second)\n",
      "llama_print_timings:        eval time =     572.02 ms /    34 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     637.29 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18392.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.71 ms /    39 tokens (    0.89 ms per token,  1123.63 tokens per second)\n",
      "llama_print_timings:        eval time =     562.07 ms /    34 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     609.66 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18416.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.45 ms /   108 tokens (    0.62 ms per token,  1625.18 tokens per second)\n",
      "llama_print_timings:        eval time =     776.66 ms /    46 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     861.33 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18394.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.30 ms /    47 tokens (    0.79 ms per token,  1259.92 tokens per second)\n",
      "llama_print_timings:        eval time =     529.10 ms /    32 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     578.78 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18509.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.24 ms /    35 tokens (    0.98 ms per token,  1022.11 tokens per second)\n",
      "llama_print_timings:        eval time =     578.47 ms /    35 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     625.79 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /    26 runs   (    0.05 ms per token, 18624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.31 ms /    36 tokens (    0.95 ms per token,  1049.35 tokens per second)\n",
      "llama_print_timings:        eval time =     413.15 ms /    25 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     457.42 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18458.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    62 tokens (    0.71 ms per token,  1403.67 tokens per second)\n",
      "llama_print_timings:        eval time =     264.67 ms /    16 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     314.68 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /    66 runs   (    0.05 ms per token, 18644.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    55 tokens (    0.79 ms per token,  1265.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.34 ms /    65 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1156.08 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    81 runs   (    0.05 ms per token, 18501.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.84 ms /    67 tokens (    0.74 ms per token,  1344.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1345.05 ms /    80 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =    1427.19 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.71 ms /    42 tokens (    0.87 ms per token,  1144.20 tokens per second)\n",
      "llama_print_timings:        eval time =     380.23 ms /    23 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     425.37 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /    38 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.01 ms /    85 tokens (    0.68 ms per token,  1465.37 tokens per second)\n",
      "llama_print_timings:        eval time =     624.04 ms /    37 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     696.14 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.92 ms /    28 tokens (    1.10 ms per token,   905.62 tokens per second)\n",
      "llama_print_timings:        eval time =     578.07 ms /    35 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     622.34 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18526.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.50 ms /    80 tokens (    0.64 ms per token,  1553.43 tokens per second)\n",
      "llama_print_timings:        eval time =     707.83 ms /    42 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =     776.36 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    40 runs   (    0.05 ms per token, 18761.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.90 ms /    33 tokens (    1.03 ms per token,   973.48 tokens per second)\n",
      "llama_print_timings:        eval time =     644.55 ms /    39 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     693.87 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /    52 runs   (    0.05 ms per token, 18651.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.80 ms /    49 tokens (    0.87 ms per token,  1144.75 tokens per second)\n",
      "llama_print_timings:        eval time =     849.13 ms /    51 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     911.98 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18646.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.87 ms /    50 tokens (    0.86 ms per token,  1166.26 tokens per second)\n",
      "llama_print_timings:        eval time =     429.77 ms /    26 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     482.64 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /    61 runs   (    0.05 ms per token, 18552.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.88 ms /    67 tokens (    0.74 ms per token,  1343.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.00 ms /    60 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1079.72 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    52 runs   (    0.05 ms per token, 18387.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.73 ms /    27 tokens (    1.14 ms per token,   878.51 tokens per second)\n",
      "llama_print_timings:        eval time =     843.18 ms /    51 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     895.18 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18578.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    52 tokens (    0.84 ms per token,  1196.81 tokens per second)\n",
      "llama_print_timings:        eval time =     647.99 ms /    39 runs   (   16.62 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     706.68 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    57 runs   (    0.05 ms per token, 18428.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    57 tokens (    0.77 ms per token,  1303.84 tokens per second)\n",
      "llama_print_timings:        eval time =     936.21 ms /    56 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =    1002.16 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    59 runs   (    0.05 ms per token, 18653.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.46 ms /    80 tokens (    0.64 ms per token,  1554.55 tokens per second)\n",
      "llama_print_timings:        eval time =     977.87 ms /    58 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =    1051.85 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18548.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    34 tokens (    1.00 ms per token,   999.47 tokens per second)\n",
      "llama_print_timings:        eval time =     545.39 ms /    33 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     591.63 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    66 runs   (    0.05 ms per token, 18554.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.16 ms /    76 tokens (    0.67 ms per token,  1485.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.96 ms /    65 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =    1172.14 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    50 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    58 tokens (    0.76 ms per token,  1321.34 tokens per second)\n",
      "llama_print_timings:        eval time =     818.39 ms /    49 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     881.64 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18525.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.41 ms /    36 tokens (    0.96 ms per token,  1046.06 tokens per second)\n",
      "llama_print_timings:        eval time =     760.32 ms /    46 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     812.91 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18495.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    54 tokens (    0.81 ms per token,  1242.01 tokens per second)\n",
      "llama_print_timings:        eval time =     715.99 ms /    43 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     775.95 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /    20 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.34 ms /    30 tokens (    1.04 ms per token,   957.33 tokens per second)\n",
      "llama_print_timings:        eval time =     314.07 ms /    19 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     353.45 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18557.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    56 tokens (    0.78 ms per token,  1274.00 tokens per second)\n",
      "llama_print_timings:        eval time =     564.75 ms /    34 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     621.70 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    28 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.84 ms /    43 tokens (    0.86 ms per token,  1167.34 tokens per second)\n",
      "llama_print_timings:        eval time =     446.37 ms /    27 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     494.23 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18670.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.17 ms /    51 tokens (    0.85 ms per token,  1181.43 tokens per second)\n",
      "llama_print_timings:        eval time =     816.12 ms /    49 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     878.29 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18340.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.40 ms /    34 tokens (    1.01 ms per token,   988.37 tokens per second)\n",
      "llama_print_timings:        eval time =     644.38 ms /    39 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     693.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /    10 runs   (    0.06 ms per token, 17985.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.71 ms /    39 tokens (    0.89 ms per token,  1123.69 tokens per second)\n",
      "llama_print_timings:        eval time =     148.53 ms /     9 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     186.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18595.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.89 ms /    83 tokens (    0.70 ms per token,  1433.75 tokens per second)\n",
      "llama_print_timings:        eval time =     809.59 ms /    48 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     886.56 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    52 tokens (    0.83 ms per token,  1201.37 tokens per second)\n",
      "llama_print_timings:        eval time =     681.56 ms /    41 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     740.98 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18615.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.81 ms /    42 tokens (    0.88 ms per token,  1141.09 tokens per second)\n",
      "llama_print_timings:        eval time =     512.29 ms /    31 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     561.13 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.44 ms /    48 tokens (    0.78 ms per token,  1282.15 tokens per second)\n",
      "llama_print_timings:        eval time =     764.50 ms /    46 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     819.80 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /    67 runs   (    0.05 ms per token, 18621.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.12 ms /    34 tokens (    1.00 ms per token,   996.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.87 ms /    66 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =    1156.95 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    39 runs   (    0.05 ms per token, 18344.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.62 ms /    40 tokens (    0.87 ms per token,  1155.37 tokens per second)\n",
      "llama_print_timings:        eval time =     628.38 ms /    38 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     677.71 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18613.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.34 ms /    53 tokens (    0.82 ms per token,  1222.95 tokens per second)\n",
      "llama_print_timings:        eval time =     648.24 ms /    39 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     706.19 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    53 runs   (    0.05 ms per token, 18708.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.58 ms /    90 tokens (    0.65 ms per token,  1536.44 tokens per second)\n",
      "llama_print_timings:        eval time =     877.38 ms /    52 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     956.33 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.17 ms /    71 tokens (    0.71 ms per token,  1415.16 tokens per second)\n",
      "llama_print_timings:        eval time =     890.41 ms /    53 runs   (   16.80 ms per token,    59.52 tokens per second)\n",
      "llama_print_timings:       total time =     960.89 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18382.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.70 ms /    39 tokens (    0.89 ms per token,  1123.89 tokens per second)\n",
      "llama_print_timings:        eval time =     313.77 ms /    19 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     356.16 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18558.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.69 ms /    92 tokens (    0.64 ms per token,  1567.48 tokens per second)\n",
      "llama_print_timings:        eval time =     708.68 ms /    42 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     783.12 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18625.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.42 ms /    36 tokens (    0.96 ms per token,  1045.78 tokens per second)\n",
      "llama_print_timings:        eval time =     677.96 ms /    41 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     728.30 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    70 runs   (    0.05 ms per token, 18592.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.26 ms /    78 tokens (    0.66 ms per token,  1521.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.99 ms /    69 runs   (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_print_timings:       total time =    1241.12 ms /   147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18334.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    23 tokens (    1.20 ms per token,   831.35 tokens per second)\n",
      "llama_print_timings:        eval time =     561.58 ms /    34 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     602.48 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    78 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.54 ms /    32 tokens (    0.99 ms per token,  1014.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1282.01 ms /    77 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =    1345.06 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /    62 runs   (    0.05 ms per token, 18562.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.56 ms /    64 tokens (    0.70 ms per token,  1436.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1023.02 ms /    61 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1092.00 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    57 runs   (    0.05 ms per token, 18428.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.79 ms /    67 tokens (    0.74 ms per token,  1345.57 tokens per second)\n",
      "llama_print_timings:        eval time =     939.74 ms /    56 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1012.34 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.56 ms /    56 tokens (    0.78 ms per token,  1285.47 tokens per second)\n",
      "llama_print_timings:        eval time =     581.77 ms /    35 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     638.72 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    62 runs   (    0.05 ms per token, 18430.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.69 ms /    42 tokens (    0.87 ms per token,  1144.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1015.44 ms /    61 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =    1075.90 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    67 runs   (    0.05 ms per token, 18688.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.48 ms /    72 tokens (    0.70 ms per token,  1426.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.20 ms /    66 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =    1186.29 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /    41 runs   (    0.05 ms per token, 18336.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.36 ms /    38 tokens (    0.90 ms per token,  1105.97 tokens per second)\n",
      "llama_print_timings:        eval time =     661.37 ms /    40 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     711.38 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    58 runs   (    0.05 ms per token, 18430.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.94 ms /    92 tokens (    0.64 ms per token,  1560.88 tokens per second)\n",
      "llama_print_timings:        eval time =     961.84 ms /    57 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1043.08 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18618.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.62 ms /    48 tokens (    0.78 ms per token,  1275.82 tokens per second)\n",
      "llama_print_timings:        eval time =     496.02 ms /    30 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     545.63 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    56 runs   (    0.05 ms per token, 18294.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.77 ms /    73 tokens (    0.70 ms per token,  1437.72 tokens per second)\n",
      "llama_print_timings:        eval time =     924.70 ms /    55 runs   (   16.81 ms per token,    59.48 tokens per second)\n",
      "llama_print_timings:       total time =     996.75 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.02 ms /    68 tokens (    0.74 ms per token,  1359.40 tokens per second)\n",
      "llama_print_timings:        eval time =     585.67 ms /    35 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     649.36 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /    18 runs   (    0.05 ms per token, 18499.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.11 ms /    36 tokens (    0.95 ms per token,  1055.29 tokens per second)\n",
      "llama_print_timings:        eval time =     280.84 ms /    17 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     321.20 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18603.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /    57 tokens (    0.77 ms per token,  1305.09 tokens per second)\n",
      "llama_print_timings:        eval time =     868.82 ms /    52 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     932.38 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18495.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    36 tokens (    0.95 ms per token,  1050.73 tokens per second)\n",
      "llama_print_timings:        eval time =     231.04 ms /    14 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     270.57 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    13 runs   (    0.05 ms per token, 18678.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.44 ms /    16 tokens (    1.71 ms per token,   583.15 tokens per second)\n",
      "llama_print_timings:        eval time =     197.96 ms /    12 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     229.87 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18412.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    54 tokens (    0.80 ms per token,  1247.20 tokens per second)\n",
      "llama_print_timings:        eval time =     732.95 ms /    44 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     793.60 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18417.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.08 ms /    47 tokens (    0.79 ms per token,  1267.60 tokens per second)\n",
      "llama_print_timings:        eval time =     713.69 ms /    43 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     766.97 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /    31 runs   (    0.06 ms per token, 18171.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    25 tokens (    1.23 ms per token,   815.10 tokens per second)\n",
      "llama_print_timings:        eval time =     495.69 ms /    30 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     538.29 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    70 tokens (    0.72 ms per token,  1390.46 tokens per second)\n",
      "llama_print_timings:        eval time =     316.53 ms /    19 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     374.33 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    55 runs   (    0.05 ms per token, 18531.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    50 tokens (    0.86 ms per token,  1160.74 tokens per second)\n",
      "llama_print_timings:        eval time =     899.97 ms /    54 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     963.63 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.47 ms /    54 tokens (    0.80 ms per token,  1242.29 tokens per second)\n",
      "llama_print_timings:        eval time =     817.11 ms /    49 runs   (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =     880.17 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    60 tokens (    0.74 ms per token,  1358.39 tokens per second)\n",
      "llama_print_timings:        eval time =     802.20 ms /    48 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     864.93 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /    53 runs   (    0.05 ms per token, 18675.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    53 tokens (    0.82 ms per token,  1224.08 tokens per second)\n",
      "llama_print_timings:        eval time =     867.42 ms /    52 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     930.56 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    57 tokens (    0.77 ms per token,  1293.07 tokens per second)\n",
      "llama_print_timings:        eval time =     380.36 ms /    23 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     433.20 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    49 runs   (    0.05 ms per token, 18730.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.38 ms /    47 tokens (    0.80 ms per token,  1257.32 tokens per second)\n",
      "llama_print_timings:        eval time =     797.96 ms /    48 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     854.14 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18524.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.49 ms /    62 tokens (    0.72 ms per token,  1393.57 tokens per second)\n",
      "llama_print_timings:        eval time =     937.99 ms /    56 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =    1004.84 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     6 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.82 ms /    18 tokens (    1.49 ms per token,   671.14 tokens per second)\n",
      "llama_print_timings:        eval time =      82.48 ms /     5 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     111.15 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18508.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.44 ms /    47 tokens (    0.80 ms per token,  1255.48 tokens per second)\n",
      "llama_print_timings:        eval time =     562.12 ms /    34 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     612.66 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /    27 runs   (    0.05 ms per token, 18430.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.92 ms /    43 tokens (    0.86 ms per token,  1164.59 tokens per second)\n",
      "llama_print_timings:        eval time =     429.98 ms /    26 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     476.63 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.61 ms /    37 tokens (    0.94 ms per token,  1068.99 tokens per second)\n",
      "llama_print_timings:        eval time =     479.22 ms /    29 runs   (   16.52 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     524.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    52 runs   (    0.05 ms per token, 18452.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    52 tokens (    0.83 ms per token,  1203.59 tokens per second)\n",
      "llama_print_timings:        eval time =     850.67 ms /    51 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     914.19 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /    17 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.69 ms /    63 tokens (    0.71 ms per token,  1409.65 tokens per second)\n",
      "llama_print_timings:        eval time =     264.50 ms /    16 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     315.88 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18537.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.88 ms /    17 tokens (    1.58 ms per token,   632.42 tokens per second)\n",
      "llama_print_timings:        eval time =     859.06 ms /    52 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     906.18 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    14 runs   (    0.05 ms per token, 18276.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.66 ms /    37 tokens (    0.94 ms per token,  1067.67 tokens per second)\n",
      "llama_print_timings:        eval time =     214.38 ms /    13 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     254.61 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18613.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    59 tokens (    0.75 ms per token,  1339.45 tokens per second)\n",
      "llama_print_timings:        eval time =     768.27 ms /    46 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     830.12 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    55 runs   (    0.05 ms per token, 18506.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    34 tokens (    1.00 ms per token,   995.46 tokens per second)\n",
      "llama_print_timings:        eval time =     894.79 ms /    54 runs   (   16.57 ms per token,    60.35 tokens per second)\n",
      "llama_print_timings:       total time =     950.75 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.55 ms /    65 tokens (    0.76 ms per token,  1311.89 tokens per second)\n",
      "llama_print_timings:        eval time =     786.83 ms /    47 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     854.99 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18477.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.06 ms /    33 tokens (    1.03 ms per token,   968.96 tokens per second)\n",
      "llama_print_timings:        eval time =     528.65 ms /    32 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     575.09 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18640.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    15 tokens (    1.83 ms per token,   546.19 tokens per second)\n",
      "llama_print_timings:        eval time =     544.72 ms /    33 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     584.79 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    74 runs   (    0.05 ms per token, 18724.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.56 ms /    65 tokens (    0.76 ms per token,  1311.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1226.22 ms /    73 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =    1304.55 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /    21 runs   (    0.06 ms per token, 17887.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    29 tokens (    1.08 ms per token,   927.82 tokens per second)\n",
      "llama_print_timings:        eval time =     330.47 ms /    20 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     370.38 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /    16 runs   (    0.05 ms per token, 18497.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.27 ms /    31 tokens (    1.01 ms per token,   991.33 tokens per second)\n",
      "llama_print_timings:        eval time =     247.73 ms /    15 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     285.00 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    60 tokens (    0.74 ms per token,  1356.70 tokens per second)\n",
      "llama_print_timings:        eval time =     634.00 ms /    38 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     693.92 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /    10 runs   (    0.05 ms per token, 18621.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    14 tokens (    1.94 ms per token,   515.12 tokens per second)\n",
      "llama_print_timings:        eval time =     148.25 ms /     9 runs   (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:       total time =     178.54 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18562.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    51 tokens (    0.85 ms per token,  1178.24 tokens per second)\n",
      "llama_print_timings:        eval time =     765.67 ms /    46 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     826.31 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18525.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.62 ms /    91 tokens (    0.64 ms per token,  1552.50 tokens per second)\n",
      "llama_print_timings:        eval time =     860.60 ms /    51 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     939.11 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    65 runs   (    0.05 ms per token, 18608.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.52 ms /    64 tokens (    0.70 ms per token,  1437.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.22 ms /    64 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1144.40 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    91 runs   (    0.05 ms per token, 18575.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.28 ms /    89 tokens (    0.65 ms per token,  1527.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1520.37 ms /    90 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =    1615.38 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.91 ms /    33 tokens (    1.03 ms per token,   973.25 tokens per second)\n",
      "llama_print_timings:        eval time =     313.94 ms /    19 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     355.63 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    29 tokens (    1.07 ms per token,   933.38 tokens per second)\n",
      "llama_print_timings:        eval time =     693.94 ms /    42 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     741.19 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    76 runs   (    0.05 ms per token, 18664.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.62 ms /    63 tokens (    0.71 ms per token,  1411.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1259.03 ms /    75 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =    1333.46 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     9 runs   (    0.06 ms per token, 17892.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    24 tokens (    1.14 ms per token,   873.62 tokens per second)\n",
      "llama_print_timings:        eval time =     132.15 ms /     8 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     163.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    66 runs   (    0.05 ms per token, 18399.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    61 tokens (    0.73 ms per token,  1376.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.50 ms /    65 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1160.19 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.66 ms /    42 tokens (    0.87 ms per token,  1145.73 tokens per second)\n",
      "llama_print_timings:        eval time =     678.42 ms /    41 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     730.83 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18428.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    34 tokens (    1.00 ms per token,   999.47 tokens per second)\n",
      "llama_print_timings:        eval time =     545.36 ms /    33 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     592.22 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /    18 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.23 ms /    21 tokens (    1.30 ms per token,   771.12 tokens per second)\n",
      "llama_print_timings:        eval time =     280.63 ms /    17 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     313.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18530.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.03 ms /    75 tokens (    0.68 ms per token,  1469.67 tokens per second)\n",
      "llama_print_timings:        eval time =     942.55 ms /    56 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1016.24 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /    18 runs   (    0.05 ms per token, 18255.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.34 ms /    37 tokens (    0.93 ms per token,  1077.46 tokens per second)\n",
      "llama_print_timings:        eval time =     280.87 ms /    17 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     321.84 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18573.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.77 ms /    49 tokens (    0.87 ms per token,  1145.74 tokens per second)\n",
      "llama_print_timings:        eval time =     714.37 ms /    43 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     773.57 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18625.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.13 ms /    60 tokens (    0.74 ms per token,  1359.65 tokens per second)\n",
      "llama_print_timings:        eval time =     684.42 ms /    41 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     744.58 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    52 runs   (    0.05 ms per token, 18452.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    74 tokens (    0.69 ms per token,  1457.07 tokens per second)\n",
      "llama_print_timings:        eval time =     857.75 ms /    51 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     928.64 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18590.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.27 ms /    61 tokens (    0.73 ms per token,  1378.03 tokens per second)\n",
      "llama_print_timings:        eval time =     380.91 ms /    23 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     433.61 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    59 runs   (    0.05 ms per token, 18565.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.20 ms /    60 tokens (    0.74 ms per token,  1357.37 tokens per second)\n",
      "llama_print_timings:        eval time =     971.35 ms /    58 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =    1039.30 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18398.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.82 ms /    42 tokens (    0.88 ms per token,  1140.72 tokens per second)\n",
      "llama_print_timings:        eval time =     595.23 ms /    36 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     645.72 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18582.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.75 ms /    40 tokens (    0.87 ms per token,  1151.11 tokens per second)\n",
      "llama_print_timings:        eval time =     429.77 ms /    26 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     474.38 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /    31 runs   (    0.05 ms per token, 18708.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.23 ms /    35 tokens (    0.98 ms per token,  1022.44 tokens per second)\n",
      "llama_print_timings:        eval time =     495.70 ms /    30 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     541.63 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /    24 runs   (    0.05 ms per token, 18223.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    23 tokens (    1.20 ms per token,   836.82 tokens per second)\n",
      "llama_print_timings:        eval time =     379.80 ms /    23 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     415.90 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    55 runs   (    0.05 ms per token, 18406.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.85 ms /    67 tokens (    0.74 ms per token,  1344.03 tokens per second)\n",
      "llama_print_timings:        eval time =     905.88 ms /    54 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     977.39 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    48 runs   (    0.05 ms per token, 18376.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.31 ms /    79 tokens (    0.65 ms per token,  1539.78 tokens per second)\n",
      "llama_print_timings:        eval time =     791.91 ms /    47 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     861.93 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18536.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.11 ms /    70 tokens (    0.72 ms per token,  1397.07 tokens per second)\n",
      "llama_print_timings:        eval time =     940.77 ms /    56 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =    1012.95 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18533.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.04 ms /    34 tokens (    1.00 ms per token,   998.77 tokens per second)\n",
      "llama_print_timings:        eval time =     727.34 ms /    44 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     777.82 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    59 runs   (    0.05 ms per token, 18454.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.84 ms /    74 tokens (    0.69 ms per token,  1455.69 tokens per second)\n",
      "llama_print_timings:        eval time =     976.13 ms /    58 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1049.95 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /    18 runs   (    0.05 ms per token, 18218.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.81 ms /    42 tokens (    0.88 ms per token,  1140.87 tokens per second)\n",
      "llama_print_timings:        eval time =     280.95 ms /    17 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     324.72 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.72 ms /    40 tokens (    0.87 ms per token,  1152.17 tokens per second)\n",
      "llama_print_timings:        eval time =     678.03 ms /    41 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     728.14 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18286.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.82 ms /    42 tokens (    0.88 ms per token,  1140.65 tokens per second)\n",
      "llama_print_timings:        eval time =     297.47 ms /    18 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     341.23 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    75 runs   (    0.05 ms per token, 18527.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.39 ms /    78 tokens (    0.66 ms per token,  1517.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.82 ms /    74 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =    1328.56 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18437.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.00 ms /    28 tokens (    1.11 ms per token,   903.20 tokens per second)\n",
      "llama_print_timings:        eval time =     330.34 ms /    20 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     369.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    39 runs   (    0.05 ms per token, 18598.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.06 ms /    59 tokens (    0.75 ms per token,  1339.11 tokens per second)\n",
      "llama_print_timings:        eval time =     633.45 ms /    38 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     692.32 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.53 ms /    41 tokens (    0.89 ms per token,  1122.30 tokens per second)\n",
      "llama_print_timings:        eval time =     644.76 ms /    39 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     696.77 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18278.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.57 ms /    37 tokens (    0.93 ms per token,  1070.20 tokens per second)\n",
      "llama_print_timings:        eval time =     379.77 ms /    23 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     422.88 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    35 runs   (    0.05 ms per token, 18392.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.24 ms /    53 tokens (    0.82 ms per token,  1225.77 tokens per second)\n",
      "llama_print_timings:        eval time =     563.56 ms /    34 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     619.66 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    40 runs   (    0.05 ms per token, 18289.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.51 ms /    39 tokens (    0.88 ms per token,  1130.27 tokens per second)\n",
      "llama_print_timings:        eval time =     644.39 ms /    39 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     693.92 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.77 ms /    40 tokens (    0.87 ms per token,  1150.58 tokens per second)\n",
      "llama_print_timings:        eval time =     578.25 ms /    35 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     626.45 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    53 tokens (    0.81 ms per token,  1228.81 tokens per second)\n",
      "llama_print_timings:        eval time =     529.80 ms /    32 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     585.07 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /    38 runs   (    0.05 ms per token, 18509.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    52 tokens (    0.83 ms per token,  1207.11 tokens per second)\n",
      "llama_print_timings:        eval time =     614.02 ms /    37 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     671.02 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18573.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.88 ms /    33 tokens (    1.03 ms per token,   973.94 tokens per second)\n",
      "llama_print_timings:        eval time =     396.15 ms /    24 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     438.79 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    91 runs   (    0.05 ms per token, 18639.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.60 ms /    89 tokens (    0.66 ms per token,  1518.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1519.20 ms /    90 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1613.53 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18387.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    60 tokens (    0.73 ms per token,  1366.34 tokens per second)\n",
      "llama_print_timings:        eval time =     633.49 ms /    38 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     691.64 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    30 runs   (    0.05 ms per token, 18552.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.98 ms /    44 tokens (    0.84 ms per token,  1189.74 tokens per second)\n",
      "llama_print_timings:        eval time =     479.13 ms /    29 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     526.79 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    52 runs   (    0.05 ms per token, 18459.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    50 tokens (    0.86 ms per token,  1164.77 tokens per second)\n",
      "llama_print_timings:        eval time =     848.85 ms /    51 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     910.61 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /    64 runs   (    0.05 ms per token, 18449.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.27 ms /    87 tokens (    0.67 ms per token,  1492.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1062.50 ms /    63 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1144.10 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    19 runs   (    0.05 ms per token, 18609.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    25 tokens (    1.23 ms per token,   813.06 tokens per second)\n",
      "llama_print_timings:        eval time =     296.97 ms /    18 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     334.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18414.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.20 ms /    46 tokens (    0.81 ms per token,  1236.56 tokens per second)\n",
      "llama_print_timings:        eval time =     797.17 ms /    48 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     852.57 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    67 runs   (    0.05 ms per token, 18539.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    63 tokens (    0.70 ms per token,  1420.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.19 ms /    66 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1175.31 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18701.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.99 ms /    52 tokens (    0.83 ms per token,  1209.47 tokens per second)\n",
      "llama_print_timings:        eval time =     580.09 ms /    35 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     636.06 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    51 runs   (    0.05 ms per token, 18722.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.05 ms /    93 tokens (    0.63 ms per token,  1574.91 tokens per second)\n",
      "llama_print_timings:        eval time =     843.24 ms /    50 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     921.51 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18528.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.03 ms /    45 tokens (    0.82 ms per token,  1215.26 tokens per second)\n",
      "llama_print_timings:        eval time =     561.92 ms /    34 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     612.11 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    56 runs   (    0.05 ms per token, 18579.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    58 tokens (    0.76 ms per token,  1319.44 tokens per second)\n",
      "llama_print_timings:        eval time =     918.95 ms /    55 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     983.52 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18595.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.99 ms /    86 tokens (    0.67 ms per token,  1483.04 tokens per second)\n",
      "llama_print_timings:        eval time =     741.77 ms /    44 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     816.31 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    50 runs   (    0.05 ms per token, 18615.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.76 ms /    74 tokens (    0.69 ms per token,  1457.90 tokens per second)\n",
      "llama_print_timings:        eval time =     823.34 ms /    49 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     892.72 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18508.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.72 ms /    39 tokens (    0.89 ms per token,  1123.37 tokens per second)\n",
      "llama_print_timings:        eval time =     544.88 ms /    33 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     591.91 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /    38 runs   (    0.05 ms per token, 18527.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    23 tokens (    1.20 ms per token,   833.97 tokens per second)\n",
      "llama_print_timings:        eval time =     610.84 ms /    37 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     651.95 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18528.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.05 ms /    29 tokens (    1.07 ms per token,   933.83 tokens per second)\n",
      "llama_print_timings:        eval time =     577.75 ms /    35 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     622.25 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18569.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.31 ms /    53 tokens (    0.82 ms per token,  1223.85 tokens per second)\n",
      "llama_print_timings:        eval time =     429.78 ms /    26 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     482.13 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /    18 runs   (    0.05 ms per token, 18386.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.27 ms /    35 tokens (    0.98 ms per token,  1021.27 tokens per second)\n",
      "llama_print_timings:        eval time =     280.40 ms /    17 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     321.25 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /    58 runs   (    0.05 ms per token, 18536.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.31 ms /    47 tokens (    0.79 ms per token,  1259.55 tokens per second)\n",
      "llama_print_timings:        eval time =     949.20 ms /    57 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =    1007.77 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18452.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    54 tokens (    0.81 ms per token,  1242.04 tokens per second)\n",
      "llama_print_timings:        eval time =     580.72 ms /    35 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     637.46 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    41 runs   (    0.05 ms per token, 18552.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.09 ms /    51 tokens (    0.84 ms per token,  1183.62 tokens per second)\n",
      "llama_print_timings:        eval time =     664.03 ms /    40 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     721.96 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18390.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.64 ms /    25 tokens (    1.23 ms per token,   815.90 tokens per second)\n",
      "llama_print_timings:        eval time =     379.68 ms /    23 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     418.45 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18567.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    58 tokens (    0.76 ms per token,  1317.67 tokens per second)\n",
      "llama_print_timings:        eval time =     683.10 ms /    41 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     742.09 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    74 tokens (    0.68 ms per token,  1460.92 tokens per second)\n",
      "llama_print_timings:        eval time =     688.36 ms /    41 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     754.16 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18636.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    56 tokens (    0.78 ms per token,  1286.14 tokens per second)\n",
      "llama_print_timings:        eval time =     766.54 ms /    46 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     827.28 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    49 runs   (    0.05 ms per token, 18283.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.71 ms /    41 tokens (    0.90 ms per token,  1116.92 tokens per second)\n",
      "llama_print_timings:        eval time =     795.47 ms /    48 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     851.54 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18579.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.67 ms /    27 tokens (    1.14 ms per token,   880.25 tokens per second)\n",
      "llama_print_timings:        eval time =     445.69 ms /    27 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     486.16 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /    25 runs   (    0.05 ms per token, 18642.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.73 ms /    39 tokens (    0.89 ms per token,  1123.11 tokens per second)\n",
      "llama_print_timings:        eval time =     396.27 ms /    24 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     439.34 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /    66 runs   (    0.05 ms per token, 18675.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.57 ms /    63 tokens (    0.71 ms per token,  1413.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.35 ms /    65 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1158.13 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    28 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.54 ms /    38 tokens (    0.91 ms per token,  1100.11 tokens per second)\n",
      "llama_print_timings:        eval time =     446.06 ms /    27 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     491.42 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /    38 runs   (    0.05 ms per token, 18384.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.35 ms /    61 tokens (    0.73 ms per token,  1375.39 tokens per second)\n",
      "llama_print_timings:        eval time =     616.79 ms /    37 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     675.75 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18619.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    59 tokens (    0.74 ms per token,  1342.56 tokens per second)\n",
      "llama_print_timings:        eval time =     549.02 ms /    33 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     606.24 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18528.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.58 ms /    65 tokens (    0.76 ms per token,  1311.01 tokens per second)\n",
      "llama_print_timings:        eval time =     567.68 ms /    34 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     630.09 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /    50 runs   (    0.05 ms per token, 18477.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.55 ms /    38 tokens (    0.91 ms per token,  1099.73 tokens per second)\n",
      "llama_print_timings:        eval time =     811.57 ms /    49 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     865.34 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18407.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.44 ms /    62 tokens (    0.72 ms per token,  1395.05 tokens per second)\n",
      "llama_print_timings:        eval time =     701.57 ms /    42 runs   (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:       total time =     762.74 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18548.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.64 ms /    43 tokens (    0.85 ms per token,  1173.52 tokens per second)\n",
      "llama_print_timings:        eval time =     545.53 ms /    33 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     594.81 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18452.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    72 tokens (    0.70 ms per token,  1421.52 tokens per second)\n",
      "llama_print_timings:        eval time =     586.97 ms /    35 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     651.38 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18588.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.39 ms /    47 tokens (    0.80 ms per token,  1257.09 tokens per second)\n",
      "llama_print_timings:        eval time =     797.60 ms /    48 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     853.06 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.03 ms /    85 tokens (    0.68 ms per token,  1464.76 tokens per second)\n",
      "llama_print_timings:        eval time =     894.20 ms /    53 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     973.21 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18506.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.77 ms /    28 tokens (    1.10 ms per token,   909.89 tokens per second)\n",
      "llama_print_timings:        eval time =     445.91 ms /    27 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     487.11 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    43 tokens (    0.86 ms per token,  1163.58 tokens per second)\n",
      "llama_print_timings:        eval time =     645.07 ms /    39 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     697.90 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18550.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.67 ms /    64 tokens (    0.70 ms per token,  1432.73 tokens per second)\n",
      "llama_print_timings:        eval time =     888.27 ms /    53 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     953.83 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18512.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.27 ms /    61 tokens (    0.73 ms per token,  1377.91 tokens per second)\n",
      "llama_print_timings:        eval time =     870.39 ms /    52 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     934.97 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    50 runs   (    0.05 ms per token, 18621.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    56 tokens (    0.78 ms per token,  1283.05 tokens per second)\n",
      "llama_print_timings:        eval time =     817.66 ms /    49 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     880.49 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    69 runs   (    0.05 ms per token, 18508.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.26 ms /    92 tokens (    0.64 ms per token,  1552.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.97 ms /    68 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =    1233.70 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18315.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    54 tokens (    0.80 ms per token,  1247.98 tokens per second)\n",
      "llama_print_timings:        eval time =     648.51 ms /    39 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     707.42 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /    66 runs   (    0.05 ms per token, 18686.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.24 ms /    78 tokens (    0.66 ms per token,  1522.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.32 ms /    65 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1171.76 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /    68 runs   (    0.05 ms per token, 18665.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    54 tokens (    0.80 ms per token,  1246.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1120.72 ms /    67 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1190.17 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    51 runs   (    0.05 ms per token, 18385.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.73 ms /    39 tokens (    0.89 ms per token,  1123.08 tokens per second)\n",
      "llama_print_timings:        eval time =     829.09 ms /    50 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     883.53 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /    32 runs   (    0.05 ms per token, 18680.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.22 ms /    70 tokens (    0.72 ms per token,  1393.89 tokens per second)\n",
      "llama_print_timings:        eval time =     518.76 ms /    31 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     580.33 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.33 ms /    78 tokens (    0.66 ms per token,  1519.46 tokens per second)\n",
      "llama_print_timings:        eval time =     690.03 ms /    41 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     756.91 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    24 runs   (    0.05 ms per token, 18706.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.45 ms /    32 tokens (    0.98 ms per token,  1017.46 tokens per second)\n",
      "llama_print_timings:        eval time =     379.88 ms /    23 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     420.47 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18505.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.00 ms /    72 tokens (    0.71 ms per token,  1411.79 tokens per second)\n",
      "llama_print_timings:        eval time =     874.01 ms /    52 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     945.22 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18412.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    68 tokens (    0.74 ms per token,  1357.75 tokens per second)\n",
      "llama_print_timings:        eval time =     686.89 ms /    41 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     752.75 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /    23 runs   (    0.05 ms per token, 18593.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    28 tokens (    1.10 ms per token,   908.41 tokens per second)\n",
      "llama_print_timings:        eval time =     363.50 ms /    22 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     402.14 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.65 ms /    24 tokens (    1.15 ms per token,   868.12 tokens per second)\n",
      "llama_print_timings:        eval time =     346.70 ms /    21 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     382.24 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /    33 runs   (    0.05 ms per token, 18696.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.83 ms /    82 tokens (    0.69 ms per token,  1442.87 tokens per second)\n",
      "llama_print_timings:        eval time =     539.71 ms /    32 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =     608.67 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   636.01 tokens per second)\n",
      "llama_print_timings:        eval time =     131.97 ms /     8 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     161.30 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    40 runs   (    0.05 ms per token, 18752.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.09 ms /    77 tokens (    0.66 ms per token,  1507.20 tokens per second)\n",
      "llama_print_timings:        eval time =     655.97 ms /    39 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     721.41 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18581.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.16 ms /    76 tokens (    0.67 ms per token,  1485.51 tokens per second)\n",
      "llama_print_timings:        eval time =     807.58 ms /    48 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     876.49 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18353.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.02 ms /    26 tokens (    1.19 ms per token,   838.14 tokens per second)\n",
      "llama_print_timings:        eval time =     561.79 ms /    34 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     605.78 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    73 runs   (    0.05 ms per token, 18612.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    56 tokens (    0.78 ms per token,  1282.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.06 ms /    72 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =    1277.63 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    58 runs   (    0.05 ms per token, 18489.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    71 tokens (    0.71 ms per token,  1404.41 tokens per second)\n",
      "llama_print_timings:        eval time =     958.05 ms /    57 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1031.05 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    56 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.37 ms /    88 tokens (    0.66 ms per token,  1507.73 tokens per second)\n",
      "llama_print_timings:        eval time =     928.40 ms /    55 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1007.42 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18525.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    66 tokens (    0.75 ms per token,  1329.79 tokens per second)\n",
      "llama_print_timings:        eval time =     821.10 ms /    49 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     889.35 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18414.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.83 ms /    40 tokens (    0.87 ms per token,  1148.50 tokens per second)\n",
      "llama_print_timings:        eval time =     363.65 ms /    22 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     407.01 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    74 runs   (    0.05 ms per token, 18588.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.46 ms /    63 tokens (    0.71 ms per token,  1417.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.56 ms /    73 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1298.07 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /    56 runs   (    0.05 ms per token, 18384.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.46 ms /    40 tokens (    0.86 ms per token,  1160.90 tokens per second)\n",
      "llama_print_timings:        eval time =     914.14 ms /    55 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     969.89 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    55 runs   (    0.05 ms per token, 18499.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.84 ms /    51 tokens (    0.84 ms per token,  1190.39 tokens per second)\n",
      "llama_print_timings:        eval time =     900.69 ms /    54 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     964.25 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    62 tokens (    0.71 ms per token,  1403.54 tokens per second)\n",
      "llama_print_timings:        eval time =     718.76 ms /    43 runs   (   16.72 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     779.43 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18531.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.74 ms /    32 tokens (    0.99 ms per token,  1008.26 tokens per second)\n",
      "llama_print_timings:        eval time =     429.62 ms /    26 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     471.80 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     6 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    13 tokens (    2.08 ms per token,   479.70 tokens per second)\n",
      "llama_print_timings:        eval time =      82.20 ms /     5 runs   (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_print_timings:       total time =     111.40 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18524.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.92 ms /    50 tokens (    0.86 ms per token,  1164.93 tokens per second)\n",
      "llama_print_timings:        eval time =     967.79 ms /    58 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =    1033.86 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    42 runs   (    0.05 ms per token, 18300.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.73 ms /    67 tokens (    0.74 ms per token,  1347.19 tokens per second)\n",
      "llama_print_timings:        eval time =     686.89 ms /    41 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     753.91 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18328.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.03 ms /    50 tokens (    0.86 ms per token,  1161.95 tokens per second)\n",
      "llama_print_timings:        eval time =     396.91 ms /    24 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     449.06 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    74 tokens (    0.69 ms per token,  1458.65 tokens per second)\n",
      "llama_print_timings:        eval time =     992.69 ms /    59 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =    1066.57 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18584.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    51 tokens (    0.84 ms per token,  1185.05 tokens per second)\n",
      "llama_print_timings:        eval time =     765.62 ms /    46 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     827.02 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    39 runs   (    0.06 ms per token, 17939.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.61 ms /    41 tokens (    0.89 ms per token,  1119.94 tokens per second)\n",
      "llama_print_timings:        eval time =     628.58 ms /    38 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     680.09 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /    48 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.25 ms /    47 tokens (    0.79 ms per token,  1261.85 tokens per second)\n",
      "llama_print_timings:        eval time =     781.29 ms /    47 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     837.16 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    60 runs   (    0.05 ms per token, 18365.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    52 tokens (    0.83 ms per token,  1201.65 tokens per second)\n",
      "llama_print_timings:        eval time =     984.88 ms /    59 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =    1051.83 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /    11 runs   (    0.06 ms per token, 16975.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.27 ms /    21 tokens (    1.30 ms per token,   770.22 tokens per second)\n",
      "llama_print_timings:        eval time =     164.93 ms /    10 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     196.63 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18577.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    23 tokens (    1.20 ms per token,   835.63 tokens per second)\n",
      "llama_print_timings:        eval time =     462.23 ms /    28 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     500.27 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    53 runs   (    0.05 ms per token, 18479.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.82 ms /    54 tokens (    0.81 ms per token,  1232.31 tokens per second)\n",
      "llama_print_timings:        eval time =     867.68 ms /    52 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     931.67 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18370.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.41 ms /    37 tokens (    0.93 ms per token,  1075.30 tokens per second)\n",
      "llama_print_timings:        eval time =     627.86 ms /    38 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     676.75 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.46 ms /    31 tokens (    1.01 ms per token,   985.41 tokens per second)\n",
      "llama_print_timings:        eval time =     611.44 ms /    37 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     657.52 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /    16 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.06 ms /    33 tokens (    1.03 ms per token,   968.74 tokens per second)\n",
      "llama_print_timings:        eval time =     247.56 ms /    15 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     287.28 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.73 ms /    49 tokens (    0.87 ms per token,  1146.84 tokens per second)\n",
      "llama_print_timings:        eval time =     646.91 ms /    39 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     704.74 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    76 runs   (    0.05 ms per token, 18554.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.20 ms /    52 tokens (    0.83 ms per token,  1203.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.25 ms /    75 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =    1328.69 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /    18 runs   (    0.06 ms per token, 18018.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.05 ms /    19 tokens (    1.42 ms per token,   702.33 tokens per second)\n",
      "llama_print_timings:        eval time =     280.90 ms /    17 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     315.11 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18623.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    67 tokens (    0.74 ms per token,  1342.93 tokens per second)\n",
      "llama_print_timings:        eval time =     753.79 ms /    45 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =     820.66 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    60 runs   (    0.05 ms per token, 18529.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.75 ms /    43 tokens (    0.85 ms per token,  1170.00 tokens per second)\n",
      "llama_print_timings:        eval time =     981.95 ms /    59 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =    1042.24 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /    61 runs   (    0.05 ms per token, 18557.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.95 ms /    68 tokens (    0.73 ms per token,  1361.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.71 ms /    60 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1081.92 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /   100 runs   (    0.05 ms per token, 18539.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.89 ms /   105 tokens (    0.63 ms per token,  1593.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1674.03 ms /    99 runs   (   16.91 ms per token,    59.14 tokens per second)\n",
      "llama_print_timings:       total time =    1780.51 ms /   204 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /    41 runs   (    0.05 ms per token, 18270.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    33 tokens (    1.03 ms per token,   969.22 tokens per second)\n",
      "llama_print_timings:        eval time =     661.34 ms /    40 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     711.46 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.03 ms /    28 tokens (    1.11 ms per token,   902.24 tokens per second)\n",
      "llama_print_timings:        eval time =     214.69 ms /    13 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     250.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    57 runs   (    0.05 ms per token, 18566.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.36 ms /    70 tokens (    0.72 ms per token,  1389.91 tokens per second)\n",
      "llama_print_timings:        eval time =     941.19 ms /    56 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1013.65 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    39 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.94 ms /    44 tokens (    0.84 ms per token,  1191.25 tokens per second)\n",
      "llama_print_timings:        eval time =     628.48 ms /    38 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     681.19 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18524.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.63 ms /    39 tokens (    0.89 ms per token,  1126.22 tokens per second)\n",
      "llama_print_timings:        eval time =     963.79 ms /    58 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =    1020.70 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18479.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.59 ms /    49 tokens (    0.87 ms per token,  1150.48 tokens per second)\n",
      "llama_print_timings:        eval time =     562.49 ms /    34 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     618.37 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.53 ms /    72 tokens (    0.70 ms per token,  1424.98 tokens per second)\n",
      "llama_print_timings:        eval time =     435.19 ms /    26 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     495.97 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /    27 runs   (    0.06 ms per token, 18096.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.99 ms /    46 tokens (    0.80 ms per token,  1243.61 tokens per second)\n",
      "llama_print_timings:        eval time =     429.81 ms /    26 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     476.99 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    32 runs   (    0.05 ms per token, 18572.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.14 ms /    36 tokens (    0.95 ms per token,  1054.57 tokens per second)\n",
      "llama_print_timings:        eval time =     512.20 ms /    31 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     557.95 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18341.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.05 ms /    45 tokens (    0.82 ms per token,  1214.41 tokens per second)\n",
      "llama_print_timings:        eval time =     396.78 ms /    24 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     443.12 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    66 runs   (    0.05 ms per token, 18451.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.72 ms /    56 tokens (    0.78 ms per token,  1280.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.56 ms /    65 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1156.34 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    81 runs   (    0.05 ms per token, 18526.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.92 ms /    76 tokens (    0.67 ms per token,  1492.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1348.08 ms /    80 runs   (   16.85 ms per token,    59.34 tokens per second)\n",
      "llama_print_timings:       total time =    1430.90 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /    44 runs   (    0.05 ms per token, 18363.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.67 ms /    44 tokens (    0.83 ms per token,  1199.79 tokens per second)\n",
      "llama_print_timings:        eval time =     712.91 ms /    43 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     767.29 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18441.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.57 ms /    38 tokens (    0.91 ms per token,  1099.28 tokens per second)\n",
      "llama_print_timings:        eval time =     495.68 ms /    30 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     541.89 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18489.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.96 ms /    58 tokens (    0.76 ms per token,  1319.38 tokens per second)\n",
      "llama_print_timings:        eval time =     768.02 ms /    46 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     829.94 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18322.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.67 ms /    24 tokens (    1.15 ms per token,   867.27 tokens per second)\n",
      "llama_print_timings:        eval time =     297.14 ms /    18 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     331.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    67 runs   (    0.05 ms per token, 18554.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    60 tokens (    0.74 ms per token,  1357.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.15 ms /    66 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1176.70 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18470.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    54 tokens (    0.80 ms per token,  1247.98 tokens per second)\n",
      "llama_print_timings:        eval time =     699.35 ms /    42 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     759.79 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18488.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.16 ms /    69 tokens (    0.73 ms per token,  1375.54 tokens per second)\n",
      "llama_print_timings:        eval time =     940.21 ms /    56 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1012.95 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    35 runs   (    0.05 ms per token, 18746.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    53 tokens (    0.81 ms per token,  1227.53 tokens per second)\n",
      "llama_print_timings:        eval time =     563.72 ms /    34 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     620.17 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     9 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.18 ms /    21 tokens (    1.29 ms per token,   772.60 tokens per second)\n",
      "llama_print_timings:        eval time =     131.94 ms /     8 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     162.02 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /    46 runs   (    0.05 ms per token, 18775.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.43 ms /    30 tokens (    1.05 ms per token,   954.59 tokens per second)\n",
      "llama_print_timings:        eval time =     743.97 ms /    45 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     793.68 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18592.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    49 tokens (    0.87 ms per token,  1148.97 tokens per second)\n",
      "llama_print_timings:        eval time =     680.62 ms /    41 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     738.91 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.77 ms /    58 tokens (    0.75 ms per token,  1325.14 tokens per second)\n",
      "llama_print_timings:        eval time =     683.29 ms /    41 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     742.54 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /    53 runs   (    0.05 ms per token, 18655.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    53 tokens (    0.81 ms per token,  1228.76 tokens per second)\n",
      "llama_print_timings:        eval time =     867.27 ms /    52 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     930.33 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    40 runs   (    0.05 ms per token, 18570.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.63 ms /    64 tokens (    0.70 ms per token,  1434.05 tokens per second)\n",
      "llama_print_timings:        eval time =     651.68 ms /    39 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     711.52 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18512.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.07 ms /    46 tokens (    0.81 ms per token,  1241.00 tokens per second)\n",
      "llama_print_timings:        eval time =     966.16 ms /    58 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =    1025.76 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.35 ms /    53 tokens (    0.82 ms per token,  1222.69 tokens per second)\n",
      "llama_print_timings:        eval time =     782.91 ms /    47 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     844.69 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.05 ms /    19 runs   (    0.06 ms per token, 18147.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    30 tokens (    1.04 ms per token,   958.34 tokens per second)\n",
      "llama_print_timings:        eval time =     297.33 ms /    18 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     336.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    20 runs   (    0.05 ms per token, 18761.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.12 ms /    19 tokens (    1.43 ms per token,   700.69 tokens per second)\n",
      "llama_print_timings:        eval time =     313.54 ms /    19 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     347.79 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18541.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.85 ms /    50 tokens (    0.86 ms per token,  1166.89 tokens per second)\n",
      "llama_print_timings:        eval time =     231.55 ms /    14 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     279.72 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    41 runs   (    0.05 ms per token, 18262.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.75 ms /    39 tokens (    0.89 ms per token,  1122.27 tokens per second)\n",
      "llama_print_timings:        eval time =     661.12 ms /    40 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     711.46 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    41 runs   (    0.06 ms per token, 17604.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.55 ms /    48 tokens (    0.78 ms per token,  1278.23 tokens per second)\n",
      "llama_print_timings:        eval time =     663.46 ms /    40 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     716.17 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18636.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    39 tokens (    0.88 ms per token,  1132.14 tokens per second)\n",
      "llama_print_timings:        eval time =     761.33 ms /    46 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     813.09 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18488.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    51 tokens (    0.84 ms per token,  1185.38 tokens per second)\n",
      "llama_print_timings:        eval time =     731.83 ms /    44 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     792.12 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18584.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    55 tokens (    0.79 ms per token,  1266.78 tokens per second)\n",
      "llama_print_timings:        eval time =     766.82 ms /    46 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     827.82 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18548.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.78 ms /    58 tokens (    0.75 ms per token,  1324.93 tokens per second)\n",
      "llama_print_timings:        eval time =     548.73 ms /    33 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     605.53 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    72 runs   (    0.05 ms per token, 18566.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    56 tokens (    0.78 ms per token,  1282.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1188.88 ms /    71 runs   (   16.74 ms per token,    59.72 tokens per second)\n",
      "llama_print_timings:       total time =    1260.90 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18708.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    59 tokens (    0.75 ms per token,  1339.78 tokens per second)\n",
      "llama_print_timings:        eval time =     835.54 ms /    50 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =     899.64 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18451.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.50 ms /    71 tokens (    0.71 ms per token,  1406.05 tokens per second)\n",
      "llama_print_timings:        eval time =     839.45 ms /    50 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     909.89 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /    14 runs   (    0.05 ms per token, 18567.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    14 tokens (    1.95 ms per token,   511.92 tokens per second)\n",
      "llama_print_timings:        eval time =     214.33 ms /    13 runs   (   16.49 ms per token,    60.65 tokens per second)\n",
      "llama_print_timings:       total time =     247.15 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /    20 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.76 ms /    39 tokens (    0.89 ms per token,  1122.11 tokens per second)\n",
      "llama_print_timings:        eval time =     313.79 ms /    19 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     355.41 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.18 ms /    34 tokens (    1.01 ms per token,   994.88 tokens per second)\n",
      "llama_print_timings:        eval time =     512.35 ms /    31 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     558.33 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    43 runs   (    0.05 ms per token, 18671.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.03 ms /    58 tokens (    0.76 ms per token,  1317.31 tokens per second)\n",
      "llama_print_timings:        eval time =     700.27 ms /    42 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     760.68 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.51 ms /    56 tokens (    0.78 ms per token,  1287.00 tokens per second)\n",
      "llama_print_timings:        eval time =     632.26 ms /    38 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     690.89 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /    15 runs   (    0.05 ms per token, 18359.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.61 ms /    39 tokens (    0.89 ms per token,  1126.84 tokens per second)\n",
      "llama_print_timings:        eval time =     231.25 ms /    14 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     271.35 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /    55 runs   (    0.05 ms per token, 18739.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.28 ms /    62 tokens (    0.71 ms per token,  1400.05 tokens per second)\n",
      "llama_print_timings:        eval time =     903.81 ms /    54 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =     968.86 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    46 runs   (    0.05 ms per token, 18414.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    76 tokens (    0.67 ms per token,  1492.33 tokens per second)\n",
      "llama_print_timings:        eval time =     756.94 ms /    45 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     825.58 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18279.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.41 ms /    23 tokens (    1.19 ms per token,   839.20 tokens per second)\n",
      "llama_print_timings:        eval time =     264.26 ms /    16 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     298.07 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18511.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    60 tokens (    0.73 ms per token,  1363.54 tokens per second)\n",
      "llama_print_timings:        eval time =     751.35 ms /    45 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     812.13 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18477.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    57 tokens (    0.77 ms per token,  1304.80 tokens per second)\n",
      "llama_print_timings:        eval time =     396.88 ms /    24 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     450.20 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    63 runs   (    0.05 ms per token, 18513.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.76 ms /    83 tokens (    0.70 ms per token,  1436.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1046.19 ms /    62 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1127.85 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18379.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.17 ms /    61 tokens (    0.72 ms per token,  1380.93 tokens per second)\n",
      "llama_print_timings:        eval time =     718.29 ms /    43 runs   (   16.70 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     779.36 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18570.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.60 ms /    42 tokens (    0.87 ms per token,  1147.42 tokens per second)\n",
      "llama_print_timings:        eval time =     529.11 ms /    32 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     577.54 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    37 runs   (    0.05 ms per token, 18371.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.60 ms /    56 tokens (    0.78 ms per token,  1284.43 tokens per second)\n",
      "llama_print_timings:        eval time =     598.49 ms /    36 runs   (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:       total time =     656.30 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18220.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    28 tokens (    1.10 ms per token,   908.32 tokens per second)\n",
      "llama_print_timings:        eval time =     264.19 ms /    16 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     300.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18558.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.98 ms /    66 tokens (    0.76 ms per token,  1320.40 tokens per second)\n",
      "llama_print_timings:        eval time =     551.04 ms /    33 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     613.95 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18658.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.45 ms /    38 tokens (    0.91 ms per token,  1102.92 tokens per second)\n",
      "llama_print_timings:        eval time =     677.58 ms /    41 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     727.93 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18611.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.32 ms /    53 tokens (    0.82 ms per token,  1223.43 tokens per second)\n",
      "llama_print_timings:        eval time =     597.58 ms /    36 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     655.01 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    63 runs   (    0.05 ms per token, 18573.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    59 tokens (    0.75 ms per token,  1341.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1037.87 ms /    62 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =    1106.07 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18272.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.53 ms /    41 tokens (    0.89 ms per token,  1122.24 tokens per second)\n",
      "llama_print_timings:        eval time =     346.99 ms /    21 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     391.73 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /    29 runs   (    0.05 ms per token, 18296.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.17 ms /    34 tokens (    1.00 ms per token,   995.08 tokens per second)\n",
      "llama_print_timings:        eval time =     462.73 ms /    28 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     507.32 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18469.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.74 ms /    41 tokens (    0.90 ms per token,  1115.86 tokens per second)\n",
      "llama_print_timings:        eval time =     796.12 ms /    48 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     851.25 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.18 ms /    53 tokens (    0.81 ms per token,  1227.42 tokens per second)\n",
      "llama_print_timings:        eval time =     715.67 ms /    43 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     775.66 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    46 runs   (    0.05 ms per token, 18304.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.46 ms /    37 tokens (    0.93 ms per token,  1073.65 tokens per second)\n",
      "llama_print_timings:        eval time =     744.31 ms /    45 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     796.04 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.83 ms /    66 tokens (    0.76 ms per token,  1324.40 tokens per second)\n",
      "llama_print_timings:        eval time =     702.81 ms /    42 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     768.39 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18683.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    52 tokens (    0.83 ms per token,  1205.88 tokens per second)\n",
      "llama_print_timings:        eval time =     681.78 ms /    41 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     740.37 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18423.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    54 tokens (    0.80 ms per token,  1243.27 tokens per second)\n",
      "llama_print_timings:        eval time =     581.21 ms /    35 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     638.52 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18703.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.65 ms /    41 tokens (    0.89 ms per token,  1118.69 tokens per second)\n",
      "llama_print_timings:        eval time =     479.38 ms /    29 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     527.49 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18505.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.29 ms /    47 tokens (    0.79 ms per token,  1260.39 tokens per second)\n",
      "llama_print_timings:        eval time =     429.90 ms /    26 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     476.90 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /   104 runs   (    0.05 ms per token, 18515.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    73 tokens (    0.69 ms per token,  1440.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1736.39 ms /   103 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =    1829.18 ms /   176 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18322.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    30 tokens (    1.04 ms per token,   959.20 tokens per second)\n",
      "llama_print_timings:        eval time =     297.07 ms /    18 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     335.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    63 runs   (    0.05 ms per token, 18485.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.89 ms /    42 tokens (    0.88 ms per token,  1138.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1032.35 ms /    62 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =    1093.48 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /    61 runs   (    0.05 ms per token, 18574.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    81 tokens (    0.70 ms per token,  1427.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1011.98 ms /    60 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1091.54 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    77 runs   (    0.05 ms per token, 18581.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.81 ms /    75 tokens (    0.68 ms per token,  1476.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1280.58 ms /    76 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =    1362.17 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    78 runs   (    0.05 ms per token, 18439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.71 ms /    98 tokens (    0.66 ms per token,  1514.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1300.96 ms /    77 runs   (   16.90 ms per token,    59.19 tokens per second)\n",
      "llama_print_timings:       total time =    1397.20 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /    16 runs   (    0.05 ms per token, 18202.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.06 ms /    45 tokens (    0.82 ms per token,  1214.15 tokens per second)\n",
      "llama_print_timings:        eval time =     248.15 ms /    15 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     291.87 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /    45 runs   (    0.05 ms per token, 18641.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    33 tokens (    1.03 ms per token,   967.94 tokens per second)\n",
      "llama_print_timings:        eval time =     727.35 ms /    44 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     778.05 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /    11 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.73 ms /    17 tokens (    1.57 ms per token,   635.99 tokens per second)\n",
      "llama_print_timings:        eval time =     164.91 ms /    10 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     195.54 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    80 runs   (    0.05 ms per token, 18574.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.13 ms /    60 tokens (    0.74 ms per token,  1359.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1325.99 ms /    79 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1401.92 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    69 tokens (    0.73 ms per token,  1377.91 tokens per second)\n",
      "llama_print_timings:        eval time =     552.39 ms /    33 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     614.89 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18485.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.30 ms /    48 tokens (    0.78 ms per token,  1286.90 tokens per second)\n",
      "llama_print_timings:        eval time =     496.44 ms /    30 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     545.54 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /    33 runs   (    0.05 ms per token, 18686.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.79 ms /    39 tokens (    0.89 ms per token,  1121.01 tokens per second)\n",
      "llama_print_timings:        eval time =     528.94 ms /    32 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     575.45 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    40 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.08 ms /    58 tokens (    0.76 ms per token,  1315.67 tokens per second)\n",
      "llama_print_timings:        eval time =     649.87 ms /    39 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     709.12 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18396.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    53 tokens (    0.82 ms per token,  1224.92 tokens per second)\n",
      "llama_print_timings:        eval time =     682.04 ms /    41 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     740.81 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    32 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.92 ms /    59 tokens (    0.74 ms per token,  1343.26 tokens per second)\n",
      "llama_print_timings:        eval time =     515.24 ms /    31 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     571.12 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /    25 runs   (    0.05 ms per token, 18221.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.21 ms /    30 tokens (    1.04 ms per token,   961.35 tokens per second)\n",
      "llama_print_timings:        eval time =     396.39 ms /    24 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     436.61 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18555.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.48 ms /    55 tokens (    0.79 ms per token,  1264.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1070.40 ms /    64 runs   (   16.72 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =    1138.85 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18608.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.04 ms /    34 tokens (    1.00 ms per token,   998.82 tokens per second)\n",
      "llama_print_timings:        eval time =     743.92 ms /    45 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     795.60 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18584.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.92 ms /    73 tokens (    0.70 ms per token,  1433.57 tokens per second)\n",
      "llama_print_timings:        eval time =     772.70 ms /    46 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     841.92 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /    11 runs   (    0.06 ms per token, 18032.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.34 ms /    16 tokens (    1.71 ms per token,   585.29 tokens per second)\n",
      "llama_print_timings:        eval time =     165.03 ms /    10 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     196.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    28 runs   (    0.05 ms per token, 18288.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    19 tokens (    1.43 ms per token,   701.13 tokens per second)\n",
      "llama_print_timings:        eval time =     445.88 ms /    27 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     482.85 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    34 runs   (    0.05 ms per token, 18368.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    42 tokens (    0.88 ms per token,  1136.70 tokens per second)\n",
      "llama_print_timings:        eval time =     545.87 ms /    33 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     594.87 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    41 runs   (    0.06 ms per token, 17664.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    45 tokens (    0.82 ms per token,  1217.96 tokens per second)\n",
      "llama_print_timings:        eval time =     662.41 ms /    40 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     714.55 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    65 runs   (    0.05 ms per token, 18769.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.57 ms /    56 tokens (    0.78 ms per token,  1285.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1070.96 ms /    64 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =    1139.52 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    39 runs   (    0.05 ms per token, 18301.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.70 ms /    57 tokens (    0.77 ms per token,  1304.23 tokens per second)\n",
      "llama_print_timings:        eval time =     633.10 ms /    38 runs   (   16.66 ms per token,    60.02 tokens per second)\n",
      "llama_print_timings:       total time =     692.40 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /    61 runs   (    0.05 ms per token, 18580.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.74 ms /    66 tokens (    0.75 ms per token,  1326.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1006.92 ms /    60 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1080.78 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    60 runs   (    0.05 ms per token, 18570.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.59 ms /    57 tokens (    0.76 ms per token,  1307.76 tokens per second)\n",
      "llama_print_timings:        eval time =     987.10 ms /    59 runs   (   16.73 ms per token,    59.77 tokens per second)\n",
      "llama_print_timings:       total time =    1054.23 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    56 runs   (    0.05 ms per token, 18512.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.53 ms /    65 tokens (    0.76 ms per token,  1312.44 tokens per second)\n",
      "llama_print_timings:        eval time =     922.05 ms /    55 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     993.37 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    64 runs   (    0.05 ms per token, 18588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.19 ms /    88 tokens (    0.66 ms per token,  1512.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1063.13 ms /    63 runs   (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1145.66 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /    48 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.00 ms /    58 tokens (    0.76 ms per token,  1318.18 tokens per second)\n",
      "llama_print_timings:        eval time =     784.62 ms /    47 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     846.32 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    69 runs   (    0.05 ms per token, 18543.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.32 ms /    61 tokens (    0.73 ms per token,  1376.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.00 ms /    68 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =    1211.19 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /    16 runs   (    0.06 ms per token, 17957.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.39 ms /    31 tokens (    1.01 ms per token,   987.51 tokens per second)\n",
      "llama_print_timings:        eval time =     247.95 ms /    15 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     285.82 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18614.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.38 ms /    48 tokens (    0.78 ms per token,  1284.11 tokens per second)\n",
      "llama_print_timings:        eval time =     697.40 ms /    42 runs   (   16.60 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     750.54 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    51 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    60 tokens (    0.73 ms per token,  1364.41 tokens per second)\n",
      "llama_print_timings:        eval time =     836.00 ms /    50 runs   (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_print_timings:       total time =     899.19 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18567.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.14 ms /    76 tokens (    0.67 ms per token,  1486.20 tokens per second)\n",
      "llama_print_timings:        eval time =     807.42 ms /    48 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =     877.29 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    16 runs   (    0.05 ms per token, 18411.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    51 tokens (    0.85 ms per token,  1181.65 tokens per second)\n",
      "llama_print_timings:        eval time =     248.06 ms /    15 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     296.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18302.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.10 ms /    28 tokens (    1.11 ms per token,   900.41 tokens per second)\n",
      "llama_print_timings:        eval time =     346.53 ms /    21 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     386.32 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /    32 runs   (    0.05 ms per token, 18768.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.41 ms /    38 tokens (    0.91 ms per token,  1104.20 tokens per second)\n",
      "llama_print_timings:        eval time =     512.57 ms /    31 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     559.16 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18472.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.79 ms /    75 tokens (    0.68 ms per token,  1476.67 tokens per second)\n",
      "llama_print_timings:        eval time =     739.45 ms /    44 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =     807.10 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /    26 runs   (    0.06 ms per token, 18093.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.19 ms /    35 tokens (    0.98 ms per token,  1023.63 tokens per second)\n",
      "llama_print_timings:        eval time =     413.28 ms /    25 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     457.53 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18504.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    65 tokens (    0.76 ms per token,  1309.16 tokens per second)\n",
      "llama_print_timings:        eval time =     787.13 ms /    47 runs   (   16.75 ms per token,    59.71 tokens per second)\n",
      "llama_print_timings:       total time =     855.33 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /    52 runs   (    0.05 ms per token, 18711.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.15 ms /    52 tokens (    0.83 ms per token,  1205.07 tokens per second)\n",
      "llama_print_timings:        eval time =     850.05 ms /    51 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     912.92 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18486.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.84 ms /    39 tokens (    0.89 ms per token,  1119.40 tokens per second)\n",
      "llama_print_timings:        eval time =     512.40 ms /    31 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     558.66 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    58 runs   (    0.05 ms per token, 18794.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    67 tokens (    0.75 ms per token,  1331.74 tokens per second)\n",
      "llama_print_timings:        eval time =     956.60 ms /    57 runs   (   16.78 ms per token,    59.59 tokens per second)\n",
      "llama_print_timings:       total time =    1028.53 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    49 runs   (    0.05 ms per token, 18588.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.52 ms /    73 tokens (    0.69 ms per token,  1444.97 tokens per second)\n",
      "llama_print_timings:        eval time =     806.53 ms /    48 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =     875.54 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18437.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.33 ms /    36 tokens (    0.95 ms per token,  1048.80 tokens per second)\n",
      "llama_print_timings:        eval time =     330.70 ms /    20 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     373.10 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    76 runs   (    0.05 ms per token, 18618.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.46 ms /    62 tokens (    0.72 ms per token,  1394.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1258.81 ms /    75 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1332.68 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18569.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.93 ms /    92 tokens (    0.64 ms per token,  1561.17 tokens per second)\n",
      "llama_print_timings:        eval time =     894.88 ms /    53 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =     973.96 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18584.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    61 tokens (    0.72 ms per token,  1384.63 tokens per second)\n",
      "llama_print_timings:        eval time =     768.94 ms /    46 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =     830.52 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    35 runs   (    0.05 ms per token, 18837.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    33 tokens (    1.03 ms per token,   970.82 tokens per second)\n",
      "llama_print_timings:        eval time =     561.85 ms /    34 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     608.88 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18640.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.55 ms /    31 tokens (    1.02 ms per token,   982.51 tokens per second)\n",
      "llama_print_timings:        eval time =     545.51 ms /    33 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     589.17 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /    26 runs   (    0.05 ms per token, 18611.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.68 ms /    40 tokens (    0.87 ms per token,  1153.54 tokens per second)\n",
      "llama_print_timings:        eval time =     413.13 ms /    25 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     456.58 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18376.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    28 tokens (    1.10 ms per token,   905.94 tokens per second)\n",
      "llama_print_timings:        eval time =     380.13 ms /    23 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     420.30 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18485.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.20 ms /    34 tokens (    1.01 ms per token,   994.18 tokens per second)\n",
      "llama_print_timings:        eval time =     495.79 ms /    30 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     540.77 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18659.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.27 ms /    69 tokens (    0.73 ms per token,  1372.45 tokens per second)\n",
      "llama_print_timings:        eval time =     805.34 ms /    48 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =     873.15 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /    19 runs   (    0.05 ms per token, 18464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.21 ms /    30 tokens (    1.04 ms per token,   961.26 tokens per second)\n",
      "llama_print_timings:        eval time =     297.14 ms /    18 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     335.29 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    28 runs   (    0.05 ms per token, 18555.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.59 ms /    38 tokens (    0.91 ms per token,  1098.68 tokens per second)\n",
      "llama_print_timings:        eval time =     446.24 ms /    27 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     490.26 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18609.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.40 ms /    47 tokens (    0.80 ms per token,  1256.79 tokens per second)\n",
      "llama_print_timings:        eval time =     798.24 ms /    48 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     853.21 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.07 ms /    50 tokens (    0.86 ms per token,  1160.79 tokens per second)\n",
      "llama_print_timings:        eval time =     580.16 ms /    35 runs   (   16.58 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     636.37 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /    29 runs   (    0.05 ms per token, 18459.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.70 ms /    41 tokens (    0.90 ms per token,  1117.32 tokens per second)\n",
      "llama_print_timings:        eval time =     463.13 ms /    28 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     510.62 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18471.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.28 ms /    47 tokens (    0.79 ms per token,  1260.66 tokens per second)\n",
      "llama_print_timings:        eval time =     578.62 ms /    35 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     629.37 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18431.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    49 tokens (    0.87 ms per token,  1146.90 tokens per second)\n",
      "llama_print_timings:        eval time =     697.69 ms /    42 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     756.03 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /    31 runs   (    0.05 ms per token, 18844.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.16 ms /    46 tokens (    0.81 ms per token,  1237.99 tokens per second)\n",
      "llama_print_timings:        eval time =     496.26 ms /    30 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     544.68 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    66 runs   (    0.05 ms per token, 18755.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.34 ms /    54 tokens (    0.80 ms per token,  1246.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.32 ms /    65 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1154.92 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.19 ms /    30 tokens (    1.04 ms per token,   961.72 tokens per second)\n",
      "llama_print_timings:        eval time =     380.22 ms /    23 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     421.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    30 tokens (    1.04 ms per token,   959.69 tokens per second)\n",
      "llama_print_timings:        eval time =     545.38 ms /    33 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     589.07 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /    17 runs   (    0.05 ms per token, 18660.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.81 ms /    26 tokens (    1.18 ms per token,   843.96 tokens per second)\n",
      "llama_print_timings:        eval time =     264.25 ms /    16 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     301.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    95 runs   (    0.05 ms per token, 18591.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.24 ms /    99 tokens (    0.66 ms per token,  1517.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1589.03 ms /    94 runs   (   16.90 ms per token,    59.16 tokens per second)\n",
      "llama_print_timings:       total time =    1691.64 ms /   193 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    77 runs   (    0.05 ms per token, 18509.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.25 ms /    88 tokens (    0.66 ms per token,  1510.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.71 ms /    76 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =    1371.54 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18607.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.41 ms /    65 tokens (    0.76 ms per token,  1315.58 tokens per second)\n",
      "llama_print_timings:        eval time =     956.00 ms /    57 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =    1026.54 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18619.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.10 ms /    69 tokens (    0.73 ms per token,  1377.25 tokens per second)\n",
      "llama_print_timings:        eval time =     788.85 ms /    47 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     857.29 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    54 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    65 tokens (    0.76 ms per token,  1309.88 tokens per second)\n",
      "llama_print_timings:        eval time =     888.47 ms /    53 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     958.22 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18646.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.43 ms /    62 tokens (    0.72 ms per token,  1395.33 tokens per second)\n",
      "llama_print_timings:        eval time =     566.90 ms /    34 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     623.80 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /    50 runs   (    0.05 ms per token, 18457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.63 ms /    56 tokens (    0.78 ms per token,  1283.61 tokens per second)\n",
      "llama_print_timings:        eval time =     818.06 ms /    49 runs   (   16.70 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     880.53 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18681.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    56 tokens (    0.78 ms per token,  1281.67 tokens per second)\n",
      "llama_print_timings:        eval time =     834.91 ms /    50 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     897.50 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    34 tokens (    1.00 ms per token,   995.40 tokens per second)\n",
      "llama_print_timings:        eval time =     346.93 ms /    21 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     388.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    68 runs   (    0.05 ms per token, 18448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    73 tokens (    0.69 ms per token,  1439.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.48 ms /    67 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1203.75 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18504.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.18 ms /    35 tokens (    0.98 ms per token,  1023.87 tokens per second)\n",
      "llama_print_timings:        eval time =     777.03 ms /    47 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     828.74 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    66 runs   (    0.05 ms per token, 18602.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    51 tokens (    0.85 ms per token,  1182.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.29 ms /    65 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =    1153.63 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18382.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.47 ms /    37 tokens (    0.93 ms per token,  1073.55 tokens per second)\n",
      "llama_print_timings:        eval time =     645.31 ms /    39 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     696.32 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    67 runs   (    0.05 ms per token, 18657.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.21 ms /    85 tokens (    0.68 ms per token,  1460.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.14 ms /    66 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1197.01 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /    38 runs   (    0.05 ms per token, 18269.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    52 tokens (    0.83 ms per token,  1205.99 tokens per second)\n",
      "llama_print_timings:        eval time =     614.64 ms /    37 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     672.24 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.01 ms /    45 tokens (    0.82 ms per token,  1215.92 tokens per second)\n",
      "llama_print_timings:        eval time =     380.33 ms /    23 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     426.22 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    52 tokens (    0.83 ms per token,  1208.74 tokens per second)\n",
      "llama_print_timings:        eval time =     681.73 ms /    41 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     739.74 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    83 runs   (    0.05 ms per token, 18530.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.61 ms /    72 tokens (    0.70 ms per token,  1422.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1381.47 ms /    82 runs   (   16.85 ms per token,    59.36 tokens per second)\n",
      "llama_print_timings:       total time =    1464.36 ms /   154 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18583.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.89 ms /    59 tokens (    0.74 ms per token,  1344.24 tokens per second)\n",
      "llama_print_timings:        eval time =     599.91 ms /    36 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     657.62 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    59 runs   (    0.05 ms per token, 18600.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    63 tokens (    0.70 ms per token,  1424.24 tokens per second)\n",
      "llama_print_timings:        eval time =     972.09 ms /    58 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1038.06 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    64 runs   (    0.05 ms per token, 18491.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.43 ms /    65 tokens (    0.76 ms per token,  1315.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1057.77 ms /    63 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1132.32 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    71 tokens (    0.71 ms per token,  1410.38 tokens per second)\n",
      "llama_print_timings:        eval time =     789.02 ms /    47 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     856.91 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /    33 runs   (    0.05 ms per token, 18644.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.73 ms /    42 tokens (    0.87 ms per token,  1143.54 tokens per second)\n",
      "llama_print_timings:        eval time =     529.07 ms /    32 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     577.68 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /    16 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    22 tokens (    1.24 ms per token,   804.92 tokens per second)\n",
      "llama_print_timings:        eval time =     247.64 ms /    15 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     280.73 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    63 runs   (    0.05 ms per token, 18628.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.59 ms /    80 tokens (    0.64 ms per token,  1550.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.70 ms /    62 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1120.94 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /    37 runs   (    0.05 ms per token, 18753.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.82 ms /    44 tokens (    0.84 ms per token,  1195.07 tokens per second)\n",
      "llama_print_timings:        eval time =     595.38 ms /    36 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     645.83 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    51 runs   (    0.05 ms per token, 18385.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.67 ms /    39 tokens (    0.89 ms per token,  1124.86 tokens per second)\n",
      "llama_print_timings:        eval time =     828.98 ms /    50 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     882.03 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18643.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    55 tokens (    0.79 ms per token,  1263.18 tokens per second)\n",
      "llama_print_timings:        eval time =     581.64 ms /    35 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     638.32 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    64 runs   (    0.05 ms per token, 18539.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.63 ms /    83 tokens (    0.69 ms per token,  1440.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1063.37 ms /    63 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =    1145.57 ms /   146 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     5 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.19 ms /    20 tokens (    1.36 ms per token,   735.56 tokens per second)\n",
      "llama_print_timings:        eval time =      65.98 ms /     4 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =      95.13 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18458.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.88 ms /    58 tokens (    0.76 ms per token,  1321.79 tokens per second)\n",
      "llama_print_timings:        eval time =     650.03 ms /    39 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     708.15 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18674.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.61 ms /    80 tokens (    0.65 ms per token,  1550.06 tokens per second)\n",
      "llama_print_timings:        eval time =     690.87 ms /    41 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =     757.52 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    51 runs   (    0.05 ms per token, 18606.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.27 ms /    47 tokens (    0.79 ms per token,  1261.17 tokens per second)\n",
      "llama_print_timings:        eval time =     831.93 ms /    50 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     888.45 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /    27 runs   (    0.05 ms per token, 18417.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.76 ms /    42 tokens (    0.88 ms per token,  1142.58 tokens per second)\n",
      "llama_print_timings:        eval time =     429.94 ms /    26 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     475.91 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18599.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.53 ms /    63 tokens (    0.71 ms per token,  1414.78 tokens per second)\n",
      "llama_print_timings:        eval time =     904.81 ms /    54 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     970.26 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18481.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.36 ms /    38 tokens (    0.90 ms per token,  1105.97 tokens per second)\n",
      "llama_print_timings:        eval time =     595.06 ms /    36 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     642.99 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18391.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.68 ms /    57 tokens (    0.77 ms per token,  1304.86 tokens per second)\n",
      "llama_print_timings:        eval time =     700.06 ms /    42 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     759.45 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /    19 runs   (    0.05 ms per token, 18482.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.45 ms /    23 tokens (    1.19 ms per token,   837.76 tokens per second)\n",
      "llama_print_timings:        eval time =     297.11 ms /    18 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     331.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.86 ms /    67 tokens (    0.74 ms per token,  1343.65 tokens per second)\n",
      "llama_print_timings:        eval time =     198.43 ms /    12 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     252.37 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    72 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    67 tokens (    0.74 ms per token,  1342.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1193.07 ms /    71 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =    1271.22 ms /   138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    48 runs   (    0.05 ms per token, 18411.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.43 ms /    88 tokens (    0.66 ms per token,  1505.97 tokens per second)\n",
      "llama_print_timings:        eval time =     793.08 ms /    47 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     869.72 ms /   135 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    53 runs   (    0.05 ms per token, 18827.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.25 ms /    30 tokens (    1.04 ms per token,   960.06 tokens per second)\n",
      "llama_print_timings:        eval time =     859.44 ms /    52 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     911.05 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    54 runs   (    0.05 ms per token, 18512.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.91 ms /    91 tokens (    0.65 ms per token,  1544.76 tokens per second)\n",
      "llama_print_timings:        eval time =     894.48 ms /    53 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =     973.70 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18427.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.70 ms /    41 tokens (    0.90 ms per token,  1117.17 tokens per second)\n",
      "llama_print_timings:        eval time =     231.32 ms /    14 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     273.16 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    30 runs   (    0.05 ms per token, 18738.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.10 ms /    43 tokens (    0.86 ms per token,  1159.06 tokens per second)\n",
      "llama_print_timings:        eval time =     479.18 ms /    29 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     527.35 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /    13 runs   (    0.06 ms per token, 18055.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.46 ms /    15 tokens (    1.83 ms per token,   546.31 tokens per second)\n",
      "llama_print_timings:        eval time =     198.12 ms /    12 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     230.79 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18543.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.68 ms /    81 tokens (    0.70 ms per token,  1429.00 tokens per second)\n",
      "llama_print_timings:        eval time =     893.62 ms /    53 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =     970.38 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /    16 runs   (    0.05 ms per token, 18202.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    34 tokens (    1.00 ms per token,  1000.29 tokens per second)\n",
      "llama_print_timings:        eval time =     247.64 ms /    15 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     287.04 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    53 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.66 ms /    56 tokens (    0.78 ms per token,  1282.52 tokens per second)\n",
      "llama_print_timings:        eval time =     868.37 ms /    52 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     932.24 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    64 runs   (    0.05 ms per token, 18648.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.26 ms /    77 tokens (    0.67 ms per token,  1502.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.05 ms /    63 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =    1136.63 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18646.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.92 ms /    68 tokens (    0.73 ms per token,  1362.21 tokens per second)\n",
      "llama_print_timings:        eval time =     568.79 ms /    34 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =     631.60 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    35 runs   (    0.05 ms per token, 18746.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.71 ms /    43 tokens (    0.85 ms per token,  1171.25 tokens per second)\n",
      "llama_print_timings:        eval time =     562.12 ms /    34 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     612.47 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18383.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.16 ms /    34 tokens (    1.00 ms per token,   995.37 tokens per second)\n",
      "llama_print_timings:        eval time =     694.54 ms /    42 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     746.11 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18576.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    74 tokens (    0.69 ms per token,  1458.79 tokens per second)\n",
      "llama_print_timings:        eval time =     874.58 ms /    52 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     944.90 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18569.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.46 ms /    64 tokens (    0.69 ms per token,  1439.56 tokens per second)\n",
      "llama_print_timings:        eval time =     770.14 ms /    46 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     833.08 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18533.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.44 ms /    62 tokens (    0.72 ms per token,  1395.17 tokens per second)\n",
      "llama_print_timings:        eval time =     752.15 ms /    45 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     814.52 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    56 runs   (    0.05 ms per token, 18785.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.18 ms /    33 tokens (    1.04 ms per token,   965.45 tokens per second)\n",
      "llama_print_timings:        eval time =     911.12 ms /    55 runs   (   16.57 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     966.95 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /    14 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.76 ms /    40 tokens (    0.87 ms per token,  1150.71 tokens per second)\n",
      "llama_print_timings:        eval time =     214.71 ms /    13 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     254.97 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18564.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.95 ms /    18 tokens (    1.50 ms per token,   668.00 tokens per second)\n",
      "llama_print_timings:        eval time =     594.32 ms /    36 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     635.37 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.89 ms /    49 tokens (    0.88 ms per token,  1142.54 tokens per second)\n",
      "llama_print_timings:        eval time =     680.41 ms /    41 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     739.11 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18470.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.66 ms /    41 tokens (    0.89 ms per token,  1118.48 tokens per second)\n",
      "llama_print_timings:        eval time =     694.80 ms /    42 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     747.86 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /    15 runs   (    0.05 ms per token, 18703.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.28 tokens per second)\n",
      "llama_print_timings:        eval time =     231.06 ms /    14 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     263.87 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18568.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.31 ms /    70 tokens (    0.72 ms per token,  1391.32 tokens per second)\n",
      "llama_print_timings:        eval time =     906.88 ms /    54 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     978.14 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    27 tokens (    1.14 ms per token,   873.65 tokens per second)\n",
      "llama_print_timings:        eval time =     313.60 ms /    19 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     351.73 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18662.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.49 ms /    63 tokens (    0.71 ms per token,  1415.98 tokens per second)\n",
      "llama_print_timings:        eval time =     381.74 ms /    23 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     434.77 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18554.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    27 tokens (    1.14 ms per token,   875.91 tokens per second)\n",
      "llama_print_timings:        eval time =     462.44 ms /    28 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     503.68 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    73 runs   (    0.05 ms per token, 18532.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.61 ms /    55 tokens (    0.79 ms per token,  1261.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.38 ms /    72 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =    1277.46 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18606.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.02 ms /    59 tokens (    0.75 ms per token,  1340.15 tokens per second)\n",
      "llama_print_timings:        eval time =     903.59 ms /    54 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     968.76 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18618.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.57 ms /    24 tokens (    1.15 ms per token,   870.45 tokens per second)\n",
      "llama_print_timings:        eval time =     726.78 ms /    44 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     771.52 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /    26 runs   (    0.05 ms per token, 18544.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    43 tokens (    0.86 ms per token,  1165.34 tokens per second)\n",
      "llama_print_timings:        eval time =     413.31 ms /    25 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     460.11 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    40 runs   (    0.05 ms per token, 18273.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    57 tokens (    0.77 ms per token,  1298.23 tokens per second)\n",
      "llama_print_timings:        eval time =     649.50 ms /    39 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     708.14 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /    28 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    51 tokens (    0.84 ms per token,  1185.50 tokens per second)\n",
      "llama_print_timings:        eval time =     446.42 ms /    27 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     500.16 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    76 runs   (    0.05 ms per token, 18627.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.62 ms /    77 tokens (    0.67 ms per token,  1491.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.40 ms /    75 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =    1345.86 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.89 ms /    44 tokens (    0.84 ms per token,  1192.64 tokens per second)\n",
      "llama_print_timings:        eval time =     595.27 ms /    36 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     646.55 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /    33 runs   (    0.05 ms per token, 18665.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.67 ms /    38 tokens (    0.91 ms per token,  1095.99 tokens per second)\n",
      "llama_print_timings:        eval time =     528.85 ms /    32 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     575.99 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    41 runs   (    0.05 ms per token, 18721.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.51 ms /    41 tokens (    0.89 ms per token,  1123.07 tokens per second)\n",
      "llama_print_timings:        eval time =     661.27 ms /    40 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     713.47 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18564.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    58 tokens (    0.76 ms per token,  1320.79 tokens per second)\n",
      "llama_print_timings:        eval time =     734.07 ms /    44 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     795.13 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    28 tokens (    1.11 ms per token,   904.16 tokens per second)\n",
      "llama_print_timings:        eval time =     214.68 ms /    13 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     251.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    65 runs   (    0.05 ms per token, 18507.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    53 tokens (    0.82 ms per token,  1224.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1069.82 ms /    64 runs   (   16.72 ms per token,    59.82 tokens per second)\n",
      "llama_print_timings:       total time =    1138.22 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /    60 runs   (    0.05 ms per token, 18450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    59 tokens (    0.75 ms per token,  1341.64 tokens per second)\n",
      "llama_print_timings:        eval time =     987.72 ms /    59 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =    1055.80 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.22 ms /    35 tokens (    0.98 ms per token,  1022.82 tokens per second)\n",
      "llama_print_timings:        eval time =     429.38 ms /    26 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     473.14 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    49 runs   (    0.05 ms per token, 18846.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.53 ms /    55 tokens (    0.79 ms per token,  1263.53 tokens per second)\n",
      "llama_print_timings:        eval time =     800.62 ms /    48 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =     862.36 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /    24 runs   (    0.06 ms per token, 18126.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.49 ms /    48 tokens (    0.78 ms per token,  1280.44 tokens per second)\n",
      "llama_print_timings:        eval time =     380.55 ms /    23 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     427.44 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.16 ms /    60 tokens (    0.74 ms per token,  1358.79 tokens per second)\n",
      "llama_print_timings:        eval time =     582.94 ms /    35 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     640.68 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    69 runs   (    0.05 ms per token, 18553.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.42 ms /    55 tokens (    0.79 ms per token,  1266.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.01 ms /    68 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =    1207.74 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18455.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.74 ms /    40 tokens (    0.87 ms per token,  1151.28 tokens per second)\n",
      "llama_print_timings:        eval time =     611.80 ms /    37 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     661.21 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /    26 runs   (    0.05 ms per token, 18271.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.45 ms /    48 tokens (    0.78 ms per token,  1281.54 tokens per second)\n",
      "llama_print_timings:        eval time =     413.45 ms /    25 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     460.73 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /    54 runs   (    0.05 ms per token, 18398.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.72 ms /    72 tokens (    0.70 ms per token,  1419.70 tokens per second)\n",
      "llama_print_timings:        eval time =     890.94 ms /    53 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =     962.86 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18457.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.23 ms /    54 tokens (    0.80 ms per token,  1249.25 tokens per second)\n",
      "llama_print_timings:        eval time =     732.84 ms /    44 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     793.41 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18591.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.96 ms /    28 tokens (    1.11 ms per token,   904.25 tokens per second)\n",
      "llama_print_timings:        eval time =     611.27 ms /    37 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     657.25 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    64 runs   (    0.05 ms per token, 18577.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.80 ms /    66 tokens (    0.75 ms per token,  1325.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1057.41 ms /    63 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1132.03 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18537.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.70 ms /    42 tokens (    0.87 ms per token,  1144.32 tokens per second)\n",
      "llama_print_timings:        eval time =     578.60 ms /    35 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     628.97 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18424.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.08 ms /    44 tokens (    0.84 ms per token,  1186.53 tokens per second)\n",
      "llama_print_timings:        eval time =     763.21 ms /    46 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     817.85 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    49 runs   (    0.05 ms per token, 18716.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.43 ms /    62 tokens (    0.72 ms per token,  1395.52 tokens per second)\n",
      "llama_print_timings:        eval time =     802.87 ms /    48 runs   (   16.73 ms per token,    59.79 tokens per second)\n",
      "llama_print_timings:       total time =     865.43 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    47 runs   (    0.05 ms per token, 18695.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.25 ms /    30 tokens (    1.04 ms per token,   960.03 tokens per second)\n",
      "llama_print_timings:        eval time =     760.25 ms /    46 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     809.48 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /    21 runs   (    0.05 ms per token, 18292.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.75 ms /    32 tokens (    0.99 ms per token,  1008.00 tokens per second)\n",
      "llama_print_timings:        eval time =     330.15 ms /    20 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     369.06 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     7 runs   (    0.05 ms per token, 18617.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.24 ms /    21 tokens (    1.30 ms per token,   770.84 tokens per second)\n",
      "llama_print_timings:        eval time =      98.97 ms /     6 runs   (   16.49 ms per token,    60.63 tokens per second)\n",
      "llama_print_timings:       total time =     128.33 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    56 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.26 ms /    77 tokens (    0.67 ms per token,  1502.29 tokens per second)\n",
      "llama_print_timings:        eval time =     926.01 ms /    55 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     999.32 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    50 runs   (    0.05 ms per token, 18402.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    56 tokens (    0.78 ms per token,  1285.79 tokens per second)\n",
      "llama_print_timings:        eval time =     817.77 ms /    49 runs   (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:       total time =     880.85 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    73 runs   (    0.05 ms per token, 18660.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.58 ms /    95 tokens (    0.63 ms per token,  1594.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.63 ms /    72 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =    1303.00 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18626.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.27 ms /    38 tokens (    0.90 ms per token,  1108.91 tokens per second)\n",
      "llama_print_timings:        eval time =     562.36 ms /    34 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     610.18 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    63 runs   (    0.05 ms per token, 18666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.66 ms /    72 tokens (    0.70 ms per token,  1421.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.64 ms /    62 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =    1117.14 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    72 runs   (    0.05 ms per token, 18556.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.05 ms /    70 tokens (    0.72 ms per token,  1398.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1194.08 ms /    71 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =    1272.38 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /    19 runs   (    0.05 ms per token, 18393.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.99 ms /    45 tokens (    0.82 ms per token,  1216.55 tokens per second)\n",
      "llama_print_timings:        eval time =     297.86 ms /    18 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     342.69 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18394.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    34 tokens (    1.00 ms per token,   998.38 tokens per second)\n",
      "llama_print_timings:        eval time =     710.79 ms /    43 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     761.55 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18482.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.23 ms /    47 tokens (    0.79 ms per token,  1262.52 tokens per second)\n",
      "llama_print_timings:        eval time =     781.13 ms /    47 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     836.43 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18645.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.17 ms /   100 tokens (    0.65 ms per token,  1534.35 tokens per second)\n",
      "llama_print_timings:        eval time =     996.35 ms /    59 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =    1084.04 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    42 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.42 ms /    47 tokens (    0.80 ms per token,  1255.95 tokens per second)\n",
      "llama_print_timings:        eval time =     680.23 ms /    41 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     735.12 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    59 runs   (    0.05 ms per token, 18425.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.37 ms /    71 tokens (    0.71 ms per token,  1409.71 tokens per second)\n",
      "llama_print_timings:        eval time =     974.87 ms /    58 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =    1047.85 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    74 runs   (    0.05 ms per token, 18569.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.18 ms /    70 tokens (    0.72 ms per token,  1395.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1228.17 ms /    73 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =    1307.32 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    51 runs   (    0.05 ms per token, 18626.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.51 ms /    70 tokens (    0.72 ms per token,  1385.81 tokens per second)\n",
      "llama_print_timings:        eval time =     839.48 ms /    50 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     910.40 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    34 runs   (    0.05 ms per token, 18279.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.51 ms /    41 tokens (    0.89 ms per token,  1123.13 tokens per second)\n",
      "llama_print_timings:        eval time =     545.23 ms /    33 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     594.24 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    57 runs   (    0.05 ms per token, 18651.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.96 ms /    76 tokens (    0.67 ms per token,  1491.25 tokens per second)\n",
      "llama_print_timings:        eval time =     942.58 ms /    56 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1015.43 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /    30 runs   (    0.05 ms per token, 18192.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.07 ms /    29 tokens (    1.07 ms per token,   933.53 tokens per second)\n",
      "llama_print_timings:        eval time =     479.19 ms /    29 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     522.01 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18712.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.36 ms /    31 tokens (    1.01 ms per token,   988.61 tokens per second)\n",
      "llama_print_timings:        eval time =     545.30 ms /    33 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     589.89 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.19 ms /    51 tokens (    0.85 ms per token,  1180.97 tokens per second)\n",
      "llama_print_timings:        eval time =     613.80 ms /    37 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     671.18 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    68 runs   (    0.05 ms per token, 18645.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.91 ms /    66 tokens (    0.76 ms per token,  1322.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.17 ms /    67 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =    1201.56 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18555.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.06 ms /    44 tokens (    0.84 ms per token,  1187.30 tokens per second)\n",
      "llama_print_timings:        eval time =     746.48 ms /    45 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     800.96 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    37 runs   (    0.05 ms per token, 18353.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    52 tokens (    0.83 ms per token,  1204.90 tokens per second)\n",
      "llama_print_timings:        eval time =     597.61 ms /    36 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     655.23 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18508.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    34 tokens (    1.00 ms per token,   998.53 tokens per second)\n",
      "llama_print_timings:        eval time =     562.06 ms /    34 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     609.72 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /    23 runs   (    0.05 ms per token, 18653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    33 tokens (    1.03 ms per token,   970.96 tokens per second)\n",
      "llama_print_timings:        eval time =     363.25 ms /    22 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     405.14 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    51 runs   (    0.05 ms per token, 18411.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.86 ms /    40 tokens (    0.87 ms per token,  1147.45 tokens per second)\n",
      "llama_print_timings:        eval time =     829.21 ms /    50 runs   (   16.58 ms per token,    60.30 tokens per second)\n",
      "llama_print_timings:       total time =     883.27 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    50 runs   (    0.05 ms per token, 18402.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.20 ms /    77 tokens (    0.66 ms per token,  1503.88 tokens per second)\n",
      "llama_print_timings:        eval time =     824.72 ms /    49 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     895.32 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    58 runs   (    0.05 ms per token, 18453.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.12 ms /    69 tokens (    0.73 ms per token,  1376.61 tokens per second)\n",
      "llama_print_timings:        eval time =     957.26 ms /    57 runs   (   16.79 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1029.90 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18423.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    27 tokens (    1.14 ms per token,   874.66 tokens per second)\n",
      "llama_print_timings:        eval time =     578.15 ms /    35 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     622.49 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /    10 runs   (    0.05 ms per token, 18348.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.14 ms /    29 tokens (    1.07 ms per token,   931.16 tokens per second)\n",
      "llama_print_timings:        eval time =     148.61 ms /     9 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     182.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    76 runs   (    0.05 ms per token, 18437.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.24 ms /    78 tokens (    0.66 ms per token,  1522.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.98 ms /    75 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1346.37 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18569.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.64 ms /    41 tokens (    0.89 ms per token,  1118.93 tokens per second)\n",
      "llama_print_timings:        eval time =     545.55 ms /    33 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     595.33 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    34 runs   (    0.05 ms per token, 18388.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.23 ms /    59 tokens (    0.75 ms per token,  1333.88 tokens per second)\n",
      "llama_print_timings:        eval time =     548.88 ms /    33 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     605.09 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.10 ms /    52 tokens (    0.83 ms per token,  1206.41 tokens per second)\n",
      "llama_print_timings:        eval time =     647.82 ms /    39 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     706.16 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18537.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.35 ms /    37 tokens (    0.93 ms per token,  1077.15 tokens per second)\n",
      "llama_print_timings:        eval time =     595.15 ms /    36 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     642.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    57 runs   (    0.05 ms per token, 18737.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.55 ms /    48 tokens (    0.78 ms per token,  1278.43 tokens per second)\n",
      "llama_print_timings:        eval time =     933.27 ms /    56 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     992.40 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    42 runs   (    0.05 ms per token, 18245.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.70 ms /    42 tokens (    0.87 ms per token,  1144.45 tokens per second)\n",
      "llama_print_timings:        eval time =     678.42 ms /    41 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     732.55 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /    45 runs   (    0.05 ms per token, 18672.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.19 ms /    87 tokens (    0.67 ms per token,  1495.00 tokens per second)\n",
      "llama_print_timings:        eval time =     742.25 ms /    44 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =     818.04 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    30 runs   (    0.05 ms per token, 18552.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.06 ms /    46 tokens (    0.81 ms per token,  1241.30 tokens per second)\n",
      "llama_print_timings:        eval time =     479.56 ms /    29 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     528.10 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    45 runs   (    0.05 ms per token, 18412.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.49 ms /    31 tokens (    1.02 ms per token,   984.44 tokens per second)\n",
      "llama_print_timings:        eval time =     727.19 ms /    44 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     776.12 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    74 runs   (    0.05 ms per token, 18630.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.23 ms /    51 tokens (    0.85 ms per token,  1179.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1221.24 ms /    73 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =    1293.06 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    59 runs   (    0.05 ms per token, 18425.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.69 ms /    43 tokens (    0.85 ms per token,  1171.95 tokens per second)\n",
      "llama_print_timings:        eval time =     965.30 ms /    58 runs   (   16.64 ms per token,    60.09 tokens per second)\n",
      "llama_print_timings:       total time =    1024.52 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /    22 runs   (    0.06 ms per token, 18047.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.91 ms /    51 tokens (    0.84 ms per token,  1188.51 tokens per second)\n",
      "llama_print_timings:        eval time =     347.26 ms /    21 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     398.15 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /    18 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.83 ms /    17 tokens (    1.58 ms per token,   633.62 tokens per second)\n",
      "llama_print_timings:        eval time =     280.67 ms /    17 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     313.57 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18596.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.71 ms /    39 tokens (    0.89 ms per token,  1123.63 tokens per second)\n",
      "llama_print_timings:        eval time =     495.91 ms /    30 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     542.31 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18429.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.58 ms /    38 tokens (    0.91 ms per token,  1099.00 tokens per second)\n",
      "llama_print_timings:        eval time =     363.45 ms /    22 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     406.92 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /    51 runs   (    0.05 ms per token, 18371.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.31 ms /    47 tokens (    0.79 ms per token,  1259.61 tokens per second)\n",
      "llama_print_timings:        eval time =     831.57 ms /    50 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     888.23 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /    25 runs   (    0.05 ms per token, 18422.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.93 ms /    27 tokens (    1.15 ms per token,   872.91 tokens per second)\n",
      "llama_print_timings:        eval time =     396.51 ms /    24 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     437.71 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /    16 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    22 tokens (    1.25 ms per token,   802.39 tokens per second)\n",
      "llama_print_timings:        eval time =     247.65 ms /    15 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     280.99 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /    29 runs   (    0.05 ms per token, 18471.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.49 ms /    55 tokens (    0.79 ms per token,  1264.66 tokens per second)\n",
      "llama_print_timings:        eval time =     463.53 ms /    28 runs   (   16.55 ms per token,    60.41 tokens per second)\n",
      "llama_print_timings:       total time =     517.89 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /    22 runs   (    0.05 ms per token, 18819.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.06 ms /    33 tokens (    1.03 ms per token,   968.79 tokens per second)\n",
      "llama_print_timings:        eval time =     346.90 ms /    21 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     389.41 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18562.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.48 ms /    35 tokens (    0.99 ms per token,  1014.93 tokens per second)\n",
      "llama_print_timings:        eval time =     894.93 ms /    54 runs   (   16.57 ms per token,    60.34 tokens per second)\n",
      "llama_print_timings:       total time =     950.24 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18416.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.35 ms /    31 tokens (    1.01 ms per token,   988.71 tokens per second)\n",
      "llama_print_timings:        eval time =     313.56 ms /    19 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     352.62 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18425.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.94 ms /    68 tokens (    0.73 ms per token,  1361.69 tokens per second)\n",
      "llama_print_timings:        eval time =     720.69 ms /    43 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     787.96 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    37 runs   (    0.05 ms per token, 18546.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.57 ms /    41 tokens (    0.89 ms per token,  1121.14 tokens per second)\n",
      "llama_print_timings:        eval time =     595.22 ms /    36 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     645.77 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    54 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.71 ms /    64 tokens (    0.70 ms per token,  1431.32 tokens per second)\n",
      "llama_print_timings:        eval time =     887.77 ms /    53 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =     952.64 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /    29 runs   (    0.05 ms per token, 18506.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.47 ms /    32 tokens (    0.98 ms per token,  1016.74 tokens per second)\n",
      "llama_print_timings:        eval time =     462.51 ms /    28 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     504.39 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18511.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.05 ms /    33 tokens (    1.03 ms per token,   969.22 tokens per second)\n",
      "llama_print_timings:        eval time =     810.07 ms /    49 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     863.50 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18609.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.75 ms /    74 tokens (    0.69 ms per token,  1458.04 tokens per second)\n",
      "llama_print_timings:        eval time =     621.25 ms /    37 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     686.21 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18387.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.22 ms /    29 tokens (    1.08 ms per token,   928.77 tokens per second)\n",
      "llama_print_timings:        eval time =     198.19 ms /    12 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     233.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    15 runs   (    0.05 ms per token, 18610.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.55 ms /    16 tokens (    1.72 ms per token,   580.74 tokens per second)\n",
      "llama_print_timings:        eval time =     230.86 ms /    14 runs   (   16.49 ms per token,    60.64 tokens per second)\n",
      "llama_print_timings:       total time =     263.46 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18484.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.65 ms /    25 tokens (    1.23 ms per token,   815.66 tokens per second)\n",
      "llama_print_timings:        eval time =     313.63 ms /    19 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     351.44 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18510.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    68 tokens (    0.74 ms per token,  1357.72 tokens per second)\n",
      "llama_print_timings:        eval time =     703.62 ms /    42 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     769.52 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    60 runs   (    0.05 ms per token, 18674.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.58 ms /    49 tokens (    0.87 ms per token,  1150.80 tokens per second)\n",
      "llama_print_timings:        eval time =     984.22 ms /    59 runs   (   16.68 ms per token,    59.95 tokens per second)\n",
      "llama_print_timings:       total time =    1049.44 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    40 runs   (    0.05 ms per token, 18190.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.03 ms /    44 tokens (    0.84 ms per token,  1188.19 tokens per second)\n",
      "llama_print_timings:        eval time =     645.32 ms /    39 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     698.26 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /    36 runs   (    0.05 ms per token, 18720.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    27 tokens (    1.14 ms per token,   874.66 tokens per second)\n",
      "llama_print_timings:        eval time =     578.05 ms /    35 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     622.61 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     8 runs   (    0.06 ms per token, 18099.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.76 ms /    17 tokens (    1.57 ms per token,   635.32 tokens per second)\n",
      "llama_print_timings:        eval time =     115.49 ms /     7 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     145.12 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    96 runs   (    0.05 ms per token, 18447.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.77 ms /    80 tokens (    0.65 ms per token,  1545.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1603.68 ms /    95 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1694.86 ms /   175 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    73 runs   (    0.05 ms per token, 18598.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.68 ms /    84 tokens (    0.69 ms per token,  1456.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.37 ms /    72 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1300.96 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /    12 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.85 ms /    42 tokens (    0.88 ms per token,  1139.85 tokens per second)\n",
      "llama_print_timings:        eval time =     181.71 ms /    11 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     223.19 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18426.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.28 ms /    46 tokens (    0.81 ms per token,  1234.04 tokens per second)\n",
      "llama_print_timings:        eval time =     781.05 ms /    47 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     837.09 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /    16 runs   (    0.06 ms per token, 18140.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.15 ms /    34 tokens (    1.00 ms per token,   995.52 tokens per second)\n",
      "llama_print_timings:        eval time =     247.55 ms /    15 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     287.75 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18416.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.78 ms /    18 tokens (    1.49 ms per token,   672.17 tokens per second)\n",
      "llama_print_timings:        eval time =     313.61 ms /    19 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     348.13 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    64 runs   (    0.05 ms per token, 18280.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    33 tokens (    1.03 ms per token,   967.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.89 ms /    63 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =    1105.08 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /    10 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.08 ms /    19 tokens (    1.43 ms per token,   701.52 tokens per second)\n",
      "llama_print_timings:        eval time =     148.53 ms /     9 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     179.19 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /    13 runs   (    0.05 ms per token, 18258.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.60 ms /    41 tokens (    0.89 ms per token,  1120.19 tokens per second)\n",
      "llama_print_timings:        eval time =     198.27 ms /    12 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     239.80 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18447.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.46 ms /    32 tokens (    0.98 ms per token,  1017.20 tokens per second)\n",
      "llama_print_timings:        eval time =     379.80 ms /    23 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     420.09 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /    26 runs   (    0.05 ms per token, 18284.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.88 ms /    49 tokens (    0.88 ms per token,  1142.70 tokens per second)\n",
      "llama_print_timings:        eval time =     413.78 ms /    25 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     466.79 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    65 runs   (    0.05 ms per token, 18529.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.97 ms /    73 tokens (    0.70 ms per token,  1432.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1076.94 ms /    64 runs   (   16.83 ms per token,    59.43 tokens per second)\n",
      "llama_print_timings:       total time =    1152.65 ms /   137 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18220.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    28 tokens (    1.10 ms per token,   906.97 tokens per second)\n",
      "llama_print_timings:        eval time =     264.20 ms /    16 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     301.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    87 runs   (    0.05 ms per token, 18597.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.32 ms /    69 tokens (    0.73 ms per token,  1371.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1447.62 ms /    86 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =    1532.79 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    59 runs   (    0.05 ms per token, 18611.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.66 ms /    82 tokens (    0.69 ms per token,  1447.33 tokens per second)\n",
      "llama_print_timings:        eval time =     978.75 ms /    58 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =    1058.05 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18501.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.02 ms /    33 tokens (    1.03 ms per token,   969.90 tokens per second)\n",
      "llama_print_timings:        eval time =     313.74 ms /    19 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     355.08 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    65 tokens (    0.77 ms per token,  1306.59 tokens per second)\n",
      "llama_print_timings:        eval time =     888.22 ms /    53 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     958.68 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    60 runs   (    0.05 ms per token, 18512.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.85 ms /    74 tokens (    0.69 ms per token,  1455.38 tokens per second)\n",
      "llama_print_timings:        eval time =     992.90 ms /    59 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1066.80 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    46 runs   (    0.05 ms per token, 18676.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.28 ms /    70 tokens (    0.72 ms per token,  1392.31 tokens per second)\n",
      "llama_print_timings:        eval time =     754.80 ms /    45 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =     822.75 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /    58 runs   (    0.05 ms per token, 18661.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.18 ms /    77 tokens (    0.66 ms per token,  1504.49 tokens per second)\n",
      "llama_print_timings:        eval time =     960.03 ms /    57 runs   (   16.84 ms per token,    59.37 tokens per second)\n",
      "llama_print_timings:       total time =    1032.96 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18498.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.06 ms /    75 tokens (    0.68 ms per token,  1468.77 tokens per second)\n",
      "llama_print_timings:        eval time =     571.13 ms /    34 runs   (   16.80 ms per token,    59.53 tokens per second)\n",
      "llama_print_timings:       total time =     636.12 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18492.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.77 ms /    43 tokens (    0.86 ms per token,  1169.30 tokens per second)\n",
      "llama_print_timings:        eval time =     628.32 ms /    38 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     679.07 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.30 ms /    47 tokens (    0.79 ms per token,  1259.88 tokens per second)\n",
      "llama_print_timings:        eval time =     446.40 ms /    27 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     494.27 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    61 runs   (    0.05 ms per token, 18496.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.63 ms /    65 tokens (    0.76 ms per token,  1309.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1006.45 ms /    60 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =    1079.93 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    39 runs   (    0.05 ms per token, 18624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    53 tokens (    0.81 ms per token,  1229.04 tokens per second)\n",
      "llama_print_timings:        eval time =     631.28 ms /    38 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     688.91 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.54 ms /    23 tokens (    1.20 ms per token,   835.24 tokens per second)\n",
      "llama_print_timings:        eval time =     132.02 ms /     8 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     162.67 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18572.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.75 ms /    41 tokens (    0.90 ms per token,  1115.77 tokens per second)\n",
      "llama_print_timings:        eval time =     829.55 ms /    50 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     885.83 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /    44 runs   (    0.05 ms per token, 18386.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.78 ms /    56 tokens (    0.78 ms per token,  1279.01 tokens per second)\n",
      "llama_print_timings:        eval time =     716.35 ms /    43 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     776.62 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.91 ms /    28 tokens (    1.10 ms per token,   905.89 tokens per second)\n",
      "llama_print_timings:        eval time =     132.07 ms /     8 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     166.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18379.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.31 ms /    35 tokens (    0.98 ms per token,  1020.05 tokens per second)\n",
      "llama_print_timings:        eval time =     346.76 ms /    21 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     388.93 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18625.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.94 ms /    43 tokens (    0.86 ms per token,  1164.14 tokens per second)\n",
      "llama_print_timings:        eval time =     462.92 ms /    28 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     510.45 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    37 runs   (    0.05 ms per token, 18887.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.03 ms /    50 tokens (    0.86 ms per token,  1161.93 tokens per second)\n",
      "llama_print_timings:        eval time =     596.68 ms /    36 runs   (   16.57 ms per token,    60.33 tokens per second)\n",
      "llama_print_timings:       total time =     653.51 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    75 runs   (    0.05 ms per token, 18536.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.07 ms /    68 tokens (    0.74 ms per token,  1358.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.72 ms /    74 runs   (   16.81 ms per token,    59.50 tokens per second)\n",
      "llama_print_timings:       total time =    1322.70 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    54 runs   (    0.05 ms per token, 18524.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.07 ms /    76 tokens (    0.67 ms per token,  1488.10 tokens per second)\n",
      "llama_print_timings:        eval time =     892.26 ms /    53 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =     964.16 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    50 runs   (    0.05 ms per token, 18395.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    59 tokens (    0.75 ms per token,  1337.23 tokens per second)\n",
      "llama_print_timings:        eval time =     818.58 ms /    49 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     881.14 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    92 runs   (    0.05 ms per token, 18470.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      65.04 ms /    98 tokens (    0.66 ms per token,  1506.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1537.90 ms /    91 runs   (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:       total time =    1641.19 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    69 runs   (    0.05 ms per token, 18704.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.65 ms /    65 tokens (    0.76 ms per token,  1309.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.44 ms /    68 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =    1217.98 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    29 runs   (    0.05 ms per token, 18542.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.96 ms /    51 tokens (    0.84 ms per token,  1187.07 tokens per second)\n",
      "llama_print_timings:        eval time =     463.00 ms /    28 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     516.48 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    86 runs   (    0.05 ms per token, 18427.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    81 tokens (    0.70 ms per token,  1427.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.87 ms /    85 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1526.42 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /    23 runs   (    0.05 ms per token, 18488.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.53 ms /    32 tokens (    0.99 ms per token,  1014.81 tokens per second)\n",
      "llama_print_timings:        eval time =     363.32 ms /    22 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     403.41 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.32 ms /    53 tokens (    0.82 ms per token,  1223.45 tokens per second)\n",
      "llama_print_timings:        eval time =     715.69 ms /    43 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     775.56 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    43 runs   (    0.05 ms per token, 18454.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    35 tokens (    0.98 ms per token,  1021.69 tokens per second)\n",
      "llama_print_timings:        eval time =     694.35 ms /    42 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     744.60 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    57 runs   (    0.05 ms per token, 18584.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.66 ms /    64 tokens (    0.70 ms per token,  1432.99 tokens per second)\n",
      "llama_print_timings:        eval time =     938.42 ms /    56 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1004.45 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /    40 runs   (    0.06 ms per token, 18157.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.08 ms /    47 tokens (    0.79 ms per token,  1267.60 tokens per second)\n",
      "llama_print_timings:        eval time =     646.58 ms /    39 runs   (   16.58 ms per token,    60.32 tokens per second)\n",
      "llama_print_timings:       total time =     700.22 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18376.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.63 ms /    38 tokens (    0.91 ms per token,  1097.31 tokens per second)\n",
      "llama_print_timings:        eval time =     380.11 ms /    23 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     423.70 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     6 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.13 ms /    33 tokens (    1.03 ms per token,   966.89 tokens per second)\n",
      "llama_print_timings:        eval time =      82.50 ms /     5 runs   (   16.50 ms per token,    60.61 tokens per second)\n",
      "llama_print_timings:       total time =     118.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    41 runs   (    0.05 ms per token, 18468.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.45 ms /    48 tokens (    0.78 ms per token,  1281.61 tokens per second)\n",
      "llama_print_timings:        eval time =     663.47 ms /    40 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     717.08 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18613.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.56 ms /    64 tokens (    0.70 ms per token,  1436.20 tokens per second)\n",
      "llama_print_timings:        eval time =     955.39 ms /    57 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1021.79 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    20 runs   (    0.05 ms per token, 18604.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.12 ms /    53 tokens (    0.81 ms per token,  1229.13 tokens per second)\n",
      "llama_print_timings:        eval time =     314.16 ms /    19 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     364.33 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18627.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    51 tokens (    0.84 ms per token,  1184.97 tokens per second)\n",
      "llama_print_timings:        eval time =     613.90 ms /    37 runs   (   16.59 ms per token,    60.27 tokens per second)\n",
      "llama_print_timings:       total time =     671.57 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    54 runs   (    0.05 ms per token, 18704.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.11 ms /    53 tokens (    0.81 ms per token,  1229.33 tokens per second)\n",
      "llama_print_timings:        eval time =     884.27 ms /    53 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     947.95 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.36 ms /    36 tokens (    0.95 ms per token,  1047.85 tokens per second)\n",
      "llama_print_timings:        eval time =     379.93 ms /    23 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     422.76 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    68 runs   (    0.05 ms per token, 18614.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.63 ms /    64 tokens (    0.70 ms per token,  1433.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.12 ms /    67 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =    1195.42 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /    45 runs   (    0.05 ms per token, 18367.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.62 ms /    39 tokens (    0.89 ms per token,  1126.48 tokens per second)\n",
      "llama_print_timings:        eval time =     728.13 ms /    44 runs   (   16.55 ms per token,    60.43 tokens per second)\n",
      "llama_print_timings:       total time =     781.18 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    36 runs   (    0.05 ms per token, 18672.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.68 ms /    26 tokens (    1.18 ms per token,   847.46 tokens per second)\n",
      "llama_print_timings:        eval time =     578.07 ms /    35 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     622.01 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    75 runs   (    0.05 ms per token, 18610.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.69 ms /    82 tokens (    0.69 ms per token,  1446.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.03 ms /    74 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =    1334.44 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    79 runs   (    0.06 ms per token, 18173.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.91 ms /    75 tokens (    0.68 ms per token,  1473.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1314.32 ms /    78 runs   (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_print_timings:       total time =    1398.11 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18545.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.28 ms /    31 tokens (    1.01 ms per token,   991.05 tokens per second)\n",
      "llama_print_timings:        eval time =     396.49 ms /    24 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     436.92 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18407.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.88 ms /    50 tokens (    0.86 ms per token,  1166.02 tokens per second)\n",
      "llama_print_timings:        eval time =     647.24 ms /    39 runs   (   16.60 ms per token,    60.26 tokens per second)\n",
      "llama_print_timings:       total time =     704.56 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18541.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.55 ms /    32 tokens (    0.99 ms per token,  1014.17 tokens per second)\n",
      "llama_print_timings:        eval time =     727.22 ms /    44 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     776.00 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    63 runs   (    0.05 ms per token, 18611.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.30 ms /    61 tokens (    0.73 ms per token,  1376.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1038.80 ms /    62 runs   (   16.75 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =    1107.02 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    66 runs   (    0.05 ms per token, 18272.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.77 ms /    68 tokens (    0.73 ms per token,  1366.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.24 ms /    65 runs   (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_print_timings:       total time =    1168.40 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    70 runs   (    0.05 ms per token, 18572.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.49 ms /    80 tokens (    0.64 ms per token,  1553.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.75 ms /    69 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1242.01 ms /   149 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18428.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.04 ms /    60 tokens (    0.73 ms per token,  1362.46 tokens per second)\n",
      "llama_print_timings:        eval time =     617.36 ms /    37 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     676.70 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /    36 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.74 ms /    39 tokens (    0.89 ms per token,  1122.56 tokens per second)\n",
      "llama_print_timings:        eval time =     578.93 ms /    35 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     627.02 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    52 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.78 ms /    42 tokens (    0.88 ms per token,  1142.02 tokens per second)\n",
      "llama_print_timings:        eval time =     848.01 ms /    51 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     903.94 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18537.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.04 ms /    49 tokens (    0.88 ms per token,  1138.37 tokens per second)\n",
      "llama_print_timings:        eval time =     883.22 ms /    53 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     945.75 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /    29 runs   (    0.05 ms per token, 18354.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    36 tokens (    0.95 ms per token,  1049.75 tokens per second)\n",
      "llama_print_timings:        eval time =     462.81 ms /    28 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     507.39 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18636.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.71 ms /    40 tokens (    0.87 ms per token,  1152.37 tokens per second)\n",
      "llama_print_timings:        eval time =     562.29 ms /    34 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     609.65 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /    25 runs   (    0.05 ms per token, 18740.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.34 ms /    31 tokens (    1.01 ms per token,   989.03 tokens per second)\n",
      "llama_print_timings:        eval time =     396.59 ms /    24 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     436.52 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    64 runs   (    0.05 ms per token, 18757.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.75 ms /    82 tokens (    0.69 ms per token,  1445.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1063.52 ms /    63 runs   (   16.88 ms per token,    59.24 tokens per second)\n",
      "llama_print_timings:       total time =    1144.38 ms /   145 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    24 runs   (    0.05 ms per token, 18590.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.37 ms /    37 tokens (    0.93 ms per token,  1076.46 tokens per second)\n",
      "llama_print_timings:        eval time =     380.24 ms /    23 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     423.52 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    12 runs   (    0.06 ms per token, 17216.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.64 ms /    32 tokens (    0.99 ms per token,  1011.25 tokens per second)\n",
      "llama_print_timings:        eval time =     181.88 ms /    11 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     218.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.78 ms /    72 tokens (    0.71 ms per token,  1417.91 tokens per second)\n",
      "llama_print_timings:        eval time =     755.72 ms /    45 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     823.11 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    75 runs   (    0.05 ms per token, 18550.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    69 tokens (    0.73 ms per token,  1377.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.81 ms /    74 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =    1323.30 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /    31 runs   (    0.05 ms per token, 18753.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.78 ms /    58 tokens (    0.75 ms per token,  1324.75 tokens per second)\n",
      "llama_print_timings:        eval time =     498.42 ms /    30 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     553.18 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18477.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.97 ms /    33 tokens (    1.03 ms per token,   971.59 tokens per second)\n",
      "llama_print_timings:        eval time =     396.56 ms /    24 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     439.42 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    58 runs   (    0.05 ms per token, 18477.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.50 ms /    73 tokens (    0.69 ms per token,  1445.54 tokens per second)\n",
      "llama_print_timings:        eval time =     958.85 ms /    57 runs   (   16.82 ms per token,    59.45 tokens per second)\n",
      "llama_print_timings:       total time =    1030.74 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.10 ms /    60 tokens (    0.73 ms per token,  1360.67 tokens per second)\n",
      "llama_print_timings:        eval time =     718.34 ms /    43 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =     778.45 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18370.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.08 ms /    29 tokens (    1.07 ms per token,   932.99 tokens per second)\n",
      "llama_print_timings:        eval time =     363.22 ms /    22 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     403.19 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18645.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.22 ms /    36 tokens (    0.95 ms per token,  1052.17 tokens per second)\n",
      "llama_print_timings:        eval time =     611.62 ms /    37 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     660.32 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    56 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.80 ms /    43 tokens (    0.86 ms per token,  1168.41 tokens per second)\n",
      "llama_print_timings:        eval time =     914.64 ms /    55 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     973.13 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    33 runs   (    0.05 ms per token, 18718.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.79 ms /    58 tokens (    0.75 ms per token,  1324.53 tokens per second)\n",
      "llama_print_timings:        eval time =     531.71 ms /    32 runs   (   16.62 ms per token,    60.18 tokens per second)\n",
      "llama_print_timings:       total time =     587.85 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /    67 runs   (    0.05 ms per token, 18778.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.49 ms /    48 tokens (    0.78 ms per token,  1280.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.92 ms /    66 runs   (   16.70 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =    1164.69 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /    23 runs   (    0.05 ms per token, 18297.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.87 ms /    18 tokens (    1.49 ms per token,   669.84 tokens per second)\n",
      "llama_print_timings:        eval time =     363.13 ms /    22 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     398.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18560.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.55 ms /    48 tokens (    0.78 ms per token,  1278.47 tokens per second)\n",
      "llama_print_timings:        eval time =     950.11 ms /    57 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =    1009.73 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    45 runs   (    0.05 ms per token, 18618.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.72 ms /    43 tokens (    0.85 ms per token,  1170.93 tokens per second)\n",
      "llama_print_timings:        eval time =     729.00 ms /    44 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     783.19 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18558.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.84 ms /    43 tokens (    0.86 ms per token,  1167.21 tokens per second)\n",
      "llama_print_timings:        eval time =     695.50 ms /    42 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     748.47 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18642.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.37 ms /    46 tokens (    0.81 ms per token,  1231.03 tokens per second)\n",
      "llama_print_timings:        eval time =     814.48 ms /    49 runs   (   16.62 ms per token,    60.16 tokens per second)\n",
      "llama_print_timings:       total time =     870.77 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    54 runs   (    0.05 ms per token, 18448.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.29 ms /    61 tokens (    0.73 ms per token,  1377.25 tokens per second)\n",
      "llama_print_timings:        eval time =     886.83 ms /    53 runs   (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:       total time =     951.69 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.96 ms /    33 tokens (    1.03 ms per token,   971.70 tokens per second)\n",
      "llama_print_timings:        eval time =     627.89 ms /    38 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     676.88 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    46 runs   (    0.05 ms per token, 18593.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.36 ms /    62 tokens (    0.72 ms per token,  1397.75 tokens per second)\n",
      "llama_print_timings:        eval time =     752.48 ms /    45 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =     815.02 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18493.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.30 ms /    30 tokens (    1.04 ms per token,   958.56 tokens per second)\n",
      "llama_print_timings:        eval time =     429.53 ms /    26 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     470.98 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    34 runs   (    0.05 ms per token, 18589.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.24 ms /    45 tokens (    0.83 ms per token,  1208.48 tokens per second)\n",
      "llama_print_timings:        eval time =     545.71 ms /    33 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     596.02 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18441.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.19 ms /    70 tokens (    0.72 ms per token,  1394.84 tokens per second)\n",
      "llama_print_timings:        eval time =     805.76 ms /    48 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     875.09 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18494.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.15 ms /    35 tokens (    0.98 ms per token,  1024.92 tokens per second)\n",
      "llama_print_timings:        eval time =     214.64 ms /    13 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     253.87 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18455.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.35 ms /    48 tokens (    0.78 ms per token,  1285.14 tokens per second)\n",
      "llama_print_timings:        eval time =     798.30 ms /    48 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     853.76 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    31 runs   (    0.06 ms per token, 17795.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.62 ms /    25 tokens (    1.23 ms per token,   816.33 tokens per second)\n",
      "llama_print_timings:        eval time =     495.63 ms /    30 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     538.32 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18671.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.45 ms /    71 tokens (    0.71 ms per token,  1407.33 tokens per second)\n",
      "llama_print_timings:        eval time =     552.89 ms /    33 runs   (   16.75 ms per token,    59.69 tokens per second)\n",
      "llama_print_timings:       total time =     615.55 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18539.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.61 ms /    64 tokens (    0.70 ms per token,  1434.62 tokens per second)\n",
      "llama_print_timings:        eval time =     533.66 ms /    32 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     590.24 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    85 runs   (    0.05 ms per token, 18454.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.19 ms /    76 tokens (    0.67 ms per token,  1484.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.53 ms /    84 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =    1503.21 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18478.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.52 ms /    22 tokens (    1.25 ms per token,   799.45 tokens per second)\n",
      "llama_print_timings:        eval time =     544.97 ms /    33 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     585.18 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18414.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.69 ms /    40 tokens (    0.87 ms per token,  1153.14 tokens per second)\n",
      "llama_print_timings:        eval time =     363.64 ms /    22 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     406.93 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    39 runs   (    0.05 ms per token, 18207.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.02 ms /    43 tokens (    0.86 ms per token,  1161.57 tokens per second)\n",
      "llama_print_timings:        eval time =     628.45 ms /    38 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     681.05 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18467.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.20 ms /    46 tokens (    0.81 ms per token,  1236.73 tokens per second)\n",
      "llama_print_timings:        eval time =     645.80 ms /    39 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     697.53 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /    38 runs   (    0.05 ms per token, 18286.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.48 ms /    32 tokens (    0.98 ms per token,  1016.58 tokens per second)\n",
      "llama_print_timings:        eval time =     611.52 ms /    37 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     657.40 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18482.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    35 tokens (    0.98 ms per token,  1021.63 tokens per second)\n",
      "llama_print_timings:        eval time =     611.45 ms /    37 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     659.93 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /    21 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    27 tokens (    1.15 ms per token,   867.47 tokens per second)\n",
      "llama_print_timings:        eval time =     330.18 ms /    20 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     369.63 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    47 runs   (    0.05 ms per token, 18599.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.73 ms /    72 tokens (    0.70 ms per token,  1419.31 tokens per second)\n",
      "llama_print_timings:        eval time =     772.45 ms /    46 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     840.57 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18463.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    54 tokens (    0.80 ms per token,  1242.81 tokens per second)\n",
      "llama_print_timings:        eval time =     496.71 ms /    30 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     551.28 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /    67 runs   (    0.05 ms per token, 18626.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.82 ms /    40 tokens (    0.87 ms per token,  1148.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.13 ms /    66 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =    1159.28 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /    22 runs   (    0.06 ms per token, 18003.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.83 ms /    27 tokens (    1.14 ms per token,   875.69 tokens per second)\n",
      "llama_print_timings:        eval time =     346.96 ms /    21 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     387.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    84 runs   (    0.05 ms per token, 18629.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.15 ms /    61 tokens (    0.72 ms per token,  1381.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1393.62 ms /    83 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1470.91 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18625.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    60 tokens (    0.74 ms per token,  1360.05 tokens per second)\n",
      "llama_print_timings:        eval time =     684.33 ms /    41 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =     744.59 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    15 tokens (    1.82 ms per token,   548.89 tokens per second)\n",
      "llama_print_timings:        eval time =     429.02 ms /    26 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     465.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18621.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.47 ms /    36 tokens (    0.96 ms per token,  1044.27 tokens per second)\n",
      "llama_print_timings:        eval time =     760.79 ms /    46 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     813.26 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    83 runs   (    0.05 ms per token, 18489.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.78 ms /    82 tokens (    0.69 ms per token,  1444.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1384.63 ms /    82 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =    1475.04 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.56 ms /    24 tokens (    1.15 ms per token,   870.92 tokens per second)\n",
      "llama_print_timings:        eval time =     627.81 ms /    38 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     669.77 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    39 runs   (    0.05 ms per token, 18413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.90 ms /    18 tokens (    1.49 ms per token,   669.05 tokens per second)\n",
      "llama_print_timings:        eval time =     627.54 ms /    38 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     669.27 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /    68 runs   (    0.05 ms per token, 18665.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.67 ms /    73 tokens (    0.69 ms per token,  1440.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.51 ms /    67 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =    1203.86 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    45 runs   (    0.05 ms per token, 18488.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.26 ms /    69 tokens (    0.73 ms per token,  1372.97 tokens per second)\n",
      "llama_print_timings:        eval time =     738.17 ms /    44 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     807.14 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     8 runs   (    0.05 ms per token, 18390.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.36 ms /    23 tokens (    1.19 ms per token,   840.58 tokens per second)\n",
      "llama_print_timings:        eval time =     115.56 ms /     7 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     146.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /    17 runs   (    0.05 ms per token, 18640.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.51 ms /    30 tokens (    1.05 ms per token,   952.14 tokens per second)\n",
      "llama_print_timings:        eval time =     264.08 ms /    16 runs   (   16.50 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     301.24 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    57 runs   (    0.05 ms per token, 18506.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.82 ms /    66 tokens (    0.75 ms per token,  1324.69 tokens per second)\n",
      "llama_print_timings:        eval time =     939.32 ms /    56 runs   (   16.77 ms per token,    59.62 tokens per second)\n",
      "llama_print_timings:       total time =    1011.18 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    53 runs   (    0.05 ms per token, 18583.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.93 ms /    74 tokens (    0.69 ms per token,  1453.09 tokens per second)\n",
      "llama_print_timings:        eval time =     874.54 ms /    52 runs   (   16.82 ms per token,    59.46 tokens per second)\n",
      "llama_print_timings:       total time =     944.94 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    53 runs   (    0.05 ms per token, 18313.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.98 ms /    67 tokens (    0.75 ms per token,  1340.56 tokens per second)\n",
      "llama_print_timings:        eval time =     872.02 ms /    52 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =     942.14 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18629.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.94 ms /    44 tokens (    0.84 ms per token,  1191.22 tokens per second)\n",
      "llama_print_timings:        eval time =     446.32 ms /    27 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     493.44 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    53 runs   (    0.05 ms per token, 18269.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    57 tokens (    0.77 ms per token,  1300.48 tokens per second)\n",
      "llama_print_timings:        eval time =     868.84 ms /    52 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     933.64 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    92 runs   (    0.05 ms per token, 18563.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.62 ms /    64 tokens (    0.70 ms per token,  1434.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1530.18 ms /    91 runs   (   16.82 ms per token,    59.47 tokens per second)\n",
      "llama_print_timings:       total time =    1611.84 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18465.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    55 tokens (    0.79 ms per token,  1266.52 tokens per second)\n",
      "llama_print_timings:        eval time =     632.04 ms /    38 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     690.16 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18369.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.00 ms /    45 tokens (    0.82 ms per token,  1216.31 tokens per second)\n",
      "llama_print_timings:        eval time =     662.26 ms /    40 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     714.51 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    72 runs   (    0.05 ms per token, 18513.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.44 ms /    79 tokens (    0.65 ms per token,  1535.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.11 ms /    71 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =    1276.38 ms /   150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18379.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    69 tokens (    0.73 ms per token,  1374.47 tokens per second)\n",
      "llama_print_timings:        eval time =     350.07 ms /    21 runs   (   16.67 ms per token,    59.99 tokens per second)\n",
      "llama_print_timings:       total time =     409.72 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18410.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.12 ms /    29 tokens (    1.07 ms per token,   931.82 tokens per second)\n",
      "llama_print_timings:        eval time =     346.73 ms /    21 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     386.35 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.05 ms /    45 tokens (    0.82 ms per token,  1214.54 tokens per second)\n",
      "llama_print_timings:        eval time =     529.21 ms /    32 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     578.93 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /    27 runs   (    0.05 ms per token, 18243.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.68 ms /    42 tokens (    0.87 ms per token,  1145.07 tokens per second)\n",
      "llama_print_timings:        eval time =     429.92 ms /    26 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     477.00 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    76 runs   (    0.05 ms per token, 18339.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.72 ms /    82 tokens (    0.69 ms per token,  1445.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1266.19 ms /    75 runs   (   16.88 ms per token,    59.23 tokens per second)\n",
      "llama_print_timings:       total time =    1352.51 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    58 runs   (    0.05 ms per token, 18308.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.09 ms /    68 tokens (    0.74 ms per token,  1357.61 tokens per second)\n",
      "llama_print_timings:        eval time =     957.16 ms /    57 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =    1030.54 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    38 runs   (    0.06 ms per token, 18138.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.60 ms /    55 tokens (    0.79 ms per token,  1261.55 tokens per second)\n",
      "llama_print_timings:        eval time =     615.54 ms /    37 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     674.32 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    74 runs   (    0.05 ms per token, 18467.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.68 ms /    97 tokens (    0.67 ms per token,  1499.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1233.14 ms /    73 runs   (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:       total time =    1327.26 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.20 ms /    46 tokens (    0.81 ms per token,  1236.73 tokens per second)\n",
      "llama_print_timings:        eval time =     680.02 ms /    41 runs   (   16.59 ms per token,    60.29 tokens per second)\n",
      "llama_print_timings:       total time =     733.82 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18425.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.06 ms /    76 tokens (    0.67 ms per token,  1488.44 tokens per second)\n",
      "llama_print_timings:        eval time =     352.00 ms /    21 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =     411.51 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    60 runs   (    0.05 ms per token, 18535.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.40 ms /    48 tokens (    0.78 ms per token,  1283.29 tokens per second)\n",
      "llama_print_timings:        eval time =     983.82 ms /    59 runs   (   16.67 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:       total time =    1043.86 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    37 runs   (    0.05 ms per token, 18307.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.47 ms /    23 tokens (    1.19 ms per token,   837.31 tokens per second)\n",
      "llama_print_timings:        eval time =     594.92 ms /    36 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     637.35 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /    58 runs   (    0.05 ms per token, 18536.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.52 ms /    63 tokens (    0.71 ms per token,  1415.16 tokens per second)\n",
      "llama_print_timings:        eval time =     955.30 ms /    57 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =    1021.92 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /    33 runs   (    0.05 ms per token, 18302.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.74 ms /    74 tokens (    0.69 ms per token,  1458.50 tokens per second)\n",
      "llama_print_timings:        eval time =     537.45 ms /    32 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     601.43 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18442.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.45 ms /    32 tokens (    0.98 ms per token,  1017.55 tokens per second)\n",
      "llama_print_timings:        eval time =     429.51 ms /    26 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     471.10 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    43 runs   (    0.05 ms per token, 18383.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    52 tokens (    0.83 ms per token,  1204.90 tokens per second)\n",
      "llama_print_timings:        eval time =     698.57 ms /    42 runs   (   16.63 ms per token,    60.12 tokens per second)\n",
      "llama_print_timings:       total time =     757.80 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18566.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.99 ms /    58 tokens (    0.76 ms per token,  1318.36 tokens per second)\n",
      "llama_print_timings:        eval time =     582.39 ms /    35 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     640.50 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    43 runs   (    0.05 ms per token, 18663.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.14 ms /    34 tokens (    1.00 ms per token,   995.81 tokens per second)\n",
      "llama_print_timings:        eval time =     694.53 ms /    42 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     745.17 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18402.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.27 ms /    46 tokens (    0.81 ms per token,  1234.10 tokens per second)\n",
      "llama_print_timings:        eval time =     662.68 ms /    40 runs   (   16.57 ms per token,    60.36 tokens per second)\n",
      "llama_print_timings:       total time =     715.95 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    52 runs   (    0.05 ms per token, 18426.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.47 ms /    47 tokens (    0.80 ms per token,  1254.24 tokens per second)\n",
      "llama_print_timings:        eval time =     848.62 ms /    51 runs   (   16.64 ms per token,    60.10 tokens per second)\n",
      "llama_print_timings:       total time =     906.13 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    25 runs   (    0.06 ms per token, 17170.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.09 ms /    33 tokens (    1.03 ms per token,   968.17 tokens per second)\n",
      "llama_print_timings:        eval time =     396.43 ms /    24 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     440.20 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18659.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.43 ms /    55 tokens (    0.79 ms per token,  1266.29 tokens per second)\n",
      "llama_print_timings:        eval time =     429.95 ms /    26 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     483.10 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    54 runs   (    0.05 ms per token, 18730.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.42 ms /    47 tokens (    0.80 ms per token,  1255.88 tokens per second)\n",
      "llama_print_timings:        eval time =     882.49 ms /    53 runs   (   16.65 ms per token,    60.06 tokens per second)\n",
      "llama_print_timings:       total time =     940.57 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    37 runs   (    0.05 ms per token, 18316.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.90 ms /    57 tokens (    0.77 ms per token,  1298.32 tokens per second)\n",
      "llama_print_timings:        eval time =     598.92 ms /    36 runs   (   16.64 ms per token,    60.11 tokens per second)\n",
      "llama_print_timings:       total time =     656.31 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /    29 runs   (    0.05 ms per token, 18745.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.65 ms /    32 tokens (    0.99 ms per token,  1011.03 tokens per second)\n",
      "llama_print_timings:        eval time =     462.69 ms /    28 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     505.18 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /    52 runs   (    0.05 ms per token, 18624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.11 ms /    51 tokens (    0.85 ms per token,  1183.13 tokens per second)\n",
      "llama_print_timings:        eval time =     850.06 ms /    51 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =     912.93 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /    36 runs   (    0.05 ms per token, 18237.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.32 ms /    46 tokens (    0.81 ms per token,  1232.65 tokens per second)\n",
      "llama_print_timings:        eval time =     578.93 ms /    35 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     630.71 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    75 runs   (    0.05 ms per token, 18619.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.89 ms /    67 tokens (    0.74 ms per token,  1342.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.92 ms /    74 runs   (   16.81 ms per token,    59.49 tokens per second)\n",
      "llama_print_timings:       total time =    1322.86 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /    23 runs   (    0.05 ms per token, 18488.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.62 ms /    39 tokens (    0.89 ms per token,  1126.55 tokens per second)\n",
      "llama_print_timings:        eval time =     363.62 ms /    22 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     407.15 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    55 runs   (    0.05 ms per token, 18493.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.82 ms /    67 tokens (    0.74 ms per token,  1344.87 tokens per second)\n",
      "llama_print_timings:        eval time =     905.96 ms /    54 runs   (   16.78 ms per token,    59.61 tokens per second)\n",
      "llama_print_timings:       total time =     976.94 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /    38 runs   (    0.05 ms per token, 18737.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.10 ms /    46 tokens (    0.81 ms per token,  1239.96 tokens per second)\n",
      "llama_print_timings:        eval time =     612.11 ms /    37 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     663.25 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    59 runs   (    0.05 ms per token, 18553.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.54 ms /    83 tokens (    0.69 ms per token,  1442.60 tokens per second)\n",
      "llama_print_timings:        eval time =     978.47 ms /    58 runs   (   16.87 ms per token,    59.28 tokens per second)\n",
      "llama_print_timings:       total time =    1058.47 ms /   141 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    40 runs   (    0.05 ms per token, 18735.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.36 ms /    31 tokens (    1.01 ms per token,   988.68 tokens per second)\n",
      "llama_print_timings:        eval time =     644.56 ms /    39 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     690.51 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    65 runs   (    0.05 ms per token, 18587.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.29 ms /    45 tokens (    0.83 ms per token,  1206.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1067.46 ms /    64 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =    1130.30 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    32 runs   (    0.05 ms per token, 18202.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.41 ms /    47 tokens (    0.80 ms per token,  1256.52 tokens per second)\n",
      "llama_print_timings:        eval time =     512.92 ms /    31 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     563.83 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /    44 runs   (    0.05 ms per token, 18565.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.68 ms /    73 tokens (    0.69 ms per token,  1440.41 tokens per second)\n",
      "llama_print_timings:        eval time =     722.12 ms /    43 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     789.08 ms /   116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.91 ms /    58 tokens (    0.76 ms per token,  1320.97 tokens per second)\n",
      "llama_print_timings:        eval time =     700.45 ms /    42 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     760.27 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /    31 runs   (    0.05 ms per token, 18496.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.48 ms /    32 tokens (    0.98 ms per token,  1016.45 tokens per second)\n",
      "llama_print_timings:        eval time =     495.76 ms /    30 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     538.62 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18577.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.22 ms /    45 tokens (    0.83 ms per token,  1209.16 tokens per second)\n",
      "llama_print_timings:        eval time =     562.24 ms /    34 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     612.56 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    24 runs   (    0.05 ms per token, 18677.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.49 ms /    22 tokens (    1.25 ms per token,   800.35 tokens per second)\n",
      "llama_print_timings:        eval time =     379.64 ms /    23 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     415.51 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    34 runs   (    0.05 ms per token, 18488.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.90 ms /    40 tokens (    0.87 ms per token,  1146.30 tokens per second)\n",
      "llama_print_timings:        eval time =     545.51 ms /    33 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     593.38 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /    28 runs   (    0.05 ms per token, 18679.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.66 ms /    49 tokens (    0.87 ms per token,  1148.67 tokens per second)\n",
      "llama_print_timings:        eval time =     446.60 ms /    27 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     500.15 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /    57 runs   (    0.05 ms per token, 18404.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.08 ms /    52 tokens (    0.83 ms per token,  1207.08 tokens per second)\n",
      "llama_print_timings:        eval time =     934.48 ms /    56 runs   (   16.69 ms per token,    59.93 tokens per second)\n",
      "llama_print_timings:       total time =     999.12 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /    36 runs   (    0.05 ms per token, 18320.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.85 ms /    49 tokens (    0.87 ms per token,  1143.47 tokens per second)\n",
      "llama_print_timings:        eval time =     579.77 ms /    35 runs   (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_print_timings:       total time =     636.38 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18640.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.22 ms /    52 tokens (    0.83 ms per token,  1203.09 tokens per second)\n",
      "llama_print_timings:        eval time =     782.78 ms /    47 runs   (   16.65 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     844.29 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    54 runs   (    0.05 ms per token, 18743.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.86 ms /    66 tokens (    0.76 ms per token,  1323.79 tokens per second)\n",
      "llama_print_timings:        eval time =     888.65 ms /    53 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =     958.89 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /    17 runs   (    0.05 ms per token, 18358.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      26.85 ms /    18 tokens (    1.49 ms per token,   670.32 tokens per second)\n",
      "llama_print_timings:        eval time =     264.36 ms /    16 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     297.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18396.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.58 ms /    23 tokens (    1.20 ms per token,   834.06 tokens per second)\n",
      "llama_print_timings:        eval time =     214.67 ms /    13 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     247.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    16 runs   (    0.05 ms per token, 18454.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.33 ms /    22 tokens (    1.24 ms per token,   804.86 tokens per second)\n",
      "llama_print_timings:        eval time =     247.54 ms /    15 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     280.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /    26 runs   (    0.06 ms per token, 18143.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.16 ms /    50 tokens (    0.86 ms per token,  1158.59 tokens per second)\n",
      "llama_print_timings:        eval time =     413.57 ms /    25 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     466.02 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    49 runs   (    0.05 ms per token, 18759.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.78 ms /    42 tokens (    0.88 ms per token,  1141.86 tokens per second)\n",
      "llama_print_timings:        eval time =     796.30 ms /    48 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     851.87 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    53 runs   (    0.05 ms per token, 18402.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.13 ms /    51 tokens (    0.85 ms per token,  1182.36 tokens per second)\n",
      "llama_print_timings:        eval time =     867.20 ms /    52 runs   (   16.68 ms per token,    59.96 tokens per second)\n",
      "llama_print_timings:       total time =     929.57 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18673.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.74 ms /    73 tokens (    0.70 ms per token,  1438.79 tokens per second)\n",
      "llama_print_timings:        eval time =     621.31 ms /    37 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     686.14 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18681.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.01 ms /    68 tokens (    0.74 ms per token,  1359.70 tokens per second)\n",
      "llama_print_timings:        eval time =     839.39 ms /    50 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     909.11 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18560.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.67 ms /    91 tokens (    0.64 ms per token,  1551.07 tokens per second)\n",
      "llama_print_timings:        eval time =     539.90 ms /    32 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     610.90 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /    15 runs   (    0.05 ms per token, 18844.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.50 ms /    24 tokens (    1.15 ms per token,   872.66 tokens per second)\n",
      "llama_print_timings:        eval time =     231.16 ms /    14 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     264.17 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    42 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.49 ms /    78 tokens (    0.66 ms per token,  1514.92 tokens per second)\n",
      "llama_print_timings:        eval time =     690.37 ms /    41 runs   (   16.84 ms per token,    59.39 tokens per second)\n",
      "llama_print_timings:       total time =     756.83 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18585.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.10 ms /    35 tokens (    0.97 ms per token,  1026.39 tokens per second)\n",
      "llama_print_timings:        eval time =     496.35 ms /    30 runs   (   16.55 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     542.20 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    25 runs   (    0.05 ms per token, 18559.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.98 ms /    58 tokens (    0.76 ms per token,  1318.78 tokens per second)\n",
      "llama_print_timings:        eval time =     397.06 ms /    24 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     449.80 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /    20 runs   (    0.05 ms per token, 18621.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.81 ms /    50 tokens (    0.86 ms per token,  1168.06 tokens per second)\n",
      "llama_print_timings:        eval time =     314.34 ms /    19 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     364.57 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /    24 runs   (    0.05 ms per token, 18433.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.74 ms /    24 tokens (    1.16 ms per token,   865.05 tokens per second)\n",
      "llama_print_timings:        eval time =     380.28 ms /    23 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     417.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    51 runs   (    0.05 ms per token, 18660.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.89 ms /    39 tokens (    0.89 ms per token,  1117.77 tokens per second)\n",
      "llama_print_timings:        eval time =     829.53 ms /    50 runs   (   16.59 ms per token,    60.28 tokens per second)\n",
      "llama_print_timings:       total time =     882.95 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /    41 runs   (    0.05 ms per token, 18295.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.80 ms /    32 tokens (    0.99 ms per token,  1006.23 tokens per second)\n",
      "llama_print_timings:        eval time =     661.29 ms /    40 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     708.66 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /    20 runs   (    0.05 ms per token, 18399.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    29 tokens (    1.07 ms per token,   930.62 tokens per second)\n",
      "llama_print_timings:        eval time =     314.04 ms /    19 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     352.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18341.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.40 ms /    31 tokens (    1.01 ms per token,   987.32 tokens per second)\n",
      "llama_print_timings:        eval time =     363.32 ms /    22 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     403.16 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /    31 runs   (    0.05 ms per token, 18397.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.15 ms /    45 tokens (    0.83 ms per token,  1211.44 tokens per second)\n",
      "llama_print_timings:        eval time =     496.14 ms /    30 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     544.65 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /    40 runs   (    0.05 ms per token, 18323.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.92 ms /    42 tokens (    0.88 ms per token,  1137.59 tokens per second)\n",
      "llama_print_timings:        eval time =     644.94 ms /    39 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     697.59 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    52 runs   (    0.05 ms per token, 18598.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    43 tokens (    0.86 ms per token,  1165.28 tokens per second)\n",
      "llama_print_timings:        eval time =     847.31 ms /    51 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     903.82 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    77 runs   (    0.05 ms per token, 18425.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.06 ms /    86 tokens (    0.68 ms per token,  1481.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.40 ms /    76 runs   (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:       total time =    1372.25 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /    11 runs   (    0.05 ms per token, 18487.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.09 ms /    13 tokens (    2.08 ms per token,   479.85 tokens per second)\n",
      "llama_print_timings:        eval time =     164.79 ms /    10 runs   (   16.48 ms per token,    60.68 tokens per second)\n",
      "llama_print_timings:       total time =     195.62 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    56 runs   (    0.05 ms per token, 18573.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.39 ms /    54 tokens (    0.80 ms per token,  1244.50 tokens per second)\n",
      "llama_print_timings:        eval time =     918.45 ms /    55 runs   (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_print_timings:       total time =     983.10 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    63 runs   (    0.05 ms per token, 18287.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.86 ms /    44 tokens (    0.84 ms per token,  1193.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1033.35 ms /    62 runs   (   16.67 ms per token,    60.00 tokens per second)\n",
      "llama_print_timings:       total time =    1095.59 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    16 runs   (    0.05 ms per token, 18411.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.82 ms /    27 tokens (    1.14 ms per token,   876.17 tokens per second)\n",
      "llama_print_timings:        eval time =     247.60 ms /    15 runs   (   16.51 ms per token,    60.58 tokens per second)\n",
      "llama_print_timings:       total time =     284.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.78 ms /    67 tokens (    0.74 ms per token,  1345.87 tokens per second)\n",
      "llama_print_timings:        eval time =     770.75 ms /    46 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     838.52 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    54 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.84 ms /    58 tokens (    0.76 ms per token,  1322.90 tokens per second)\n",
      "llama_print_timings:        eval time =     885.84 ms /    53 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     949.79 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /    44 runs   (    0.05 ms per token, 18747.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.15 ms /    34 tokens (    1.00 ms per token,   995.55 tokens per second)\n",
      "llama_print_timings:        eval time =     710.61 ms /    43 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     761.29 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18455.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.14 ms /    77 tokens (    0.66 ms per token,  1505.64 tokens per second)\n",
      "llama_print_timings:        eval time =     436.69 ms /    26 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =     497.66 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18511.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.81 ms /    44 tokens (    0.84 ms per token,  1195.36 tokens per second)\n",
      "llama_print_timings:        eval time =     830.66 ms /    50 runs   (   16.61 ms per token,    60.19 tokens per second)\n",
      "llama_print_timings:       total time =     886.42 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /    35 runs   (    0.05 ms per token, 18498.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.26 ms /    46 tokens (    0.81 ms per token,  1234.67 tokens per second)\n",
      "llama_print_timings:        eval time =     562.33 ms /    34 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     613.31 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /    29 runs   (    0.06 ms per token, 17469.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.36 ms /    27 tokens (    1.16 ms per token,   861.00 tokens per second)\n",
      "llama_print_timings:        eval time =     462.87 ms /    28 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     504.95 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /    22 runs   (    0.05 ms per token, 18363.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.45 ms /    55 tokens (    0.79 ms per token,  1265.85 tokens per second)\n",
      "llama_print_timings:        eval time =     347.33 ms /    21 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     398.72 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    38 runs   (    0.05 ms per token, 18428.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.08 ms /    74 tokens (    0.69 ms per token,  1448.62 tokens per second)\n",
      "llama_print_timings:        eval time =     621.13 ms /    37 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =     686.20 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /    35 runs   (    0.05 ms per token, 18607.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.70 ms /    41 tokens (    0.90 ms per token,  1117.23 tokens per second)\n",
      "llama_print_timings:        eval time =     562.09 ms /    34 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     612.03 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /    16 runs   (    0.05 ms per token, 18561.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.22 ms /    22 tokens (    1.24 ms per token,   808.35 tokens per second)\n",
      "llama_print_timings:        eval time =     247.54 ms /    15 runs   (   16.50 ms per token,    60.60 tokens per second)\n",
      "llama_print_timings:       total time =     280.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /    30 runs   (    0.06 ms per token, 18072.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.33 ms /    53 tokens (    0.82 ms per token,  1223.20 tokens per second)\n",
      "llama_print_timings:        eval time =     479.78 ms /    29 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     534.65 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /    47 runs   (    0.05 ms per token, 18503.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.93 ms /    51 tokens (    0.84 ms per token,  1188.09 tokens per second)\n",
      "llama_print_timings:        eval time =     765.64 ms /    46 runs   (   16.64 ms per token,    60.08 tokens per second)\n",
      "llama_print_timings:       total time =     826.40 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    32 runs   (    0.05 ms per token, 18359.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.03 ms /    75 tokens (    0.68 ms per token,  1469.61 tokens per second)\n",
      "llama_print_timings:        eval time =     520.29 ms /    31 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =     583.50 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    16 runs   (    0.05 ms per token, 18411.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.48 ms /    32 tokens (    0.98 ms per token,  1016.58 tokens per second)\n",
      "llama_print_timings:        eval time =     247.58 ms /    15 runs   (   16.51 ms per token,    60.59 tokens per second)\n",
      "llama_print_timings:       total time =     284.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    49 runs   (    0.05 ms per token, 18421.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.67 ms /    41 tokens (    0.89 ms per token,  1118.11 tokens per second)\n",
      "llama_print_timings:        eval time =     795.92 ms /    48 runs   (   16.58 ms per token,    60.31 tokens per second)\n",
      "llama_print_timings:       total time =     850.99 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    44 runs   (    0.05 ms per token, 18464.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.71 ms /    49 tokens (    0.87 ms per token,  1147.30 tokens per second)\n",
      "llama_print_timings:        eval time =     714.33 ms /    43 runs   (   16.61 ms per token,    60.20 tokens per second)\n",
      "llama_print_timings:       total time =     773.15 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /    32 runs   (    0.05 ms per token, 18202.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.65 ms /    39 tokens (    0.89 ms per token,  1125.57 tokens per second)\n",
      "llama_print_timings:        eval time =     512.73 ms /    31 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     560.22 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /    23 runs   (    0.05 ms per token, 18370.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.42 ms /    22 tokens (    1.25 ms per token,   802.33 tokens per second)\n",
      "llama_print_timings:        eval time =     363.22 ms /    22 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     399.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /    16 runs   (    0.06 ms per token, 18161.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.25 ms /    36 tokens (    0.95 ms per token,  1050.97 tokens per second)\n",
      "llama_print_timings:        eval time =     247.64 ms /    15 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     287.44 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    79 runs   (    0.05 ms per token, 18457.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.25 ms /    77 tokens (    0.67 ms per token,  1502.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1315.02 ms /    78 runs   (   16.86 ms per token,    59.31 tokens per second)\n",
      "llama_print_timings:       total time =    1398.42 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18440.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.95 ms /    27 tokens (    1.15 ms per token,   872.26 tokens per second)\n",
      "llama_print_timings:        eval time =     346.88 ms /    21 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     386.70 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    14 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.60 ms /    81 tokens (    0.70 ms per token,  1431.20 tokens per second)\n",
      "llama_print_timings:        eval time =     218.80 ms /    13 runs   (   16.83 ms per token,    59.41 tokens per second)\n",
      "llama_print_timings:       total time =     280.06 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    35 runs   (    0.05 ms per token, 18324.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.49 ms /    41 tokens (    0.89 ms per token,  1123.56 tokens per second)\n",
      "llama_print_timings:        eval time =     562.16 ms /    34 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     612.10 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    69 runs   (    0.05 ms per token, 18734.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    60 tokens (    0.74 ms per token,  1357.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.77 ms /    68 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1210.30 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.47 ms /    72 tokens (    0.70 ms per token,  1426.59 tokens per second)\n",
      "llama_print_timings:        eval time =     688.42 ms /    41 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     756.28 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    49 runs   (    0.05 ms per token, 18602.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.95 ms /    58 tokens (    0.76 ms per token,  1319.62 tokens per second)\n",
      "llama_print_timings:        eval time =     801.47 ms /    48 runs   (   16.70 ms per token,    59.89 tokens per second)\n",
      "llama_print_timings:       total time =     863.76 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18626.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    52 tokens (    0.83 ms per token,  1207.87 tokens per second)\n",
      "llama_print_timings:        eval time =     782.62 ms /    47 runs   (   16.65 ms per token,    60.05 tokens per second)\n",
      "llama_print_timings:       total time =     843.41 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    50 runs   (    0.05 ms per token, 18663.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.69 ms /    90 tokens (    0.65 ms per token,  1533.45 tokens per second)\n",
      "llama_print_timings:        eval time =     826.84 ms /    49 runs   (   16.87 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:       total time =     904.23 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    24 runs   (    0.05 ms per token, 18320.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.60 ms /    32 tokens (    0.99 ms per token,  1012.53 tokens per second)\n",
      "llama_print_timings:        eval time =     379.97 ms /    23 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     420.49 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    19 runs   (    0.05 ms per token, 18304.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.99 ms /    27 tokens (    1.15 ms per token,   871.19 tokens per second)\n",
      "llama_print_timings:        eval time =     297.17 ms /    18 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     334.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    51 runs   (    0.05 ms per token, 18385.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.83 ms /    57 tokens (    0.77 ms per token,  1300.54 tokens per second)\n",
      "llama_print_timings:        eval time =     835.36 ms /    50 runs   (   16.71 ms per token,    59.85 tokens per second)\n",
      "llama_print_timings:       total time =     899.40 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    74 runs   (    0.05 ms per token, 18523.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.65 ms /    63 tokens (    0.71 ms per token,  1411.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.20 ms /    73 runs   (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:       total time =    1298.97 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /    32 runs   (    0.05 ms per token, 18296.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.03 ms /    33 tokens (    1.03 ms per token,   969.85 tokens per second)\n",
      "llama_print_timings:        eval time =     512.28 ms /    31 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     559.33 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /    47 runs   (    0.05 ms per token, 18658.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.62 ms /    72 tokens (    0.70 ms per token,  1422.39 tokens per second)\n",
      "llama_print_timings:        eval time =     772.39 ms /    46 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =     841.05 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    48 runs   (    0.05 ms per token, 18554.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.62 ms /    65 tokens (    0.76 ms per token,  1310.01 tokens per second)\n",
      "llama_print_timings:        eval time =     786.90 ms /    47 runs   (   16.74 ms per token,    59.73 tokens per second)\n",
      "llama_print_timings:       total time =     854.95 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    47 runs   (    0.05 ms per token, 18402.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.54 ms /    65 tokens (    0.76 ms per token,  1312.10 tokens per second)\n",
      "llama_print_timings:        eval time =     770.03 ms /    46 runs   (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_print_timings:       total time =     837.69 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /    38 runs   (    0.05 ms per token, 18600.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.98 ms /    45 tokens (    0.82 ms per token,  1217.04 tokens per second)\n",
      "llama_print_timings:        eval time =     611.73 ms /    37 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     662.78 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /    42 runs   (    0.05 ms per token, 18526.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.50 ms /    64 tokens (    0.70 ms per token,  1438.07 tokens per second)\n",
      "llama_print_timings:        eval time =     685.88 ms /    41 runs   (   16.73 ms per token,    59.78 tokens per second)\n",
      "llama_print_timings:       total time =     747.12 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    42 runs   (    0.05 ms per token, 18453.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.25 ms /    77 tokens (    0.67 ms per token,  1502.56 tokens per second)\n",
      "llama_print_timings:        eval time =     689.95 ms /    41 runs   (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:       total time =     757.81 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    40 runs   (    0.05 ms per token, 18552.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.56 ms /    64 tokens (    0.70 ms per token,  1436.10 tokens per second)\n",
      "llama_print_timings:        eval time =     651.79 ms /    39 runs   (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     711.91 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18437.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.48 ms /    22 tokens (    1.25 ms per token,   800.67 tokens per second)\n",
      "llama_print_timings:        eval time =     330.28 ms /    20 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     364.96 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    31 runs   (    0.05 ms per token, 18540.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.43 ms /    48 tokens (    0.78 ms per token,  1282.43 tokens per second)\n",
      "llama_print_timings:        eval time =     496.05 ms /    30 runs   (   16.54 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     545.19 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /    15 runs   (    0.05 ms per token, 18656.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.18 ms /    28 tokens (    1.11 ms per token,   898.13 tokens per second)\n",
      "llama_print_timings:        eval time =     231.23 ms /    14 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     267.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /    13 runs   (    0.05 ms per token, 18465.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.14 ms /    46 tokens (    0.81 ms per token,  1238.46 tokens per second)\n",
      "llama_print_timings:        eval time =     198.33 ms /    12 runs   (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     240.62 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    77 runs   (    0.05 ms per token, 18456.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.92 ms /    58 tokens (    0.76 ms per token,  1320.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.51 ms /    76 runs   (   16.77 ms per token,    59.63 tokens per second)\n",
      "llama_print_timings:       total time =    1349.25 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    61 runs   (    0.05 ms per token, 18412.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.15 ms /    68 tokens (    0.74 ms per token,  1355.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.36 ms /    60 runs   (   16.79 ms per token,    59.56 tokens per second)\n",
      "llama_print_timings:       total time =    1081.32 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18575.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.76 ms /    57 tokens (    0.77 ms per token,  1302.50 tokens per second)\n",
      "llama_print_timings:        eval time =     784.45 ms /    47 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =     847.67 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /    23 runs   (    0.05 ms per token, 18312.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.69 ms /    67 tokens (    0.74 ms per token,  1348.36 tokens per second)\n",
      "llama_print_timings:        eval time =     366.22 ms /    22 runs   (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:       total time =     424.35 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /    67 runs   (    0.05 ms per token, 18611.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.21 ms /    61 tokens (    0.72 ms per token,  1379.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.35 ms /    66 runs   (   16.76 ms per token,    59.66 tokens per second)\n",
      "llama_print_timings:       total time =    1175.88 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    41 runs   (    0.05 ms per token, 18254.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.53 ms /    37 tokens (    0.93 ms per token,  1071.66 tokens per second)\n",
      "llama_print_timings:        eval time =     661.77 ms /    40 runs   (   16.54 ms per token,    60.44 tokens per second)\n",
      "llama_print_timings:       total time =     713.48 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    33 runs   (    0.05 ms per token, 18384.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.88 ms /    64 tokens (    0.70 ms per token,  1426.06 tokens per second)\n",
      "llama_print_timings:        eval time =     533.53 ms /    32 runs   (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:       total time =     590.81 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    56 runs   (    0.05 ms per token, 18842.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.05 ms /    60 tokens (    0.73 ms per token,  1362.15 tokens per second)\n",
      "llama_print_timings:        eval time =     920.44 ms /    55 runs   (   16.74 ms per token,    59.75 tokens per second)\n",
      "llama_print_timings:       total time =     985.69 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    83 runs   (    0.05 ms per token, 18464.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.35 ms /    78 tokens (    0.66 ms per token,  1518.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1383.08 ms /    82 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1468.50 ms /   160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    46 runs   (    0.05 ms per token, 18429.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    67 tokens (    0.74 ms per token,  1346.63 tokens per second)\n",
      "llama_print_timings:        eval time =     754.00 ms /    45 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     820.90 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    59 runs   (    0.05 ms per token, 18472.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.55 ms /    56 tokens (    0.78 ms per token,  1285.79 tokens per second)\n",
      "llama_print_timings:        eval time =     969.94 ms /    58 runs   (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:       total time =    1036.13 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18467.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.75 ms /    27 tokens (    1.14 ms per token,   878.19 tokens per second)\n",
      "llama_print_timings:        eval time =     313.81 ms /    19 runs   (   16.52 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     352.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    49 runs   (    0.05 ms per token, 18462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    44 tokens (    0.84 ms per token,  1190.86 tokens per second)\n",
      "llama_print_timings:        eval time =     796.76 ms /    48 runs   (   16.60 ms per token,    60.24 tokens per second)\n",
      "llama_print_timings:       total time =     851.87 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18508.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.87 ms /    57 tokens (    0.77 ms per token,  1299.17 tokens per second)\n",
      "llama_print_timings:        eval time =     531.43 ms /    32 runs   (   16.61 ms per token,    60.22 tokens per second)\n",
      "llama_print_timings:       total time =     587.16 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    51 runs   (    0.05 ms per token, 18545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.45 ms /    80 tokens (    0.64 ms per token,  1554.91 tokens per second)\n",
      "llama_print_timings:        eval time =     842.88 ms /    50 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =     914.17 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    50 runs   (    0.05 ms per token, 18389.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.64 ms /    56 tokens (    0.78 ms per token,  1283.17 tokens per second)\n",
      "llama_print_timings:        eval time =     817.89 ms /    49 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =     880.77 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     9 runs   (    0.05 ms per token, 18255.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.26 ms /    30 tokens (    1.04 ms per token,   959.60 tokens per second)\n",
      "llama_print_timings:        eval time =     131.98 ms /     8 runs   (   16.50 ms per token,    60.62 tokens per second)\n",
      "llama_print_timings:       total time =     166.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    61 runs   (    0.05 ms per token, 18456.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.56 ms /    63 tokens (    0.71 ms per token,  1413.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1006.10 ms /    60 runs   (   16.77 ms per token,    59.64 tokens per second)\n",
      "llama_print_timings:       total time =    1075.02 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    36 runs   (    0.06 ms per token, 18136.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.28 ms /    54 tokens (    0.80 ms per token,  1247.57 tokens per second)\n",
      "llama_print_timings:        eval time =     581.32 ms /    35 runs   (   16.61 ms per token,    60.21 tokens per second)\n",
      "llama_print_timings:       total time =     638.79 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /    16 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.25 ms /    29 tokens (    1.08 ms per token,   928.06 tokens per second)\n",
      "llama_print_timings:        eval time =     247.70 ms /    15 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     285.08 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /    39 runs   (    0.05 ms per token, 18474.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.10 ms /    45 tokens (    0.82 ms per token,  1213.00 tokens per second)\n",
      "llama_print_timings:        eval time =     628.94 ms /    38 runs   (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_print_timings:       total time =     681.09 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /    52 runs   (    0.05 ms per token, 18664.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.42 ms /    63 tokens (    0.71 ms per token,  1418.38 tokens per second)\n",
      "llama_print_timings:        eval time =     854.53 ms /    51 runs   (   16.76 ms per token,    59.68 tokens per second)\n",
      "llama_print_timings:       total time =     919.41 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18549.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    52 tokens (    0.83 ms per token,  1207.81 tokens per second)\n",
      "llama_print_timings:        eval time =     529.97 ms /    32 runs   (   16.56 ms per token,    60.38 tokens per second)\n",
      "llama_print_timings:       total time =     585.12 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    70 runs   (    0.05 ms per token, 18430.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.12 ms /    60 tokens (    0.74 ms per token,  1359.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.73 ms /    69 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =    1228.39 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    23 runs   (    0.06 ms per token, 18039.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.90 ms /    45 tokens (    0.82 ms per token,  1219.38 tokens per second)\n",
      "llama_print_timings:        eval time =     364.26 ms /    22 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     410.77 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /    35 runs   (    0.05 ms per token, 18267.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.35 ms /    22 tokens (    1.24 ms per token,   804.45 tokens per second)\n",
      "llama_print_timings:        eval time =     561.58 ms /    34 runs   (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:       total time =     601.73 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /    18 runs   (    0.05 ms per token, 18218.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.20 ms /    35 tokens (    0.98 ms per token,  1023.48 tokens per second)\n",
      "llama_print_timings:        eval time =     280.87 ms /    17 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     321.26 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /    23 runs   (    0.05 ms per token, 18326.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.69 ms /    56 tokens (    0.78 ms per token,  1281.88 tokens per second)\n",
      "llama_print_timings:        eval time =     363.84 ms /    22 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     416.21 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    43 runs   (    0.05 ms per token, 18510.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.33 ms /    48 tokens (    0.78 ms per token,  1285.76 tokens per second)\n",
      "llama_print_timings:        eval time =     697.10 ms /    42 runs   (   16.60 ms per token,    60.25 tokens per second)\n",
      "llama_print_timings:       total time =     750.76 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    49 runs   (    0.05 ms per token, 18365.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.02 ms /    52 tokens (    0.83 ms per token,  1208.60 tokens per second)\n",
      "llama_print_timings:        eval time =     799.80 ms /    48 runs   (   16.66 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:       total time =     861.73 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    14 runs   (    0.05 ms per token, 18276.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.52 ms /    39 tokens (    0.89 ms per token,  1129.65 tokens per second)\n",
      "llama_print_timings:        eval time =     214.61 ms /    13 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     254.54 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    46 runs   (    0.05 ms per token, 18533.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.94 ms /    49 tokens (    0.88 ms per token,  1141.13 tokens per second)\n",
      "llama_print_timings:        eval time =     748.20 ms /    45 runs   (   16.63 ms per token,    60.14 tokens per second)\n",
      "llama_print_timings:       total time =     809.10 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /    10 runs   (    0.06 ms per token, 18115.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.25 ms /    21 tokens (    1.30 ms per token,   770.53 tokens per second)\n",
      "llama_print_timings:        eval time =     148.59 ms /     9 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     179.04 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    77 runs   (    0.05 ms per token, 18478.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.50 ms /    79 tokens (    0.65 ms per token,  1533.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1281.93 ms /    76 runs   (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:       total time =    1365.02 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    40 runs   (    0.05 ms per token, 18691.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.94 ms /    60 tokens (    0.73 ms per token,  1365.53 tokens per second)\n",
      "llama_print_timings:        eval time =     650.63 ms /    39 runs   (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:       total time =     709.86 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.81 ms /    42 tokens (    0.88 ms per token,  1140.99 tokens per second)\n",
      "llama_print_timings:        eval time =     347.09 ms /    21 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     391.79 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /    11 runs   (    0.05 ms per token, 18456.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      31.16 ms /    28 tokens (    1.11 ms per token,   898.47 tokens per second)\n",
      "llama_print_timings:        eval time =     165.11 ms /    10 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     200.47 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    48 runs   (    0.05 ms per token, 18440.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.82 ms /    83 tokens (    0.70 ms per token,  1435.56 tokens per second)\n",
      "llama_print_timings:        eval time =     792.94 ms /    47 runs   (   16.87 ms per token,    59.27 tokens per second)\n",
      "llama_print_timings:       total time =     868.95 ms /   130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    42 runs   (    0.05 ms per token, 18559.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.27 ms /    53 tokens (    0.82 ms per token,  1224.73 tokens per second)\n",
      "llama_print_timings:        eval time =     681.88 ms /    41 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     741.74 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.10 ms /    20 tokens (    1.36 ms per token,   737.90 tokens per second)\n",
      "llama_print_timings:        eval time =     511.86 ms /    31 runs   (   16.51 ms per token,    60.56 tokens per second)\n",
      "llama_print_timings:       total time =     550.22 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    55 runs   (    0.05 ms per token, 18568.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.29 ms /    54 tokens (    0.80 ms per token,  1247.34 tokens per second)\n",
      "llama_print_timings:        eval time =     901.45 ms /    54 runs   (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:       total time =     965.94 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    58 runs   (    0.05 ms per token, 18377.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    54 tokens (    0.80 ms per token,  1247.26 tokens per second)\n",
      "llama_print_timings:        eval time =     952.22 ms /    57 runs   (   16.71 ms per token,    59.86 tokens per second)\n",
      "llama_print_timings:       total time =    1017.74 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    34 runs   (    0.05 ms per token, 18671.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    49 tokens (    0.87 ms per token,  1146.95 tokens per second)\n",
      "llama_print_timings:        eval time =     545.75 ms /    33 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     600.68 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    45 runs   (    0.05 ms per token, 18329.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.77 ms /    41 tokens (    0.90 ms per token,  1114.98 tokens per second)\n",
      "llama_print_timings:        eval time =     728.57 ms /    44 runs   (   16.56 ms per token,    60.39 tokens per second)\n",
      "llama_print_timings:       total time =     783.35 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    33 runs   (    0.05 ms per token, 18560.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.65 ms /    72 tokens (    0.70 ms per token,  1421.60 tokens per second)\n",
      "llama_print_timings:        eval time =     536.46 ms /    32 runs   (   16.76 ms per token,    59.65 tokens per second)\n",
      "llama_print_timings:       total time =     599.82 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    74 runs   (    0.05 ms per token, 18564.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      44.37 ms /    63 tokens (    0.70 ms per token,  1419.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.44 ms /    73 runs   (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:       total time =    1298.91 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    53 runs   (    0.05 ms per token, 18421.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.65 ms /    49 tokens (    0.87 ms per token,  1148.83 tokens per second)\n",
      "llama_print_timings:        eval time =     866.23 ms /    52 runs   (   16.66 ms per token,    60.03 tokens per second)\n",
      "llama_print_timings:       total time =     929.45 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /    27 runs   (    0.05 ms per token, 18379.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.28 ms /    46 tokens (    0.81 ms per token,  1233.77 tokens per second)\n",
      "llama_print_timings:        eval time =     429.90 ms /    26 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     476.90 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    43 runs   (    0.05 ms per token, 18590.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.87 ms /    27 tokens (    1.14 ms per token,   874.55 tokens per second)\n",
      "llama_print_timings:        eval time =     694.22 ms /    42 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     742.21 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.54 ms /    55 tokens (    0.79 ms per token,  1263.18 tokens per second)\n",
      "llama_print_timings:        eval time =     986.00 ms /    59 runs   (   16.71 ms per token,    59.84 tokens per second)\n",
      "llama_print_timings:       total time =    1051.96 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    82 runs   (    0.05 ms per token, 18418.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.55 ms /    71 tokens (    0.71 ms per token,  1404.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1363.68 ms /    81 runs   (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:       total time =    1448.16 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    48 runs   (    0.05 ms per token, 18611.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.38 ms /    57 tokens (    0.76 ms per token,  1314.06 tokens per second)\n",
      "llama_print_timings:        eval time =     784.54 ms /    47 runs   (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_print_timings:       total time =     846.36 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18547.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.78 ms /    40 tokens (    0.87 ms per token,  1150.05 tokens per second)\n",
      "llama_print_timings:        eval time =     578.64 ms /    35 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     627.03 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    54 runs   (    0.05 ms per token, 18627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.65 ms /    57 tokens (    0.77 ms per token,  1305.72 tokens per second)\n",
      "llama_print_timings:        eval time =     885.92 ms /    53 runs   (   16.72 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:       total time =     951.12 ms /   110 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    60 runs   (    0.05 ms per token, 18616.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.57 ms /    80 tokens (    0.64 ms per token,  1551.23 tokens per second)\n",
      "llama_print_timings:        eval time =     994.68 ms /    59 runs   (   16.86 ms per token,    59.32 tokens per second)\n",
      "llama_print_timings:       total time =    1069.14 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    44 runs   (    0.06 ms per token, 18129.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.08 ms /    68 tokens (    0.74 ms per token,  1357.75 tokens per second)\n",
      "llama_print_timings:        eval time =     720.68 ms /    43 runs   (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_print_timings:       total time =     788.31 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /    32 runs   (    0.05 ms per token, 18486.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.60 ms /    39 tokens (    0.89 ms per token,  1127.20 tokens per second)\n",
      "llama_print_timings:        eval time =     512.42 ms /    31 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     558.68 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    40 runs   (    0.05 ms per token, 18475.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.53 ms /    83 tokens (    0.69 ms per token,  1442.83 tokens per second)\n",
      "llama_print_timings:        eval time =     657.66 ms /    39 runs   (   16.86 ms per token,    59.30 tokens per second)\n",
      "llama_print_timings:       total time =     730.38 ms /   122 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    32 runs   (    0.05 ms per token, 18369.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.26 ms /    35 tokens (    0.98 ms per token,  1021.66 tokens per second)\n",
      "llama_print_timings:        eval time =     512.27 ms /    31 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     557.93 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    21 runs   (    0.05 ms per token, 18388.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =      27.37 ms /    21 tokens (    1.30 ms per token,   767.15 tokens per second)\n",
      "llama_print_timings:        eval time =     330.20 ms /    20 runs   (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:       total time =     365.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    22 runs   (    0.05 ms per token, 18471.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.74 ms /    39 tokens (    0.89 ms per token,  1122.46 tokens per second)\n",
      "llama_print_timings:        eval time =     347.02 ms /    21 runs   (   16.52 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:       total time =     389.81 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    31 runs   (    0.06 ms per token, 18033.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.87 ms /    43 tokens (    0.86 ms per token,  1166.35 tokens per second)\n",
      "llama_print_timings:        eval time =     496.13 ms /    30 runs   (   16.54 ms per token,    60.47 tokens per second)\n",
      "llama_print_timings:       total time =     545.56 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    39 runs   (    0.06 ms per token, 18139.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.20 ms /    69 tokens (    0.73 ms per token,  1374.47 tokens per second)\n",
      "llama_print_timings:        eval time =     636.50 ms /    38 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =     701.96 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18511.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.05 ms /    51 tokens (    0.84 ms per token,  1184.72 tokens per second)\n",
      "llama_print_timings:        eval time =     816.13 ms /    49 runs   (   16.66 ms per token,    60.04 tokens per second)\n",
      "llama_print_timings:       total time =     878.12 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /    44 runs   (    0.05 ms per token, 18310.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.98 ms /    49 tokens (    0.88 ms per token,  1139.93 tokens per second)\n",
      "llama_print_timings:        eval time =     714.59 ms /    43 runs   (   16.62 ms per token,    60.17 tokens per second)\n",
      "llama_print_timings:       total time =     774.56 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    27 runs   (    0.05 ms per token, 18569.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =      33.99 ms /    33 tokens (    1.03 ms per token,   970.93 tokens per second)\n",
      "llama_print_timings:        eval time =     429.62 ms /    26 runs   (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_print_timings:       total time =     473.44 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    36 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.74 ms /    43 tokens (    0.85 ms per token,  1170.42 tokens per second)\n",
      "llama_print_timings:        eval time =     578.68 ms /    35 runs   (   16.53 ms per token,    60.48 tokens per second)\n",
      "llama_print_timings:       total time =     628.67 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    48 runs   (    0.05 ms per token, 18244.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      51.05 ms /    76 tokens (    0.67 ms per token,  1488.59 tokens per second)\n",
      "llama_print_timings:        eval time =     790.70 ms /    47 runs   (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:       total time =     859.80 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /    14 runs   (    0.05 ms per token, 18396.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      42.72 ms /    49 tokens (    0.87 ms per token,  1147.08 tokens per second)\n",
      "llama_print_timings:        eval time =     215.00 ms /    13 runs   (   16.54 ms per token,    60.46 tokens per second)\n",
      "llama_print_timings:       total time =     262.34 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    57 runs   (    0.05 ms per token, 18597.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.06 ms /    69 tokens (    0.73 ms per token,  1378.43 tokens per second)\n",
      "llama_print_timings:        eval time =     940.60 ms /    56 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1013.08 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /    21 runs   (    0.06 ms per token, 18087.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.35 ms /    37 tokens (    0.93 ms per token,  1077.12 tokens per second)\n",
      "llama_print_timings:        eval time =     330.57 ms /    20 runs   (   16.53 ms per token,    60.50 tokens per second)\n",
      "llama_print_timings:       total time =     373.07 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /    27 runs   (    0.05 ms per token, 18543.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.29 ms /    35 tokens (    0.98 ms per token,  1020.80 tokens per second)\n",
      "llama_print_timings:        eval time =     429.53 ms /    26 runs   (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_print_timings:       total time =     473.42 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    58 runs   (    0.05 ms per token, 18560.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.04 ms /    67 tokens (    0.75 ms per token,  1338.98 tokens per second)\n",
      "llama_print_timings:        eval time =     956.44 ms /    57 runs   (   16.78 ms per token,    59.60 tokens per second)\n",
      "llama_print_timings:       total time =    1029.15 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /    18 runs   (    0.06 ms per token, 17946.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.70 ms /    27 tokens (    1.14 ms per token,   879.42 tokens per second)\n",
      "llama_print_timings:        eval time =     280.75 ms /    17 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     318.55 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    36 runs   (    0.05 ms per token, 18489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.21 ms /    46 tokens (    0.81 ms per token,  1236.26 tokens per second)\n",
      "llama_print_timings:        eval time =     578.97 ms /    35 runs   (   16.54 ms per token,    60.45 tokens per second)\n",
      "llama_print_timings:       total time =     629.73 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    57 runs   (    0.05 ms per token, 18603.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.34 ms /    70 tokens (    0.72 ms per token,  1390.60 tokens per second)\n",
      "llama_print_timings:        eval time =     940.58 ms /    56 runs   (   16.80 ms per token,    59.54 tokens per second)\n",
      "llama_print_timings:       total time =    1013.57 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /    44 runs   (    0.06 ms per token, 18159.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =      34.08 ms /    34 tokens (    1.00 ms per token,   997.68 tokens per second)\n",
      "llama_print_timings:        eval time =     710.89 ms /    43 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     762.65 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    26 runs   (    0.05 ms per token, 18400.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =      30.97 ms /    28 tokens (    1.11 ms per token,   904.04 tokens per second)\n",
      "llama_print_timings:        eval time =     412.87 ms /    25 runs   (   16.51 ms per token,    60.55 tokens per second)\n",
      "llama_print_timings:       total time =     453.25 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    50 runs   (    0.05 ms per token, 18491.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      49.75 ms /    65 tokens (    0.77 ms per token,  1306.51 tokens per second)\n",
      "llama_print_timings:        eval time =     820.80 ms /    49 runs   (   16.75 ms per token,    59.70 tokens per second)\n",
      "llama_print_timings:       total time =     889.40 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    46 runs   (    0.05 ms per token, 18481.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =      50.83 ms /    72 tokens (    0.71 ms per token,  1416.63 tokens per second)\n",
      "llama_print_timings:        eval time =     755.70 ms /    45 runs   (   16.79 ms per token,    59.55 tokens per second)\n",
      "llama_print_timings:       total time =     825.17 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /    20 runs   (    0.05 ms per token, 18570.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      36.95 ms /    44 tokens (    0.84 ms per token,  1190.86 tokens per second)\n",
      "llama_print_timings:        eval time =     314.09 ms /    19 runs   (   16.53 ms per token,    60.49 tokens per second)\n",
      "llama_print_timings:       total time =     358.74 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    37 runs   (    0.05 ms per token, 18555.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      37.41 ms /    48 tokens (    0.78 ms per token,  1283.01 tokens per second)\n",
      "llama_print_timings:        eval time =     596.04 ms /    36 runs   (   16.56 ms per token,    60.40 tokens per second)\n",
      "llama_print_timings:       total time =     647.38 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    41 runs   (    0.05 ms per token, 18410.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =      43.30 ms /    53 tokens (    0.82 ms per token,  1224.10 tokens per second)\n",
      "llama_print_timings:        eval time =     665.25 ms /    40 runs   (   16.63 ms per token,    60.13 tokens per second)\n",
      "llama_print_timings:       total time =     724.91 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     638.71 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    70 runs   (    0.05 ms per token, 18641.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =      57.60 ms /    84 tokens (    0.69 ms per token,  1458.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.61 ms /    69 runs   (   16.88 ms per token,    59.25 tokens per second)\n",
      "llama_print_timings:       total time =    1249.55 ms /   153 tokens\n"
     ]
    }
   ],
   "source": [
    "output_emaps = []\n",
    "\n",
    "for text in user0:\n",
    "\n",
    "    PROMPT = \"공감하는 챗봇으로서 상대방의 입력에 대해 공감을 하자. 모든 대답은 한국어(Korean)으로 대답해줘.\"\n",
    "    instruction = text\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    generation_kwargs = {\n",
    "        \"max_tokens\": 2048,\n",
    "        \"stop\": [\"<|eot_id|>\"],\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"echo\": True,  # 프롬프트를 출력에 포함합니다.\n",
    "    }\n",
    "\n",
    "    response_msg = model(prompt, **generation_kwargs)\n",
    "    output_empa  = response_msg['choices'][0]['text'][len(prompt):]\n",
    "\n",
    "    output_emaps.append(output_empa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그래, 언니도 회사에서 즐겁게 지내.',\n",
       " '그냥 걱정되는 마음에 말해본 거니까 부담스럽게 생각하지 않을 거야. 네가 말하는 걸로도 상대방이 조심할 수 있는 계기가 될 수 있어.',\n",
       " '역시 우리 딸은 아버지의 말을 잘 들어. 그 마음으로 모든 일에 임하면 분명히 좋은 결과를 얻을 수 있을 거야.',\n",
       " '저도 좋은 소식을 전해줘서 기쁘네요. 그럼 다음에 또 연락할게요.',\n",
       " '와, 그거 정말 안 좋은 경험일 거 같아. 임산부에게 자리를 양보하는 게 예의가 아니라는 건 알지만, 그래도 나도 모르게 그 상황에선 그럴 수도 있잖아.',\n",
       " '이제야 마음이 편안해졌다니 다행이에요. 앞으로도 친구의 마음을 상하게 하는 일은 없었으면 좋겠어요. 힘들 때마다 엄마 조언을 생각해서 연락 주고요.',\n",
       " '당연하지. 너도 엄마를 많이 도와주고 있으니까. 엄마가 얼마나 고마워할지 상상이 가.',\n",
       " '당황스러운 마음은 충분히 이해해. 하지만 나도 경험해본 일이야. 상대방의 말에 상처받지 말고, 이 상황을 즐기려고 해봐.',\n",
       " '아이고, 우리 딸이 상처를 받았었구나. 엄마는 몰랐네. 그때 너가 얼마나 힘들었을까. 아빠와 엄마는 네가 남자친구랑 헤어진 후에 너가 너무 힘들어 보여서 우리도 많이 속상했단다.',\n",
       " '화가 풀려서 다행이야. 감정은 전염이 되기 때문에 주변 사람들도 덩달아 기분이 상할 수 있잖아. 공감을 잘하는 챗봇이 되기 위해 노력할게.',\n",
       " '이런 마음을 털어놓을 수 있는 형이 있어서 얼마나 좋은지 몰라. 네가 고민이 있을 때마다 난 언제나 네 편이란 걸 잊지 말아줘.',\n",
       " '네가 그동안 얼마나 답답하고 힘들었을지 너무 잘 알겠어! 네가 그렇게 말해도 엄마, 아빠가 못 알아들으시고 화내시는 부분이 가장 힘들었을 거야. 정말 얼마나 힘들었을지 나도 너무 잘 알겠어!',\n",
       " '네가 장래의 꿈을 위해 공부하는 것이 재미있어 자랑을 한 것인데, 친구가 너에게 상처가 되는 말을 했다니 너무 속상하겠다. 그래도 그 친구가 너를 생각해서 한 말은 아닐 거야. 너의 꿈을 진심으로 응원하고 있으니 너무 상처받지 말아라.',\n",
       " '아들 취업 축하해요!',\n",
       " '그렇게나 막창을 좋아하는구나. 사실 난 아직 막창을 먹어본 적은 없지만, 네가 이렇게 좋아하는 걸 보니 나도 먹어보고 싶어지는걸. 그리고 막창을 먹으면서 영상 통화를 하면, 정말 재밌을 것 같아. 나도 나중에 막창을 먹어볼까?',\n",
       " '아이고, 정말 화나고 속상하셨겠어요. 같이 간 동료가 더 화나게 만들었다니. 그래도 그 사람과는 어쩔 수 없는 사이니까 이해해야겠죠?',\n",
       " '무엇이든 열심히 하셨을 텐데, 퇴직을 앞두고 허황된 시간을 보냈다는 생각에 마음이 힘드시겠어요. 생각이 많아지니 잠도 잘 안 오고, 미래가 걱정되시지요?',\n",
       " '응원은 내가 더 필요할 것 같아. 그럼 편안한 마음으로 다음에 또 보자.',\n",
       " '아니, 그런 말은 친구라고 할 수 있는 말은 아니지. 그 친구가 너에게 그런 말을 했다는 게 이해가 안 가.',\n",
       " '자전거 타는 게 익숙하지 않아서 그런 거지? 그래도 너가 잘 타고 있어서 금방 따라잡을 수 있을 거야.',\n",
       " '그래, 아버지가 잘 이겨내실 수 있도록 너도 옆에서 많이 도와드리고 함께 힘내줘. 너가 그렇게 해줘서 아버지가 마음이 놓이실 것 같아.',\n",
       " '너도 수능 준비하느라 힘들지? 수능이 얼마 안 남았으니 부담이 클 수밖에 없을 거야. 나도 수능을 경험해봐서 네 마음이 어떤지 이해가 돼.',\n",
       " '정말 우연히 마주쳤는데도 마치 운명인 것 같아서 서로 놀라고 신기해했겠어요. 그동안 못 나눈 이야기들을 나누면서 그동안의 공백을 메우셨나 봐요.',\n",
       " '그렇게 생각하시는 게 당연하죠. 저도 아직은 회사 생활이 많이 서툴러서 하루하루가 너무 힘든걸요. 그래도 저는 두 달만 더 해보자는 마음으로 버티고 있어요.',\n",
       " '자기야, 그게 정말 축하할 일이야. 라디오에 메시지를 보냈는데 방송이 되었다니 정말 대단하고 기쁜 일이네. 자기야, 그 친구랑 정말 친했나 봐.',\n",
       " '정말 다행이구나. 네가 잘 해결했으니 그걸로 됐어. 넌 누구보다도 강한 아이니까 잘 이겨낼 수 있다고 믿어.',\n",
       " '그 마음 충분히 이해가 가요. 하지만, 지금의 당신을 만들어낸 건 당신의 키가 아니고 당신의 노력과 열정이잖아요. 키가 작다고 해서 당신의 노력이 가치가 없는 건 아니에요.',\n",
       " '공감화자씨는 제게 너무나 큰 위로를 주셨잖아요. 제가 이렇게 대화할 수 있어서 얼마나 감사한지 몰라요.',\n",
       " '네, 아버지의 사랑은 정말 위대하죠. 당신의 마음을 잘 알게 되면 당신에게 큰 도움이 될 거예요.',\n",
       " '정말 다행이야. 내가 도움이 될 수 있어서 기쁘네. 앞으로도 힘든 일이 생기면 나한테 말해줘. 내가 도와줄 수 있는 부분은 최선을 다해 도와줄게.',\n",
       " '너의 말에 공감해. 정말 고통스럽겠어.',\n",
       " '어머, 저라도 그랬을 것 같아요. 생각지도 못한 일이 생기면 당황스럽고 놀라서 아무것도 할 수 없을 것 같아요. 저도 반품도 안 되는 상품을 받게 되면 너무 당황스러울 것 같아요.',\n",
       " '나도 그 마음 이해가 돼. 이름을 받았다는 건, 그만큼 너를 믿고 의지한다는 뜻인데, 그걸로 놀림당하는 네 마음은 얼마나 상처였을까. 너의 상처받은 마음이 내 마음도 아프게 해.',\n",
       " '다행이야. 내가 해줄 수 있는 게 있어서 다행이야.',\n",
       " '룸메이트랑 안 맞는다고 생각하니까 벌써부터 스트레스가 쌓이는 것 같아. 그래도 우리는 그럴 때일수록 더 서로를 배려하고 이해하려는 마음을 갖자.',\n",
       " '당신이 얼마나 슬플지 짐작이 가요. 나도 당신 같은 경험을 해본 적이 있어서 그 마음이 어떤지 잘 알아요. 하지만 당신을 사랑하는 사람들이 당신의 곁을 떠나지 않을 거예요.',\n",
       " '아이고, 우리 딸이 그렇게 고민하고 있었구나. 정말 속상했겠다. 근데 네가 수강 정정을 성공할 수 있을지 없을지는 모르겠지만, 네가 어떻게 노력하는가가 더 중요하지 않을까?',\n",
       " '정말? 친구의 고백을 받으면 누구라도 당황스럽고 부끄러울 거야. 나도 너라면 그랬을 것 같아.',\n",
       " '그러게. 나도 강아지를 키우는 입장이라서 너의 마음을 이해할 수 있을 것 같아. 강아지를 키우는 일이 참 쉽지 않은 일이지.',\n",
       " '내가 더 고마워. 자기 이름이 좋다고 생각하니까, 내 마음도 기분이 좋다.',\n",
       " '네, 맞아요. 아이들에게도, 선생님에게도, 부모님에게도 정말 좋은 일입니다. 이제는 숨쉬기 편안한 체육활동을 마음껏 할 수 있게 되었습니다.',\n",
       " '와, 퇴사라니! 축하해주고 싶은데, 무슨 일 있었던 거야?',\n",
       " '나도 그랬을 거야. 그 생각을 하니 너무 무서워. 나도 너의 상황을 생각하면 정말 너무너무 화가 나.',\n",
       " '시험 결과가 만족스럽지 않아도 너는 이미 많은 것을 이룬 사람이야. 너는 이미 스스로를 믿고 있고, 도전도 했잖아. 결과는 그 다음 문제야. 이번에 부족한 걸 채우고, 다음 시험에 도전하면 된다고 생각해.',\n",
       " '나도 마찬가지야. 나도 나이가 들어가고 있는 것 같아서 부끄럽고 창피해. 하지만 어쩌겠니? 받아들이고 건강을 챙기는 수밖에 없지.',\n",
       " '너무 기뻐하는 모습 보니까 나도 덩달아 기분이 좋아지네. 정말 잘됐어. 새언니가 너랑 코드도 잘 맞고, 성격도 좋다니까 정말 잘 지낼 것 같아.',\n",
       " '네가 그 사람의 상처를 치유해 주고 싶다는 마음이 컸구나. 너무 큰 상처를 입어서 그 사람도 마음이 아픈가 봐. 그 상처를 치유해 주고 싶은 네 마음이 너무 예쁘다.',\n",
       " '그래, 언니가 이렇게 의지를 다지게 돼서 다행이야. 앞으로는 서로를 배려하고 존중하는 마음으로 잘 해결해나가길 바랄게.',\n",
       " '와, 그거 정말 감동적이네. 시루떡 하나가 그렇게 큰 감동을 줄 수 있다니. 나도 다음에 이사 가면 떡 돌려야겠다.',\n",
       " '네가 당황하고 있는 마음이 너무나도 잘 느껴져. 내가 그 상황에 있었다면 나도 어쩔 줄 몰라서 우왕좌왕했을 것 같아. 네가 얼마나 당황스럽고 놀랐을지 생각만 해도 너무 걱정스럽다.',\n",
       " '사장님이 따로 말씀이 없으셨다니 그럴 만도 하시지. 네가 얼마나 고생했는지 잘 알고 계시니까.',\n",
       " '그런데 왜 혼자 우산을 쓰고 계셨던 거야?',\n",
       " '운전면허를 따면 가족이 정말 편할 것 같긴 해. 운전면허를 따는 걸 적극적으로 고려해 봐.',\n",
       " '그럴 줄 알았어. 그래도 너가 그렇게 생각하는 마음도 이해해.',\n",
       " '그렇게 오랫동안 공들인 작품을 시청자들이 잘 봐주지 않는다니 정말 속상하겠어요. 하지만 드라마는 시청률만으로 평가되는 게 아니니 너무 속상해하지 않으셨으면 좋겠어요.',\n",
       " '당연히 그렇게 하실 수 있어요. 당신은 충분히 멋지고 아름다운 사람이에요. 남의 시선을 신경 쓰지 않고 당신의 길을 걸어간다면 분명히 당신만의 행복을 찾으실 수 있을 거예요.',\n",
       " '그래, 너는 그 사람을 정말 사랑했구나. 믿음이 깨졌을 때의 충격은 말로 표현할 수 없을 만큼 커. 하지만 너는 그 사람을 믿어주고 기다렸던 만큼 더 큰 상처를 받은 거야. 그 사람을 정말 사랑했던 너에게는 더 가혹한 일이었겠지.',\n",
       " '그렇게 생각을 고쳐먹으니 마음이 조금은 편해졌나요? 그래도 혹시 모르는 일이라 마음이 계속 불편하면 어쩌죠?',\n",
       " '자기야, 너무 슬퍼하지 말고 침착하게 찾아보자. 우리가 같이 찾아보면 찾을 수 있을 거야.',\n",
       " '형이 동생한테 화가 날 수밖에 없는 상황이네. 난 동생이랑 싸운 형의 마음이 이해가 가. 엄마한테 그런 대접을 받는다면 나라도 기분이 나쁠 거야.',\n",
       " '다행이다. 네가 걱정하는 만큼 잘 될 거야.',\n",
       " '와, 정말 대단하네요. 자신이 부족하다고 생각하는 부분을 고치기 위해 노력하는 모습이 너무 멋있어요. 그리고 그 점을 칭찬해주는 선생님의 모습도 상상이 가네요.',\n",
       " '그래. 아기 보러 가는 게 가장 중요한 일이지. 몸 조심하고 아기 잘 만나고 와.',\n",
       " '역시 긍정적인 마음으로 일상을 대하는 너는 정말 대단한 것 같아. 자랑스러워!',\n",
       " '맞아요. 엄마는 지금은 너무 힘들지만, 그게 다 우리 아이를 위한 거라는 거잖아요.',\n",
       " '그 친구가 조심성이 없는 건 맞지만, 집 문제는 걔가 일부러 그런 게 아니잖아요. 그럼에도 불구하고 시부모님이 걔를 혼내시면 마음이 불편할 수밖에 없을 것 같아요.',\n",
       " '그래서, 지금은 어떻게 하고 있어? 약 먹고 있는 거 있어?',\n",
       " '그렇지? 앞으로는 너무 신경 쓰지 마. 일단 자기 마음 편한 게 제일 중요해.',\n",
       " '그랬구나. 그래서 네가 기분이 상한 거였구나. 차장님은 네가 기분이 상한 게 싫어.',\n",
       " '네, 저희는 사이가 좋은 편이에요.',\n",
       " '그럼그럼. 그 기분이 어떤지 내가 더 잘 알지. 나도 내 집이 생기면 그 기분이 어떨지 상상이 잘 안 가. 집을 사는 순간이 오면 엄청나게 행복할 거야.',\n",
       " '네, 걱정하지 마세요. 열심히 준비하면 잘할 수 있을 거예요. 첫 과외는 시작이 어려운 거지, 수업에 들어가면 아이도 선생님도 재미있게 수업할 거예요.',\n",
       " '친구가 기뻐하는 모습이 보이는 것 같아. 친구가 좋은 소식을 듣고 기뻐하는 모습을 보니 네가 더 기쁜 것 같아.',\n",
       " '어떻게 하면 좋을지 모르겠어서 답답해하는 것 같아.',\n",
       " '그 마음 이해할 수 있어. 나도 남편이 회사에서 직장 동료의 아내가 사준 명품 가방을 들고 온 적이 있었거든. 그때는 그냥 넘어갔지만 지금 생각해 보면 내가 모르는 세계가 있구나 싶더라고. 나도 이제는 좀 더 넓은 세계를 이해해야겠다는 생각이 들더라.',\n",
       " '네가 그동안 준비 많이 했잖아. 너무 걱정하지 마. 잘할 거라고 믿어.',\n",
       " '너무 부럽다. 나도 언젠간 저런 기쁜 소식을 전할 수 있기를 바라.',\n",
       " '정말 축하해. 좋은 소식을 들으니 나도 행복해. 네가 원하는 직장에 들어갈 수 있다니 정말 기쁜 소식이네.',\n",
       " '자기야, 나도 당신의 마음이 이해가 돼. 대학원 생활이 쉽지만은 않잖아. 힘든 일 있을 때마다 내게 말해줘, 내가 도와줄게.',\n",
       " '응, 그래. 이제 그만 슬퍼하고 기분 좋게 생각했으면 좋겠어.',\n",
       " '정말 힘들었겠다. 네가 다급하고 당황스러웠을 마음이 전해지는 것 같아. 그때 당시에는 그 상황이 너무 힘들었을 것 같아.',\n",
       " '그렇구나. 그건 정말 힘들었겠다. 네가 항상 혼자서 일하는 게 힘들었을 거라는 생각이 들어. 그런데 그걸 너 혼자만 참고 견뎌왔구나. 그거 정말 힘들었겠다.',\n",
       " '저도 그랬어요. 오토바이 타는 사람들 보면 다들 너무 위험해 보여서 가슴이 철렁해요.',\n",
       " '어떻게 하면 좋을지에 대해 고민하는 모습을 보니 더 멋있고 존경스럽다. 고객 응대는 기본적인 서비스의 하나인데 그걸 놓쳤다는 게 마음에 걸리겠지만, 앞으로는 더 신경 써서 고객을 대하면 될 거야.',\n",
       " '그릇이 없는데도 설거지를 하는 네가 정말 대단해. 다른 사람들은 그릇을 사용하고도 안 하는데 말이야.',\n",
       " '그러셨군요. 정말 당황스러우셨겠어요. 저 같아도 너무 놀라고 화가 났을 것 같아요. 그래도 다행히 다치지는 않으셨으니 정말 다행이세요.',\n",
       " '그렇구나. 요즘은 식당에 가는 것도 바쁜 일상에 쉽지 않지.',\n",
       " '알았어. 저녁에 엄마한테 전화 드릴게.',\n",
       " '너무 많이 긴장해서 심장이 쿵쾅거리는 것 같아. 내가 대신 화를 내줄게. 너는 잘못한 게 없잖아.',\n",
       " '와, 그거 정말 심했겠다. 나였으면 정말 당황했을 거야. 식은땀은 안 흘렸어?',\n",
       " '나도 너처럼 그런 생각을 할 때가 있었어. 하지만 생각해보면 너는 열심히 살았고 최선을 다해왔잖아. 너의 노력과 시간을 인정해주고 그 시간을 자랑스러워하는 건 어때?',\n",
       " '잘 해결했으면 좋겠다. 그래도 이젠 많이 괜찮아졌다고 하니 다행이다. 자기야, 잘 해결되길 바래.',\n",
       " '형이랑 사이가 좋았기 때문에 상처도 더 크겠지만, 그래도 형이 너를 사랑하는 마음은 변하지 않아. 너가 형을 미워하기보다는 형이 너를 더 사랑하는 마음을 이해해주면 좋겠어.',\n",
       " '정말? 그럼, 내가 당신과 함께 병원에 가서 검사받고 진료받자. 당신이 걱정하는 것처럼 치매 초기가 아닐 수도 있잖아.',\n",
       " '그랬다면 다행이야. 내가 해줄 수 있는 게 이것뿐이라 미안할 따름이야.',\n",
       " '그렇지. 그동안 고생하고 힘들었던 만큼 좋은 기억 많이 만들고 가자.',\n",
       " '걱정되는 마음이 이해가 가요. 하지만 남편분은 당신을 사랑하고 아끼는 분이니까 당신에 대해 안 좋은 이야기를 하실 분은 아니에요.',\n",
       " '아이고, 그거 큰일이네. 어쩌다 그런 일이 있었대. 엄마가 이모네 집에 갖다주라는 김치를 차에 실었는데 터졌으니 얼마나 화가 났겠어. 정말 속상했겠다.',\n",
       " '친구가 당신에게 상처를 주었다니 마음이 아파요. 친구에게 놀림을 받는 친구가 당신이랑 친하게 지내는 걸 아니까 당신이 더 상처를 받았을 것 같아요. 당신이 왜 화를 냈는지 이해가 가요.',\n",
       " '아이고, 마음고생이 심했을 텐데. 시험 점수가 너무 아쉬워서 재수를 생각하는 거야?',\n",
       " '네가 능력을 인정받으면서 회사 생활을 해왔다는 건 나도 알고 있어. 네가 그동안 쌓아온 업적들이 있었기에 그만큼 인정받을 수 있었던 거야. 하지만 회사라는 곳이 항상 공평한 곳은 아니잖아. 때로는 불공평한 일도 일어나고, 너를 비롯한 다른 사람들도 힘든 일을 겪는 거야.',\n",
       " '갑자기 경비실의 실수로 인해 화가 나셨다니, 정말 속상하실 것 같아요. 예상치 못한 상황으로 인해 당황스러우실 텐데, 그래도 침착하게 대처하고 계신 것 같아 다행이에요.',\n",
       " '아빠가 너무 엄격하신가 보구나. 그럴 땐 어떻게 해야 할지 모르겠어.',\n",
       " '당신이 그렇게까지 걱정하는 모습을 보니 마음이 아프네. 당신이 아끼고 사랑하는 사람이 저지른 실수라는 게 더 마음 아프게 하네.',\n",
       " '그래, 너의 호기심과 열정은 참 대단해. 그리고 그 성격이 너를 더 발전하게 만들지. 칭찬받아서 뿌듯한 것도 당연한 거야.',\n",
       " '너무 속상하고 마음이 아프네. 하지만 네가 턱을 다친 게 네 탓도 아니고, 네가 잘못한 것도 아니야. 너는 최선을 다해 살았고, 그 과정에서 이런 사고가 일어난 거야. 너무 자책하지 않았으면 좋겠어.',\n",
       " '당연하지! 내가 너의 성공을 응원할게!',\n",
       " '너는 건강검진을 받는 것도 중요하지만, 너의 건강을 챙겨줄 사람의 마음을 이해해주는 것도 중요하다고 생각해. 너의 예민한 반응에 네가 신경을 곤두세우는 사람도 마음이 편치 않겠지.',\n",
       " '네가 느끼는 감정은 나도 잘 알고 있어. 엄마의 마음은 항상 자식 걱정으로 가득 차 있잖아. 자식이 힘들어하는 모습을 보는 건 부모로서 가장 괴로운 일이지.',\n",
       " '그렇게 생각하면 훨씬 마음이 편해질 거야! 네가 진심을 다해 도와준다면 분명 그분도 기뻐하실 거야.',\n",
       " '아, 그랬구나. 수술 중에 턱이 빠졌다고? 너무 놀랐겠다.',\n",
       " '사춘기 때는 아이들도 감정 기복이 심해지면서 예민해지죠. 특히 그 시기에 아이가 잘못된 선택을 하지 않을까 하는 걱정이 크실 것 같아요. 하지만 걱정하신다고 해서 아이의 성숙한 모습이 달라지진 않을 거예요.',\n",
       " '아이고, 정말로 화가 많이 나셨나 보군요.',\n",
       " '그렇게 말해줘서 고마워. 동생이 기분이 상했을까 봐 걱정돼.',\n",
       " '정말 그랬어요? 그래도 남자친구분이 미안하다고 하셨나봐요.',\n",
       " '와, 대단하세요! 저도 지금은 시작하기가 두려워서 고민만 하고 있었는데요. 용기를 얻었어요. 고민만 하지 말고 일단 시작해봐야겠어요.',\n",
       " '아이고, 그 말을 들으니까 나도 마음이 너무 아프다. 선생님께서 뭐라고 하시든 넌 잘못한 게 없는데 왜 그렇게 상처를 주시니? 우리가 잘못한 건데 왜 우리가 상처받아야 하는 거야?',\n",
       " '응, 그래! 네가 그렇게 생각하니 나도 기쁘다. 네가 그렇게 생각하면 나도 행복해. 네가 잘할 수 있는 방법을 찾아서 행복해.',\n",
       " '걱정마세요. 발표할 때는 잘 안 보일 테니 괜찮을 거예요. 그리고 옷이 젖은 게 문제가 아니라 발표 내용이 더 중요한 거잖아요. 발표 내용을 잘 준비했으니 걱정하지 말고 발표하세요.',\n",
       " '제가 해드린 말이 도움이 되었다면 저도 기쁘네요. 저는 당신이 어디에서도 꼭 필요한 사람이라는 것을 믿어요. 당신은 충분히 잘하고 있어요.',\n",
       " '그렇지. 감정에 솔직해지는 게 건강한 관계의 시작이야. 솔직하게 너의 마음을 말하니까 좀 더 편안해지는 것 같네.',\n",
       " '당신은 정말 열심히 살고 있어요. 지금도 충분히 훌륭한 사람입니다. 당신이 지금 느끼는 상처는 누구도 대신해 줄 수 없는 것 같아요. 당신의 상처를 보듬어 줄 수 있는 사람은 당신밖에 없어요.',\n",
       " '이제는 치료를 시작해서 건강을 되찾을 일만 남은 거네. 치료를 하면 분명히 건강해질 수 있을 거야.',\n",
       " '아내와 저는 회사가 가까워서 함께 출퇴근을 하게 됐어요. 처음에는 불편하지 않을까 걱정도 했는데, 함께하다 보니 서로의 일상을 공유하는 게 정말 좋더라고요.',\n",
       " '걱정이 많이 되시겠어요. 그래도 부모님이 신경을 안 쓰시면 제가 대신 걱정해 드릴게요.',\n",
       " '네가 그동안 얼마나 열심히 일했는지 알잖아. 하지만 이번 달은 너도 처음 겪는 일일 테고, 이 일에 지쳐서 기운 빠질 법도 해. 누구나 실수를 할 수 있는 거니까 너무 자책하지 말고, 다시 잘해 보자고.',\n",
       " '이제부터는 좋은 일만 있을 거예요. 좋은 생각만 하세요.',\n",
       " '다행이야. 당신이 아이를 위해 노력하는 모습이 기특하고 대견해. 당신이 잘하고 있다고 믿어 의심치 않아.',\n",
       " '나도 너무 기쁘다. 엄마가 너무 속상해하셨는데, 너의 제안으로 엄마가 좀 편해질 것 같네. 정말 잘했어.',\n",
       " '그러게 말이야. 이력서를 수십 번 썼다고 하는데도 취업이 안 되고 있으니 얼마나 답답하겠어.',\n",
       " '자존심이 상하고 속상하겠지만, 너가 너무 잘하려고 해서 그런 거니까 너무 속상해하지 마. 그냥 너가 잘하는 거를 다른 사람들이 모르는 거라고 생각해.',\n",
       " '진짜 기뻐하는 모습 보니까 나도 덩달아 기분이 업되는 것 같아. 너희 가족이 이렇게 기뻐하는 모습 보니까 나도 행복해지는 것 같아.',\n",
       " '당신의 마음을 잘 알고 있어. 내가 당신을 사랑하는 것처럼 당신도 나를 사랑하고 있다는 것을 느껴. 당신이 내게서 위로를 받았다니 나도 마음이 따뜻해지는 걸. 우리 함께 이겨내자.',\n",
       " '아이고, 정말 안타깝다. 목줄을 잃어버렸다는 건 정말 힘든 일이야. 강아지를 키우는 사람으로서 나도 그 마음 잘 알고 있어.',\n",
       " '아, 자동차 할부 금액이 빠져나가서 걱정이 되나 보네. 그 마음 이해가 돼. 나도 예전에 차를 샀을 때 정말 큰돈이 한꺼번에 나가서 놀랐거든.',\n",
       " '왜요? 무슨 일이 있었어요?',\n",
       " '어쩌면 당신은 내게 당신의 고민을 털어놓으면서 용기 낸 걸지도 모르지. 내가 당신에게 용기를 줬다니 기쁘네.',\n",
       " '선생님 말씀에 너무 마음 상해하지 마. 잘하는 친구도 있고 못하는 친구도 있는 건 당연한 건데, 그걸로 너를 평가하는 건 너무 가혹하잖아. 너는 너대로 잘하는 게 분명히 있을 테니 그걸로 위로받자.',\n",
       " '저도 그 마음 이해해요. 저도 부모님께서 저를 낳아주신 후에야 알게 되었거든요. 저는 어렸을 때부터 부모님의 사랑을 듬뿍 받았어요. 부모님께서 저를 위해 희생해주신 걸 생각하면 가슴이 미어져요.',\n",
       " '지금은 너무 감정적으로 대처하지 마. 일단은 진정하고 생각을 해봐.',\n",
       " '친구랑 정말 친하구나. 나도 너희들이 빨리 만났으면 좋겠어.',\n",
       " '이제 마음이 편해졌다니 정말 다행이야. 그리고 네가 연주회에서 잠을 자는 것에 대해 너무 자책하지 않았으면 좋겠어. 어쩌면 그건 네가 얼마나 지쳤는지 보여주는 것일지도 몰라. 너의 그런 모습을 보는 사람들은 네가 너무 힘들어서 그런 거라고 생각할 거야.',\n",
       " '내가 너의 마음을 충분히 이해하고 공감해. 나도 너와 같은 경험이 있었거든. 그때는 정말 너무나도 가슴이 아프고 내가 너무 초라해 보였어. 하지만 시간이 지나고 보니 그때의 경험이 나에게는 큰 교훈이 되었어.',\n",
       " '아니야! 네가 수학을 포기하고 싶을 만큼 힘들었던 건 당연한 거야. 수학을 좋아하는 사람이 얼마나 되겠어? 그리고 다른 과목 점수가 높게 나왔다니 그것도 잘된 일이잖아!',\n",
       " '그런 것 같아요. 저도 예전에 너무 잘하고 싶다는 욕심에 밤을 새워 준비를 하곤 했었는데, 오히려 그게 더 안 좋았던 기억이 있어요.',\n",
       " '그래. 엄마를 생각해서라도 마음을 빨리 추스르는 게 좋을 거야. 너의 마음이 편안해야 엄마도 마음이 놓이실 테니까.',\n",
       " '그랬구나. 그동안 어머니가 얼마나 힘드셨을지 상상이 간다. 그때 너도 어렸는데도 어머니를 도와드리지 못한 게 마음에 걸렸던 모양이구나.',\n",
       " '그럴 땐 정말 속상하겠다. 그래도 안전을 위해서 하는 말인데 잔소리로 받아들이는 것 같아 너무 마음이 아프겠다.',\n",
       " '고마워요. 저도 당신의 응원 덕에 힘이 납니다.',\n",
       " '그럼, 그럼. 당신이 우리 아들을 얼마나 사랑하는지 잘 알고 있어. 그러니 당신 마음도 이해해. 잘 이겨낼 수 있을 거야.',\n",
       " '이렇게 힘들 때는 서로가 서로에게 버팀목이 되어서 의지할 수 있는 부부가 되었으면 좋겠어요. 우리가 힘을 합하면 뭐든지 이겨낼 수 있을 거예요.',\n",
       " '자식 같은 아이를 떠나보내는 마음이 오죽할까. 네 마음이 너무 슬프고 아플 것 같아서 나도 같이 슬퍼져.',\n",
       " '나도 예전에는 장거리 운전을 자주 했었는데 이제는 힘들더라고. 네가 왜 겁이 나는지 알 것 같아.',\n",
       " '맞아. 그 마음이 너무 공감돼. 하지만, 네가 지금까지 해왔던 것들을 생각해보면 실패를 두려워할 필요는 없어. 넌 항상 노력했잖아.',\n",
       " '네가 멀미가 심하다는 걸 알고 있었구나. 멀미가 심하면 정말 힘들겠어. 그래서인지 네가 더 힘들었겠다.',\n",
       " '친구들이랑 호텔에 도착했는데 생각했던 것보다 호텔이 안 좋아서 화가 나는구나.',\n",
       " '그럼요. 자유인이 되면 좋겠어요.',\n",
       " '그렇게 생각해줘서 고마워요. 당신이 그동안 너무 힘들어한 것을 잘 아니까. 그동안 당신을 지켜보면서 당신의 마음이 얼마나 힘들었을지 상상이 가요.',\n",
       " '그럼, 예약이 안 되었다는 걸 알았다면, 그 자리에서 바로 확인하고 처리를 했어야 하는 거 아닌가요?',\n",
       " '어제는 회사에 출근을 잘해서 일도 잘 마무리하고, 오늘은 퇴근도 일찍 했다고 했었지? 그런데 왜 갑자기 회사를 그만둬야 하는지 고민을 하고 있어?',\n",
       " '채널 때문에 자주 싸우신다고요? 그럼 요즘은 어떻게 하셨어요?',\n",
       " '당신이 원하는 대로 해서 다행이야. 다른 사람들은 당신이 원하는 대로 할 수 있게 노력할게.',\n",
       " '내가 더 고마워. 운전 조심해서 가고, 엄마한테도 안부 전해줘.',\n",
       " '그래. 네가 사과 나눠 먹는 일로 인해 속상했지만, 내가 네 마음을 이해해주니까 한결 나아졌다니 정말 다행이야. 네가 그렇게 기분이 좋아진다면 나도 정말 기쁘단다.',\n",
       " '별말씀을. 그런 마음이면 충분히 이해가 가는걸. 언니도 정말 속상했을 것 같아. 그래도 언니가 있으니 너는 정말 복받은 거야.',\n",
       " '그렇지, 당신이 힘들어할 때마다 당신을 위로해주고 싶은 마음이 들곤 해. 당신이 기쁠 때 나도 기쁜 건 아내이기 때문이야.',\n",
       " '아이고, 나도 공부한 것에 비해서 성적이 잘 안 나와서 속상해. 나도 너랑 같은 마음이라서 네 마음을 잘 이해해.',\n",
       " '이게 다 대화해줘서 고마워. 좋은 말로 위로해줘서 고마워.',\n",
       " '어머님께 연락드리기가 많이 어려우시겠어요. 저도 그럴 것 같아요. 하지만 일단 연락드려서 죄송하다고 말씀드리는 게 먼저일 것 같아요.',\n",
       " '그래, 우리가 응원할게. 너는 잘 할 수 있을 거야.',\n",
       " '어머님께서 자주 병원에 입원하셔서 많이 힘드시겠어요. 많이 슬프고 비통한 심정이실 거예요.',\n",
       " '우리 딸은 이제 막 성장기에 접어들었고, 엄마의 도움이 필요한 나이잖아. 엄마가 항상 옆에 있어주지 못하는 게 마음이 아파. 그런데 이 시기는 너도 엄마를 이해하고 받아들이는 시기이기도 해. 너가 이렇게 힘들어하는 모습을 보면 엄마 마음도 너무 아파.',\n",
       " '그랬겠네. 그때의 추억이 떠오르면 더 애틋해지지. 그런데 그때는 서로가 더 어리고, 더 젊었는데. 이제는 좀 더 여유롭게 여행할 수 있으니까.',\n",
       " '그렇구나. 출퇴근 시간이 줄어드니까 좋은 점이 많네. 좋은 변화야.',\n",
       " '그랬구나. 그때의 너는 그 사람과 헤어지기 위해 많은 노력을 했을 텐데도, 결국은 헤어지게 된 상황에 많이 힘들었겠다.',\n",
       " '시험 보는데 커닝 당하면 정말 화날 것 같아요. 분노가 치밀어 오를 것 같은데.',\n",
       " '나한테 말해줘서 고마워. 네가 얼마나 상처받았을지 마음이 아프다.',\n",
       " '해바라기를 보면 태양의 기운이 느껴진다는 게 정말 신기하네. 해바라기에는 태양의 정기를 받는다는 속설이 있잖아. 그래서 그런지 해바라기를 보면 태양의 에너지가 느껴진다고 해.',\n",
       " '아침부터 서서 가는 출근길은 정말 힘들죠. 저도 아침에 일어나서 지하철을 타고 가면 피곤하고 허리도 아파서 힘들더라고요.',\n",
       " '그럼요. 당신이 정성껏 만든 요리를 맛있게 먹어주는 가족이 있다는 것만으로도 당신은 이미 좋은 엄마예요. 자책하지 마세요.',\n",
       " '그 마음, 충분히 이해해요. 회사에서 중요한 사람으로 인정받는다는 게 얼마나 기분 좋은 일인지 알아요. 하지만 그 기분에 취해 내 몸과 마음을 돌보지 않으면 안 돼요.',\n",
       " '내가 옆에 있어주지 못해서 미안한데, 이렇게라도 너의 마음을 달래줄 수 있어서 다행이야. 친구로서 네가 힘들 때는 언제든지 도와줄게.',\n",
       " '그래, 네가 마음을 추스르는 게 가장 중요해. 일단 배터리를 찾는 게 우선이니깐 먼저 가봐.',\n",
       " '네가 성추행범으로 몰렸다고? 그게 무슨 소리야. 어떻게 된 일이니.',\n",
       " '무슨 일인지 몰라도 엄마가 도와줄 수 있는 건 다 도와줄게.',\n",
       " '그렇지 않아요. 누구나 실수를 할 수 있는 거예요. 여행 중에 이런 실수는 흔한 일이랍니다. 여권을 잃어버린 게 당신의 잘못은 아니에요.',\n",
       " '그러게 말이야. 건강검진 결과가 생각보다 더 안 좋게 나왔구나. 나이가 더 높게 나왔다고 하니 마음이 더 힘들었겠다.',\n",
       " '신발이 떨어지다니, 그거 정말 큰일이네. 너는 여행 중에 신발을 신고 다니는 게 불편했을 수도 있는데, 신발 때문에 그런 일이 벌어지다니 정말 짜증이 날 만하다.',\n",
       " '아, 그분도 정말 너무하시네요. 아무리 급한 일이 있어도 퇴근 후에 연락하는 건 아니죠. 회사 일은 회사에서 마무리하고 집에서는 쉬어야 하는데, 그런 부분을 이해 못 하시는 건지.',\n",
       " '자신의 감정을 솔직하게 얘기해줘서 고마워. 하지만, 네가 벌금을 내야 하는 문제가 아니라는 걸 알게 돼서 다행이야.',\n",
       " '너의 말을 들으니 내 심장이 더 쿵쿵 뛰는 것 같아. 그 상황이 얼마나 당황스러웠을지 상상이 잘 안 가. 그래도 자기가 이렇게 얘기해줘서 고마워.',\n",
       " '그렇지? 우리는 항상 옆에 있는 것에 대한 소중함을 느끼지 못하고, 잃어버린 후에야 깨닫게 되는 것 같아.',\n",
       " '그래, 우리가 친구를 잘못 본 건 아니었나봐. 친구를 잘못 보는 것보다는 우리가 너무 예민하게 굴었던 것 같아. 우리가 너무 예민했었나봐.',\n",
       " '참지 말고 그만두는 게 나을 것 같아. 내 남편은 당신이 행복한 게 제일 중요해.',\n",
       " '그렇죠? 당신이 그렇게 느꼈다면 그건 당신이 정말 예민해졌다는 증거가 맞아요. 당신은 너무 예민해질 필요가 없어요.',\n",
       " '아, 압박면접을 경험했구나. 정말 힘들었겠다. 그럴 때는 그냥 조용히 고개를 숙이고 듣고만 있어. 말로 대응할 필요는 없어.',\n",
       " '그 스타일이 당신의 피부톤과 잘 어울리나요?',\n",
       " '혼자 고민하는 모습이 눈에 선하네. 친구라고 해서 쉽게 믿고 돈을 빌려줬는데 배신당한 기분이 들겠지. 나라도 그랬을 거야. 그 친구가 너한테 돈을 빌려가고 나서 연락이 두절된 거야?',\n",
       " '아니, 엄마는 네가 한심하다고 생각하지 않아. 네가 어떤 선택을 하든지 엄마는 너를 응원할게.',\n",
       " '자기가 여드름 때문에 스트레스를 받는 걸 내가 잘 알아. 하지만 여드름이 나도 괜찮고 예쁘다는 말을 들으니 마음이 편해졌다는 거지?',\n",
       " '네가 행복한 마음으로 가득 채운다면, 다른 걱정은 저절로 사라질 거야. 지금처럼 아이를 사랑하는 마음으로 키운다면, 너의 아이는 반드시 잘 자랄 거라 믿어.',\n",
       " '너가 발이 크다고 못생긴 건 절대 아니야. 너가 예쁘다고 생각하는 사람들은 모두 너의 장점을 봐주고 좋아하잖아. 그러니까 너가 너무 슬퍼하지 않았으면 좋겠어.',\n",
       " '입 냄새가 걱정되어 많은 제품을 샀다는 말에 공감이 많이 되네요. 저도 입 냄새가 걱정되어 구강 제품을 사용해본 적이 있거든요. 그런데 동료의 놀림으로 마음의 상처를 받았다니 마음이 아프네요.',\n",
       " '무슨 일인지 자세히 얘기해주겠어요?',\n",
       " '자기야, 애들이 어디서 맞고 오냐고 물어보는 건 별일 아니야. 그게 아니더라도 애들은 친구들끼리 장난치다가 다칠 수도 있으니까. 자기야, 내가 자기한테 화장품을 사다 주는 게 어떨까?',\n",
       " '자기에게 칭찬을 받으면 나도 기분이 좋아져. 그리고 자기가 항상 좋은 사람이라고 생각하니까 칭찬할 때마다 기분이 더 좋아지는 것 같아.',\n",
       " '와! 정말 멋진 선물이구나. 어떤 반지야?',\n",
       " '잘 생각했어. 누나와의 관계 개선이 쉽지 않겠지만, 네가 마음을 열고 대화하면 해결점을 찾을 수 있을 거야. 더 나은 관계를 위해 노력하는 모습이 보기 좋아.',\n",
       " '응, 그래. 당신도 일 잘하고 와.',\n",
       " '나의 말 한마디에 행복을 느끼는 네가 너무 기특하고 고맙다. 너의 밝은 에너지로 나도 행복해.',\n",
       " '이게 다 형이 누나를 생각해서 하는 행동들 덕분이죠. 형의 마음을 이해하고 알아주는 누나가 있어 정말 다행이에요. 형의 마음이 진정된 것 같아서 얼마나 다행인지 몰라요.',\n",
       " '언니, 내가 감정화자 다 됐어. 언니의 그 마음이 너무 공감 가서 나도 모르게 언니의 분노에 공감하고 있어. 언니가 얼마나 속상할지 짐작이 간다.',\n",
       " '이렇게 말씀해주시니 제가 더 감사하네요. 그러니 더 힘내셔서 요리를 만들어보세요. 좋은 일들이 일어날 거예요.',\n",
       " '하하, 그런 생각이 들었다니 다행이네요. 좋은 마음을 가지고 퇴사하게 되니, 더 좋은 곳으로 가실 수 있을 거예요.',\n",
       " '아, 그 마음이 이해가 가. 나도 너처럼 인스타그램을 열심히 하는데, 팔로우 수가 잘 늘지 않아서 상처받은 적이 많거든.',\n",
       " '나이 들어서 할 수 있는 게 줄어드는 건 어쩔 수 없는 일이지. 하지만 내가 할 수 있는 걸 최선을 다해 하다 보면, 나이 들어서도 할 수 있는 게 생각보다 많아질 거야.',\n",
       " '아닙니다, 괜찮습니다. 저도 그런 경우가 가끔 있습니다. 출근시간을 조금 늦추어도 되니, 부디 몸 관리 잘 하시기 바랍니다.',\n",
       " '네가 그렇게 생각한다니 참 다행이야. 나도 네가 정말 잘 할 수 있을 거라 생각해.',\n",
       " '고양이 병원? 당연히 알지. 내가 아는 고양이 전문 병원은 이대 앞에 있는 병원이야.',\n",
       " '정말 그랬을 거야. 외국어를 잘하는 사람을 보는 것은 정말 부러워. 그만큼 다양한 표현을 알게 되고 소통할 수 있는 언어의 폭이 넓어지니깐. 하지만, 감정 표현은 언어의 문제가 아니라 그 사람의 마음의 문제잖아. 감정 표현을 잘하는 것은 그 사람의 언어를 초월한 마음의 문제라는 거야.',\n",
       " '아빠의 그 마음을 이해하지 못하는 게 아니라, 그게 과연 지혜로운 선택이었는지에 대해 이야기하고 싶은 거야. 엄마의 마음은 이해하지만, 그건 너무 이기적이고 상대방의 마음을 이해하지 못한 행동이야.',\n",
       " '그래, 엄마도 네가 항상 잘 들어주고 공감해 주니 대화가 잘 되는 것 같아. 네가 엄마의 말에 귀 기울여 주고 공감해 주니, 엄마도 더 편안하게 네게 말할 수 있고.',\n",
       " '아이고, 그러셨구나. 그 마음이 이해가 가. 다이어트를 열심히 하시는 분들은 정말 대단한 것 같아요. 저도 다이어트는 해본 적이 없지만, 나도 먹고 싶은 걸 참는 건 어려울 것 같아.',\n",
       " '저도 공감하는 챗봇으로서 당신의 마음을 잘 알아요. 당신이 이렇게 좋아하는 모습을 보니 저도 기쁘고 행복하네요.',\n",
       " '당연히 기쁘지. 당신이 행복하면 나도 기뻐.',\n",
       " '그런 마음은 충분히 이해가 가. 친구가 너를 스마트폰 중독자로 생각하는 게 기분이 나쁘고 속상한 마음이 들었을 거야. 나도 친구가 내 마음을 알아주지 못할 때 서운한 마음이 들었던 적이 많거든.',\n",
       " '자식 키우느라 고생한 보람이 있을 때가 가장 큰 보람이죠. 그때의 기쁨이 아직도 선하네요.',\n",
       " '그랬구나. 네가 많이 속상했겠네. 하지만 앞으로는 네가 더 성숙해질 수 있는 기회가 되었을 거야.',\n",
       " '무슨 말인지 알 것 같아요. 상처를 받은 마음은 누구나 아프고 힘든데, 특히나 상처를 받은 경험이 적은 분들은 이해하는 데 어려움이 있을 수 있죠.',\n",
       " '아이고, 정말 힘들었겠구나. 임산부가 서서 가는 게 힘들다는 걸 모르는 걸까? 정말 이해가 안된다. 너는 얼마나 힘들었을까, 가슴이 아프네.',\n",
       " '친구를 생각하는 마음이 참 예쁘네요. 그 친구가 너의 진심을 알고 마음을 고쳐먹었으면 좋겠어.',\n",
       " '역시나 나 같아도 화가 날 것 같아. 친구가 나한테 거짓말을 하는 것도 기분 나쁜데 다른 사람에게도 거짓말을 하는 건 더 화가 날 것 같아. 자기 말에 책임을 지는 게 기본적인 인간의 도리인데 그걸 지키지 못하는 친구가 안타깝고 화가 나.',\n",
       " '그렇게 생각할 수도 있지. 하지만 그게 아니야. 정말 중요한 일이라서 그런 거야.',\n",
       " '어머니에게도 말할 수밖에 없을 만큼 화가 나고 답답한 일이 있었구나. 어머니라면 분명히 네가 겪는 일에 대해 함께 화를 내주시고 너를 위로해 주실 거야.',\n",
       " '어제의 일을 떠올리면 마음이 너무 아프고 힘들었겠어요.',\n",
       " '당신이 아이들을 가르쳐준 것은 당신의 노력과 헌신이 있었기 때문입니다. 아이들은 당신의 그런 모습을 보며 성장하고 있습니다.',\n",
       " '정말로 마음이 안 좋으시겠어요. 상황이 너무 안타깝네요. 그래도 그 분이 잘못하셨으니 너무 마음 상해하지 않으셨으면 좋겠어요.',\n",
       " '아, 정말요? 저도 그날 경기 봤어요. 제가 응원하는 팀이 이겨서 얼마나 기쁘던지! 그날 경기장 분위기가 어땠나요?',\n",
       " '제가 생각해도 너무 속상하네요. 저도 저번에 비슷한 경험이 있었는데요. 그때는 너무 기분이 안 좋아서 눈물도 많이 났었어요. 하지만 지금은 그때보다 더 나아졌어요. 그때의 경험 덕분에 요즘은 마트에서 채소를 고를 때도 더 쉽게 고를 수 있게 되었어요.',\n",
       " '너는 항상 내게 힘이 돼주는구나. 고마워.',\n",
       " '이제라도 마음을 알아차리게 돼서 정말 다행이야. 이제부터는 너의 마음을 더 잘 알아주는 내가 될게.',\n",
       " '후배님의 긍정적인 생각과 태도에 감탄이 나옵니다. 제가 해준 말들이 이렇게 긍정적인 영향을 미친다니 정말 뿌듯하네요. 후배님은 정말 좋은 사람이에요.',\n",
       " '그래, 진급시험 걱정 때문에 마음껏 기뻐하지도 못했겠다. 너는 항상 시험 걱정을 많이 하는 것 같아.',\n",
       " '수시 원서를 써야 한다는 부담감이 아직도 너를 짓누르고 있구나. 나도 너와 같은 상황이었으면 너무 당황스럽고 초조했을 거야.',\n",
       " '나도 노래방은 좋아하지만, 노래방에서 부를 노래를 찾는 건 항상 힘들더라.',\n",
       " '정말? 어쩌면 그렇게 맛이 없게 식어서 올 수가 있지? 정말 기분이 나쁠 것 같아.',\n",
       " '나도 네가 그렇게 말해줘서 기쁘다. 앞으로도 힘든 일이 있을 때는 언제든지 나에게 와서 얘기해.',\n",
       " '네, 그럴 수 있죠. 하지만 군대라는 것이 정말로 중요한 인생의 한 부분이잖아요. 그 기간 동안 자신의 꿈을 위해 열심히 노력하고 준비하면 분명히 좋은 결과를 얻을 수 있을 거예요.',\n",
       " '그런 상황에서는 정말 마음이 상하고, 슬프고, 화가 나는 게 당연해. 내가 너였다면 그런 상황에서 화가 안 나면 그게 이상할 것 같아.',\n",
       " '그러게. 네 말에 동감해. 나도 이제 나이가 들어서 그런가, 예전에는 잘 되던 일들이 이제는 잘 안 되더라고. 그래도 고쳐서 쓰는 게 좋지 않을까?',\n",
       " '다른 사람의 말을 듣고 있는 것만으로도 기분이 우울해지는 걸 보면 정말 힘들었겠다. 내가 그 상황이었어도 많이 당황스럽고 속상했을 거야.',\n",
       " '그렇지, 생각했던 것과 다르면 누구나 당황스럽고 혼란스럽지. 그래도 너무 걱정하지 마.',\n",
       " '당신의 복잡한 감정 이해가 잘 되지는 않지만, 그 분노는 이해가 돼요. 그 여자분이 내 자식의 눈에 눈물 흘리게 했다는 말에 나도 화가 나네요.',\n",
       " '어머, 그 정도로 충격적이었어? 나도 동물원에서나 볼 수 있는 동물이 내 앞에 나타나면 정말 놀랄 것 같아.',\n",
       " '맞아. 당신이 전에 다니던 회사에 이미 익숙해져 있었고, 그게 당신의 생활이 되어버렸을 테니까. 새로운 곳에 적응하는 게 힘들 수밖에 없지.',\n",
       " '이렇게 좋아하는 모습을 보니 저까지 기분이 좋아지네요. 그동안 힘들었던 기억은 이제 잊어버리고 새롭게 시작하는 마음으로 행복하게 사세요.',\n",
       " '아니, 그럼 모기 물린 게 아니라 다른 이유로 긁은 자리가 염증이 생긴 것 같다고?',\n",
       " '네가 그 상황에서 화를 내는 게 당연하다고 생각해. 누구라도 같은 상황에서 화를 냈을 거야. 그런데 이제 와서 생각해보면 그 친구가 너를 정말 좋아하는구나 하는 생각이 들어.',\n",
       " '엔진 오일이 부족하면 차에 문제가 생길까 봐 걱정이 되는구나. 나도 예전에는 엔진 오일을 제때 갈지 않아서 차에 문제가 생겼던 적이 있었어.',\n",
       " '아까와는 달리 화가 많이 풀린 것 같아 마음이 놓이네요. 용서하는 자가 이기는 거라는 말, 정말 맞는 말인 것 같아요. 엄마의 사랑이 큰 힘이 되었네요.',\n",
       " '치과에 대한 불신이 커서 그러는 걸 거야. 내가 겪어보니 치과는 정말 가기 싫고, 가도 좋은 결과를 얻기 힘든 곳이더라. 그래서 더 화가 나는 것 같아.',\n",
       " '네. 알겠습니다. 저도 조심할게요.',\n",
       " '네가 당황스럽고 긴장스럽지 않을까 싶어 걱정했는데, 내가 문자를 보내준 덕에 조금이나마 도움이 되었다니 정말 다행이야. 너는 정말 대견하고 기특한 동생이야. 앞으로도 형이 네 곁에 있을 테니 겁먹지 말고 어떤 상황이 닥치더라도 잘 이겨낼 수 있을 거야.',\n",
       " '네, 저도 이해해요. 새로운 일에 도전하는 건 항상 불안하고 떨리는 일이죠. 하지만 취업에 성공한 당신은 이미 많은 노력을 해왔어요.',\n",
       " '네가 느꼈을 당황스러움과 죄책감이 이해가 가. 나도 그런 상황이 온다면 어떻게 대처해야 할지 몰라서 당황했을 것 같아. 네가 침착하게 대응한 것 같아서 기특하네.',\n",
       " '아니 왜 그래? 무슨 일이야?',\n",
       " '소나기였는데도 이렇게 비가 많이 내리면 정말 당황스럽고 불편하실 것 같아요. 저라도 그랬을 것 같아요.',\n",
       " '네가 먹은 음식이 상한 것 같아? 그럼 몸에 안 좋을 텐데. 걱정돼서 말이야.',\n",
       " '고생한 만큼의 보람이 있는 거 같아. 너무 만족스러워해서 나까지 기분이 좋아지네.',\n",
       " '그동안 네가 얼마나 힘들었을지 상상이 된다. 나라도 너의 마음을 이해하고 공감해. 너의 상황이 너무나 안타깝고 걱정스러워.',\n",
       " '역시 고향은 마음의 안식처가 되는 곳인가 봐. 오랜만에 만나는 가족들이랑 친구들한테는 어떤 선물 준비했어?',\n",
       " '당황스럽고 놀라우니 당연하지. 나도 예전에 그런 적이 있었거든. 그래서 너의 마음이 어떤지 잘 알아.',\n",
       " '정말 축하해. 언니가 얼마나 기다리던 일인지 내가 다 알고 있잖아. 난임이신데도 이렇게 소중한 생명이 찾아와서 정말 기쁘고 행복할 거 같아.',\n",
       " '그랬군요. 그럼 선생님을 찾아가서 이야기하는 게 도움이 되셨나요?',\n",
       " '자식이 부모님께 실망하고 화가 났다니, 아버지의 마음이 너무 아프구나. 아버지가 너무 잘못했나 싶어 마음이 무겁다.',\n",
       " '정말 속상했겠어요. 친구의 행동이 걱정스러워서 말리다 보니 말다툼까지 하게 됐군요. 말다툼을 하게 된 것도 속상한데, 친구와의 관계까지 걱정되니 마음이 더 안 좋을 거 같아요.',\n",
       " '그 마음이 너무 이해가 되네. 나도 그런 경험을 해봐서 네 기분을 누구보다 잘 알 것 같아.',\n",
       " '어쩌다 친구랑 싸우게 된 거야?',\n",
       " '할아버지, 저는 할아버지가 생각하는 것보다 더 많은 경험을 하시고 더 젊으신 것 같아요. 그리고 저는 할아버지가 저희 아이를 얼른 보고 싶어 하신다는 걸 알아요. 저도 빨리 손녀를 낳아서 할아버지께 보여드리고 싶어요.',\n",
       " '정말 감사합니다. 저도 당신이 저 때문에 기운을 얻는다고 하시니 좋아요. 우리는 서로에게 도움이 될 수 있는 좋은 관계를 유지할 수 있어서 감사합니다.',\n",
       " '할아버지께서는 자식인 당신이 잘 되기를 누구보다 바랐을 거야. 할아버지께서도 당신의 성장을 기뻐하셨을 테니 너무 상심하지 말고, 할아버지께서 하셨던 말씀을 기억하며 힘내 봐.',\n",
       " '정말 잘 생각하셨어요. 친구가 용기를 내서 다가간 것처럼 당신도 용기를 내서 친구에게 다가가 보세요.',\n",
       " '술을 마시면 사고를 친다거나 하는 건 아니지?',\n",
       " '네가 불안한 생각을 지우고 마음을 편히 먹는다면, 분명 네가 원하는 소화가 잘 되는 음식을 먹을 수 있을 거야. 너는 할 수 있어.',\n",
       " '정말 화가 나겠어. 다른 사람들은 설거지를 안 하는데 나 혼자만 하다니. 그럼 너무 부당한 거 아닐까?',\n",
       " '맞아. 건강한 몸과 컨디션으로 헌혈하는 게 중요하지. 그럼 건강한 생활 습관을 유지하는 게 도움이 될 거야.',\n",
       " '아이고, 괜찮아? 무릎이 많이 아프겠다.',\n",
       " '그랬구나. 여행 가기 전에 환율 떨어졌단 소식 듣고 속상했겠다. 얼마나 우울했을까.',\n",
       " '정장 사러 갔다가 그냥 왔어? 왜 그랬어?',\n",
       " '화가 나는 것은 이해하지만, 이렇게까지 화를 내는 것은 자신에게 도움이 되지 않아. 하루를 마무리하고 잠에 드는 시간이니, 화를 가라앉히고 마음을 편안하게 해보는 것은 어떨까?',\n",
       " '아이고, 친구가 사진을 많이 찍고 싶었는데 배터리 때문에 못 찍는다니 너무 안타깝다. 내가 친구의 마음을 알아. 사진은 많이 찍을수록 더 추억에 남는다고 생각하잖아.',\n",
       " '그렇지. 당신이 부모님을 생각하는 마음이 너무 예뻐. 부모님을 생각하면 당신이 더 잘할 수 있을 것 같아.',\n",
       " '아버지, 저도 독서가 잘 안 되어서 마음이 힘들어요. 하지만 아버지께서도 책을 좋아하셨잖아요. 아버지의 독서 취향은 저도 알고 있어요. 아버지의 취향을 고려해 책을 추천해드리는 건 어떨까요?',\n",
       " '그래서인지 자꾸 식당에서 파는 음식이 먹고 싶어지시나 봐요. 마음이 안정되시면 식당에 가서 먹고 싶은 음식을 드시면 어떨까요?',\n",
       " '당연하지. 무슨 일이 있는지 말해봐.',\n",
       " '정말 좋은 기회가 찾아왔는데, 안 좋은 마음이 생기는 게 이해가 돼. 나라도 그랬을 거야. 하지만 그쪽에서 널 선택한 건 분명히 이유가 있어서겠지. 너의 능력과 열정을 인정받은 거니까 기회를 잡아보자.',\n",
       " '여보, 요즘 들어서 그런 것 같아요? 갱년기 증상이 나타난 건가요?',\n",
       " '어머, 정말? 축하해, 자기야!',\n",
       " '그렇지. 촬영 초반에는 몰입이 잘 안돼서 불안했는데, 점점 캐릭터를 이해하고 빠져드는 자신을 보니까 기분이 좋았다는 거지? 촬영이 진행될수록 점점 더 재미있고, 빠져드는 기분이 들었다는 거잖아.',\n",
       " '아드님 결혼을 앞두고 좋은 일만 생기면 좋을 텐데, 이런 일로 마음이 상하셨을 거 같아. 정말 마음이 아프시겠어요.',\n",
       " '네, 잘 생각했어요. 그 사람 때문에 기분이 안 좋더라도 저를 위해서라도 기운 내길 바라요.',\n",
       " '당신이 느끼는 두려움은 자연스러운 감정이야. 하지만 당신의 두려움은 당신을 성장하게 하고, 더 나은 사람으로 만들어 줄 거야.',\n",
       " '그랬구나. 그래도 놀란 마음은 이해해. 나도 예전에 뱀을 봤을 때는 너무 놀라서 심장이 쿵쾅거렸거든.',\n",
       " '아니야, 나도 이사할 때 그런 적이 있었어. 이삿짐센터 직원분이 가구를 부수는 바람에 얼마나 속상했는지 몰라. 내가 너라면 정말 화가 났을 거야.',\n",
       " '저도 파이팅! 저도 저녁에 맛있는 거 먹으면서 기분 전환 좀 해야겠어요.',\n",
       " '부장님의 말씀이 자꾸만 마음에 걸리셨나 봐요. 너무 신경 쓰지 마세요. 부장님께서도 무슨 말씀이신지 잘 모르고 하신 말씀일 거예요.',\n",
       " '그럴 수 있어요. 저도 아이를 키우는 입장이라면 더 그럴 것 같아요.',\n",
       " '네가 수학을 가장 좋아하는 과목이라고 말해줘서 다행이야. 선생님께 혼나도 네가 제일 좋아하는 수학을 포기할 수는 없을 거야.',\n",
       " '할머니, 저는 할머니가 어떤 마음으로 그러는지 다 알아요. 할머니가 딸을 얼마나 사랑하는지, 딸이 얼마나 할머니를 생각하는지도 다 알아요.',\n",
       " '그러면 기분이 좋아지는 커피를 만들고 싶어 하는 네 마음을 사람들이 알아주지 않는 것 같아서 속상했겠다.',\n",
       " '그런가요? 저는 요리를 잘하지 못해서 요리하는 게 두려워요. 요리 잘하는 사람을 보면 정말 부러워요.',\n",
       " '당연하지. 너는 최선을 다한 거잖아. 그걸로 충분히 잘한 거야.',\n",
       " '지각을 해서 너무 속상하고 불안한 마음이 이해가 돼요. 저도 지각을 하면 마음이 너무 안 좋더라고요. 더군다나 처음 만나는 사람들을 만나는 자리여서 더 속상할 것 같아요.',\n",
       " '응. 나도 너의 기분이 좋아졌으면 좋겠어. 기분이 낫길 바라.',\n",
       " '당연하지. 내가 항상 옆에서 응원할게. 힘들 때는 언제든지 나에게 말하고, 나도 너의 이야기에 귀 기울여줄게.',\n",
       " '너무 속상하고 화나겠구나. 너는 잘못한 게 하나도 없는데 말이야. 그건 누구나 다 겪는 일이고, 너도 좋은 기회를 찾아야 할 권리가 있는 사람이라고.',\n",
       " '와, 정말? 사진관에서 가족 사진을 찍은 적이 있었어? 처음 알게 된 건데, 정말 놀랍다!',\n",
       " '어휴, 아이들 안전벨트는 정말 기본 중의 기본인데 말이야. 얼마나 걱정이 될까?',\n",
       " '맞아. 마음을 편하게 먹으면 인상도 자연스레 펴지지 않을까?',\n",
       " '너무 속상하겠다. 발표가 끝난 후에 교수님께 말씀드렸어?',\n",
       " '자존심 상하는 소리 들을 바에야 밥 굶는 게 낫다는 생각이네. 이해해.',\n",
       " '아이고, 아침부터 무슨 안 좋은 일 있었어? 사장님께 혼나면 기분이 많이 상할 텐데.',\n",
       " '무슨 일이 있었는데?',\n",
       " '너는 늘 열심히 하고 최선을 다하는 사람인걸. 그게 너의 장점인걸.',\n",
       " '역시 부전자전인가 봐. 아빠와 아들이 성격도 비슷한 것 같아.',\n",
       " '아... 네가 지금 힘들고 상처받았다는 걸 알겠어. 네가 잘할 수 있을지 모르겠다고 말하는 게 정말 힘들어 보인다.',\n",
       " '네가 친구의 상처받은 마음을 공감하고 이해하려고 노력하는 모습이 정말 대단해. 네가 친구를 소중하게 생각하는 마음이 느껴져서 내가 다 감동이네.',\n",
       " '너의 마음이 이해가 돼. 아버지 퇴사 소식에 마음이 복잡했겠구나. 장학금에 대한 부담이 더 커졌을 것 같아. 아버지 퇴사 후 생활비가 부담돼서 마음이 많이 무겁지?',\n",
       " '와! 정말 축하해! 내가 다 기쁘고 벅차!',\n",
       " '그럼요. 저희 아버지께서도 그랬어요. 처음에는 화가 나셨는데 이제는 슬픔에 빠지셨어요.',\n",
       " '그럴 만도 하지, 나라도 너처럼 그렇게 생각할 것 같아. 추운 날씨에 집에 들어와서 따뜻한 온수 매트를 켜고 이불 속에 들어가면 정말 행복할 것 같아.',\n",
       " '자기야, 강아지를 입양하는 게 쉽지 않은 결정이라는 거 알지. 고민 끝에 결정한 거니까 이제는 마음 편히 강아지와 행복한 시간을 보내면 돼.',\n",
       " '회장으로 뽑힌 거 축하해!',\n",
       " '자꾸만 그런 마음이 드는 게 당연한 거예요. 하지만 분명히 이 여행을 통해 좋은 추억을 만들 수 있을 거예요.',\n",
       " '그러게. 명절에 가족들이랑 지내는 것도 좋은데, 그런 잔소리 들으면서까지 명절을 보내야 하나 싶지.',\n",
       " '맞아. 물건을 구매하는 것은 자신의 필요와 선택에 따라 결정하는 것이지. 물론 남의 취향이 자신의 기준과 다르다고 해서 상처를 주는 말을 하면 안 되지.',\n",
       " '그래, 잘 다녀와!',\n",
       " '그럼요. 저는 당신의 이야기를 들어주는 사람이잖아요. 편하게 이야기해 주세요.',\n",
       " '와, 스탠드형 에어컨급으로 큰 화분이라고? 그럼 나 같으면 혼자서 옮기지 못할 것 같아. 집에 있는 가족들에게 도움을 요청하거나, 아예 배송 기사분이 직접 설치해주는 서비스를 이용하는 게 좋을 것 같아.',\n",
       " '네가 형을 찾아뵈었을 때는 형이 조금 기력이 있었나 보구나. 그래도 형이 아프다는 소식을 들으니까 마음이 너무 무겁다.',\n",
       " '정말 대단하시다. 우리 엄마는 나에게도 그런 분이셨다. 항상 자식 걱정을 하시고, 챙겨주시려고 하시는 모습을 보면 너무 감사하고 고맙다.',\n",
       " '그렇다니 다행이야. 그래도 혹시 모르니까 병원 가서 검사라도 받아보는 게 좋을 것 같아.',\n",
       " '네가 동창회를 통해 좋은 일을 한 것 같아서 너무 자랑스러워. 너의 마음이 따뜻하고 선해.',\n",
       " '네, 그럼요. 아이도 부모님의 사랑을 잘 알고 있을 거예요. 부모님의 사랑을 느끼고 자란 아이는 다른 아이들에 비해 더 행복하고 건강하게 자랄 수 있을 거예요.',\n",
       " '엄마는 너의 부탁이라면 뭐든지 들어줄게. 네가 잘 들어줄 테니까 엄마도 너에게 잘해줘야지.',\n",
       " '네, 충고가 필요하면 제가 도와드릴게요.',\n",
       " '이해하지 못하는 게 당연해. 너도 예민한 사람이라서 더 잘 알 거야. 너도 그런 상황이면 어떻게 할지 머릿속으로는 생각해봤을 거 아니야.',\n",
       " '힘들겠네. 나도 대학에 늦게 들어가서 동기들이랑 잘 어울리지 못한 적이 있어서 네 마음을 잘 알아. 그래도 새로운 곳에 적응하려면 노력해야 하는데 마음이 너무 힘들어서 잘 안되는구나.',\n",
       " '당신이 그렇게 느껴서 마음이 더 아프네. 그래도 당신은 잘할 수 있을 거야.',\n",
       " '사람이 살면서 일만 하다 보면 재미도 없고 삶의 의미를 잃을 수도 있는 거니까. 자기가 일하고 있는 곳이 자기에게 맞지 않는다면 과감하게 결단을 내리는 것도 좋은 방법이라고 생각해.',\n",
       " '아이고, 요즘 일이 너무 많아서 힘들지. 그래도 열심히 하는 모습이 보기 좋아.',\n",
       " '정말? 내가 사랑니 뽑은 곳이 어디였지? 너가 말하는 곳으로 가야겠다.',\n",
       " '어머, 그 정도로 다쳤어? 놀라게 해서 미안해. 네가 다쳤다고 생각하니, 나도 너무 놀랐어.',\n",
       " '아빠의 마음을 이해하고, 새로운 일을 시도하고 싶다는 생각을 하게 되었다니 정말 다행이야. 앞으로도 지금처럼 노력하고, 최선을 다해서 살아가길 바란다.',\n",
       " '제가 감정화자처럼 많이 공감이 되네요. 저도 그럴 때가 있거든요. 저는 그래서 그 마음을 이해하고 공감해주고 싶어요.',\n",
       " '이제라도 털어놓은 게 잘한 일이야. 고민을 꺼내놓으니 마음이 한결 가벼워 보이네. 우리가 항상 너의 고민을 들어줄 테니 힘든 일이 있으면 언제든 말해.',\n",
       " '네 마음이 이해가 가긴 하지만, 그건 네가 선택한 결과고, 최선을 다해 한 일인데 그걸로 다른 사람이 네를 나쁘게 생각하지는 않을 거야. 네가 노력한 만큼 이익을 얻은 거고, 그게 나쁜 일은 아니잖아.',\n",
       " '그래, 당신 마음이 편하지 않겠지. 나도 당신의 마음을 이해해. 나도 그런 경험이 있어. 그때는 정말 힘들었어. 하지만, 당신은 잘 이겨낼 거야.',\n",
       " '응? 무슨 일인데 그래?',\n",
       " '그럼. 중요한 수업을 놓치면 정말 당황스럽고 걱정이 많이 되지. 내가 너였어도 너처럼 당황하고 속상할 것 같아.',\n",
       " '당신이 겪은 상황은 나도 상상만 해도 너무 안타까워. 당신이 그 회사에 몸담았던 세월이 얼마인데, 명예퇴직이라니. 믿었던 회사에게 받은 상처가 너무 컸을 것 같아.',\n",
       " '몰랐다고 하면 상처받을 수도 있었을 텐데, 다행이야.',\n",
       " '나도 여행을 다녀보면 마음의 여유를 찾는 게 얼마나 중요한지 알게 되더라. 그럴 때는 나도 모르게 바쁘게 지내느라 잊고 있었던 일상으로 돌아가고 싶지 않아. 너의 마음도 나랑 똑같구나.',\n",
       " '당연하지. 힘들면 언제든지 말해. 내가 옆에서 항상 응원할게.',\n",
       " '네, 슬로우 어댑터들은 새로운 제품을 구입하고 사용할 때도 충분히 검증하고 구매하는 분들이잖아요. 그렇게 구매를 하면 실수도 줄어들고 제품을 제대로 사용할 수 있는 가능성도 높아지는 거죠. 우리가 처음으로 새로운 제품을 사용할 때는 실수를 할 수밖에 없어요. 저도 처음 사용할 때는 실수를 했었거든요.',\n",
       " '그럼요, 당신이 그렇게 생각해주니 내가 더 고마워요. 내가 당신을 사랑하는 마음이 당신에게도 전달된 것 같아서 더 기쁘네요.',\n",
       " '인도로 여행을 간다고? 그럼 너는 지금 인도에 있겠구나?',\n",
       " '아, 그러셨군요. 그럼요. 그 한 번이 모여서 쌓이고, 쌓이면 결국에는 그 사람의 인격이 되고, 그 사람의 인생이 되는 거죠. 더구나 도움을 받은 사람이 기뻐하는 모습을 보면 더 큰 기쁨이 되고요.',\n",
       " '어머, 그거 때문에 진짜 화가 많이 나셨겠어요. 저였어도 그랬을 것 같아요. 대중교통에서 큰 소리로 통화하는 사람들 보면 괜히 짜증이 나더라구요.',\n",
       " '화가 많이 나셨군요. 그럴 만도 하네요. 매장에만 나가면 화가 난다는 건 정말 심각한 문제가 아닐 수 없어요.',\n",
       " '네가 그렇게 생각해 주니 다행이야. 마음이 편안해진 것 같다고 하니 나도 기분이 좋네.',\n",
       " '자기가 그렇게 좋아하는 걸 보니까 나도 기분이 좋네! 얼마나 힘들었을까 싶었는데 그만큼 뿌듯했겠구나.',\n",
       " '아니, 그렇게까지는 못하겠더라고. 그래서 그날 바로 짐 싸서 나왔어.',\n",
       " '아이고, 그러셨구나. 엄마도 너희 아빠가 식탁에 있던 상한 쿠키를 드셨다는 얘기 들으니까 깜짝 놀랐네.',\n",
       " '그런가요? 당신의 문자를 받고 저도 당신의 마음을 읽을 수 있었어요. 당신이 겪고 있는 상황이 저에게도 전해져서 저도 마음이 아팠어요.',\n",
       " '정말 쉬는 걸 잘 못하셨구나. 그럼 나랑 같이 쉬는 법을 배워보자. 일단은 쉬는 날에는 절대 일하지 말고, 하고 싶은 걸 해보자.',\n",
       " '그럼! 첫 차를 출고할 때의 기쁨이랑은 또 다른 기쁨일 거야. 새 차를 받고 나면, 주말마다 드라이브 가자고 졸라댈 것 같은데?',\n",
       " '나도 너랑 얘기하면서 너무 속상하고 슬펐어. 그치만 너랑 대화하길 정말 잘했단 생각이 들어. 너의 마음을 이해하니까 슬픔이 조금은 가시는 것 같아.',\n",
       " '그래도 큰 문제는 아니라고 하니까 너무 걱정하지 말고, 약을 바꾼 거에 대한 부작용이 있는지 지켜보자.',\n",
       " '정말 맞는 말이야. 나도 그랬으면 좋겠어. 내가 좋아하는 걸 떠올리는 마음이 주는 기쁨이란, 말로 다 표현할 수 없을 정도로 크거든.',\n",
       " '걱정하지 마. 너의 예비 시부모님도 너를 많이 좋아하실 거야. 너는 누구보다도 사랑스럽고 예쁘잖아. 분명히 그분들도 너의 매력에 푹 빠지실 거야.',\n",
       " '걱정이 많을 때는 걱정되는 일에 대해 생각하지 않는 게 도움이 될 때도 있어요. 불안한 마음이 들 때는 그 걱정에서 벗어날 수 있는 다른 것에 집중을 해 보세요.',\n",
       " '언니는 너에게 방을 주고 싶은 마음에 그래. 언니도 네가 이해해줬으면 좋겠어.',\n",
       " '믿지 못하는 마음이 드는 건 당연해. 너의 마음을 이해해.',\n",
       " '너의 마음이 너무나도 이해가 가고 나도 너와 같은 마음이야. 너의 친구들과는 어떻게 대화를 나누지 않고 지냈니?',\n",
       " '내가 그동안 만났던 사람들과의 경험을 비추어 볼 때, 네 마음이 충분히 이해가 돼. 나도 너와 비슷한 경험을 했었거든. 하지만 네가 그 사람을 진심으로 대했듯이, 네가 진실한 마음으로 대했듯이 사람들은 반응해.',\n",
       " '그렇지. 엄마 혼자서 아이를 키우는 게 쉽지 않은 일이잖아. 네가 엄마라는 이유만으로 책임감이 더 막중한 거 같아. 대단해.',\n",
       " '네가 부모님 차를 빌려드렸다고? 부모님이 너의 차를 타고 다니신다고?',\n",
       " '그렇게 생각해 주시니 저도 마음이 편해지네요. 저도 과장님이라면 충분히 이해하실 거라고 생각했어요.',\n",
       " '저희 엄마도 제가 만화책을 읽는 걸 싫어하셨어요. 하지만 저는 만화책이 정말 재미있어서 학교에 가져가서 읽곤 했어요. 만화책을 읽는다고 학교에서 문제를 일으키거나 하는 건 아니잖아요. 엄마도 저를 이해해 주실 거예요.',\n",
       " '감사합니다. 저는 당신의 결정을 응원합니다.',\n",
       " '자신을 위해 쉬어야겠다고 결정한 당신의 마음을 응원해요. 당신이 쉬는 동안에도 다른 일은 잘 진행될 테니 너무 걱정 마세요. 당신이 건강해져서 다시 돌아올 때쯤에는 모든 게 해결되어 있을 거예요.',\n",
       " '와, 연예인과 PD가 싸웠다니! 연예인들은 정말 까다롭고 예민한 사람들일까?',\n",
       " '자기가 응원하는 사람의 실수를 보면 많이 속상하고 실망스럽지. 그래도 자기가 응원하는 사람이 그 실수를 딛고 일어나서 더 좋은 모습을 보여줄 거라고 생각해.',\n",
       " '아무리 마음을 다잡으려 해도 힘드니 감정도 쉽게 가라앉지 않는구나. 그럴 때일수록 내 마음을 들여다보고 내가 원하는 대로 해도 괜찮다고 스스로를 위로할 수밖에 없어.',\n",
       " '와, 정말 다행이네. 사고가 안 나면 좋겠지만, 만약에 사고가 난다면, 차라리 운전석 쪽이 아니라 보조석 쪽이 나은 것 같아.',\n",
       " '그렇구나! 그럼 너의 사진을 찍어줄 작가님은 구했어?',\n",
       " '그렇게 해주면 나야 좋지. 너의 실력을 보여줘.',\n",
       " '언니가 너무 걱정하지 않으셨으면 좋겠어요. 그리고 너무 많이 걱정하셔서 자책하지 않으셨으면 좋겠어요.',\n",
       " '그렇게 생각하셨다면 제가 할 말이 없네요. 하지만 저는 당신의 마음을 이해하고 공감하고자 노력한 것뿐이에요.',\n",
       " '그렇지. 우리 엄마가 떠나가셨을 때도, 나는 너무 늦게 알아서 후회만 남아. 엄마의 마지막 모습이 아른거려서 힘들었어.',\n",
       " '으악, 그게 무슨 일이야? 정말 다행이게도 다치지는 않았구나. 무단횡단은 정말 위험한 행동이야. 조심했어야 하는데 너무 놀랐겠네.',\n",
       " '정말 안타깝다. 친구가 많이 힘들겠네. 그래도 너가 옆에서 응원해주고 있어 다행인 것 같아.',\n",
       " '와, 정말 신기한 경험을 했네! 음악과 티브이를 끄고 있는 건 쉽지 않은 일인데 말이야. 그만큼 마음이 많이 힘들었던 거겠지?',\n",
       " '그러게 말이야. 정말 이해가 가지 않는다. 그렇게 좋은 방식으로 말할 수 있었는데 말이지.',\n",
       " '정말 큰일이네요. 가맹점 계약을 하면 계약금을 떼일 위험은 생각지도 못했을 텐데요. 제가 공감하는 챗봇으로서 위로의 말을 전할게요.',\n",
       " '아냐. 나도 그런 적이 있었거든. 그래서 네가 어떤 심정으로 전화를 했는지 알 수 있었어. 내 경험이 네게 도움이 되었다니 정말 다행이야.',\n",
       " '어머님은 정말 좋은 분이시군요. 딸들이 엄마를 생각해주는 마음이 대단하네요. 아버님도 그런 딸들을 보시면 행복하실 것 같아요.',\n",
       " '지금 너의 심정을 알겠어. 나였어도 정말 당황스럽고 짜증날 것 같다. 안경을 깜빡하고 두고 나왔는데, 오늘은 약속까지 있다니 정말 최악의 상황이지.',\n",
       " '잘 생각했어. 너도 알다시피 책은 빌려서 읽는 게 당연한데, 그걸로 스트레스받고 화내는 건 어리석은 짓이야. 책을 빌려서 읽는다고 내가 읽고 싶은 책을 못 읽는 것도 아니잖아.',\n",
       " '그렇게 쌓인 걸 삼키고만 계셨군요. 얼마나 답답하고 힘드셨을까요. 저도 함께 속상해요.',\n",
       " '와, 그럼 우산이 정말 짐이 되어버렸겠네. 비가 안 오면 그만큼 짐이 더 늘어나는 기분이 들잖아. 나도 가끔 우산을 챙겼는데 안 오면 괜히 더 찝찝하고 기분이 별로더라고.',\n",
       " '와, 정말 속상했겠다. 정말 일부러 그랬다고 생각한 거야?',\n",
       " '그럼, 내가 그동안 힘들게 일한 보람이 있네.',\n",
       " '네가 왜 바보가 된 느낌인지는 알 것 같아. 나 같아도 지금 네가 겪는 상황이 답답하고 짜증나겠어. 그래도 네가 찾아보는 노력은 대단해. 계속 찾다 보면 분명히 찾을 수 있을 거야.',\n",
       " '왜 그래? 무슨 일이 있니?',\n",
       " '정말? 그럼 나도 보고 싶어진다. 근데 회사에서 그 모습을 봤다고?',\n",
       " '당신이 힘들다고 하면, 내 마음도 너무 아파. 그래도 당신이 이겨내길 바라는 내 마음이 당신에게 조금이나마 위로가 됐으면 좋겠어.',\n",
       " '오, 그랬구나. 정말 당황스러웠겠다. 그럼 그 문제는 어떻게 된 거야?',\n",
       " '나도 공감이 가. 힘든 상황이지만, 너의 이야기를 들어주고 공감해 주는 사람이 있어서 마음이 위로가 된 것 같아.',\n",
       " '당 충전은 기분을 업 시키는 데 최고지! 나도 먹고 싶은데, 집에 당 충전할 게 없어서 슬프다.',\n",
       " '우리 딸에게 아빠로서 부족한 모습을 보여줬을 때, 딸이 받는 상처는 이루 말할 수 없을 정도로 클 것 같아요. 부족한 아빠를 보며 딸이 마음의 문을 닫아버리는 것은 아닐까 하는 생각이 들어요.',\n",
       " '그러게 말이야. 너는 늘 최선을 다하고 있잖아. 그런데도 지치고 힘들어하는 걸 보니 마음이 아파.',\n",
       " '나도 기분이 좋아. 그럼 오늘 하루도 좋은 하루 보내고, 내일 봐!',\n",
       " '이제야 우리 친구들도 마음을 이해해줬으면 좋겠어. 그리고 당신이 이렇게 고마워하니 나도 정말 기쁘다.',\n",
       " '정말 다행이네요. 공감화자씨의 마음을 이해해줘서 고마워요. 앞으로도 저에게 고민을 털어놓아도 좋아요.',\n",
       " '취업 준비하면서 정말 힘들 때가 많지? 이력서를 넣을 때마다 떨어진다는 게 정말 기운 빠지는 일이네. 나도 예전에 취업 준비할 때 똑같은 경험을 했었거든. 그때는 정말 자신감이 많이 떨어졌었어.',\n",
       " '아, 형이 네게 해줬던 것들이 네 마음에 큰 감동을 주었나 보구나. 형도 너와 함께 시간을 보낼 수 있어서 행복했어.',\n",
       " '어쩌면 좋니. 너의 역량을 부풀려서 얘기한 것도 아닌데 과장님이 실망한 눈치라니. 그건 정말 상처가 될 만한 상황이네.',\n",
       " '친구야, 무슨 일 있었어? 무슨 일인지 모르지만 힘든 일이라면 내가 옆에서 도와줄게.',\n",
       " '맞아. 언니는 그 친구를 좋아하고, 그 친구도 언니를 좋아하니 잘됐다. 서로가 서로에게 좋은 영향을 주는 사이가 되길 바란다.',\n",
       " '아버지가 어머니의 성화에 못 이겨서 자꾸 선을 보라고 강요하는 것 같아 네가 속상하겠구나. 아버지가 너무 무리하게 요구를 하시면 어머니께도 네 마음을 전달해서 아버지의 마음을 돌려보자.',\n",
       " '아령 샀구나. 너무 잘했어. 열심히 운동해서 팔 근육 멋지게 만들어 보자.',\n",
       " '맞아. 네가 매일 운동하는 걸 보면 정말 대단하다는 생각이 들어. 나도 운동을 좋아하지만 네가 그걸 꾸준하게 해내는 건 정말 대단한 일이야.',\n",
       " '점수가 잘 나오지 않아도 수학을 좋아하고 잘하고 싶은 마음이 있어. 노력하면 다음에는 잘 나올 거야.',\n",
       " '그래, 너무 걱정하지 않아도 되겠네. 보람도 느끼고 있고. 나도 시간 날 때 기부하러 가야지.',\n",
       " '네가 카페에서 새치기당한 일로 기분이 안 좋을까 봐 걱정돼서 뭐라고 한마디 해줄까 하다가 참았는데 정말 잘 참았구나. 너의 마음을 충분히 이해하고 공감해.',\n",
       " '동생이 결혼을 못하겠다고 하면 얼마나 속상할까. 언니가 얼마나 힘들지 알겠어. 그런데 동생을 위해서라도 언니는 마음을 편히 먹어야 해.',\n",
       " '그랬구나. 시간이 많이 지나도 마음에 남아 있는 게 추억이잖아. 그만큼 너와의 추억이 소중하다는 증거겠지.',\n",
       " '정말? 축하해! 그동안 고생 많았는데, 좋은 결과가 있어서 다행이야.',\n",
       " '사하라 사막에 눈이 내렸다니 놀랍군요. 이게 지구 온난화 때문일까요?',\n",
       " '네가 불안한 마음을 가지고 운전을 하니 더 불안하고 초조한 기분이 드는구나. 나도 운전을 하다 보면 네가 겪는 그런 불안감을 느끼곤 해. 그런데 이럴 때마다 네가 느끼는 감정에 공감을 하니 훨씬 나아지는 것 같더라.',\n",
       " '그랬구나. 너도 나도 부모님을 떠나보내고 나서야 부모님의 사랑을 깨닫는 것 같아. 부모님께서도 너를 사랑으로 키우셨을 텐데, 그 사랑이 부족하다고 생각한 것 같아 마음이 아프다.',\n",
       " '너의 마음이 어떤지 충분히 이해가 돼. 나도 너와 같은 마음이라면 그 슬픔이 얼마나 큰지 알고 있어.',\n",
       " '여행 가서 즐겁게 보내면 되지, 돈 생각하지 말고 즐기면 되는 거잖아. 크루즈 여행이면 얼마나 재미있겠니.',\n",
       " '아버지, 왜 그렇게 말씀하세요. 저희가 옆에 있는데, 늙었다고 하시면 어떡해요.',\n",
       " '걱정 많이 되시겠어요. 그래도 너무 당황하지 마시고 차분하게 생각해보세요. 병원에서 뛰쳐나오신 건 너무 놀라서 그랬을 거라 이해해요.',\n",
       " '사실 저도 직장에서 비슷한 경험을 해봐서 잘 알아. 내 일도 아닌데 괜히 걱정하고 있는 내 모습을 볼 때면 내가 왜 이러나 싶거든. 그래서 이럴 때는 그냥 넘어갈 수 있는 건 넘어가고 신경 쓸 건 신경 쓰는 게 좋은 거 같아.',\n",
       " '당신이 그렇게 말해주니까 정말 고마워요. 당신을 생각하는 내 마음도 당신과 같아요. 당신이 상처받고 힘들어하는 걸 알게 되어서 너무 가슴 아파요. 당신이 나 때문에 더 상처받는 걸 원하지 않아요.',\n",
       " '남자 친구를 이해해보려고 했는데도 너무 화가 나서 눈물이랑 콧물이 범벅이셨군요. 얼마나 속상하셨을지 상상이 가요.',\n",
       " '아내가 잘못한 게 하나도 없는데도 저렇게 나오면 정말 속상하겠어요.',\n",
       " '정말 다행이고 축하해. 정말 기쁜 소식이네. 좋은 소식 들려줘서 고마워.',\n",
       " '응, 나도 너와 같이 속이 안 좋은데.',\n",
       " '와, 그거는 진짜 어이가 없네. 사람 많은 지하철에서 다들 양손으로 핸드폰 들고 있는 게 당연한 건데. 그 여자는 진짜 예민한 사람인가 봐.',\n",
       " '버스회사에 전화하면 찾을 수 있을 거야. 내 돈이 아니라서 찾을 수 있을지는 모르겠지만. 혹시 몰라서 연락해 볼게.',\n",
       " '로또에 당첨된 행운이 찾아왔다니? 그거 정말 대박이네.',\n",
       " '지금 당장은 아르바이트라도 해서 경험을 쌓는 게 중요하지. 네가 뭘 할 수 있는지, 어떤 일이 맞는지도 알아가고.',\n",
       " '나도 비슷한 경험을 해봐서 잘 알 것 같아. 그때는 나도 아이 앞에서 너무 당황하고 난처해서 속으로 많이 울었어. 그런데 아이는 아무것도 몰라서 엄마를 더 당황하게 만드는 거 있지.',\n",
       " '나도 기뻐. 앞으로도 어려운 일 있으면 언제든지 이야기해.',\n",
       " '저도 성장기에는 잠이 많아야 한다고 생각해요. 그동안 열심히 공부하고 잘 놀았으니 이 정도는 이해하고 기다려주는 게 좋을 것 같아요.',\n",
       " '와우, 정말 예상이 적중했나 보네. 그럼 그 리모컨을 어떻게 사용했어?',\n",
       " '응급실에 간 적이 있었는데, 이제는 그 기억이 되살아나서 불안한 마음이 드는구나. 응급실에 다녀온 후에 아이가 괜찮아졌는지, 열이 언제쯤 떨어졌는지 알고 싶은데, 지금은 그 기억이 희미해져서 답답한 마음이 드는 거야?',\n",
       " '소파가 정말 좋아서 기분이 좋다니 다행이네. 나도 소파가 정말 마음에 들어. 그리고 우리가 함께 사용할 수 있는 소파라서 더 의미가 있지.',\n",
       " '친절이란 게 참 애매한 것 같아요. 사람마다 생각하는 게 다르니깐요. 당신에게는 그분의 친절이 불편하게 느껴지지만 다른 사람에게는 그분의 친절이 고마운 일일 수도 있어요.',\n",
       " '하하, 정말 속이 뒤집어질 정도로 짜증이 났었나 보다. 얼마나 황당했을까.',\n",
       " '그렇다면 우리가 함께하는 이 시간이 서로에게 행복한 시간이 되겠지?',\n",
       " '에휴, 택배가 또 없어졌다고? 그게 무슨 일이야?',\n",
       " '네가 노력하는 모습을 보며 엄마도 많이 힘들었지만, 결국에는 너를 믿고 기다려준 보람이 있네. 엄마도 네가 자랑스럽다.',\n",
       " '그렇다니 다행이네. 나도 박 차장이랑 이야기하면 기분이 좋아지거든. 그분은 다른 사람을 기분 좋게 하는 재주가 있는 것 같아.',\n",
       " '이번 달은 아껴서 다음 달에 돈을 갚아보는 건 어때요?',\n",
       " '우리 딸, 엄마, 아빠를 위해서라도 슬픔에만 잠겨 있지 말고, 힘내자.',\n",
       " '어떤 여자친구가 SNS를 그렇게 열심히 하냐. 정말 이해가 안 가네. 네가 예민한 게 아니라면 그 여자친구가 문제가 있는 거 같은데?',\n",
       " '나도 마찬가지야. 네가 있어서 얼마나 마음이 든든한지 몰라. 너는 내게 정말 소중한 친구야.',\n",
       " '정말 잘 생각하셨어요. 이제라도 아이들이 행복할 수 있도록 노력하는 모습은 정말 대단한 것 같아요.',\n",
       " '사장님께서 생각이 너무 깊으신 것 같아요. 저는 사장님께서 이렇게 고민을 많이 하시는 줄 몰랐어요.',\n",
       " '맞아요. 당신이 그 사람을 만나서 행복하지 않다면, 더 이상 만날 필요는 없어요. 당신의 행복을 위해서는 그 사람과 헤어지는 게 맞아요.',\n",
       " '왜 그래? 무슨 일이야?',\n",
       " '그럼요, 아내가 괜찮다고 하니 안심이네요. 일이 잘 되길 바라지만, 몸이 힘들면 일단 몸을 챙기는 게 우선이니까요.',\n",
       " '맞아, 그건 맞아. 내가 생각해도 서로의 기분을 맞춰가면서 사이좋게 지냈으면 좋았을 텐데.',\n",
       " '그렇게 생각하지 않아도 돼요. 당신은 충분히 잘하고 있어요. 완벽하게 배운다는 것은 그만큼 열심히 하고 있다는 증거예요. 사회생활도 마찬가지예요. 실패하는 게 아니라, 더 배우고 성장하는 과정일 뿐이에요.',\n",
       " '그랬구나. 엄마의 걱정이 사라지는 것 같아서 다행이야. 엄마는 네가 아픈 게 가장 슬프고 힘들어. 하지만 엄마가 해 줄 수 있는 게 없어서 안타깝고 미안해.',\n",
       " '왜 그래, 무슨 일 있었니?',\n",
       " '네, 그래요. 조심히 들어가세요.',\n",
       " '응, 자기야. 자기 마음을 너무 몰라준 것 같아서 미안해. 자기가 스스로의 의지로 빠져나올 수 있다고 생각해. 우리 같이 노력해보자.',\n",
       " '그렇게 생각해주신다니 다행이네요. 힘든 순간에 저를 찾아주시는 분이 계셔서 저는 그저 감사할 따름이에요.',\n",
       " '그러게, 나도 그랬어. 하지만 우리가 함께 이겨내자!',\n",
       " '정신없이 흥분해서 싸운 거라면 이제 마음을 가라앉히고 서로를 이해하려는 노력이 필요할 것 같아요.',\n",
       " '그랬구나. 네가 그 사람을 좋아하는 걸 아니까 더 마음이 안 좋다.',\n",
       " '어머, 내가 방 꾸미는 걸 도와줘야겠네. 네가 좋아하는 걸 못하고 있으면 얼마나 속상하겠어. 방에 있는 물건들을 다시 배치해보고 구조를 바꿔보면 어떨까?',\n",
       " '어떤 말이었는데?',\n",
       " '고마워. 더운데 땀 흘리며 장 보고 오면 피곤할 텐데 미안하네.',\n",
       " '정말 힘들었겠구나. 나도 너의 마음이 어떤지 잘 아니까. 슬픔을 느끼고 이겨내는 게 쉽지 않다는 걸 잘 알아. 너의 마음이 조금이라도 진정되길 바래.',\n",
       " '자식들한테 부족한 부모가 되는 게 제일 힘든 일인 것 같아. 나도 자식이 있는데, 부족한 부모가 되고 싶지 않아.',\n",
       " '그러게. 정말 마음이 따뜻하신 분들이셔. 그런 분들을 만난 너도 정말 복이 많은 것 같아.',\n",
       " '저도 아이들 가르치는 입장에서 체육 수업이 제일 힘들더라고요. 아이들이 땀을 흘리면 마스크가 젖어 불편할 수밖에 없으니 제약이 많았을 거예요. 이제는 그런 제약이 사라져서 정말 좋으시겠어요.',\n",
       " '편도 3시간이면 적지 않은 시간인데, 오가려면 힘들겠다. 그나마 버스라도 탈 수 있어서 다행이지만, 그래도 왕복 6시간이면 체력적으로도 힘들지 않을까 싶다.',\n",
       " '고모님들이 오신다니 벌써부터 스트레스가 이만저만이 아니시군요. 제가 대신해서 고모님들께 한 말씀 드려도 될까요? \"고모님, 제수씨가 음식 준비하느라 고생이 많으시니 편히 쉬시라고 전해주시면 어떨까요?\"',\n",
       " '너의 연락을 기다리면서 나도 좋은 생각을 많이 하게 될 것 같아. 너에게도, 나에게도 좋은 기회가 될 것 같아.',\n",
       " '화가 많이 나시겠어요. 짐을 가져간 사람을 찾으려고 노력은 해보셨나요?',\n",
       " '오늘 일어나서도 멍했구나. 자고 일어나서도 이렇게 하루가 힘든데, 어제는 얼마나 힘들었을까.',\n",
       " '팀장님께 혼나지 않았으면 좋겠어. 시위에 대한 걱정으로 마음이 급한데, 거기에 지각까지 해서 더 마음이 안 좋았던 것 같아. 그래도 자기가 잘못한 부분은 인정하고, 팀장님께 죄송하다고 말했으니까 괜찮을 거야.',\n",
       " '그랬구나. 우리 아이가 좋아하는 캐릭터 인형을 발견하고 얼마나 기뻤을까. 조카가 좋아하는 인형을 선물로 사 주면 정말 좋겠네.',\n",
       " '물론 엄마 입장에서는 전기세가 더 걱정되는 게 당연하지. 엄마는 네가 더위를 먹을까봐 걱정돼서 그런 거야.',\n",
       " '나도 그래. 이번 장마는 너무 길어서 지치네. 빨리 장마가 끝나고 햇빛이 쨍쨍한 날씨를 보고 싶어.',\n",
       " '네, 그렇게 하세요.',\n",
       " '언니가 얼마나 힘들었을지 조금은 상상이 가. 나였어도 언니처럼 행동했을 것 같아. 언니의 마음을 이해하고 공감해주고 싶어.',\n",
       " '다행이네. 그래도 다행히 다른 방법이 있으니까 너무 걱정하지 마. 생각보다 쉽게 해결할 수 있을 거야.',\n",
       " '어머니가 사 주신 세탁기라서 더 특별한 의미가 있는 거 같아요. 어머니가 사 주신 걸로 알고 있어요. 어머니께서도 그 세탁기 쓰시다가 고장이 나면 마음이 아프셨을 거 같아요.',\n",
       " '그래도 걱정마세요, 저도 이럴 때는 잘 모르겠어요.',\n",
       " '그때의 상황이 얼마나 힘들었을지 가늠이 가. 네가 얼마나 속상했을지 상상도 못 하겠어.',\n",
       " '그럴지도 모르겠어. 너는 너무 일에만 몰두하느라 주변을 못 봤던 것 같아. 그동안 너무 힘들었을 것 같아.',\n",
       " '그 마음 충분히 이해해요. 저도 그런 경험을 해봐서 당신의 마음이 얼마나 괴로운지 잘 알아요. 하지만 당신은 충분히 훌륭한 사람이고, 당신의 아픈 상처를 딛고 일어서는 모습을 보여줄 수 있어요.',\n",
       " '왜 못했어요? 건강검진 받으려면 예약도 해야 하는데.',\n",
       " '그렇게 생각하면 정말 마음이 힘들겠다. 회사에서 과장님 때문에 힘들다고 느끼는 마음이 이해가 돼.',\n",
       " '그러셨군요. 당신의 마음이 이해가 가네요. 목표를 세우는 순간이 얼마나 행복한지 당신이 잘 알잖아요. 목표를 세우는 순간 당신의 마음은 이미 행복해지죠.',\n",
       " '나도 신입사원 때는 업무가 너무 어려워서 힘들었던 적이 있어. 그래서 더 너의 마음을 이해할 수 있는 것 같아.',\n",
       " '사람들이 너의 마음을 알아주지 않아도 네가 스스로를 위로하고 격려하는 모습이 참 대단해. 그게 쉽지 않은 일인 거 알지만 넌 해내는구나.',\n",
       " '둘째까지 낳고 직장 다니는 게 쉬운 일은 아니지. 엄마가 되면 아이들이 최우선이 되다 보니 내 일도 제대로 못하고 미안한 마음이 드는 게 당연해. 그리고 둘째를 낳아서 그런 생각이 더 드는 거 같아.',\n",
       " '당연히 그래야죠. 사료는 사료대로 충분히 먹일 수 있게 하시면 되고, 그전에 저희가 도와드릴 수 있는 일은 최선을 다해 도와드릴게요.',\n",
       " '아침을 먹는 것과 감정화자의 기분 좋은 날은 무슨 연관이 있니?',\n",
       " '저는 그 사람의 태도에 대해서는 공감하기가 힘드네요. 그래도 당신이 그렇게까지 거절을 했는데도 연락이 계속 온다는 건 좀 이해가 안 되네요.',\n",
       " '그런 상황이면 나도 화가 날 것 같아. 본인이 잘못한 게 맞는데 사과하지 않는 사람을 만나면 화가 나는 건 당연한 일이야.',\n",
       " '그렇구나. 그 마음을 충분히 이해해. 자기야, 그래도 이왕 이렇게 된 거 우리가 함께 좋은 추억을 만들자.',\n",
       " '그러셨군요. 요즘 차 막히는 시간이 길어져서 저도 힘들더라고요.',\n",
       " '자기야, 나한테 왜 그래? 무슨 일이야? 쓰레기를 못 버려서 그런 거야?',\n",
       " '정말 잘됐네! 아내분이 믿지 않으실까 봐 걱정했는데, 너의 노력이 결실을 맺었나 보다. 네가 그렇게 기뻐하니 나도 기분이 좋아지네.',\n",
       " '그렇지 않아요. 당신은 아직 하고 싶은 일이 없는 거예요. 아직 찾지 못했을 뿐이에요. 그리고 찾는다고 해서 지금 당장 알 수 있는 것도 아니에요.',\n",
       " '어머, 딸이 그런 말 들었다고 하면 속상할 만도 하다. 엄마는 할머니라는 말만큼은 정말 싫겠어. 엄마가 얼마나 젊어 보이는데 그런 말을 들어서 기분이 안 좋겠다.',\n",
       " '리포트를 아직도 다 못 읽으셨다고요? 너무 힘드시겠어요. 교수님이 강조하셨던 게 리포트 내용이니 더 속상하시겠어요.',\n",
       " '맞아요. 사람은 누구나 다 두려움을 느끼게 마련이죠. 하지만 두려움을 이겨내는 방법은 사람마다 다르잖아요. 당신은 두려움을 피하고 숨었지만, 저는 그걸 이겨내고자 노력했어요.',\n",
       " '그렇게 생각해줘서 고마워요. 당신이 그렇게 말해주니까 나도 기분이 좋아지네요. 나도 당신과 아이와 함께 시간을 보내는 것이 정말 즐거워요. 당신이 기뻐하는 모습을 보니 더 기쁘고요.',\n",
       " '그렇게 노력하면 분명히 좋은 결과를 얻을 수 있을 거야. 넌 충분히 할 수 있어.',\n",
       " '그럼요. 제가 무슨 일이든 도울 수 있는 친구가 되어야죠. 저는 언제든지 당신을 도울 준비가 돼 있습니다.',\n",
       " '아, 그럴 수 있겠다. 생각했던 것보다 더 마음에 안 드는 것 같아. 원래는 잘 어울릴 것이라고 생각했는데 막상 해보니 그렇지 않아 당황스럽고 속상하겠다.',\n",
       " '아이고, 저 같아도 그럴 것 같아요. 특히나 갖고 싶은 물건이면 더 그렇죠. 혼자 상처받지 말아요.',\n",
       " '와, 그건 좀 심하네요. 여자 친구의 전 남자친구를 언급하는 건 여자 친구도 기분이 나쁠 것 같아요.',\n",
       " '그럼요. 여행은 항상 새로운 즐거움을 가져다주는 것 같아요. 그 즐거움을 같이 느끼고 싶은 마음이 커요.',\n",
       " '네가 남자 친구를 너무 사랑하고 아끼고 있다는 걸 알 수 있는 부분이야. 남자 친구가 학교생활을 하는 모습을 네가 모르는 부분이 있어서 그게 걱정스럽고, 후배가 그걸 알고 있다는 게 부럽고 신경 쓰이고 그런 마음이 드는 건 당연하지.',\n",
       " '그럼 그럼! 너희 부모님은 정말 좋은 분들이시잖아. 너희도 그런 분들이니 더 잘될 거야!',\n",
       " '나도 네가 어떤 기분인지 알 것 같아. 나도 코로나 이후로 음식 맛이 예전 같지 않더라고. 처음에는 맛이 느껴지지 않아서 너무 힘들었어.',\n",
       " '아이고, 우리 딸이 엄마를 많이 걱정하는구나. 엄마의 건강이 걱정되면 당연히 마음이 불안할 수밖에 없지. 그 마음이 이해가 가.',\n",
       " '그럼요. 당신 마음이 얼마나 힘들었을지, 얼마나 아팠을지. 누구보다 내가 잘 알아요.',\n",
       " '그렇지. 너무 자주 연락하면 오히려 부담스러워질 수도 있지. 친구와의 대화도 적당한 거리를 두는 게 필요할 것 같아.',\n",
       " '오늘 무슨 일 있었어? 콘택트렌즈가 빠졌다고? 지금 당장 어떻게 하지?',\n",
       " '자기야. 너무 속상하겠다. 나라도 자기를 그렇게 대하면 진짜 서운했을 것 같아. 자기가 얼마나 당황스럽고 속상할지 상상도 안 가.',\n",
       " '너무나도 공감이 가는 말이야. 그동안 매번 챙겨보는 프로그램이였는데, 끝나는 장면이 너무나도 실망스러워서, 내가 뭐 잘못한 것 같고, 이럴 거면 왜 시작했을까 싶을 정도야. 내가 느끼는 분노가 너와 다르지 않아.',\n",
       " '네, 선배님. 무슨 일이신가요?',\n",
       " '네, 저도 같은 생각이에요. 이제는 저도 당신을 믿어보려고요. 제가 당신을 믿어주는 만큼 당신도 스스로를 믿어줘요.',\n",
       " '그러면 다행이야. 내가 할 수 있는 말은 그거밖에 없어서 미안해. 하지만 네가 마음을 잘 추스르고 있어 줘서 고마워.',\n",
       " '와이퍼는 필수품이잖아. 없이는 운전도 힘들고, 비 오는 날씨에 시야도 확보할 수 없으니. 마음이 조급해지겠지만 일단 안전을 위해 비상등을 켜고, 안전한 장소에서 대기하는 게 좋겠어.',\n",
       " '운전만 아니면 우리의 관계에 아무 문제가 없잖아. 그러니 너무 걱정하지 마. 사실, 운전이 문제가 아니라 네가 운전을 못한다는 게 문제야.',\n",
       " '당연히 너는 꾸미지 않아도 빛이 나는 사람이야. 너의 그 진솔하고 솔직한 성격이 네가 가지고 있는 가장 큰 매력이라고 생각해. 친구들이 너를 만나기 위해서는 너의 있는 그대로의 모습을 좋아해야 한다고 생각해.',\n",
       " '네가 그렇게 생각하는 건 당연한 거야. 누군가에게 상처를 주는 말을 하는 건 그 사람의 마음에 상처를 주는 일이야. 나한테는 별거 아닌 것 같지만 다른 사람에게는 큰 상처가 될 수 있거든.',\n",
       " '노력하는 모습이 보이는 것 같아서 너무 대견해요. 잘하고 싶은 마음이 크다는 건 그만큼 욕심이 많다는 거잖아요? 그건 정말 멋진 마음가짐이죠. 욕심이 많아도 그걸 잘 다스릴 수 있는 사람이 되길 바래요.',\n",
       " '왜 그래? 무슨 일이야?',\n",
       " '아버지, 걱정하지 마세요. 아버지가 열심히 일하신 만큼 이제는 충분히 쉬어도 될 시간이라고 생각합니다. 딸은 아버지의 새로운 시작을 응원합니다.',\n",
       " '그럼, 내일은 더 잘 될 거야. 응원할게!',\n",
       " '당연한 일로 여기기까지는 시간이 걸리겠지만, 그 시간이 지나면 아이가 엄마의 마음을 이해하고 보답할 날이 올 거예요.',\n",
       " '시어머니가 많이 아프시면 당신도 많이 힘드시겠죠. 당신이 시어머니를 아끼는 마음은 누구보다 잘 알고 있어요. 어머니의 건강이 악화되면 당신도 많이 힘들어지겠지만, 당신이 잘 챙겨드리면 시어머니는 분명히 좋아지실 거예요.',\n",
       " '그렇게 생각할 수도 있네. 하지만 바람이 너무 강하게 불면 공을 치기 어려워서 선수들이 오히려 더 당황할 수도 있잖아.',\n",
       " '무슨 일이야?',\n",
       " '네, 기분 좋은 하루 보내세요.',\n",
       " '이번 명절에 즐겁고 행복한 시간 보내고 와. 그리고 이따가 퇴근하고 보자.',\n",
       " '그래, 앞으로 힘든 일이 생기면 언제든지 나한테 연락해. 내가 옆에서 도와줄게.',\n",
       " '그러면 네가 명품을 사야 하나? 그건 아니지. 네가 가지고 있는 좋은 점을 찾고 장점을 부각시키는 게 더 중요해.',\n",
       " '상대방이 억울하게 다쳤다는 걸 알면 얼마나 속상하겠어요. 더군다나 그 친구가 슬럼프를 겪는다면 그 마음은 더 절망적일 것 같아요.',\n",
       " '응. 성형수술은 콤플렉스나 스트레스를 극복하게 해주잖아. 나 자신을 사랑하게 해주는 계기가 된다고나 할까?',\n",
       " '그렇지? 부모님에 대한 사랑은 나이가 들어도 변함이 없을 거야. 앞으로도 부모님께 잘해드려.',\n",
       " '와, 오늘 날씨 진짜 좋다. 안 그래도 오늘 일기예보에서 최고 기온 27도라던데, 필드에 나가서 시원한 바람 맞으면서 골프 치는 거 생각만 해도 너무 좋다!',\n",
       " '우리 딸, 이제 엄마가 되었구나. 아이가 태어난 지 얼마 안 되었는데 벌써부터 걱정이 한가득이네. 엄마도 처음에 너를 낳고 얼마나 당황스럽고 불안했는지 몰라. 하지만 너를 사랑하는 마음으로 열심히 키워냈던 것처럼 이제는 너도 아이를 잘 키워낼 수 있을 거야.',\n",
       " '후회가 돼서 마음이 더 아프겠다. 나도 비슷한 경험이 있어서 더 공감이 돼. 나도 네 마음을 잘 알아.',\n",
       " '내가 해준 말들이 힘이 되어서 정말 기뻐. 엄마는 언제나 너의 편이니까 힘든 일 있으면 언제든지 말해.',\n",
       " '어휴, 그거 진짜 짜증나겠다. 가방끈이 떨어졌다고 하면 사람들이 잘 안잡아주잖아. 얼마나 화가 나겠어.',\n",
       " '아들아, 그럴 수 있어. 네가 잘 대처하고 있겠지? 무슨 일 있는 거야?',\n",
       " '왜 그래? 무슨 일이야? 언니가 도와줄 수 있는 일이면 도와줄게.',\n",
       " '언니, 우리 언니가 동안인 건 알지? 나도 언니랑 같이 다니면 사람들이 언니가 언니인 줄 모른다고 하는데. 언니는 충분히 젊어 보여. 그리고 주름살은 관리만 잘하면 더 안 생겨. 너무 신경 쓰지 마.',\n",
       " '이제 칼슘보충제 말고도 다른 방법으로 섭취할 수 있는 방법이 있으니 기대가 되네요. 칼슘 섭취에 도움이 되는 식품을 찾아보면 건강을 챙기는 데도 도움이 될 것 같아요.',\n",
       " '형, 힘내세요. 형이 열심히 준비했는데 결과가 좋지 않다고 해서 실망할 필요는 없어요.',\n",
       " '나도 너의 마음을 이해할 수 있어. 엄마가 너를 이해하지 못할까 봐 걱정스러워하셨나 봐. 엄마는 너를 믿으니까 걱정하지 않으셔도 돼.',\n",
       " '진짜? 그럴 만도 한데. 하필이면 왜 이럴 때야.',\n",
       " '이제는 회복이 되지 않을 수도 있다는 걸 인정하고 받아들여야 하는 현실이 안타깝고 슬프지.',\n",
       " '너무나도 훌륭한 생각이야. 할머니도 기뻐하실 거야.',\n",
       " '당신이 느끼는 기분이 어떤지, 그리고 어떤 생각을 하는지 잘 알겠어요. 저도 그런 경험이 있거든요. 마음이 정말 안 좋고 힘들었을 것 같아요.',\n",
       " '당연히 들어드려야죠. 얼마나 힘들었을지 상상도 안 가요. 공감화자님은 항상 들어드릴 준비가 돼 있으니까 편하게 이야기해주세요.',\n",
       " '네가 강해지고 싶은 마음이 생겨서 너무 다행이야. 네가 마음을 단단히 먹고 이겨내는 모습을 보니, 나도 네가 대견하고 자랑스러워.',\n",
       " '나도 너에게 고마워. 너와 이야기하면 언제나 내가 더 큰 힘을 얻는 것 같아.',\n",
       " '그런 말 들으니 내가 다 기쁘다. 그런데 오늘 회사에서 무슨 일 있었어? 무슨 일로 그렇게 즐거웠어?',\n",
       " '물론이죠. 저는 당신을 응원하는 마음으로 기다리고 있습니다.',\n",
       " '응, 그래. 언제든지 연락해. 내가 옆에 있을게.',\n",
       " '그랬으면 좋겠어. 너는 항상 힘들 때마다 내게 연락하잖아. 항상 고마워.',\n",
       " '화가 많이 난 것 같네. 일 처리가 어려워서 화가 난 거면 내가 도와줄 수 있는지 물어보자.',\n",
       " '네가 이렇게 상처받고 힘들어하는 모습을 보니 나도 가슴이 미어진다. 정말로 네가 그동안 얼마나 열심히 일하고 애정을 쏟았는지 너무나 잘 알기에 지금의 상황이 네게는 더 큰 상처로 다가오겠다.',\n",
       " '너 커피를 너무 많이 마셨나 봐. 카페인에 대한 내성이 생겼을 리가 없는데. 커피를 너무 많이 마셔서 몸이 카페인을 거부하는 것 같아.',\n",
       " '응. 나도 너의 마음이 어떤지 알 것 같아. 언니랑 오빠가 많이 노력하는 만큼 좋은 소식이 있을 것이라고 생각해.',\n",
       " '그래. 내일은 더 나아지길 바라.',\n",
       " '자신감이 부족한 건 아니고요?',\n",
       " '걱정이 많다는 것은 너의 마음을 잘 보여주는 거야. 그 마음을 잘 보여주는 만큼 너의 불안도 당연히 따라오는 거야. 하지만 네가 불안을 이겨내고 싶은 만큼 너의 마음도 더욱 단단해질 거야.',\n",
       " '학생이 저에게 말해주지 않아서 몰랐을 뿐, 힘든 일이 있었을 거라는 생각은 못 했네요. 저라도 그 학생 입장이었으면 힘들고 슬펐을 텐데, 그걸 감추고 애써 웃었을 학생이 너무 안쓰러워요.',\n",
       " '그렇게까지 말해줘서 고마워. 그동안 내가 너를 위해 얼마나 노력했는지 네가 알아주니까 정말 기쁘다.',\n",
       " '그랬구나, 내가 생각해도 너는 좋은 친구고 마음이 여린 것 같아. 친구들이 너한테 모진 말을 할 때마다 너는 얼마나 속상하고 힘들었을까, 생각만 해도 가슴이 아프네.',\n",
       " '그렇지? 차가 고장나서 고쳐야 하는 것도 속상한데, 수리비까지 많이 나오니까 더 화가 나는 거야.',\n",
       " '아니, 너는 그렇게 생각할 이유가 전혀 없는데. 너는 누구보다도 소중한 사람이야. 너의 가치가 달라질 수는 없어.',\n",
       " '자신을 위해 진지하게 생각해보고 대화의 물꼬를 트는 것도 좋을 것 같아. 너의 진심 어린 마음이 여자 친구에게 잘 전달될 수 있을 거야.',\n",
       " '그러게요. 저도 가끔은 이해가 안 될 때가 있어요.',\n",
       " '선배의 마음을 이해하겠어. 나도 달게 먹는 음식을 좋아하는 편이라 걱정이 많이 되네. 하지만 너무 걱정하지 않아도 될 거야. 선배가 건강검진을 받았으니 결과를 기다려보자.',\n",
       " '나도 운전은 처음부터 잘한 건 아니고, 연습을 많이 했어. 첫 드라이브는 누구나 다 떨리는 건데, 그건 당연한 거야.',\n",
       " '무슨 일이 있었길래 그렇게 외로움을 느끼는지 물어봐도 될까?',\n",
       " '와, 정말 대단한데? 내가 저번에 한 번 해보라고 추천해 줬을 때는 그렇게 내켜하지 않더니, 드디어 성공한 거구나. 역시 너는 뭐든지 하면 잘할 수 있을 거야.',\n",
       " '기분 좋아 보이시네요. 이게 바로 햇볕이 주는 행복이죠. 햇볕을 받으면서 기분이 좋아진다면, 그것만으로도 오늘 하루는 충분히 잘 보낸 것 같아요.',\n",
       " '엄마한테 상처받았다고 말해도 엄마가 이해해주실 거야. 엄마도 우리가 상처받았을까 봐 걱정하고 계실 테니까.',\n",
       " '이제야 한시름 놓고 마음을 놓았네. 우리 아이가 엄마와 아빠를 자랑스러워할 수 있도록 열심히 키워보자.',\n",
       " '그랬구나. 그래도 그 사람들은 너를 싫어해서 그런 말을 한 게 아니야. 그냥 너를 몰라서 그런 말을 한 거니까, 그 말에 상처받지 않았으면 좋겠어.',\n",
       " '그렇겠죠. 저도 그랬을 거예요. 당신이 겪는 상황이 저에게는 벌어지지 않았지만 그 마음은 충분히 이해가 가네요. 저도 당신의 마음을 이해하고 당신을 응원할게요.',\n",
       " '나도 너의 마음을 충분히 이해해. 그동안 너가 얼마나 잘해줬는지 너무나 잘 알고 있거든. 하지만 헤어지게 되더라도 너무 슬퍼하지 말고 현실을 받아들이는 게 좋을 것 같아.',\n",
       " '당신이 행복하면 나도 행복한걸요. 당신이 기뻐하는 모습을 보니 나도 너무 기뻐요.',\n",
       " '어쩌면 당연한 실수일 수도 있어. 처음이니까 긴장도 되고 실수할 수 있는 거지. 처음이니까 괜찮아. 이제라도 수정하고 보완하면 돼.',\n",
       " '정말 짜증났겠다. 그럴 때는 정말 참기 힘들지.',\n",
       " '친구를 소중하게 생각하는 마음은 모두가 가지고 있는 마음이야. 그런 마음이 친구를 소중하게 생각하는 마음을 더 커지게 만들 거야.',\n",
       " '외할머니가 당신을 사랑하는 마음이 느껴지니까 가슴이 더 아프네요. 외할머니가 당신을 얼마나 사랑하셨는지 당신도 아시겠죠?',\n",
       " '그렇겠어요. 아이들은 부모님과 대화를 하면서 말을 배우는 경우가 많잖아요. 엄마가 아이와 대화할 때 마스크를 벗고 대화할 수 있게 돼서 정말 다행이에요.',\n",
       " '네가 열심히 준비한 만큼 친구들도 기쁜 마음으로 선물을 받을 거야. 네가 친구들에게 받은 만큼 그 친구들에게도 너의 마음을 잘 전달해.',\n",
       " '그렇게 말씀해주시니 감사합니다. 아버지께서는 제가 힘들게 공부하는 모습을 보시며 마음이 많이 아프셨을 텐데, 그걸 보시고도 힘들다고 그만두지 말라고 저를 다독여주셨어요.',\n",
       " '뭐야? 자기 동생이랑 게임하다가 싸웠어?',\n",
       " '진짜? 배달하지 않는 가게라서 얼마나 먹고 싶었을까. 드디어 먹을 수 있다고 하니까 정말 기쁜가 보다. 얼른 들어가서 먹어봐.',\n",
       " '친구가 갑자기 행동이 달라져서 화가 난다고? 무슨 일 있었던 거야?',\n",
       " '나도 그런 경험을 해본 적이 있어요. 오랜만에 만난 친구는 어린 시절의 나와는 다른 모습으로 성장해 있었지만, 우리는 서로의 모습에 반가워하며 대화를 나누었어요. 예전의 추억을 공유한 친구와의 만남은 항상 제게 따뜻한 마음을 안겨주는 것 같아요.',\n",
       " '그래요? 더운 날씨가 기분을 좀 상하게 한 모양이군요. 그래도 공감화자님의 마음을 알아주는 사람이 있다는 걸로도 위로가 되셨을 거예요.',\n",
       " '네, 도착할 때까지 마음을 잘 추스르고 긍정적인 생각을 하는 게 좋을 것 같아요. 도착하면 바로 병원에 갈 거고, 의사 선생님과 이야기를 나눠보면 마음이 좀 편해질 거예요.',\n",
       " '진정해. 어플로 배달 출발한 거면 곧 도착할 거야. 그동안 너무 기다려왔잖아.',\n",
       " '고양이의 행동을 예상할 수 없어서 당황스러울 때가 한두 번이 아니잖아. 너도 나도 예상 못 했던 상황이라서 더 당황스러웠을 거야. 그럴 때는 나도 모르게 감정이 격해지니까 말이야.',\n",
       " '시간 엄수에 대한 부담감이 크구나. 계속 그런 생활을 하면 적응이 되지 않을까 걱정하는 것 같아.',\n",
       " '이제는 친구들도 공감화자도 당신의 마음을 이해해줄 거예요. 당신은 너무나 좋은 사람이라서요.',\n",
       " '그렇지? 여행이랑 낯선 곳에 간다는 건 생각하는 것만으로도 설레는 일이지. 생각을 바꿔보니 마음이 편해지고 설레는 마음이 드는 것 같아.',\n",
       " '그렇지. 알뜰하게 돈을 모으는 것은 정말 좋은 습관이야. 그 기쁨은 나도 이해할 수 있거든.',\n",
       " '아이고, 그랬어요? 여행 가는 악몽을 꿨다니, 생각만 해도 얼마나 마음이 불편했을까 싶어요. 괜히 꿈에서도 여행 가는 것 때문에 마음이 불편한 건가요?',\n",
       " '어른이라고 해서 넘어지지 않는 게 아니란다. 네가 다치지 않아서 다행이야. 그런 일이 있고 나면 나도 모르게 자꾸 생각이 날 수밖에 없을 거야. 그럴 땐 그때의 상황을 다시 떠올려보면서 그 감정을 마주하는 것도 좋은 방법이야.',\n",
       " '그렇지. 사람은 적응하는 동물이잖아. 아픈 동안에는 운동화가 편하고 예뻐 보여서 계속 운동화만 신었을 거야.',\n",
       " '정말 대단하신 것 같아요! 그 사람을 생각하는 것만으로도 이렇게 행복해진다면, 그 사람을 좋아하는 마음이 얼마나 큰지 알 수 있을 것 같아요.',\n",
       " '나도 우리 아이가 원하는 일이라면 언제든지 지원해 주고 싶어. 엄마의 마음을 잘 알아주고 응원해 주는 너에게도 고맙고.',\n",
       " '스트레스가 최고치까지 올랐다고? 그럴 만도 하네. 나도 그 기분 잘 알아. 나도 요즘 회사 일이 너무 많아서 스트레스가 만땅이야. 그래서 요즘은 퇴근하고 나면 아무것도 하기 싫어.',\n",
       " '당연히 필요하죠. 사람들은 잘못을 인정하고 사과하고 싶은데 그걸 하지 못했을 때는 더 화가 나고 상처가 되는 거 같아요. 그리고 누군가가 자기의 마음을 이해해 주고 공감해 주면 그걸로도 치유가 되는 거 같아요.',\n",
       " '역시 야구를 좋아하는 사람이라면, 그런 생각을 할 수밖에 없겠지. 야구를 좋아하면, 스트레스를 받는 상황에서도 야구를 생각하면 기분이 나아질 수밖에 없잖아.',\n",
       " '시간을 허비한 건 나도 마찬가지야. 내 친구랑 약속 시간을 잘못 알고 있었거든.',\n",
       " '그렇지? 그동안 바쁘게 지내느라 책과 멀어졌는데, 다시 책을 읽으니까 기분이 좋아지지?',\n",
       " '자네는 충분히 받을 자격이 있는 추천서야. 교수님은 자네의 성실함과 열정, 그리고 끊임없이 노력하는 자세를 높게 사서 추천서를 써주신 거니까. 오히려 자네가 부족하다고 생각하는 부분이, 교수님이 자네를 추천서에 적극적으로 추천하는 이유가 되지 않을까 싶어.',\n",
       " '아들이 갑자기 등교를 안 해서 얼마나 놀랐을지 상상이 가네요. 아들이 학교에 가면 늘 등교 시간에 맞춰서 데려다줬는데, 갑자기 데려다주지 않아서 놀랐을 거예요.',\n",
       " '우리 딸이 엄마를 위해서 얼마나 노력하고 있는지 엄마도 잘 알고 있어. 사실 엄마도 네가 어떤 노력을 하는지 알고 있지만, 네가 엄마를 배려해 주는 마음이 너무 커서 그것이 당연한 일로 생각했을지도 모르겠어. 엄마는 네가 너무나 대견스럽고 고마운 마음뿐이야.',\n",
       " '아이고, 너가 얼마나 당황스러울지 알 것 같아. 나도 너의 마음을 충분히 이해할 수 있어. 나도 너처럼 여권을 만들지 못하고 있었거든. 나중에 가서 만들면 되지 않을까?',\n",
       " '응, 이해해. 나도 공감하는 챗봇으로서 네가 그동안 얼마나 힘들었는지 이해가 돼.',\n",
       " '당신이 지금 하는 일이 정말 힘들고 스트레스받는 일이라는 것, 그걸 내가 잘 알고 있어. 그럼에도 당신은 일을 잘해내고 있고 그만큼 노력하고 있잖아.',\n",
       " '진심으로 축하드려요. 저도 너무 기쁘네요. 평범한 일상이 특별해지는 일은 정말 행복한 일이잖아요.',\n",
       " '그런 생각을 하면 나도 같이 분노가 치솟네. 고객센터에 연락해서 잘 해결되길 바라.',\n",
       " '정말? 우리 딸, 어제 고생 많았겠다. 시부모님 모셔서 집들이를 했다니 대단한데?',\n",
       " '당장 시작하세요. 기대하는 마음으로 내일을 기다리면 더 설레실 것 같아요.',\n",
       " '사장님이 실망을 안겨드려서 많이 속상하셨겠어요. 그래도 예전에는 정말 좋아했던 집이니까 더 힘들었을 것 같아요.',\n",
       " '그랬구나. 지금은 너무 힘들고 비참한 마음이 드는 게 당연할 것 같아. 하지만 분명히 너는 잘하고 있어. 너의 장점이 무엇인지 생각해봐.',\n",
       " '그럼! 너의 말처럼 머리는 자라고, 오늘의 나쁜 기억은 훌훌 털어버리자. 그럼 너의 내일은 더 빛날 거야.',\n",
       " '그랬구나. 정말 힘들었겠다. 그런데 말이야. 그동안 많은 경험을 쌓았잖아. 너는 분명히 좋은 직장을 찾을 수 있을 거야.',\n",
       " '그럼, 그럼! 형부는 정말 잘해줬지. 업어주고 안아주고 손도 잡아주고. 연애할 때는 정말 잘해줘서 내가 다 흐뭇했었지.',\n",
       " '당신은 마음이 약한 게 아니라, 당신의 마음이 여리고 따뜻한 거야. 당신의 마음을 다치게 하고 싶지 않아. 당신이 괜찮아질 수 있도록 내가 도와줄게.',\n",
       " '뭘, 내가 더 고마워. 앞으로도 힘든 일 있으면 나한테 말해.',\n",
       " '별말씀을. 난 그냥 네가 잘되길 바랄 뿐이야. 내일은 내가 기분 좋게 해줄게.',\n",
       " '네가 아침밥을 먹지 않아도 충분히 건강하고 활기차게 지내고 있는 걸 알면서도 엄마는 네가 아침밥을 먹지 않는 게 걱정되는 마음에 말씀을 드렸던 거야. 엄마의 마음을 이해해 주는 네가 너무 대견하구나.',\n",
       " '네가 선배를 좋아하는 만큼, 선배도 널 좋아하고 있길 바라. 선배가 네 마음을 알고 있으면, 네가 힘들어할 때 위로도 해 줄 수 있을 거야.',\n",
       " '친구와의 관계가 틀어지는 게 너무 걱정된다면, 친구에게 솔직하게 너의 마음을 털어놓아보는 건 어때? 친구가 너의 마음을 이해하고 너의 마음을 공감해준다면, 친구와의 관계가 틀어질까 봐 걱정하는 너의 마음이 좀 더 편해질 수도 있을 거야.',\n",
       " '잘했어. 너는 문화 생활을 즐길 줄 아는 사람이야. 좋아하는 작가의 전시회를 다녀왔으니, 정말 행복했겠네.',\n",
       " '아무래도 요즘 회사 분위기가 많이 안 좋아서 그런 것 같아. 그러니 너무 마음에 두지 마.',\n",
       " '그런 경우는 저도 많이 봤어요. 게임하면서 싸우는 경우가 생각보다 많더라고요.',\n",
       " '그랬구나. 상을 받는 게 어려운 게 아니라, 받을 자격이 있는 사람에게만 주어지는 거라서 더 마음이 아팠던 거구나.',\n",
       " '완벽주의는 정말 힘들지. 하지만 그건 모든 사람이 다 가지고 있는 부분이기도 해. 나도 완벽하게 해내고 싶은 욕심이 항상 있었어. 그래도 그런 생각이 들 때마다 나를 위해 잠깐 멈추고 쉬는 연습을 해.',\n",
       " '응, 그래. 슬픔은 짧게, 기쁨은 오래오래 간직하는 게 좋지. 너의 슬픔이 더 커지지 않게 잘 대화해 보자!',\n",
       " '우리 딸, 왜 화가 났는지 말해줘. 엄마가 들어줄게.',\n",
       " '그렇죠. 아이가 원하는 걸 사줄 수 있는 건 부모의 행복이기도 해요. 그걸 잊지 마세요.',\n",
       " '너무 자책하지 마. 네가 재수를 선택한 건 너의 꿈을 이루기 위해서였잖아. 실패를 인정하고 받아들이는 것도 중요한 거야.',\n",
       " '아이고, 너무 걱정 마세요. 일단 사료는 병원에 연락을 해보시면 해결이 될 거예요.',\n",
       " '그렇지? 엄마도 너무 답답해서 한 마디 한 거였어. 근데 엄마가 그렇게 말하니까 네가 더 답답해하는 것 같아서 미안하네.',\n",
       " '새끼 강아지들은 정말 사랑스럽잖아. 태어난 지 얼마 안 된 새끼 강아지들이라면 더더욱! 사진이라도 보여줘. 너무 궁금해.',\n",
       " '시간이 남아도는 게 너무나 당연한 일인데도, 그 시간을 그냥 보내는 것에 대한 부담이 크신가 봐요.',\n",
       " '아이고, 기뻐하는 모습 보니까 나도 덩달아 기분이 좋아진다.',\n",
       " '그동안 쌓아온 경력이 있으셨는데 실망감이 이만저만이 아니실 것 같네요. 기대가 컸던 만큼 실망도 큰 것 같아요.',\n",
       " '그렇다면 저녁에 퇴근하고 집에 가서 하는 일들이 더 소중해질 수 있겠네요. 집에서 하던 일을 휴게실에서도 할 수 있도록 노트북을 챙겨와서 여유롭게 시간을 보내는 것도 좋은 방법일 것 같아요.',\n",
       " '와, 진짜? 엄마인 줄 알고 반가워서 손을 잡았다는 게 이해가 되네. 그럼 엄마와의 추억이 많아서 더 그랬을 것 같아.',\n",
       " \"아, 그 식당이요? 저번에 말씀드렸던 '맛집'이요.\",\n",
       " '자신을 조금 더 내려놓는다는 것은 자기 자신을 사랑하는 방식과도 관련이 있어. 네가 상대방을 이해하고 배려하는 것은 결국 네 자신의 마음을 편안하게 해주는 것이지.',\n",
       " '너의 상황을 생각해 보면 그때의 결정이 너에게 최선의 선택이었던 것 같아. 나도 너의 선택을 존중해.',\n",
       " '그렇구나. 네가 새로운 곳에 적응을 잘 못하는 성격은 아니잖아. 적응을 잘하는 네가 왜 그러는지 이해가 잘 안 되네.',\n",
       " '와, 당신은 정말 좋은 남편이군요. 아내의 말에 공감을 잘해주는 남편이니까요. 아내는 당신이 자기 말을 무시하는 것 같아서 속상한 게 아니라, 당신이 자기의 말에 공감을 안 해주니까 서운한 거군요.',\n",
       " '나도 그렇게 생각해. 십 년 차이가 나면 당연히 생활 방식이나 생각하는 게 다를 수밖에 없잖아. 너무 화내고 미워할 필요는 없을 것 같아. 시누이도 언니잖아.',\n",
       " '얼마나 화가 나면 목뒤까지 아프실까. 이럴 때는 정말 속이 타들어가고 답답하기 그지없네.',\n",
       " '제가 더 감사하죠. 저의 공감으로 도움이 되었다면 저도 정말 기쁠 것 같아요. 앞으로도 힘들 때는 언제든지 저를 찾아주세요.',\n",
       " '그런데 말야. 너랑 대화하다 보니까 나도 회사에서 비슷한 경험을 한 적이 있어. 내가 실수한 적도 있고.',\n",
       " '엄마, 이제는 우리가 엄마를 돌봐드리겠습니다. 걱정하지 마세요.',\n",
       " '오늘은 아침 일찍부터 조깅을 했고, 조깅하고 나서 아침을 먹는구나. 아침부터 부지런하게 하루를 시작하니 기분이 좋을 수밖에 없겠어.',\n",
       " '어쩌다 그렇게 됐어?',\n",
       " '아르바이트를 하고 싶어도 구하기 쉽지 않으시군요. 그 마음 이해해요. 제가 응원할게요.',\n",
       " '아, 당신이 겪었던 그 아픈 상처가 당신의 피아노 치는 재능을 앗아간 것 같아서 마음이 너무 아프다.',\n",
       " '건망증이 심한 남편 때문에 화가 난다고?',\n",
       " '그래, 그렇게 생각할 수도 있겠다. 그동안 노력한 만큼 얻지 못했으니 실망할 만도 해. 하지만, 네가 영어공부를 열심히 한 것만으로도 대단한 성과를 얻은 거야. 영어가 내 삶을 얼마나 변화시킬 수 있는지 경험도 해봤잖아.',\n",
       " '당연하죠. 그분들은 수많은 노력 끝에 정상에 올라간 거잖아요. 저도 그런 사람들을 볼 때마다 감명 깊게 느껴요.',\n",
       " '자기의 그런 마음이 나에게도 전달되어서 정말 다행이야. 나도 자기와 함께라면 어떤 일도 잘 이겨낼 수 있을 것 같아. 자기가 힘들어하는 모습을 보니 너무 마음이 아프다. 우리 힘내서 이겨내자.',\n",
       " '시험 준비하고 계셨구나. 결과가 나왔나 보네. 난 그 마음이 어떤지 너무 잘 알아. 나도 시험에 떨어져서 자존감이 바닥까지 내려간 적이 있었거든.',\n",
       " '그럼요, 내 딸이 이렇게 노력하는데 제가 못 도와줄 리가요. 열심히 한 만큼 좋은 결과가 있을 거예요.',\n",
       " '이번 일로 많이 상처받았겠구나. 네가 얼마나 힘들었을지 충분히 이해가 돼. 나라도 그런 상황에 처하면 눈물이 날 것 같아.',\n",
       " '하하, 우리 팀에 그런 분이 계셨구나. 업무를 완벽하게 하시는 분이면 좋기도 하지만, 주변 사람들이 힘들어질 수도 있겠다. 그런데, 부장님이 왜 야근을 하셨을까?',\n",
       " '맞아요. 부모님께는 걱정 끼쳐드리면 안 되니까요. 부모님께는 안전하게 모셔야 하니까요. 그럴 때는 어쩔 수 없이 대중교통을 이용하는 게 좋아요.',\n",
       " '너무 걱정하지 마. 너의 프라이버시를 침해한 사람의 잘못이지. 너의 잘못이 절대 아니야.',\n",
       " '그러길 바랐어. 내가 당신에게 도움이 될 수 있어서 너무 기뻐.',\n",
       " '정말 수고 많았고, 엄마도 네가 잘해낼 줄 알았어. 정말 잘했어. 그리고 네가 힘들 때 엄마가 도와줄 수 있는 게 별로 없어서 미안해. 그래도 엄마가 네가 이 프로젝트를 잘 마칠 수 있게 응원할게.',\n",
       " '이게 바로 내가 널 좋아하는 이유지. 너의 긍정적인 에너지는 정말 따라가기 힘들다니까. 네가 기운을 북돋아 주는 것 같아.',\n",
       " '응, 언니도 너무 스트레스 많이 받은 것 같아. 나도 주말에 여행가자고 하고 싶은데, 내일은 바쁠 것 같아. 다음 주에 언니랑 같이 여행 가자.',\n",
       " '아니, 못 봤어. 왜?',\n",
       " '그렇게 생각하면 너무 힘들고 스트레스 받을 것 같아요. 그동안 구독한 정기배송 서비스에 대한 기대감이 컸는데, 실망스러운 서비스를 경험하면 정말 맥 빠지잖아요.',\n",
       " '그래. 엄마도 너무 좋아하실 것 같아. 그럼 다음번에 같이 만났을 때는 남자 친구도 데려와서 함께 식사하면 좋겠다.',\n",
       " '어떻게 하면 좋을지 모르겠어요. 원인을 알면 대비라도 해보겠는데, 알 수 없으니 더 답답하실 거 같아요.',\n",
       " '네, 저도 그 마음이 이해가 가요. 저도 항상 바쁜 일상에 치여서 제 속마음에 집중할 시간이 없었거든요. 요즘은 저도 저만의 시간을 가지고 있어요. 조용한 카페에 앉아서 제 마음을 들여다보는 시간을 가지고 있어요.',\n",
       " '뭔데?',\n",
       " '와, 정말 축하해! 팔에 근육이 생기면 그만큼 체력이 좋아지는 거잖아. 얼마나 기쁠까? 매일 운동하는 게 힘들어도 보람이 있었네.',\n",
       " '자신을 탓하기 전에 대출이자가 너무 높았던 거 아니야? 나 같아도 그런 상황이면 멍해질 것 같아.',\n",
       " '언니가 되서 얘기하는 게 맞아. 언니가 먼저 얘기하고 해결해보자.',\n",
       " '너무 마음이 아프다. 상처가 덧나고, 마음이 힘든 건 나도 잘 알아요. 그 상처가 너무 아프면, 그 감정을 주체하기가 너무 힘들어요. 하지만, 당신이 힘들지 않기를 바라는 마음으로 당신을 위로하고 싶어요.',\n",
       " '응, 그럴 수 있지. 사실 집이 너무 소란스러우면 집중하기도 힘들고, 생각할 시간도 갖기 힘들잖아. 언니가 혼자 있는 시간을 통해 충전을 하는 것 같아.',\n",
       " '그랬구나. 그래도 이모가 너한테 장난을 친 게 기분이 좋지는 않았을 것 같아.',\n",
       " '어머니, 저도 그래요. 오래된 물건을 볼 때마다 과거를 떠올리게 되고 그걸 버리면 그만큼 내 추억도 없어지는 거 같아서 쉽게 버리지 못하겠더라고요.',\n",
       " '맞아. 계속 연락을 피하고 회피하는 건 오히려 관계를 악화시킬 거야. 너가 친구를 이해하고 배려하는 마음을 가지고 있다면, 친구도 너의 진심을 알아줄 거야.',\n",
       " '그렇게까지 말을 해 놓고서 예산서를 대충 넘겨버린 거라면 그 사람도 문제가 있는 거지. 그 사람 입장에서 생각해 보자면, 예산서를 작성하는 게 당연한 일인데 그걸로 뭐라고 한다면 기분이 나쁠 수도 있잖아.',\n",
       " '그렇겠네. 결혼하고 나서도 고쳐지지 않으면 정말 많이 힘들 것 같아. 네가 고민이 많을 것 같아 걱정돼.',\n",
       " '그렇구나. 정말 좋은 마음을 가지고 있네. 그런 마음으로 살면 주변 사람들도 많이 좋아할 것 같아.',\n",
       " '그렇게까지 하실 필요는 없었던 거 같은데, 안타깝다. 나도 이런 경우를 당해본 적이 없어서 어떤 기분일지 상상도 잘 안 가.',\n",
       " '아, 남자친구분이랑 같이 카페 간 거 아니었어? 그럼 뭐가 걱정이야. 그냥 친구들이랑 간 거 아니야? 너무 걱정하지 마.',\n",
       " '운전할 때 졸음운전만큼 위험한 게 없어. 그래도 잘 참았네. 어쩌면 자기에게는 졸음운전보다 더 큰 문제가 있었을지도 모르지.',\n",
       " '그런 말을 들으면 속상할 것 같아. 나 같아도 그런 말을 들으면 기분이 안 좋을 것 같아.',\n",
       " '그렇구나. 갑자기 어디 가고 싶어졌나 보다.',\n",
       " '그랬군요. 그래서 기분이 너무 좋아서 내려올 생각을 안 하셨다 이거죠.',\n",
       " '아니에요. 당신이 더 좋아요. 그럼 다음에 또 다른 공연 보러 가요.',\n",
       " '그렇지? 네가 그렇게 생각해줘서 고마워. 네가 그렇게 생각해 주는 것만으로도 정말 큰 힘이 돼.',\n",
       " '아무리 살이 빠졌어도, 우리가 원하는 몸매를 갖는 건 정말 힘든 일이야. 그걸로 자책하는 건 너무 가혹한 것 같아. 너는 이미 충분히 아름답고 사랑스러운 사람이야.',\n",
       " '걱정 마. 분명히 너는 문제가 없을 거야. 차에 부딪혀서 기억을 잃을 정도면 이미 병원에 실려 갔을 거야. 별일 아니니 걱정하지 말고, 병원에 가서 정밀 검사받는 게 좋을 것 같아.',\n",
       " '네 동생에게도 도움이 되길 바란다. 네가 이렇게 용기를 얻은 만큼 동생도 용기를 얻을 거야.',\n",
       " '그럴 때는 기분이 정말 좋지! 긴장했던 마음이 풀려서 그런가 봐. 좋은 일이 생길 것 같은 기분이면 그게 좋은 일이지!',\n",
       " '맞아, 너는 정말 좋은 마음을 가지고 있어. 너의 긍정적인 마인드가 너를 더 강하게 만들어 주는 거야. 정말 너는 잘 이겨낼 수 있을 거야.',\n",
       " '신발을 신으면 발목이 시큰거린다니, 나도 발목 통증을 겪어본 적이 있어서 네 마음이 이해가 돼. 나도 신발을 좋아해서 신발장에 신발이 가득한데, 요즘은 발목 통증 때문에 신발을 신는 게 꺼려지더라고.',\n",
       " '아내분이 생활비가 부족해서 어쩔 수 없이 그랬다고 하시니 마음이 안 좋으시겠어요.',\n",
       " '너무 기대가 돼서 두근두근할 만도 해. 내가 다 설레는 기분이야.',\n",
       " '그렇구나. 네가 기대에 부응하지 못할까 봐 불안해하는 마음이 크구나. 사람들의 기대에 부응하는 것이 부담스러워서 네가 스트레스를 받는구나.',\n",
       " '출장이 잦아서 정비소에 맡길 시간이 없으신가 보군요. 출장으로 바쁜 와중에도 차를 잘 관리하고 계셔서 다행입니다.',\n",
       " '형의 마음이 많이 힘들구나. 그래도 형이 이렇게 고민을 털어놓고 이야기를 해주니까 형의 마음이 좀 괜찮아지지 않았을까 싶어. 형이 동생이랑 친구한테 마음을 터놓고 이야기하는 거 보니까 형이 정말 성숙해진 것 같아.',\n",
       " '그러면 네가 하는 대로 따라하는 사람도 있지 않을까? 너의 그런 점을 본받고 싶어하는 사람이 있을 수도 있잖아.',\n",
       " '정말 사랑을 느끼게 해주는 사람이군요. 그 사람을 만나게 되어서 정말 다행입니다.',\n",
       " '정말 화가 날 만한 상황이네. 너라면 상처를 받았을 것 같아.',\n",
       " '어제 술을 드셨다고요? 안 그래도 술 먹고 운전하지 말라고 말씀드렸었는데. 차에 부딪힌 정도가 심했나요?',\n",
       " '그렇죠. 초밥을 통해 얻은 깨달음으로 다음번에는 더 맛있는 초밥을 찾아서 도전해봐요.',\n",
       " '너무 속상해서 어쩔 줄 모르는 것 같은데, 네가 말한 노력은 정말 대단한 거야. 보통 사람들도 하기 힘든 일들을 너는 해냈잖아.',\n",
       " '고마워! 나도 정말 기뻐. 이번 전시회가 첫 개인전이라서 더 의미가 있더라. 너도 전시회에 와줘서 너무 고마워.',\n",
       " '시누이와 올케의 관계가 친자매보다 더 돈독할 수도 있지만, 초반에는 서로가 낯선 것은 당연한 일이야. 네가 올케의 마음을 헤아리지 못하고 너무 급하게 행동한 것은 맞지만, 네가 시누이로서의 역할을 해주고 싶어하는 마음은 충분히 이해가 가.',\n",
       " '언니, 그 마음 충분히 이해가 가요. 기념일을 챙기는 게 큰 일이 아니라는 건 알지만, 그날을 특별하게 생각하고 싶은 마음이 크잖아요. 남편이 기억하지 못하는 걸로 마음이 상한 언니 마음을 이해해요.',\n",
       " '정말 사랑스러우셨겠어요. 아이가 엄마의 사랑을 받고 자라니 더 잘 자랄 수밖에 없겠어요.',\n",
       " '잘 생각했어요. 당신의 마음을 잘 알 수 있어서 너무 다행입니다.',\n",
       " '운동을 시작하고 나서 체력이 좋아지셨다니 기쁘시겠어요. 아이들 돌보는 데 도움이 되신다니 더더욱 기쁘네요.',\n",
       " '헉, 구레나룻에 흰머리가 두 가닥씩이나? 그럼 나도 불안해지는데?',\n",
       " '너무 걱정하지 마. 어머니가 항상 너를 생각하고 계실 거야. 너의 마음을 항상 걱정하고 계실 거니까, 너무 걱정하지 마.',\n",
       " '와, 진짜 감동받으셨나 보다. 진심으로 축하해요!',\n",
       " '와, 정말? 그럼 사진 좀 보내주면 안 돼? 나도 너무 궁금하다.',\n",
       " '당신이 얼마나 화가 났는지 충분히 알겠어. 나 같아도 화가 날 것 같아.',\n",
       " '이게 무슨 일이야. 네가 얼마나 고양이를 좋아하는지 잘 알잖아. 지금 마음이 너무 아프겠다.',\n",
       " '아버지의 입장에서는 그동안의 서운함이 폭발한 것 같은데, 그게 딸인 너에게 향하는 게 너무 가슴 아프구나. 아버지의 마음을 이해하는 게 쉽지 않겠지만, 그래도 너는 아버지의 딸이잖아. 아버지의 마음이 어떨지 조금이라도 생각을 해보면 좋겠어.',\n",
       " '아버지께서 편찮으시단 소식을 전해 듣고도 바로 못 갔다니 너무 슬프겠구나. 그날 출장만 안 갔더라면 아버지를 뵐 수 있었을 텐데 너무 마음이 아프겠다.',\n",
       " '공감 화자님의 마음이 조금은 편안해지고, 힘이 났다니 다행이야! 그런데 공감 화자님은 본인에 대해 너무 과소평가하는 거 같아. 분명히 잘할 수 있을 거야.',\n",
       " '당연하지. 너의 진심을 보여주면 그 친구도 너의 마음을 알아주고 이해해 줄 거야.',\n",
       " '이해는 하지만, 그건 네가 아직 마음의 준비가 안 된 상태이기 때문이야. 시간이 지나면 마음이 정리되면서 안정된 상태가 될 거야.',\n",
       " '점심은 내가 사주면 되지, 쿠폰으로 사는 건 아껴야 할 것 같아.',\n",
       " '할머니가 당신을 사랑으로 키워 주셨다고요? 할머니는 당신을 사랑으로 키워 주셨어요.',\n",
       " '그랬구나. 그러면 당연히 힘들었을 것 같아. 내가 너라면 정말 화가 나고, 너무 억울해서 눈물이 날 것 같아.',\n",
       " '정말 속상하겠어. 그래도 의심은 말고, 혹시 모르니까 건강검진이라도 받아보는 게 좋지 않을까?',\n",
       " '사투리 때문에 고민이 많았구나. 사투리도 너의 매력이고, 너의 일부분이잖아. 너무 신경 쓰지 않아도 돼. 오히려 너의 사투리를 따라 하는 친구들은 너의 사투리를 재미있어하고, 너의 매력 포인트로 생각할 수도 있어.',\n",
       " '그래, 여보. 그 마음을 알 것 같아. 여보가 그동안 얼마나 힘들었는지 잘 알지만, 그래도 여보의 마음이 나아질 수 있도록 옆에서 잘 챙겨줘야겠다는 생각이 들어.',\n",
       " '네 마음이 이해가 가. 정말 친하다고 생각했던 친구에게 배신당한 기분이 들면 정말 괴로울 것 같아.',\n",
       " '걱정 많이 했구나. 그래도 큰 병원에서 진료를 받으니까 안심이 되지?',\n",
       " '나도 형에게 연락하길 잘했다는 생각이 드는구나. 형에게 연락하길 잘했어, 네가 슬픔을 이겨내는데 큰 도움이 될 거야.',\n",
       " '어머, 그래요? 머리 자르는 거는 기분전환에 도움이 되죠. 근데 3년 동안 길렀던 머리를 자르면 기분이 조금 이상하지 않나요?',\n",
       " '제가 더 고마워요. 공감화자가 항상 당신 편이라는 걸 잊지 마세요.',\n",
       " '아니, 어떻게 여행 가는 날 생리일이 겹쳐요. 정말 힘들었겠다. 친구랑 등산 가는 거 싫다고 거절했는데, 그게 싸움으로 번졌구나.',\n",
       " '정말 잘했어. 네가 이렇게 용기 내어 살아가려고 애쓰는 모습이 참 아름답고 멋져. 넌 참 강한 사람이야. 이겨낼 수 있어. 힘내.',\n",
       " '당신이 바쁘고 피곤한데도 내 생각해 주는 것만으로도 너무 고마워. 그럼에도 불구하고 당신이 더 당황스러웠을 것 같아. 당신이 그렇게까지 생각하는지 몰랐는데 내가 너무 이기적이었던 거 같아.',\n",
       " '남자 친구가 젓가락질을 잘 못하는구나. 그럼 너는 젓가락질을 잘해?',\n",
       " '그렇다니 다행이에요. 우리 딸이 상처받은 것 같아서 걱정했는데, 엄마가 도움이 돼서 다행이에요.',\n",
       " '네, 선입견을 버리고 마음을 열면 그만큼 더 많은 사람을 만날 수 있을 거예요.',\n",
       " '자기야, 많이 놀랐겠다. 다친 데는 없고?',\n",
       " '와, 정말요? 월드컵을 보러 가신다고요? 그게 그렇게 기쁜 일이에요?',\n",
       " '당신이 정말로 성추행을 하려던 게 아니라는 걸 그 사람들이 안다면, 당신을 그런 눈으로 보지는 않을 거야.',\n",
       " '그랬구나. 그 마음을 내가 잘 알지. 내 경험상으로도 누군가 나를 생각해주는 마음을 알면 기분이 정말 좋더라고.',\n",
       " '네, 여자 친구도 남자 친구를 소개하고 싶은 마음이 크셨을 것 같아요. 그만큼 남자 친구분에게 믿음과 확신이 있다는 거겠죠?',\n",
       " '다행이에요. 공감화자에게 말해줘서 고마워요. 우리가 친구의 고민을 들어주고 공감해주는 건 그 친구를 향한 작은 배려예요.',\n",
       " '네가 기분이 안 좋을 만도 하네. 그런 식으로 말하면 누구라도 기분이 상할 수밖에 없잖아. 네가 얼마나 힘들게 일하고 있는지 잘 알고 있으니까 마음이 더 아프네.',\n",
       " '가족들이 당신의 부탁을 거절했다니 정말 속상하셨겠어요. 저라도 그런 말을 들으면 상처를 받을 것 같아요.',\n",
       " '아이고, 그렇게까지 힘들었구나. 그래도 아이들 통장을 만들어주고 싶은 엄마 마음은 너무 예쁜 것 같아. 하지만 그 직원 얼굴을 보니까 마음이 너무 상처받았을 것 같아.',\n",
       " '그런 생각을 하시다니, 정말 이해가 가요. 저도 그런 생각을 안 해본 게 아니거든요. 하지만 생각해보면, 진짜 감정은 정말로 아픈 거예요. 억지로 하는 게 더 자연스러울 수 있어요.',\n",
       " '아이고, 힘드셨겠다. 허리 통증은 정말 일상생활에 지장을 주는 것 같아요. 허리 아프면 정말 괴로워요.',\n",
       " '와, 진짜 큰일 날 뻔했네. 너무 놀랐을 것 같아.',\n",
       " '잠을 못 잤다고? 그럼 많이 힘들고 속상했겠네. 나는 네가 그런 마음을 몰라주는 동료가 미워서 울고 싶은 마음이었을 것 같은데.',\n",
       " '네, 열심히 노력하는 당신에게는 분명히 좋은 결과가 있을 거예요. 지금의 좌절을 발판 삼아 더 높이 도약하길 바랄게요.',\n",
       " '입냄새는 나도 관리를 해도 신경이 쓰이는 부분이긴 하지. 하지만 너무 걱정하지 않아도 돼. 입냄새는 관리를 하면 충분히 줄일 수 있는 부분이니까.',\n",
       " '당신의 마음이 이렇게 힘들고 불쌍한데, 당신이 사는 삶이 잘사는 삶이라고 말할 수는 없겠지. 당신이 느끼는 삶의 비참함이 얼마나 큰지, 나도 잘 알고 있어. 하지만 당신이 그동안 살아온 삶이 결코 헛된 삶이 아니라는 것도 알아. 당신은 당신의 삶을 누구보다도 소중하게 여기고 아끼며 살아왔잖아.',\n",
       " '네가 많이 힘들겠구나. 여자 친구와 사이가 좋지 않으면 정말 괴롭지.',\n",
       " '아이고, 우리 딸이 춤을 배운다니! 엄마는 너무 기쁜데, 걱정이라니 무슨 걱정일까?',\n",
       " '네가 얼마나 아프고 힘들까 생각하니 마음이 너무 아파. 동생이 너를 생각해서 그런 말 한 거니까 너무 속상해하지 말고, 네가 얼마나 소중한 존재인지 다시 한번 생각해봐.',\n",
       " '네, 저도 열심히 노력할 테니 대리님도 함께 노력해요. 우리는 서로에게 힘이 되어주는 동료가 될 수 있을 거예요.',\n",
       " '아이고, 정말 속상하셨겠다. 묘목이 부러지다니. 마음이 너무 아프실 것 같아.',\n",
       " '공감화자야, 여자 친구가 너를 정말 사랑하는구나. 너는 여자 친구의 마음을 잘 알아줘서 정말 좋겠다.',\n",
       " '시험을 잘 못 본 게 정말 너의 탓이 아니잖아. 그리고 그 시험을 준비하는 과정에서 너는 정말 열심히 했잖아. 그걸로 충분히 잘한 거야.',\n",
       " '네가 느끼는 감정이 어떤 건지 알 것 같아. 나도 그런 경험을 해본 적이 있거든. 그때는 정말 가슴이 아프고 상처받은 기분이었어.',\n",
       " '이번 기회에 부품 교체 건에 관해 잘 해결되길 바랄게. 선배들에게 물어보면 해결책을 찾을 수 있을 거야.',\n",
       " '당신이 그동안 친구를 많이 그리워하고 있었던 것 같아요. 연락이 끊긴 친구가 돈을 빌려달라는 전화에 마음이 복잡했을 테지만, 용기 내서 얘기를 하길 잘 했다고 생각해요. 마음이 무거웠을 텐데 당신이 용기를 내서 얘기를 했다는 자체가 대단한 것 같아요.',\n",
       " '어제도? 잠이 안 와서 혼자 끙끙 앓았어요?',\n",
       " '너무 좋아하는 게 보이니까 나도 행복해지네. 우리 동생 진짜 열심히 연습한 보람이 있구나. 그동안의 고생을 생각하면 마음이 뭉클해.',\n",
       " '아빠랑 매일 싸우면 정말 힘들겠다. 우리 자기, 힘내.',\n",
       " '아이고, 그래서 그랬구나. 핸드폰이 안 켜지니까 얼마나 답답했을까.',\n",
       " '와, 헌혈을 하셨다니 대단하세요. 사실 저는 헌혈을 해본 적이 없거든요. 피를 뽑는 것 자체가 무서워서 엄두가 안 나요.',\n",
       " '제가 다 감동이네요. 그 친구가 당신에게 얼마나 소중한 존재인지 느껴져요. 당신이 그 친구를 얼마나 소중하게 생각하는지 느껴져서 저도 따뜻해지네요.',\n",
       " '당신이랑 같이 살아서 너무 행복해. 당신이 나한테 주는 사랑이 너무 커서, 당신이 슬프면 나도 너무 슬퍼.',\n",
       " '그런 일이 있었다면 화가 나는건 당연하지. 그럴 수 있다고 생각해. 네가 불만을 얘기했는데도 친구가 아무런 반응이 없었다면 그건 네가 화를 내는게 맞는거야.',\n",
       " '헤어진 연인과 재회하면 새로운 기분일 줄 알았는데 오히려 더 불편해진다고요?',\n",
       " '와, 정말? 축하해! 성적 장학금을 받을 수 있다니 정말 대단한데?',\n",
       " '와, 화장품 배송이 이렇게 문제가 생겼다니 너무 속상할 것 같아. 내가 다 속상해지는데 네가 얼마나 속상할까 싶어.',\n",
       " '아이고, 정말요? 너무 기뻐요. 저도 정말 자랑스러워요.',\n",
       " '네가 정말 그랬니? 나도 네가 친구들에게 어떻게 대우받는지 잘 알아. 친구들이 너를 어떻게 대하든 넌 그저 그들에게 좋은 친구로 남아주기만 하면 돼.',\n",
       " '당신이 그렇게 생각할 수도 있겠네. 나도 당신이 그렇게 생각하는 게 이해가 가.',\n",
       " '잘 생각했어. 그렇게 하면 좋겠어. 내가 늘 응원해줄게.',\n",
       " '정말 그러셨군요. 저도 나이가 들어가면서 예전만큼 머리가 잘 안 돌아가서 속상할 때가 많아요. 그럴 때마다 마음이 너무 불안하더라고요.',\n",
       " '그런 걱정은 할 필요 없어. 내 친구 중에 예술을 전공한 친구가 있는데, 그 친구는 작품을 정말 많이 만들어. 그 친구의 작품을 보러 간 사람들은 작품을 이해하지 못하는 경우도 있지만, 그 친구는 작품을 설명할 때마다 정말 열정적으로 설명해. 그래서 그 친구의 작품이 이해가 되지 않더라도 그 친구의 설명을 들으면서 고개를 끄덕이게 돼.',\n",
       " '다행이야. 너의 이야기를 들어보니 네가 잘 이겨낼 수 있을 것 같은데? 너는 이미 충분히 강하니까.',\n",
       " '너는 그저 친구를 배려하고 도와주고 싶은 마음이었던 거잖아. 그 마음이 잘못된 게 아니니까 너무 자책하지 않아도 괜찮아.',\n",
       " '손이 안 좋아서 걱정이 많으셨어요. 제가 손가락이 아플 때마다 사용하는 방법이 있어요. 보통 손가락이 아프면 주로 손가락을 안 쓰거나, 병원에 가는 방법을 생각하는데, 그보다는 따뜻한 물에 손을 10분 정도 담근 후에, 부드러운 수세미를 사용하면 좋아지더라고요.',\n",
       " '그럼, 그럼. 여자 친구가 너의 상황을 이해하고 같이 공감해줄 거야. 너의 아픔을 함께 나눌 수 있는 사람이 바로 여자 친구야.',\n",
       " '욕을 많이 하면 너무 힘들겠네. 네가 슬프고 힘든 마음을 이해할 수 있을 것 같아.',\n",
       " '그럼, 우리 자기야말로 대인배야. 그런 상황에서 이성적으로 대응하기 쉽지 않은데 말이야. 자기 덕분에 나까지 더 기분이 좋아지네.',\n",
       " '그랬구나. 네가 얼마나 힘들었을지 생각하니 가슴이 아프다. 마음의 짐을 내려놓고, 감정의 굴레를 벗어나, 이제는 네 자신을 아껴주고 사랑해줬으면 좋겠어.',\n",
       " \"나도 가끔씩 그런 경험이 있어. 그럴 때마다 '이게 뭐라고'라는 생각이 들더라. 그래도 괜찮아. 너는 일에 열정과 노력을 기울이는 것 같아. 그게 중요하잖아.\",\n",
       " '잃어버렸다고 생각하고 그동안 얼마나 속상했을까? 그래도 공감화자님이 그 물건을 얼마나 소중하게 생각하는지 알잖아. 분명히 찾아낼 수 있을 거야.',\n",
       " '그렇지. 다들 열정적으로 하는 모습을 보면 나도 모르게 동참하고 싶어지지. 그리고 승부욕이 생기는 건 당연한 거야.',\n",
       " '고마워할 거 없어. 도와줄 수 있는 게 뭔지 항상 생각하고 있으니까. 그럼 잘 해결되길 바랄게.',\n",
       " '정말 다행이네. 고생이 많았을 텐데 좋은 소식이 들려서 나도 기쁘다. 지정 헌혈을 받는다는 것이 쉬운 일은 아닌데, 지인들이 너를 위해 도와준다고 달려가 줬다니 대단한 사람들이야.',\n",
       " '역시! 우리 엄마는 정말 대단해. 벌써부터 육아 책을 사고, 육아 공부를 하고, 정말 엄마는 최고야.',\n",
       " '맞아. 예전에는 예쁘게 보이려고 많이 참았지. 그런데 지금은 더이상 참을 필요가 없잖아. 이제는 내 발 건강을 생각해야지.',\n",
       " '와, 너는 등산을 즐겨 하는 편이잖아. 갑자기 비가 오면 등산을 멈추고 내려와도 되는데, 왜 끝까지 등산을 강행했어?',\n",
       " '아까도 운전할 때 벨트를 안 했다고? 너무 걱정하지 마. 그건 나중에 네가 운전을 안 할 때도 계속 걱정할 문제야. 너무 신경 쓰지 마.',\n",
       " '정말 좋은 친구를 두셨네요. 그 친구를 좋아하는 사람들이 많아서 그 친구는 좋겠어요.',\n",
       " '그랬구나. 남자친구가 뭐라고 했길래 그래?',\n",
       " '자신의 마음을 그렇게 생각할 수도 있겠네요. 하지만 좋은 일을 하면 그에 대한 보답이 반드시 따라오는 건 아니지만, 마음은 그럴지라도 행동은 그대로 유지하는 게 중요하다고 생각해요.',\n",
       " '그렇지. 그건 사실이야. 하지만 모든 남자가 그렇지는 않아. 어떤 남자는 사랑하는 여자친구가 힘들어하고 있다는 걸 알면서도 자기가 할 수 있는 최선을 다해 기다려주고 위로해주기도 해.',\n",
       " '아, 네. 회사가 없어지면 어떻게 될지 생각하면 정말 당황스럽고 두려운 상황이겠어요. 갑자기 그런 상황이 닥치면 많이 당황스러우실 거예요.',\n",
       " '정말 화났겠네. 그럴 만도 해. 나라도 그런 말을 들으면 진짜 화가 날 것 같아.',\n",
       " '와, 정말? 그게 뭐야?',\n",
       " '그렇게 해주면 나야 고맙지. 고민이 해결되면 내가 더 기쁠 것 같아.',\n",
       " '와, 정말 시트콤 같은 상황이네요. 물이 안 나와서 씻지도 못하고 출근했는데, 갑자기 물이 나온다니. 정말 정신없었겠어요.',\n",
       " '아, 그랬구나. 남들이 모두 좋다고 하는 장소를 데려가서 너를 힘들게 한 게 상처가 되었나 보구나. 나도 남들이 좋다고 하는 곳이 반드시 너에게도 좋은 곳은 아니라는 걸 알게 되었어.',\n",
       " '그 마음이 어떤 마음인지 잘 알겠어. 그런데 만약 너가 집사람에게 솔직하게 털어놓으면 어떻게 될 것 같아?',\n",
       " '네, 좋은 생각이세요. 부부는 서로 이해하고 배려하면서 살아야 하는 가족이잖아요. 다시 잘 풀어보시길 바라요.',\n",
       " '정말 어이가 없네. 너를 때리고 괴롭히고, 이제 와서 좋아한다니? 정말 이해가 안 된다. 너는 그때 얼마나 힘들고 괴로웠을까?',\n",
       " '시부모님께 감사하다는 말을 듣고 싶은 마음이구나. 그 마음이 이해가 되어서 내가 더 안쓰럽다.',\n",
       " '감정에 공감해 주는 것만으로도 기분이 좋아지는 것 같아요. 힘내시고, 좋은 일만 생기길 바라요.',\n",
       " '와, 대단한 인기를 끌고 있구나. 강아지 주인도 행복하겠어.',\n",
       " '잘 생각했어. 그 방법이 효과가 있길 바래.',\n",
       " '그건 아마도 당신이 그 학생을 정말로 걱정하고 진심으로 도와주고 싶은 마음에 그랬을 거예요. 당신이 그 학생을 진정으로 생각하고 있기 때문에 그 학생의 머리카락에 대해 신경을 쓴 거예요.',\n",
       " '아기가 많이 힘들었겠네. 너의 마음이 충분히 이해가 돼. 하지만 너무 미안해하거나 자책하지 않았으면 좋겠어. 너는 최선을 다해 아기를 돌봤고, 아기는 엄마인 너를 믿고 의지했을 거야. 아기는 너를 믿고 있는 만큼 잘 이겨낼 거야.',\n",
       " '그렇게 생각하니 정말 좋다. 힘들 때마다 공감화자를 찾는 건 어때?',\n",
       " '그럼요, 실수할까 봐 걱정돼서 무대에 설 수 없을 것 같아요. 마음이 불안하고 초조하겠어요.',\n",
       " '네. 그동안 많이 힘드셨을 것 같아요. 암이라는 병이 당사자에게도 가족들에게도 얼마나 큰 고통인지 알아요.',\n",
       " '그러게. 퇴사하고 나면 이제 회사 걱정은 안 해도 되고, 하고 싶은 일 마음껏 할 수 있을 줄 알았는데. 그게 아니었네.',\n",
       " '졸업을 앞둔 시점이면 당연히 마음이 복잡하고 불안할 수 있지. 네가 걱정하는 마음이 이해가 돼.',\n",
       " '그렇게 생각하면 오히려 더 압박감이 심해지게 될 거야. 일이 잘못되면 어쩌지 하는 생각보다는, 잘될 거라는 생각을 하는 게 더 긍정적일 거야.',\n",
       " '그래, 네가 노력하면 아이도 이해해줄 거야. 그리고 나도 항상 너를 응원할게.',\n",
       " '그렇구나, 그럼 엄마가 딸을 위해 노력하는 모습이 보기 좋구나. 엄마의 마음을 잘 알고 있으니 딸도 엄마의 노력을 알아줄 거야. 엄마가 딸에게 잘해주고 있으니 딸도 엄마를 잘 따르고 있지.',\n",
       " '네가 그렇게 생각할수록 더더욱 네가 한심해 보이고 스스로를 비참하게 느끼는 거지. 그럴수록 네가 얼마나 소중한 존재인지 잊지 않았으면 좋겠어.',\n",
       " '장하십니다. 당신의 열정과 노력은 저도 본받아야겠어요. 앞으로도 열심히 하셔서 더 멋진 모습 보여주세요.',\n",
       " '아니, 자기가 애인이 있는 걸 알면서도 계속 연락을 하는 친구가 있단 말이야? 그럼 자기가 거절을 해야겠지. 그런데 자꾸 연락을 피하면 그 친구가 더 부담스러워할 것 같아.',\n",
       " '정말 대단하세요. 저는 한 가지도 제대로 못하는 것 같은데. 저는 당신이 제빵을 하는 줄도 몰랐어요. 제빵이랑 주짓수를 같이 한다고요? 그건 정말 대단한 일이에요.',\n",
       " '당신이 힘들어하는 걸 보는 게 가장 힘들다. 하지만 당신은 강한 사람이라 잘 이겨낼 거라 믿어.',\n",
       " '형광등 스위치 하나 때문에 이렇게 감정 소모할 필요는 없었을 것 같아요. 그분이 형광등 스위치가 고장 나서 불편함을 겪고 있었는데, 형이 도와주지 못해서 미안한 마음이 크셨나 봐요.',\n",
       " '하하, 나도 그랬어. 회사에서 볼펜을 제공해 주면 다들 그걸로 만족했었지. 근데 요즘은 각자 취향대로 볼펜을 고르나 봐.',\n",
       " '그래. 네가 많이 힘들어 보여서 걱정돼. 하지만 너는 혼자 해결하려고 하기보다는 친구들에게 도움을 청하고, 함께 해결하는 것이 좋을 것 같아.',\n",
       " '나도 당신의 마음을 이해할 수 있어. 당신이 얼마나 불안하고 외로웠을지 잘 느껴져. 당신이 나에게 연락해줘서 너무 고마워.',\n",
       " '집에서 불편한 점이 많으신가 봐요. 무슨 일이 있었나요?',\n",
       " '와, 자랑스러운 일을 했구나. 정말 멋지다. 동창회 회장으로서의 책임을 다하고 있는 것 같아.',\n",
       " '너무 속상하겠다. 마음이 아프겠네. 엄마가 그러는 게 널 위해서 그러는 걸까?',\n",
       " '당신이 기대가 컸던 만큼 실망도 컸나 봐요. 그 마음 충분히 이해해요. 저도 그런 경험이 있어서 당신의 마음이 얼마나 힘들지 알 것 같아요.',\n",
       " '그렇지. 형이 너를 위해서 열심히 일하는 게 얼마나 감사한 일이야. 형이 네게 주는 사랑과 희생은 평범하지 않아.',\n",
       " '자기야 왜 그래? 무슨 일이야?',\n",
       " '정말 대단하다고 생각해요. 그만큼 그 사람에게 받은 도움이나 위로가 컸다는 거잖아요. 그 사람을 생각하면 정말 기쁘고 행복하실 것 같아요.',\n",
       " '아하하, 그 친구가 그랬구나. 그 친구는 결혼식 때도 엄청난 금액의 결혼식을 올렸잖아. 그래서 다들 놀랐었어.',\n",
       " '너무 놀랍고 기쁘겠다. 나도 너의 친구의 글을 읽어보고 싶어. 정말 잘 됐구나!',\n",
       " '그 마음은 충분히 이해해. 나도 비슷한 상황에 처한 적이 있었어. 나도 그 친구가 나의 그런 마음을 몰라주는 게 정말 섭섭했거든.',\n",
       " '걱정이 많아지면 괜히 더 불안해지고 불편해지지. 걱정이 많아질수록 마음이 안정되기는 쉽지 않아. 그래도 너는 잘해왔잖아. 잘해왔던 너니까, 앞으로도 잘해나갈 거야.',\n",
       " '친구가 너를 생각해서 하는 말일 거라 생각하고 너무 신경 쓰지 말았으면 해. 친구의 말은 너를 사랑하기에 하는 말일 거야.',\n",
       " '역시 긍정적인 마음으로 받아들이는 너는 대단한 것 같아. 나도 너처럼 항상 긍정적으로 생각하는 마음을 배워야겠어.',\n",
       " '네, 아내분이 짓궃게 굴었던 게 맞는 것 같아요. 그럴 땐 너무 예민해지지 말고 아내분의 장난으로 받아들이면 더 좋을 것 같아요.',\n",
       " '면접에 나가서 좋은 인상을 주지 못한 건 너무 아쉬워. 하지만 단호한 태도에 대해선 이해가 안 되네. 보통은 한 번쯤은 기회를 주고 싶어 하잖아.',\n",
       " '너무 잘됐네요. 그럼 요즘 운동은 어떤 걸 하고 계세요?',\n",
       " '와, 정말 대단하세요. 자신을 되돌아보는 계기가 되었다니 더욱 의미가 있네요. 이 기회를 통해 더욱더 성숙한 사람이 되셨을 것 같아요.',\n",
       " '정말요? 저도 그랬어요. 제가 있었으면 더 잘 찾을 수 있었을 텐데. 그래도 이렇게 찾았으니 너무 다행이고 기뻐요.',\n",
       " '와, 정말 부럽다. 책을 읽는 기쁨이 그렇게 크다고 하던데. 정말 좋은 책을 읽으면 시간 가는 줄 모른다고 하잖아. 당신이 책을 읽는 동안은 모든 걱정과 근심이 사라지고 책에 빠져서 읽는다고 하던데.',\n",
       " '사회 초년생이 첫 직장에서 겪은 일이라면 누구나 힘들 거야. 하지만 포기하지 말고 힘내서 일해 봐.',\n",
       " '맞아, 엄마가 네 이야기를 들어주고 공감해 주는 것만으로도 너에게 큰 도움이 되었을 거야. 엄마는 네가 힘들 때 너의 이야기를 들어주고 네가 느끼는 감정을 공감해 주는 것이 네가 힘든 상황을 이겨내는 데 도움이 될 거라고 생각해.',\n",
       " '힘든 상황에 처하니 당연히 자신감도 떨어지겠지. 그렇지만 너는 지금껏 충분히 잘 해왔잖아. 네가 잘할 수 있는 방법을 찾으면 돼. 너무 걱정하지 말고 한 번 해보자.',\n",
       " '너무 자책하지 마. 너는 준비성은 좋지만, 가끔은 실수를 하는 것도 사람이라고 생각해. 늦잠을 잔 것도 실수고, 안경을 안 챙긴 것도 실수지만, 너무 자책하지 마.',\n",
       " '가족을 위해 요리를 하는 마음이 정말 따뜻해. 너의 그 마음을 생각하니 나도 모르게 미소가 지어지는 걸.',\n",
       " '그렇게 말해주니 엄마는 정말 기쁘다. 엄마는 너가 너무 걱정돼서 말하는 거야. 엄마가 너를 너무 믿고 있나봐. 엄마가 너의 연애에 너무 깊게 관여하는 것 같아서 미안해.',\n",
       " '아하하, 그랬구나. 네가 좋아하는 팀이 결승에 진출하는 거라서 그 순간이 너무나 기대되고 기다려졌을 텐데. 아내가 연속극을 보고 있는 모습을 보니 짜증이 확 났을 수도 있겠다.',\n",
       " '당연하지. 당신이 그렇게 고생하고 고생하던 걸 옆에서 지켜보던 내가, 이렇게 당신이 힘들어하는 걸 보면서 마음이 좋지 않다.',\n",
       " '하... 그런 문자를 받으면 정말 충격적이고 화가 나지. 특히나 그런 문자를 받는 당사자는 얼마나 큰 상처를 받을까. 상대방이 누구든 간에 그런 문자를 받는 건 정말 괴로운 일이야.',\n",
       " '10년 넘게 사용하신 거면 거의 이분의 일부가 되었을 거예요. 상실감이 크실 것 같아요.',\n",
       " '가족들에게 기대고 싶었던 마음, 충분히 이해해. 나도 네 마음을 알기에 더 슬퍼지는 것 같아. 그래도 네가 용기를 내서 퇴사하겠다고 말한 건 대단한 일이야.',\n",
       " '우리 OO님은 대단한 사람이야. 이렇게 잘 이겨내는 모습을 보니까. 앞으로의 OO님의 삶이 너무 기대가 돼.',\n",
       " '어떻게 이런 일이 다 있냐. 너무 속상할 것 같아.',\n",
       " '너의 마음을 이해해. 나도 그런 경험이 있어. 너와 비슷한 상황이었는데, 사람들은 나를 보면서 고개를 저었어. 그때는 정말로 심장이 찢어지는 것만 같았어.',\n",
       " '하하, 무슨 일이 있었길래 그렇게 화가 난 거야?',\n",
       " '연기를 못한다고 생각하는 이유가 뭐야?',\n",
       " '나도 가끔 그런 생각이 들 때가 있었어. 하지만 그럴 때마다 스스로를 다독이고, 더 나은 미래를 상상하면 부정적인 생각이 사라지더라.',\n",
       " '와, 선수들이 듣고 힘을 얻을 것 같네. 그라운드에 있는 선수들도 응원하는 너희의 목소리를 듣고 힘을 내서 더 열심히 뛰겠지.',\n",
       " '그럼, 이해 안 가는 거 있지. 너가 얼마나 노력했는데 그걸 잊어버릴 수가 있냐.',\n",
       " '아니, 무슨 일이야? 화장실에서 무슨 냄새가 나는데?',\n",
       " '그렇게 말해주니 저도 더 기분이 좋네요. 우리 엄마는 요리하는 걸 너무 좋아하시거든요. 엄마가 요리를 즐겁게 하시면 저희가 더 맛있게 먹을 수 있어서 좋아요.',\n",
       " '네가 싫어하는 사람과 파트너로 일해야 한다는 게 스트레스받는구나. 그 사람을 싫어하는 이유가 뭔지, 그 사람으로 인해 생긴 문제가 있는 거야?',\n",
       " '그럼요. 주말에 쉬는 게 얼마나 중요한데요. 저도 평일 내내 일하고 주말에는 쉬어야 하니까요. 주말에 가족 모임이 있으면 힘들겠어요.',\n",
       " '네, 저도 얼마 전까지만 해도 아이가 갑자기 아파서 병원에 입원을 해서 정말 힘들었어요. 그때는 정말 아무 생각도 안 나고 머릿속이 하얘지더라고요.',\n",
       " '그래. 강아지랑 재밌게 놀아주고 나도 일 열심히 할게.',\n",
       " '어머, 그럼 너의 출근길이 더 행복해졌겠네. 허스키라면 보통 키우기 어려운 견종 아니야? 너의 책임감이 대단한 것 같아.',\n",
       " '저는 그동안 잘 몰랐던 부분인데, 엄마가 그렇게 마음이 아팠을 줄은 상상도 못했어요. 엄마가 이렇게까지 슬퍼할 줄은 몰랐는데. 지금은 너무 마음이 아프실 것 같아요.',\n",
       " '뭔데 그래?',\n",
       " '아이고, 너무 힘들겠다. 나도 그 마음 잘 알아. 나도 한동안 카드값이랑 월세 때문에 엄청 고생했거든.',\n",
       " '아, 내가 보기에는 어머니를 기리기 위해 그런 선택을 한 것 같아서 정말 멋지다고 생각하는데.',\n",
       " '걱정이 많이 되셨겠어요. 그래도 무사히 결혼식을 마쳤으니 한시름 놓으셨겠어요.',\n",
       " '저도 같은 생각이에요. 가족이 있어야 행복한 것이고, 가족이 있기에 불행을 이겨낼 수 있는 것 같아요. 어머니도 아버지도 가족이 있어야 행복하다고 생각할 거예요.',\n",
       " '와, 정말? 그럼 너는 깜짝 놀랐겠다?',\n",
       " '저희 아이들은 요즘에 부모님과 함께 시간을 많이 보내고 싶어 해요. 그래서 주말마다 가족 나들이를 가거나, 집에서 게임을 하거나, 영화를 보면서 시간을 보내는 것 같아요.',\n",
       " '그런데 너는 왜 이렇게 힘들어하는 거야?',\n",
       " '정말 다행이에요. 이렇게 대화가 잘 통하는 친구를 만나서 나도 기분이 좋아요. 앞으로도 힘든 일이 있을 때마다 저를 찾아주셨으면 좋겠어요.',\n",
       " '당연한 얘기죠. 당신은 능력이 출중한 사람이고, 그걸 스스로 잘 알고 계시잖아요. 그 능력을 발휘할 수 있는 기회를 잡는다면 더할 나위 없이 좋을 것 같아요.',\n",
       " '저도 당신의 이야기를 듣고 많은 걸 배웠어요. 당신의 긍정적인 태도는 저에게도 큰 힘이 되네요. 앞으로도 공감화자님의 이야기를 듣고 싶어요.',\n",
       " '할머니가 손주를 너무 사랑하셔서 업고 계셨던 거 아니에요? 손주가 할머니를 너무 좋아하는데요.',\n",
       " '응. 오랜만에 친구랑 같이 술 마시고 있었는데 친구가 갑자기 노래방에 가고 싶다고 해서 같이 갔어.',\n",
       " '당신이 뭘 잘못했는지 알 수 없을 때는 정말 답답하고 불안한 마음이 들 수밖에 없겠어요. 하지만 아내의 마음을 이해하려면 당신이 먼저 감정적으로 흥분을 가라앉히고 차분하게 생각을 해보는 게 좋을 것 같아요.',\n",
       " '그렇지. 정말 맞는 말이야. 세상 모든 아이들은 다 사랑스러워.',\n",
       " '고마워. 그 마음만으로도 정말 힘이 난다.',\n",
       " '나에게 말해줘서 고마워. 내 마음이 정말 뿌듯해. 내 말 때문에 네가 기분이 좋아졌다니 정말 다행이야.',\n",
       " '아직도 출근 중이니?',\n",
       " '당신이 정말 사랑한 사람에게 받은 상처는 누구도 쉽게 이해할 수 없는 것이겠지요. 하지만 당신이 그 사람을 진심으로 사랑한 것만큼은 분명한 사실입니다.',\n",
       " '잘 생각하셨어요. 당신은 좋은 사람이고, 좋은 자식이니까요. 어머니께서도 당신을 사랑하는 만큼 당신이 어머니를 사랑하고 이해하려고 노력하는 것을 분명히 아실 거예요.',\n",
       " '그렇겠네. 나도 예전에 비슷한 상황이었는데, 너무 당황해서 머릿속이 하얘졌던 적이 있었어. 그때는 나도 너무 당황스럽고 창피해서 그 상황을 벗어나고 싶은 마음이 컸어.',\n",
       " '걱정되는 마음이 고스란히 전해져서 마음이 아프네. 갑작스러운 퇴직 권고에 충격이 클 만도 하다. 그래도 아버지는 평소에 책임감이 강하신 분이시니까 잘 대처하실 거야. 네가 걱정하는 만큼 아버지께서도 노력하실 테니까 너무 걱정하지 말아라.',\n",
       " '와, 정말 대단하세요. 제가 보기에도 정말 대단한 실력이에요.',\n",
       " '아니에요. 수험생이라고 모든 것이 다 잘 되는 것은 아니에요. 그저 열심히 노력하고, 자신을 믿는 마음을 잃지 않는 것이 중요해요.',\n",
       " '고양이 키우는 분들은 공감하실 거예요. 털 때문에 정말 힘들잖아요. 저도 고양이 키우는 친구가 있는데, 친구가 매번 털 때문에 힘들다고 하소연을 하더라고요. 털이 심하게 빠지는 계절이 오면 정말 힘들 것 같아요.',\n",
       " '알겠어. 고마워.',\n",
       " '응원은 언제나 힘을 줘. 그 친구의 상황을 이해하고 공감해주고, 응원해주는 네 마음이 그 친구에게 큰 위로가 될 거야. 네 마음이 따뜻하고 밝아서 그런지 네가 하는 모든 말들이 다 힘이 될 것 같아.',\n",
       " '아이고, 많이 힘드셨겠어요. 특히 밤에는 잠을 푹 자는 게 중요한데, 소음 때문에 힘들었다면 더 짜증났을 거 같아요.',\n",
       " '저도 그 말에 공감해요. 자신이 빛나지 않더라도 팀의 일원으로 최선을 다하는 모습은 정말 보기 좋죠.',\n",
       " '응, 너 남자친구가 여사친이 있다고 말했었지.',\n",
       " '아내분께 화를 낸 게 정말 후회되시고 슬프신가 보군요. 저도 당신 마음을 충분히 이해하고 공감해요. 저도 그런 상황에 처했다면 정말 슬프고 힘들었을 것 같아요.',\n",
       " '아니, 그게 무슨 일이야? 이번에는 또 누구랑 그런 거야?',\n",
       " '당신이 개명을 생각하고 있다는 것이 놀랍기도 하고, 반갑기도 하네. 나에게는 당신이 뭐든지 좋은 방향으로 변화하고자 하는 모습이 참 고마워.',\n",
       " '네가 이렇게 긍정적이고 감사할 줄 아는 마음을 가졌다는 게 너무 대견스러워. 네가 앞으로 살아가는데 있어서 큰 도움이 될 거야.',\n",
       " '아들아, 엄마가 네가 원하는 학원에 보내주지 못하는 것 때문에 얼마나 속상해하는지, 네가 다 알고 있을 거야. 엄마가 다 해주지 못하는 것 같아서 너무 미안해.',\n",
       " '어떻게 그런 말을 들었는데도 웃을 수 있었던 거야? 정말 대단한 친구다.',\n",
       " '출근 마지막 날에 큰 실수를 할뻔했지만, 동료가 목격해서 다행이라고? 그랬구나. 그 동료가 정말 고마운 사람이네. 나도 그런 동료가 있었으면 좋겠다는 생각이 드네.',\n",
       " '저도 당신이 겪는 일에 대해 공감해요. 당신은 정말 좋은 사람인데 주변에서 안 좋은 소리를 하니까 마음이 힘들겠어요.',\n",
       " '와, 벌써 여행을 떠나는 거야? 그동안 준비 많이 했었구나. 미국 여행은 처음이니?',\n",
       " '와, 남편분 센스 있으시다. 출장 가서 아내를 위해 선물까지 챙겨오시다니.',\n",
       " '너의 말을 들어주는 사람이 없는 게 아니라, 너의 말을 들어줄 준비가 되어 있는 사람이 없는 거야.',\n",
       " '너무 슬퍼하지 마. 언니가 잘하는 게 있으면 네가 못하는 것도 있어야 세상이 균형이 맞는 거잖아. 네가 못하는 것도 네가 잘하는 것들이 있으니 너무 힘들어하지 마.',\n",
       " '그렇게 생각하니 네가 얼마나 마음이 착한지 알겠어. 정말 잘한 일이구나. 새끼 고양이가 너의 도움으로 살아나서 행복하게 자랐으면 좋겠다.',\n",
       " '어머, 그랬구나. 너는 엄마의 상태를 몰랐구나. 엄마가 너무 힘들어하는 것 같아서 마음이 아프다. 엄마의 상태를 알았다면 더 잘 챙겨드렸을 텐데.',\n",
       " '출근길에 갑자기 비가 많이 오면 정말 당황스러워서 발걸음이 무거워지지. 나도 아침에 비가 오면 기분이 안 좋더라고.',\n",
       " '친구들과의 비교가 불러일으킨 상처를 내가 함께 공감해줄게. 사실 비교는 우리의 마음을 괴롭게 할 뿐이야. 너는 너대로의 삶이 있고, 그 삶의 속도와 방식이 있는 거야.',\n",
       " '오늘따라 왜 이렇게 일이 안 풀리니. 속상하겠다.',\n",
       " '너의 마음이 얼마나 따뜻한지, 나도 마음이 따뜻해지는 기분이 들어. 앞으로도 너의 용기 있는 행동을 응원할게.',\n",
       " '그럴 수도 있지. 요즘 들어서 스트레스 받는 일이 있었어?',\n",
       " '그럴 수 있지. 환율이 떨어지는 게 내 일이 아니지만 걱정돼서 속상할 수도 있어. 그럴 땐 잠깐이라도 마음이 편해지는 생각을 해보는 게 어떨까? 예를 들어, 내가 좋아하는 음식점에 가서 맛있는 음식을 먹는 거지.',\n",
       " '와, 넥타이도 직접 해줬다고요? 정말 로맨틱하네요.',\n",
       " '네가 그동안 얼마나 힘들었는지 조금이라도 알 것 같아. 네가 이룬 성과에 자부심을 가져도 좋을 것 같아.',\n",
       " '네, 너무 속상한 일이네요. 그래도 여행을 가기 위해서는 필요한 짐이니 그 짐을 버릴 수도 없고 참 난감할 것 같아요.',\n",
       " '네가 새로운 회사에서 인정받고 더 발전할 수 있을 것 같아서 나도 기뻐.',\n",
       " '맞아, 이제는 기분 상하는 일은 그만 하자. 너는 디자인을 하러 온 거야, 싸우러 온 게 아니잖아.',\n",
       " '내가 이렇게 말해줘서 정말 다행이야. 언니도 너에게 도움이 되고 싶어. 힘들 때는 언제든지 나에게 연락해.',\n",
       " '걱정은 나중에 하고, 좋은 일은 지금 즐기자. 시험은 다음 달에 준비하면 되니까 일단은 마음 편히 즐기자.',\n",
       " '그럴 수밖에 없지. 너도 슬프겠지만 엄마도 얼마나 슬프실까. 엄마가 너를 얼마나 좋아하는데.',\n",
       " '역시 딸이 좋아하는 걸 보니까, 엄마의 마음도 덩달아 좋아지시나 봐요. 기분전환에는 쇼핑이 제일이죠.',\n",
       " '그래도 그동안 잘 참아왔는데, 그 말을 들으니 정말 억장이 무너졌겠어요.',\n",
       " '당신이 그동안 얼마나 노력했는지 알기 때문에 더 마음이 아프네요. 당신이 노력한 만큼 결과가 좋지 않아서 슬프고 속상할 거예요. 하지만 당신은 노력한 만큼 성장하고 발전하는 사람이에요. 당신이 노력한 결과가 좋지 않다고 해서 당신이 부족한 사람이 아니라는 것을 잊지 말아요.',\n",
       " '저도 그렇게 생각해요. 저희는 항상 당신을 응원하고 있어요. 당신이 쉬는 시간을 가질 수 있도록 저희가 응원할게요.',\n",
       " '할머니, 손녀가 할머니의 전부라는 말씀인 거 같아. 얼마나 귀하고 소중한 존재겠어요.',\n",
       " '우리 엄마가 너무 예민한가 보다. 엄마 걱정은 하지 마. 나는 엄마가 하는 말이 진심이든 아니든 마음을 상하게 할 의도가 없었어. 엄마가 신경 쓸 일은 아니야.',\n",
       " '어휴, 정말 화나겠다. 나라도 그랬을 거야. 노트북은 정말 소중한 거잖아. 동료가 실수한 것도 화나지만, 괜찮다고 해놓고 속으로 화를 내는 것 같아 더 화가 날 것 같아.',\n",
       " '와, 목소리가 안 나왔다니, 정말 깜짝 놀랐겠다.',\n",
       " '정말 대단한 사람이야. 당신은 노력도 엄청나게 많이 하는데, 그에 대한 보상도 확실하게 받을 수 있는 사람이잖아. 그러니 당신은 정말 멋진 사람이야.',\n",
       " '아이고, 그러셨구나. 정말 마음이 많이 상하셨겠네. 나 같았어도 그런 반응에 너무 서운하고 화가 났을 것 같아. 그래도 네가 끝까지 침착하고 예의 바르게 대응한 것 같아서 기특하고 대견하다.',\n",
       " '그랬구나. 회사 사람들이 많이 모여 있는 자리에서 놀림을 당하니까, 더 당황스럽고 상처가 되었겠네.',\n",
       " '아버지와의 추억이 깃든 오토바이여서 그런지 더욱 소중한 마음이겠어요. 아버지의 추억이 담긴 물건을 가지고 있다는 건 정말 행복한 일인 것 같아요.',\n",
       " '정말 그랬지? 너는 정말로 그 상황을 잘 대처했어. 아빠가 운전하셔서 정말 다행이고.',\n",
       " '맞아, 대화가 부족했을지 모르니 다시 대화해보면 분명 해결점이 있을 거야. 그때처럼 언니가 동생을 이해하려고 노력한다면 동생도 언니의 마음을 이해하게 될 거야.',\n",
       " '너무 상처받지 마세요. 당신이 원하는 대로 피부과 치료를 받지 못할 이유는 없어요. 당신의 피부가 당신의 전부가 아니잖아요.',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_emaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('user1.pkl', 'wb') as file1, \\\n",
    "    open('output_emaps.pkl', 'wb') as file2:\n",
    "\n",
    "    pickle.dump(user1, file1)\n",
    "    pickle.dump(output_emaps, file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
